Config file loaded successfully.
Running experiment with 20 worlds and 10 demonstrations per world.
Feature weights for environment: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Feature weights for environment: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Feature weights for environment: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Feature weights for environment: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Feature weights for environment: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Feature weights for environment: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Feature weights for environment: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Feature weights for environment: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Feature weights for environment: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Feature weights for environment: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Feature weights for environment: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Feature weights for environment: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Feature weights for environment: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Feature weights for environment: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Feature weights for environment: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Feature weights for environment: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Feature weights for environment: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Feature weights for environment: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Feature weights for environment: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Feature weights for environment: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Initialized 20 GridWorld environments.
Generated optimal policies for all environments.
Shuffled demonstration order: [16, 12, 9, 19, 18, 6, 5, 10, 15, 21, 11, 17, 1, 14, 22, 13, 2, 23, 4, 24, 7, 8, 0, 3, 20]

Running world 1/20

Running BIRL with demonstration 1/10 in world 1
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.52
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.12821175  0.60143487  0.47471572 -0.47997797 -0.19346611 -0.17011713
  0.31580851]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 1.647489
0.95-VaR bound for 1 demonstrations: 2.082776
0.99-VaR bound for 1 demonstrations: 3.776298
True expected value difference for MAP policy: 1.039092
Evaluating threshold 0.1 with avar bound: [2.082776240387405]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.082776240387405]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.082776240387405]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.082776240387405]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.082776240387405]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.082776240387405]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.082776240387405]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.082776240387405]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.082776240387405]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 1
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.348
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.03343637 -0.12361458  0.75810796 -0.41388773 -0.37369742 -0.31067783
  0.03741975]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 1.366669
0.95-VaR bound for 2 demonstrations: 1.944245
0.99-VaR bound for 2 demonstrations: 11.241266
True expected value difference for MAP policy: 0.688855
Evaluating threshold 0.1 with avar bound: [1.9442451118693176]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.9442451118693176]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.9442451118693176]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.9442451118693176]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.9442451118693176]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.9442451118693176]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.9442451118693176]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.9442451118693176]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.9442451118693176]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 1
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.272
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.16469061  0.16824983  0.87344955 -0.2987524   0.18283682 -0.19283308
  0.14760755]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.989391
0.95-VaR bound for 3 demonstrations: 1.366837
0.99-VaR bound for 3 demonstrations: 4.961558
True expected value difference for MAP policy: 0.688160
Evaluating threshold 0.1 with avar bound: [1.3668371682869407]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3668371682869407]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3668371682869407]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3668371682869407]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3668371682869407]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3668371682869407]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3668371682869407]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3668371682869407]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3668371682869407]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 1
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.24
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.30347919 -0.17607114  0.58443772 -0.11524341 -0.20404173 -0.07254738
  0.68931465]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: -0.001915
0.95-VaR bound for 4 demonstrations: 0.005151
0.99-VaR bound for 4 demonstrations: 0.040600
True expected value difference for MAP policy: -0.009264
Evaluating threshold 0.1 with avar bound: [0.005150857936017428]
Threshold 0.1 SUFFICIENT with avar bound: 0.005150857936017428
Evaluating threshold 0.2 with avar bound: [0.005150857936017428]
Threshold 0.2 SUFFICIENT with avar bound: 0.005150857936017428
Evaluating threshold 0.3 with avar bound: [0.005150857936017428]
Threshold 0.3 SUFFICIENT with avar bound: 0.005150857936017428
Evaluating threshold 0.4 with avar bound: [0.005150857936017428]
Threshold 0.4 SUFFICIENT with avar bound: 0.005150857936017428
Evaluating threshold 0.5 with avar bound: [0.005150857936017428]
Threshold 0.5 SUFFICIENT with avar bound: 0.005150857936017428
Evaluating threshold 0.6 with avar bound: [0.005150857936017428]
Threshold 0.6 SUFFICIENT with avar bound: 0.005150857936017428
Evaluating threshold 0.7 with avar bound: [0.005150857936017428]
Threshold 0.7 SUFFICIENT with avar bound: 0.005150857936017428
Evaluating threshold 0.8 with avar bound: [0.005150857936017428]
Threshold 0.8 SUFFICIENT with avar bound: 0.005150857936017428
Evaluating threshold 0.9 with avar bound: [0.005150857936017428]
Threshold 0.9 SUFFICIENT with avar bound: 0.005150857936017428

Running BIRL with demonstration 5/10 in world 1
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.221
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62203112 -0.11377235  0.32184098 -0.02443832 -0.00980905 -0.02125614
  0.70385101]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.005519
0.95-VaR bound for 5 demonstrations: -0.003828
0.99-VaR bound for 5 demonstrations: 0.004717
True expected value difference for MAP policy: -0.008807
Evaluating threshold 0.1 with avar bound: [-0.003827714777739298]
Threshold 0.1 SUFFICIENT with avar bound: -0.003827714777739298
Evaluating threshold 0.2 with avar bound: [-0.003827714777739298]
Threshold 0.2 SUFFICIENT with avar bound: -0.003827714777739298
Evaluating threshold 0.3 with avar bound: [-0.003827714777739298]
Threshold 0.3 SUFFICIENT with avar bound: -0.003827714777739298
Evaluating threshold 0.4 with avar bound: [-0.003827714777739298]
Threshold 0.4 SUFFICIENT with avar bound: -0.003827714777739298
Evaluating threshold 0.5 with avar bound: [-0.003827714777739298]
Threshold 0.5 SUFFICIENT with avar bound: -0.003827714777739298
Evaluating threshold 0.6 with avar bound: [-0.003827714777739298]
Threshold 0.6 SUFFICIENT with avar bound: -0.003827714777739298
Evaluating threshold 0.7 with avar bound: [-0.003827714777739298]
Threshold 0.7 SUFFICIENT with avar bound: -0.003827714777739298
Evaluating threshold 0.8 with avar bound: [-0.003827714777739298]
Threshold 0.8 SUFFICIENT with avar bound: -0.003827714777739298
Evaluating threshold 0.9 with avar bound: [-0.003827714777739298]
Threshold 0.9 SUFFICIENT with avar bound: -0.003827714777739298

Running BIRL with demonstration 6/10 in world 1
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.194
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.68437532 -0.29235359  0.15141244 -0.27675053  0.12749372  0.10130871
  0.565796  ]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.005783
0.95-VaR bound for 6 demonstrations: -0.003607
0.99-VaR bound for 6 demonstrations: 0.003302
True expected value difference for MAP policy: -0.008482
Evaluating threshold 0.1 with avar bound: [-0.0036074589289889977]
Threshold 0.1 SUFFICIENT with avar bound: -0.0036074589289889977
Evaluating threshold 0.2 with avar bound: [-0.0036074589289889977]
Threshold 0.2 SUFFICIENT with avar bound: -0.0036074589289889977
Evaluating threshold 0.3 with avar bound: [-0.0036074589289889977]
Threshold 0.3 SUFFICIENT with avar bound: -0.0036074589289889977
Evaluating threshold 0.4 with avar bound: [-0.0036074589289889977]
Threshold 0.4 SUFFICIENT with avar bound: -0.0036074589289889977
Evaluating threshold 0.5 with avar bound: [-0.0036074589289889977]
Threshold 0.5 SUFFICIENT with avar bound: -0.0036074589289889977
Evaluating threshold 0.6 with avar bound: [-0.0036074589289889977]
Threshold 0.6 SUFFICIENT with avar bound: -0.0036074589289889977
Evaluating threshold 0.7 with avar bound: [-0.0036074589289889977]
Threshold 0.7 SUFFICIENT with avar bound: -0.0036074589289889977
Evaluating threshold 0.8 with avar bound: [-0.0036074589289889977]
Threshold 0.8 SUFFICIENT with avar bound: -0.0036074589289889977
Evaluating threshold 0.9 with avar bound: [-0.0036074589289889977]
Threshold 0.9 SUFFICIENT with avar bound: -0.0036074589289889977

Running BIRL with demonstration 7/10 in world 1
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.201
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.70859669 -0.18248264  0.16999505 -0.36430136 -0.05804904  0.17117016
  0.51991163]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.007122
0.95-VaR bound for 7 demonstrations: -0.006166
0.99-VaR bound for 7 demonstrations: -0.002375
True expected value difference for MAP policy: -0.008067
Evaluating threshold 0.1 with avar bound: [-0.006166282938264424]
Threshold 0.1 SUFFICIENT with avar bound: -0.006166282938264424
Evaluating threshold 0.2 with avar bound: [-0.006166282938264424]
Threshold 0.2 SUFFICIENT with avar bound: -0.006166282938264424
Evaluating threshold 0.3 with avar bound: [-0.006166282938264424]
Threshold 0.3 SUFFICIENT with avar bound: -0.006166282938264424
Evaluating threshold 0.4 with avar bound: [-0.006166282938264424]
Threshold 0.4 SUFFICIENT with avar bound: -0.006166282938264424
Evaluating threshold 0.5 with avar bound: [-0.006166282938264424]
Threshold 0.5 SUFFICIENT with avar bound: -0.006166282938264424
Evaluating threshold 0.6 with avar bound: [-0.006166282938264424]
Threshold 0.6 SUFFICIENT with avar bound: -0.006166282938264424
Evaluating threshold 0.7 with avar bound: [-0.006166282938264424]
Threshold 0.7 SUFFICIENT with avar bound: -0.006166282938264424
Evaluating threshold 0.8 with avar bound: [-0.006166282938264424]
Threshold 0.8 SUFFICIENT with avar bound: -0.006166282938264424
Evaluating threshold 0.9 with avar bound: [-0.006166282938264424]
Threshold 0.9 SUFFICIENT with avar bound: -0.006166282938264424

Running BIRL with demonstration 8/10 in world 1
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.187
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.30249637 -0.09420479  0.35163708  0.04733146 -0.15188396  0.3611103
  0.78756785]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.005506
0.95-VaR bound for 8 demonstrations: -0.003608
0.99-VaR bound for 8 demonstrations: 0.007269
True expected value difference for MAP policy: -0.009739
Evaluating threshold 0.1 with avar bound: [-0.0036082464166829827]
Threshold 0.1 SUFFICIENT with avar bound: -0.0036082464166829827
Evaluating threshold 0.2 with avar bound: [-0.0036082464166829827]
Threshold 0.2 SUFFICIENT with avar bound: -0.0036082464166829827
Evaluating threshold 0.3 with avar bound: [-0.0036082464166829827]
Threshold 0.3 SUFFICIENT with avar bound: -0.0036082464166829827
Evaluating threshold 0.4 with avar bound: [-0.0036082464166829827]
Threshold 0.4 SUFFICIENT with avar bound: -0.0036082464166829827
Evaluating threshold 0.5 with avar bound: [-0.0036082464166829827]
Threshold 0.5 SUFFICIENT with avar bound: -0.0036082464166829827
Evaluating threshold 0.6 with avar bound: [-0.0036082464166829827]
Threshold 0.6 SUFFICIENT with avar bound: -0.0036082464166829827
Evaluating threshold 0.7 with avar bound: [-0.0036082464166829827]
Threshold 0.7 SUFFICIENT with avar bound: -0.0036082464166829827
Evaluating threshold 0.8 with avar bound: [-0.0036082464166829827]
Threshold 0.8 SUFFICIENT with avar bound: -0.0036082464166829827
Evaluating threshold 0.9 with avar bound: [-0.0036082464166829827]
Threshold 0.9 SUFFICIENT with avar bound: -0.0036082464166829827

Running BIRL with demonstration 9/10 in world 1
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.188
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.57440428 -0.01533131  0.23979538 -0.30556747 -0.20095461  0.31282111
  0.6170183 ]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.004909
0.95-VaR bound for 9 demonstrations: -0.003858
0.99-VaR bound for 9 demonstrations: 0.001707
True expected value difference for MAP policy: -0.008067
Evaluating threshold 0.1 with avar bound: [-0.0038581735749486567]
Threshold 0.1 SUFFICIENT with avar bound: -0.0038581735749486567
Evaluating threshold 0.2 with avar bound: [-0.0038581735749486567]
Threshold 0.2 SUFFICIENT with avar bound: -0.0038581735749486567
Evaluating threshold 0.3 with avar bound: [-0.0038581735749486567]
Threshold 0.3 SUFFICIENT with avar bound: -0.0038581735749486567
Evaluating threshold 0.4 with avar bound: [-0.0038581735749486567]
Threshold 0.4 SUFFICIENT with avar bound: -0.0038581735749486567
Evaluating threshold 0.5 with avar bound: [-0.0038581735749486567]
Threshold 0.5 SUFFICIENT with avar bound: -0.0038581735749486567
Evaluating threshold 0.6 with avar bound: [-0.0038581735749486567]
Threshold 0.6 SUFFICIENT with avar bound: -0.0038581735749486567
Evaluating threshold 0.7 with avar bound: [-0.0038581735749486567]
Threshold 0.7 SUFFICIENT with avar bound: -0.0038581735749486567
Evaluating threshold 0.8 with avar bound: [-0.0038581735749486567]
Threshold 0.8 SUFFICIENT with avar bound: -0.0038581735749486567
Evaluating threshold 0.9 with avar bound: [-0.0038581735749486567]
Threshold 0.9 SUFFICIENT with avar bound: -0.0038581735749486567

Running BIRL with demonstration 10/10 in world 1
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.175
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61536863 -0.36654381  0.14371746 -0.20338113 -0.08150692  0.23539088
  0.60240871]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.007036
0.95-VaR bound for 10 demonstrations: -0.004110
0.99-VaR bound for 10 demonstrations: -0.001222
True expected value difference for MAP policy: -0.009739
Evaluating threshold 0.1 with avar bound: [-0.004110049219524583]
Threshold 0.1 SUFFICIENT with avar bound: -0.004110049219524583
Evaluating threshold 0.2 with avar bound: [-0.004110049219524583]
Threshold 0.2 SUFFICIENT with avar bound: -0.004110049219524583
Evaluating threshold 0.3 with avar bound: [-0.004110049219524583]
Threshold 0.3 SUFFICIENT with avar bound: -0.004110049219524583
Evaluating threshold 0.4 with avar bound: [-0.004110049219524583]
Threshold 0.4 SUFFICIENT with avar bound: -0.004110049219524583
Evaluating threshold 0.5 with avar bound: [-0.004110049219524583]
Threshold 0.5 SUFFICIENT with avar bound: -0.004110049219524583
Evaluating threshold 0.6 with avar bound: [-0.004110049219524583]
Threshold 0.6 SUFFICIENT with avar bound: -0.004110049219524583
Evaluating threshold 0.7 with avar bound: [-0.004110049219524583]
Threshold 0.7 SUFFICIENT with avar bound: -0.004110049219524583
Evaluating threshold 0.8 with avar bound: [-0.004110049219524583]
Threshold 0.8 SUFFICIENT with avar bound: -0.004110049219524583
Evaluating threshold 0.9 with avar bound: [-0.004110049219524583]
Threshold 0.9 SUFFICIENT with avar bound: -0.004110049219524583

Running world 2/20

Running BIRL with demonstration 1/10 in world 2
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.545
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.60035296 -0.01667557 -0.16780047 -0.75064204  0.06076502 -0.20159118
  0.05784793]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 1.647232
0.95-VaR bound for 1 demonstrations: 2.076534
0.99-VaR bound for 1 demonstrations: 3.264967
True expected value difference for MAP policy: 2.148344
Evaluating threshold 0.1 with avar bound: [2.0765340541830315]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.0765340541830315]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.0765340541830315]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.0765340541830315]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.0765340541830315]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.0765340541830315]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.0765340541830315]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.0765340541830315]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.0765340541830315]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 2
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.438
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.35213551 -0.11022421  0.72104223 -0.54604484 -0.08293097 -0.0125115
 -0.19685085]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 1.971718
0.95-VaR bound for 2 demonstrations: 2.381020
0.99-VaR bound for 2 demonstrations: 5.578409
True expected value difference for MAP policy: 1.526657
Evaluating threshold 0.1 with avar bound: [2.381019746092475]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.381019746092475]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.381019746092475]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.381019746092475]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.381019746092475]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.381019746092475]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.381019746092475]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.381019746092475]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.381019746092475]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.345
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.06086038 -0.23712856  0.81897493 -0.19067533 -0.48086788 -0.0405683
 -0.01045615]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 2.026172
0.95-VaR bound for 3 demonstrations: 3.116082
0.99-VaR bound for 3 demonstrations: 27.350294
True expected value difference for MAP policy: 1.613503
Evaluating threshold 0.1 with avar bound: [3.1160821810633683]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.1160821810633683]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.1160821810633683]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.1160821810633683]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.1160821810633683]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.1160821810633683]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.1160821810633683]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.1160821810633683]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.1160821810633683]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.253
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.07875719 -0.32951721  0.22665508 -0.44001184  0.22122822 -0.31226186
  0.70269721]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.018396
0.95-VaR bound for 4 demonstrations: 0.033682
0.99-VaR bound for 4 demonstrations: 0.056239
True expected value difference for MAP policy: 0.000473
Evaluating threshold 0.1 with avar bound: [0.03368175119504575]
Threshold 0.1 SUFFICIENT with avar bound: 0.03368175119504575
Evaluating threshold 0.2 with avar bound: [0.03368175119504575]
Threshold 0.2 SUFFICIENT with avar bound: 0.03368175119504575
Evaluating threshold 0.3 with avar bound: [0.03368175119504575]
Threshold 0.3 SUFFICIENT with avar bound: 0.03368175119504575
Evaluating threshold 0.4 with avar bound: [0.03368175119504575]
Threshold 0.4 SUFFICIENT with avar bound: 0.03368175119504575
Evaluating threshold 0.5 with avar bound: [0.03368175119504575]
Threshold 0.5 SUFFICIENT with avar bound: 0.03368175119504575
Evaluating threshold 0.6 with avar bound: [0.03368175119504575]
Threshold 0.6 SUFFICIENT with avar bound: 0.03368175119504575
Evaluating threshold 0.7 with avar bound: [0.03368175119504575]
Threshold 0.7 SUFFICIENT with avar bound: 0.03368175119504575
Evaluating threshold 0.8 with avar bound: [0.03368175119504575]
Threshold 0.8 SUFFICIENT with avar bound: 0.03368175119504575
Evaluating threshold 0.9 with avar bound: [0.03368175119504575]
Threshold 0.9 SUFFICIENT with avar bound: 0.03368175119504575

Running BIRL with demonstration 5/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.242
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.28488158 -0.73496829 -0.13209146  0.11718348 -0.02642836  0.39016887
  0.4410825 ]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: 0.000768
0.95-VaR bound for 5 demonstrations: 0.004407
0.99-VaR bound for 5 demonstrations: 0.053230
True expected value difference for MAP policy: -0.010083
Evaluating threshold 0.1 with avar bound: [0.004407048077414675]
Threshold 0.1 SUFFICIENT with avar bound: 0.004407048077414675
Evaluating threshold 0.2 with avar bound: [0.004407048077414675]
Threshold 0.2 SUFFICIENT with avar bound: 0.004407048077414675
Evaluating threshold 0.3 with avar bound: [0.004407048077414675]
Threshold 0.3 SUFFICIENT with avar bound: 0.004407048077414675
Evaluating threshold 0.4 with avar bound: [0.004407048077414675]
Threshold 0.4 SUFFICIENT with avar bound: 0.004407048077414675
Evaluating threshold 0.5 with avar bound: [0.004407048077414675]
Threshold 0.5 SUFFICIENT with avar bound: 0.004407048077414675
Evaluating threshold 0.6 with avar bound: [0.004407048077414675]
Threshold 0.6 SUFFICIENT with avar bound: 0.004407048077414675
Evaluating threshold 0.7 with avar bound: [0.004407048077414675]
Threshold 0.7 SUFFICIENT with avar bound: 0.004407048077414675
Evaluating threshold 0.8 with avar bound: [0.004407048077414675]
Threshold 0.8 SUFFICIENT with avar bound: 0.004407048077414675
Evaluating threshold 0.9 with avar bound: [0.004407048077414675]
Threshold 0.9 SUFFICIENT with avar bound: 0.004407048077414675

Running BIRL with demonstration 6/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.21
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.19856872 -0.63179135 -0.2425826   0.02398193 -0.21009279  0.49078009
  0.46581609]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.004656
0.95-VaR bound for 6 demonstrations: -0.001365
0.99-VaR bound for 6 demonstrations: 0.006506
True expected value difference for MAP policy: -0.007115
Evaluating threshold 0.1 with avar bound: [-0.0013646207078717289]
Threshold 0.1 SUFFICIENT with avar bound: -0.0013646207078717289
Evaluating threshold 0.2 with avar bound: [-0.0013646207078717289]
Threshold 0.2 SUFFICIENT with avar bound: -0.0013646207078717289
Evaluating threshold 0.3 with avar bound: [-0.0013646207078717289]
Threshold 0.3 SUFFICIENT with avar bound: -0.0013646207078717289
Evaluating threshold 0.4 with avar bound: [-0.0013646207078717289]
Threshold 0.4 SUFFICIENT with avar bound: -0.0013646207078717289
Evaluating threshold 0.5 with avar bound: [-0.0013646207078717289]
Threshold 0.5 SUFFICIENT with avar bound: -0.0013646207078717289
Evaluating threshold 0.6 with avar bound: [-0.0013646207078717289]
Threshold 0.6 SUFFICIENT with avar bound: -0.0013646207078717289
Evaluating threshold 0.7 with avar bound: [-0.0013646207078717289]
Threshold 0.7 SUFFICIENT with avar bound: -0.0013646207078717289
Evaluating threshold 0.8 with avar bound: [-0.0013646207078717289]
Threshold 0.8 SUFFICIENT with avar bound: -0.0013646207078717289
Evaluating threshold 0.9 with avar bound: [-0.0013646207078717289]
Threshold 0.9 SUFFICIENT with avar bound: -0.0013646207078717289

Running BIRL with demonstration 7/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.10194399 -0.33248563 -0.35077944  0.00969921 -0.29207104  0.61734034
  0.53805748]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: 0.008470
0.95-VaR bound for 7 demonstrations: 0.022672
0.99-VaR bound for 7 demonstrations: 2.842132
True expected value difference for MAP policy: -0.003928
Evaluating threshold 0.1 with avar bound: [0.02267171674688752]
Threshold 0.1 SUFFICIENT with avar bound: 0.02267171674688752
Evaluating threshold 0.2 with avar bound: [0.02267171674688752]
Threshold 0.2 SUFFICIENT with avar bound: 0.02267171674688752
Evaluating threshold 0.3 with avar bound: [0.02267171674688752]
Threshold 0.3 SUFFICIENT with avar bound: 0.02267171674688752
Evaluating threshold 0.4 with avar bound: [0.02267171674688752]
Threshold 0.4 SUFFICIENT with avar bound: 0.02267171674688752
Evaluating threshold 0.5 with avar bound: [0.02267171674688752]
Threshold 0.5 SUFFICIENT with avar bound: 0.02267171674688752
Evaluating threshold 0.6 with avar bound: [0.02267171674688752]
Threshold 0.6 SUFFICIENT with avar bound: 0.02267171674688752
Evaluating threshold 0.7 with avar bound: [0.02267171674688752]
Threshold 0.7 SUFFICIENT with avar bound: 0.02267171674688752
Evaluating threshold 0.8 with avar bound: [0.02267171674688752]
Threshold 0.8 SUFFICIENT with avar bound: 0.02267171674688752
Evaluating threshold 0.9 with avar bound: [0.02267171674688752]
Threshold 0.9 SUFFICIENT with avar bound: 0.02267171674688752

Running BIRL with demonstration 8/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.178
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47531115 -0.2644742  -0.19638809  0.02088545 -0.59950514  0.29385658
  0.46836964]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.004306
0.95-VaR bound for 8 demonstrations: -0.001748
0.99-VaR bound for 8 demonstrations: 0.040786
True expected value difference for MAP policy: -0.008177
Evaluating threshold 0.1 with avar bound: [-0.0017476532828184924]
Threshold 0.1 SUFFICIENT with avar bound: -0.0017476532828184924
Evaluating threshold 0.2 with avar bound: [-0.0017476532828184924]
Threshold 0.2 SUFFICIENT with avar bound: -0.0017476532828184924
Evaluating threshold 0.3 with avar bound: [-0.0017476532828184924]
Threshold 0.3 SUFFICIENT with avar bound: -0.0017476532828184924
Evaluating threshold 0.4 with avar bound: [-0.0017476532828184924]
Threshold 0.4 SUFFICIENT with avar bound: -0.0017476532828184924
Evaluating threshold 0.5 with avar bound: [-0.0017476532828184924]
Threshold 0.5 SUFFICIENT with avar bound: -0.0017476532828184924
Evaluating threshold 0.6 with avar bound: [-0.0017476532828184924]
Threshold 0.6 SUFFICIENT with avar bound: -0.0017476532828184924
Evaluating threshold 0.7 with avar bound: [-0.0017476532828184924]
Threshold 0.7 SUFFICIENT with avar bound: -0.0017476532828184924
Evaluating threshold 0.8 with avar bound: [-0.0017476532828184924]
Threshold 0.8 SUFFICIENT with avar bound: -0.0017476532828184924
Evaluating threshold 0.9 with avar bound: [-0.0017476532828184924]
Threshold 0.9 SUFFICIENT with avar bound: -0.0017476532828184924

Running BIRL with demonstration 9/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.172
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34386134 -0.34033339 -0.31569122 -0.08483023 -0.18783955  0.53409921
  0.58183312]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.007385
0.95-VaR bound for 9 demonstrations: -0.005962
0.99-VaR bound for 9 demonstrations: 0.007255
True expected value difference for MAP policy: -0.008953
Evaluating threshold 0.1 with avar bound: [-0.00596233751022647]
Threshold 0.1 SUFFICIENT with avar bound: -0.00596233751022647
Evaluating threshold 0.2 with avar bound: [-0.00596233751022647]
Threshold 0.2 SUFFICIENT with avar bound: -0.00596233751022647
Evaluating threshold 0.3 with avar bound: [-0.00596233751022647]
Threshold 0.3 SUFFICIENT with avar bound: -0.00596233751022647
Evaluating threshold 0.4 with avar bound: [-0.00596233751022647]
Threshold 0.4 SUFFICIENT with avar bound: -0.00596233751022647
Evaluating threshold 0.5 with avar bound: [-0.00596233751022647]
Threshold 0.5 SUFFICIENT with avar bound: -0.00596233751022647
Evaluating threshold 0.6 with avar bound: [-0.00596233751022647]
Threshold 0.6 SUFFICIENT with avar bound: -0.00596233751022647
Evaluating threshold 0.7 with avar bound: [-0.00596233751022647]
Threshold 0.7 SUFFICIENT with avar bound: -0.00596233751022647
Evaluating threshold 0.8 with avar bound: [-0.00596233751022647]
Threshold 0.8 SUFFICIENT with avar bound: -0.00596233751022647
Evaluating threshold 0.9 with avar bound: [-0.00596233751022647]
Threshold 0.9 SUFFICIENT with avar bound: -0.00596233751022647

Running BIRL with demonstration 10/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.188
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.30992922 -0.32561088 -0.54085537 -0.22209863 -0.26650294  0.25625668
  0.56513521]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.006443
0.95-VaR bound for 10 demonstrations: -0.004242
0.99-VaR bound for 10 demonstrations: 0.012246
True expected value difference for MAP policy: -0.008243
Evaluating threshold 0.1 with avar bound: [-0.00424203595787044]
Threshold 0.1 SUFFICIENT with avar bound: -0.00424203595787044
Evaluating threshold 0.2 with avar bound: [-0.00424203595787044]
Threshold 0.2 SUFFICIENT with avar bound: -0.00424203595787044
Evaluating threshold 0.3 with avar bound: [-0.00424203595787044]
Threshold 0.3 SUFFICIENT with avar bound: -0.00424203595787044
Evaluating threshold 0.4 with avar bound: [-0.00424203595787044]
Threshold 0.4 SUFFICIENT with avar bound: -0.00424203595787044
Evaluating threshold 0.5 with avar bound: [-0.00424203595787044]
Threshold 0.5 SUFFICIENT with avar bound: -0.00424203595787044
Evaluating threshold 0.6 with avar bound: [-0.00424203595787044]
Threshold 0.6 SUFFICIENT with avar bound: -0.00424203595787044
Evaluating threshold 0.7 with avar bound: [-0.00424203595787044]
Threshold 0.7 SUFFICIENT with avar bound: -0.00424203595787044
Evaluating threshold 0.8 with avar bound: [-0.00424203595787044]
Threshold 0.8 SUFFICIENT with avar bound: -0.00424203595787044
Evaluating threshold 0.9 with avar bound: [-0.00424203595787044]
Threshold 0.9 SUFFICIENT with avar bound: -0.00424203595787044

Running world 3/20

Running BIRL with demonstration 1/10 in world 3
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.413
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62816261 -0.38953359  0.60304226 -0.01779511  0.23801721  0.16427118
  0.07785547]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 1.292358
0.95-VaR bound for 1 demonstrations: 1.778245
0.99-VaR bound for 1 demonstrations: 4.463102
True expected value difference for MAP policy: 0.942064
Evaluating threshold 0.1 with avar bound: [1.7782453444011144]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.7782453444011144]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.7782453444011144]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.7782453444011144]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.7782453444011144]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.7782453444011144]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.7782453444011144]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.7782453444011144]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.7782453444011144]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 3
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.218
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.49464999 -0.2271083   0.47146261  0.36622001 -0.25795841 -0.03477045
  0.52876989]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 1.074862
0.95-VaR bound for 2 demonstrations: 1.458665
0.99-VaR bound for 2 demonstrations: 16.564819
True expected value difference for MAP policy: -0.004191
Evaluating threshold 0.1 with avar bound: [1.458664521783587]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.458664521783587]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.458664521783587]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.458664521783587]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.458664521783587]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.458664521783587]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.458664521783587]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.458664521783587]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.458664521783587]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 3
Current demos: [(16, 1), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.223
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.51355369  0.00434344  0.38099561  0.14656393  0.07084614 -0.31155607
  0.68375342]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: -0.000082
0.95-VaR bound for 3 demonstrations: 0.005917
0.99-VaR bound for 3 demonstrations: 0.392074
True expected value difference for MAP policy: -0.004446
Evaluating threshold 0.1 with avar bound: [0.005916866421355295]
Threshold 0.1 SUFFICIENT with avar bound: 0.005916866421355295
Evaluating threshold 0.2 with avar bound: [0.005916866421355295]
Threshold 0.2 SUFFICIENT with avar bound: 0.005916866421355295
Evaluating threshold 0.3 with avar bound: [0.005916866421355295]
Threshold 0.3 SUFFICIENT with avar bound: 0.005916866421355295
Evaluating threshold 0.4 with avar bound: [0.005916866421355295]
Threshold 0.4 SUFFICIENT with avar bound: 0.005916866421355295
Evaluating threshold 0.5 with avar bound: [0.005916866421355295]
Threshold 0.5 SUFFICIENT with avar bound: 0.005916866421355295
Evaluating threshold 0.6 with avar bound: [0.005916866421355295]
Threshold 0.6 SUFFICIENT with avar bound: 0.005916866421355295
Evaluating threshold 0.7 with avar bound: [0.005916866421355295]
Threshold 0.7 SUFFICIENT with avar bound: 0.005916866421355295
Evaluating threshold 0.8 with avar bound: [0.005916866421355295]
Threshold 0.8 SUFFICIENT with avar bound: 0.005916866421355295
Evaluating threshold 0.9 with avar bound: [0.005916866421355295]
Threshold 0.9 SUFFICIENT with avar bound: 0.005916866421355295

Running BIRL with demonstration 4/10 in world 3
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.21
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50145811  0.06055106  0.27616635  0.19673684 -0.00073661 -0.44664637
  0.65605379]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.001858
0.95-VaR bound for 4 demonstrations: 0.003460
0.99-VaR bound for 4 demonstrations: 0.062429
True expected value difference for MAP policy: -0.002859
Evaluating threshold 0.1 with avar bound: [0.0034602968210275366]
Threshold 0.1 SUFFICIENT with avar bound: 0.0034602968210275366
Evaluating threshold 0.2 with avar bound: [0.0034602968210275366]
Threshold 0.2 SUFFICIENT with avar bound: 0.0034602968210275366
Evaluating threshold 0.3 with avar bound: [0.0034602968210275366]
Threshold 0.3 SUFFICIENT with avar bound: 0.0034602968210275366
Evaluating threshold 0.4 with avar bound: [0.0034602968210275366]
Threshold 0.4 SUFFICIENT with avar bound: 0.0034602968210275366
Evaluating threshold 0.5 with avar bound: [0.0034602968210275366]
Threshold 0.5 SUFFICIENT with avar bound: 0.0034602968210275366
Evaluating threshold 0.6 with avar bound: [0.0034602968210275366]
Threshold 0.6 SUFFICIENT with avar bound: 0.0034602968210275366
Evaluating threshold 0.7 with avar bound: [0.0034602968210275366]
Threshold 0.7 SUFFICIENT with avar bound: 0.0034602968210275366
Evaluating threshold 0.8 with avar bound: [0.0034602968210275366]
Threshold 0.8 SUFFICIENT with avar bound: 0.0034602968210275366
Evaluating threshold 0.9 with avar bound: [0.0034602968210275366]
Threshold 0.9 SUFFICIENT with avar bound: 0.0034602968210275366

Running BIRL with demonstration 5/10 in world 3
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.22
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.78909901 -0.00405947 -0.0305401  -0.00325064 -0.08011874 -0.00725586
  0.60818693]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.005309
0.95-VaR bound for 5 demonstrations: -0.001166
0.99-VaR bound for 5 demonstrations: 0.021773
True expected value difference for MAP policy: -0.009607
Evaluating threshold 0.1 with avar bound: [-0.0011662203987430782]
Threshold 0.1 SUFFICIENT with avar bound: -0.0011662203987430782
Evaluating threshold 0.2 with avar bound: [-0.0011662203987430782]
Threshold 0.2 SUFFICIENT with avar bound: -0.0011662203987430782
Evaluating threshold 0.3 with avar bound: [-0.0011662203987430782]
Threshold 0.3 SUFFICIENT with avar bound: -0.0011662203987430782
Evaluating threshold 0.4 with avar bound: [-0.0011662203987430782]
Threshold 0.4 SUFFICIENT with avar bound: -0.0011662203987430782
Evaluating threshold 0.5 with avar bound: [-0.0011662203987430782]
Threshold 0.5 SUFFICIENT with avar bound: -0.0011662203987430782
Evaluating threshold 0.6 with avar bound: [-0.0011662203987430782]
Threshold 0.6 SUFFICIENT with avar bound: -0.0011662203987430782
Evaluating threshold 0.7 with avar bound: [-0.0011662203987430782]
Threshold 0.7 SUFFICIENT with avar bound: -0.0011662203987430782
Evaluating threshold 0.8 with avar bound: [-0.0011662203987430782]
Threshold 0.8 SUFFICIENT with avar bound: -0.0011662203987430782
Evaluating threshold 0.9 with avar bound: [-0.0011662203987430782]
Threshold 0.9 SUFFICIENT with avar bound: -0.0011662203987430782

Running BIRL with demonstration 6/10 in world 3
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.197
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.75380978  0.23745684  0.25303561  0.00900047 -0.02751229 -0.04498145
  0.55542486]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.005813
0.95-VaR bound for 6 demonstrations: -0.003493
0.99-VaR bound for 6 demonstrations: -0.003027
True expected value difference for MAP policy: -0.008970
Evaluating threshold 0.1 with avar bound: [-0.00349290553572944]
Threshold 0.1 SUFFICIENT with avar bound: -0.00349290553572944
Evaluating threshold 0.2 with avar bound: [-0.00349290553572944]
Threshold 0.2 SUFFICIENT with avar bound: -0.00349290553572944
Evaluating threshold 0.3 with avar bound: [-0.00349290553572944]
Threshold 0.3 SUFFICIENT with avar bound: -0.00349290553572944
Evaluating threshold 0.4 with avar bound: [-0.00349290553572944]
Threshold 0.4 SUFFICIENT with avar bound: -0.00349290553572944
Evaluating threshold 0.5 with avar bound: [-0.00349290553572944]
Threshold 0.5 SUFFICIENT with avar bound: -0.00349290553572944
Evaluating threshold 0.6 with avar bound: [-0.00349290553572944]
Threshold 0.6 SUFFICIENT with avar bound: -0.00349290553572944
Evaluating threshold 0.7 with avar bound: [-0.00349290553572944]
Threshold 0.7 SUFFICIENT with avar bound: -0.00349290553572944
Evaluating threshold 0.8 with avar bound: [-0.00349290553572944]
Threshold 0.8 SUFFICIENT with avar bound: -0.00349290553572944
Evaluating threshold 0.9 with avar bound: [-0.00349290553572944]
Threshold 0.9 SUFFICIENT with avar bound: -0.00349290553572944

Running BIRL with demonstration 7/10 in world 3
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.178
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.83920277  0.00924956  0.17785999 -0.09985501  0.13473128  0.17165834
  0.45434442]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.006209
0.95-VaR bound for 7 demonstrations: -0.003642
0.99-VaR bound for 7 demonstrations: -0.000018
True expected value difference for MAP policy: -0.010004
Evaluating threshold 0.1 with avar bound: [-0.0036422806142350256]
Threshold 0.1 SUFFICIENT with avar bound: -0.0036422806142350256
Evaluating threshold 0.2 with avar bound: [-0.0036422806142350256]
Threshold 0.2 SUFFICIENT with avar bound: -0.0036422806142350256
Evaluating threshold 0.3 with avar bound: [-0.0036422806142350256]
Threshold 0.3 SUFFICIENT with avar bound: -0.0036422806142350256
Evaluating threshold 0.4 with avar bound: [-0.0036422806142350256]
Threshold 0.4 SUFFICIENT with avar bound: -0.0036422806142350256
Evaluating threshold 0.5 with avar bound: [-0.0036422806142350256]
Threshold 0.5 SUFFICIENT with avar bound: -0.0036422806142350256
Evaluating threshold 0.6 with avar bound: [-0.0036422806142350256]
Threshold 0.6 SUFFICIENT with avar bound: -0.0036422806142350256
Evaluating threshold 0.7 with avar bound: [-0.0036422806142350256]
Threshold 0.7 SUFFICIENT with avar bound: -0.0036422806142350256
Evaluating threshold 0.8 with avar bound: [-0.0036422806142350256]
Threshold 0.8 SUFFICIENT with avar bound: -0.0036422806142350256
Evaluating threshold 0.9 with avar bound: [-0.0036422806142350256]
Threshold 0.9 SUFFICIENT with avar bound: -0.0036422806142350256

Running BIRL with demonstration 8/10 in world 3
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.186
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.63639459 -0.08951945 -0.01997495 -0.08559686  0.33601991  0.32780948
  0.59907758]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.003429
0.95-VaR bound for 8 demonstrations: 0.001451
0.99-VaR bound for 8 demonstrations: 0.006098
True expected value difference for MAP policy: -0.010004
Evaluating threshold 0.1 with avar bound: [0.0014506940670289759]
Threshold 0.1 SUFFICIENT with avar bound: 0.0014506940670289759
Evaluating threshold 0.2 with avar bound: [0.0014506940670289759]
Threshold 0.2 SUFFICIENT with avar bound: 0.0014506940670289759
Evaluating threshold 0.3 with avar bound: [0.0014506940670289759]
Threshold 0.3 SUFFICIENT with avar bound: 0.0014506940670289759
Evaluating threshold 0.4 with avar bound: [0.0014506940670289759]
Threshold 0.4 SUFFICIENT with avar bound: 0.0014506940670289759
Evaluating threshold 0.5 with avar bound: [0.0014506940670289759]
Threshold 0.5 SUFFICIENT with avar bound: 0.0014506940670289759
Evaluating threshold 0.6 with avar bound: [0.0014506940670289759]
Threshold 0.6 SUFFICIENT with avar bound: 0.0014506940670289759
Evaluating threshold 0.7 with avar bound: [0.0014506940670289759]
Threshold 0.7 SUFFICIENT with avar bound: 0.0014506940670289759
Evaluating threshold 0.8 with avar bound: [0.0014506940670289759]
Threshold 0.8 SUFFICIENT with avar bound: 0.0014506940670289759
Evaluating threshold 0.9 with avar bound: [0.0014506940670289759]
Threshold 0.9 SUFFICIENT with avar bound: 0.0014506940670289759

Running BIRL with demonstration 9/10 in world 3
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.165
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47752876 -0.01603174  0.00267722 -0.08238559  0.38033097  0.42756103
  0.66140354]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.007715
0.95-VaR bound for 9 demonstrations: -0.007267
0.99-VaR bound for 9 demonstrations: -0.006321
True expected value difference for MAP policy: -0.010004
Evaluating threshold 0.1 with avar bound: [-0.0072674613524414235]
Threshold 0.1 SUFFICIENT with avar bound: -0.0072674613524414235
Evaluating threshold 0.2 with avar bound: [-0.0072674613524414235]
Threshold 0.2 SUFFICIENT with avar bound: -0.0072674613524414235
Evaluating threshold 0.3 with avar bound: [-0.0072674613524414235]
Threshold 0.3 SUFFICIENT with avar bound: -0.0072674613524414235
Evaluating threshold 0.4 with avar bound: [-0.0072674613524414235]
Threshold 0.4 SUFFICIENT with avar bound: -0.0072674613524414235
Evaluating threshold 0.5 with avar bound: [-0.0072674613524414235]
Threshold 0.5 SUFFICIENT with avar bound: -0.0072674613524414235
Evaluating threshold 0.6 with avar bound: [-0.0072674613524414235]
Threshold 0.6 SUFFICIENT with avar bound: -0.0072674613524414235
Evaluating threshold 0.7 with avar bound: [-0.0072674613524414235]
Threshold 0.7 SUFFICIENT with avar bound: -0.0072674613524414235
Evaluating threshold 0.8 with avar bound: [-0.0072674613524414235]
Threshold 0.8 SUFFICIENT with avar bound: -0.0072674613524414235
Evaluating threshold 0.9 with avar bound: [-0.0072674613524414235]
Threshold 0.9 SUFFICIENT with avar bound: -0.0072674613524414235

Running BIRL with demonstration 10/10 in world 3
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.178
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.75762824 -0.10227481 -0.11067128 -0.13009434  0.12682403  0.36433801
  0.48738089]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.006561
0.95-VaR bound for 10 demonstrations: -0.005072
0.99-VaR bound for 10 demonstrations: -0.003427
True expected value difference for MAP policy: -0.010004
Evaluating threshold 0.1 with avar bound: [-0.0050715936314264035]
Threshold 0.1 SUFFICIENT with avar bound: -0.0050715936314264035
Evaluating threshold 0.2 with avar bound: [-0.0050715936314264035]
Threshold 0.2 SUFFICIENT with avar bound: -0.0050715936314264035
Evaluating threshold 0.3 with avar bound: [-0.0050715936314264035]
Threshold 0.3 SUFFICIENT with avar bound: -0.0050715936314264035
Evaluating threshold 0.4 with avar bound: [-0.0050715936314264035]
Threshold 0.4 SUFFICIENT with avar bound: -0.0050715936314264035
Evaluating threshold 0.5 with avar bound: [-0.0050715936314264035]
Threshold 0.5 SUFFICIENT with avar bound: -0.0050715936314264035
Evaluating threshold 0.6 with avar bound: [-0.0050715936314264035]
Threshold 0.6 SUFFICIENT with avar bound: -0.0050715936314264035
Evaluating threshold 0.7 with avar bound: [-0.0050715936314264035]
Threshold 0.7 SUFFICIENT with avar bound: -0.0050715936314264035
Evaluating threshold 0.8 with avar bound: [-0.0050715936314264035]
Threshold 0.8 SUFFICIENT with avar bound: -0.0050715936314264035
Evaluating threshold 0.9 with avar bound: [-0.0050715936314264035]
Threshold 0.9 SUFFICIENT with avar bound: -0.0050715936314264035

Running world 4/20

Running BIRL with demonstration 1/10 in world 4
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.367
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.15635523  0.06226088 -0.11189303 -0.60991824 -0.28727962  0.28479233
  0.6507842 ]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.223175
0.95-VaR bound for 1 demonstrations: 3.227447
0.99-VaR bound for 1 demonstrations: 106.714230
True expected value difference for MAP policy: -0.007113
Evaluating threshold 0.1 with avar bound: [3.2274470916336724]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.2274470916336724]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.2274470916336724]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.2274470916336724]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.2274470916336724]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.2274470916336724]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.2274470916336724]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.2274470916336724]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.2274470916336724]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 4
Current demos: [(16, 1), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.222
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61080954 -0.04141806 -0.16963507 -0.3344149   0.08131508  0.29088844
  0.6271831 ]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 2.210365
0.95-VaR bound for 2 demonstrations: 3.770922
0.99-VaR bound for 2 demonstrations: 7.674857
True expected value difference for MAP policy: -0.009930
Evaluating threshold 0.1 with avar bound: [3.7709223588764997]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.7709223588764997]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.7709223588764997]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.7709223588764997]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.7709223588764997]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.7709223588764997]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.7709223588764997]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.7709223588764997]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.7709223588764997]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 4
Current demos: [(16, 1), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.212
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.44884963 -0.35341037  0.1278161  -0.26647614  0.03314085  0.27709254
  0.71302878]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: -0.002793
0.95-VaR bound for 3 demonstrations: -0.000027
0.99-VaR bound for 3 demonstrations: 1.774345
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-2.6721840199494506e-05]
Threshold 0.1 SUFFICIENT with avar bound: -2.6721840199494506e-05
Evaluating threshold 0.2 with avar bound: [-2.6721840199494506e-05]
Threshold 0.2 SUFFICIENT with avar bound: -2.6721840199494506e-05
Evaluating threshold 0.3 with avar bound: [-2.6721840199494506e-05]
Threshold 0.3 SUFFICIENT with avar bound: -2.6721840199494506e-05
Evaluating threshold 0.4 with avar bound: [-2.6721840199494506e-05]
Threshold 0.4 SUFFICIENT with avar bound: -2.6721840199494506e-05
Evaluating threshold 0.5 with avar bound: [-2.6721840199494506e-05]
Threshold 0.5 SUFFICIENT with avar bound: -2.6721840199494506e-05
Evaluating threshold 0.6 with avar bound: [-2.6721840199494506e-05]
Threshold 0.6 SUFFICIENT with avar bound: -2.6721840199494506e-05
Evaluating threshold 0.7 with avar bound: [-2.6721840199494506e-05]
Threshold 0.7 SUFFICIENT with avar bound: -2.6721840199494506e-05
Evaluating threshold 0.8 with avar bound: [-2.6721840199494506e-05]
Threshold 0.8 SUFFICIENT with avar bound: -2.6721840199494506e-05
Evaluating threshold 0.9 with avar bound: [-2.6721840199494506e-05]
Threshold 0.9 SUFFICIENT with avar bound: -2.6721840199494506e-05

Running BIRL with demonstration 4/10 in world 4
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.203
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34127886  0.07404615  0.18944206 -0.29451745 -0.03848514  0.35817806
  0.7909769 ]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: -0.005376
0.95-VaR bound for 4 demonstrations: -0.004538
0.99-VaR bound for 4 demonstrations: -0.002355
True expected value difference for MAP policy: -0.009930
Evaluating threshold 0.1 with avar bound: [-0.004538338424559377]
Threshold 0.1 SUFFICIENT with avar bound: -0.004538338424559377
Evaluating threshold 0.2 with avar bound: [-0.004538338424559377]
Threshold 0.2 SUFFICIENT with avar bound: -0.004538338424559377
Evaluating threshold 0.3 with avar bound: [-0.004538338424559377]
Threshold 0.3 SUFFICIENT with avar bound: -0.004538338424559377
Evaluating threshold 0.4 with avar bound: [-0.004538338424559377]
Threshold 0.4 SUFFICIENT with avar bound: -0.004538338424559377
Evaluating threshold 0.5 with avar bound: [-0.004538338424559377]
Threshold 0.5 SUFFICIENT with avar bound: -0.004538338424559377
Evaluating threshold 0.6 with avar bound: [-0.004538338424559377]
Threshold 0.6 SUFFICIENT with avar bound: -0.004538338424559377
Evaluating threshold 0.7 with avar bound: [-0.004538338424559377]
Threshold 0.7 SUFFICIENT with avar bound: -0.004538338424559377
Evaluating threshold 0.8 with avar bound: [-0.004538338424559377]
Threshold 0.8 SUFFICIENT with avar bound: -0.004538338424559377
Evaluating threshold 0.9 with avar bound: [-0.004538338424559377]
Threshold 0.9 SUFFICIENT with avar bound: -0.004538338424559377

Running BIRL with demonstration 5/10 in world 4
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.214
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.41412486 -0.38121779  0.0207921  -0.35098244 -0.23853207  0.35921684
  0.61124327]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.007222
0.95-VaR bound for 5 demonstrations: -0.006863
0.99-VaR bound for 5 demonstrations: 0.012066
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.006862856257319174]
Threshold 0.1 SUFFICIENT with avar bound: -0.006862856257319174
Evaluating threshold 0.2 with avar bound: [-0.006862856257319174]
Threshold 0.2 SUFFICIENT with avar bound: -0.006862856257319174
Evaluating threshold 0.3 with avar bound: [-0.006862856257319174]
Threshold 0.3 SUFFICIENT with avar bound: -0.006862856257319174
Evaluating threshold 0.4 with avar bound: [-0.006862856257319174]
Threshold 0.4 SUFFICIENT with avar bound: -0.006862856257319174
Evaluating threshold 0.5 with avar bound: [-0.006862856257319174]
Threshold 0.5 SUFFICIENT with avar bound: -0.006862856257319174
Evaluating threshold 0.6 with avar bound: [-0.006862856257319174]
Threshold 0.6 SUFFICIENT with avar bound: -0.006862856257319174
Evaluating threshold 0.7 with avar bound: [-0.006862856257319174]
Threshold 0.7 SUFFICIENT with avar bound: -0.006862856257319174
Evaluating threshold 0.8 with avar bound: [-0.006862856257319174]
Threshold 0.8 SUFFICIENT with avar bound: -0.006862856257319174
Evaluating threshold 0.9 with avar bound: [-0.006862856257319174]
Threshold 0.9 SUFFICIENT with avar bound: -0.006862856257319174

Running BIRL with demonstration 6/10 in world 4
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.209
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.41155056 -0.34199432  0.16183068 -0.09712806  0.16856222  0.37397724
  0.71398235]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.008351
0.95-VaR bound for 6 demonstrations: -0.008015
0.99-VaR bound for 6 demonstrations: -0.007082
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.008015264082128996]
Threshold 0.1 SUFFICIENT with avar bound: -0.008015264082128996
Evaluating threshold 0.2 with avar bound: [-0.008015264082128996]
Threshold 0.2 SUFFICIENT with avar bound: -0.008015264082128996
Evaluating threshold 0.3 with avar bound: [-0.008015264082128996]
Threshold 0.3 SUFFICIENT with avar bound: -0.008015264082128996
Evaluating threshold 0.4 with avar bound: [-0.008015264082128996]
Threshold 0.4 SUFFICIENT with avar bound: -0.008015264082128996
Evaluating threshold 0.5 with avar bound: [-0.008015264082128996]
Threshold 0.5 SUFFICIENT with avar bound: -0.008015264082128996
Evaluating threshold 0.6 with avar bound: [-0.008015264082128996]
Threshold 0.6 SUFFICIENT with avar bound: -0.008015264082128996
Evaluating threshold 0.7 with avar bound: [-0.008015264082128996]
Threshold 0.7 SUFFICIENT with avar bound: -0.008015264082128996
Evaluating threshold 0.8 with avar bound: [-0.008015264082128996]
Threshold 0.8 SUFFICIENT with avar bound: -0.008015264082128996
Evaluating threshold 0.9 with avar bound: [-0.008015264082128996]
Threshold 0.9 SUFFICIENT with avar bound: -0.008015264082128996

Running BIRL with demonstration 7/10 in world 4
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.18
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.23336083 -0.38147531  0.14539259 -0.2258245  -0.38761058  0.28989349
  0.70256915]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.008111
0.95-VaR bound for 7 demonstrations: -0.007208
0.99-VaR bound for 7 demonstrations: -0.003402
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.007207901523980506]
Threshold 0.1 SUFFICIENT with avar bound: -0.007207901523980506
Evaluating threshold 0.2 with avar bound: [-0.007207901523980506]
Threshold 0.2 SUFFICIENT with avar bound: -0.007207901523980506
Evaluating threshold 0.3 with avar bound: [-0.007207901523980506]
Threshold 0.3 SUFFICIENT with avar bound: -0.007207901523980506
Evaluating threshold 0.4 with avar bound: [-0.007207901523980506]
Threshold 0.4 SUFFICIENT with avar bound: -0.007207901523980506
Evaluating threshold 0.5 with avar bound: [-0.007207901523980506]
Threshold 0.5 SUFFICIENT with avar bound: -0.007207901523980506
Evaluating threshold 0.6 with avar bound: [-0.007207901523980506]
Threshold 0.6 SUFFICIENT with avar bound: -0.007207901523980506
Evaluating threshold 0.7 with avar bound: [-0.007207901523980506]
Threshold 0.7 SUFFICIENT with avar bound: -0.007207901523980506
Evaluating threshold 0.8 with avar bound: [-0.007207901523980506]
Threshold 0.8 SUFFICIENT with avar bound: -0.007207901523980506
Evaluating threshold 0.9 with avar bound: [-0.007207901523980506]
Threshold 0.9 SUFFICIENT with avar bound: -0.007207901523980506

Running BIRL with demonstration 8/10 in world 4
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.211
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.37881148 -0.3535057   0.13150516 -0.2008112   0.09423769  0.35809594
  0.73266868]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.007318
0.95-VaR bound for 8 demonstrations: -0.005010
0.99-VaR bound for 8 demonstrations: 0.139565
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.005010053094811788]
Threshold 0.1 SUFFICIENT with avar bound: -0.005010053094811788
Evaluating threshold 0.2 with avar bound: [-0.005010053094811788]
Threshold 0.2 SUFFICIENT with avar bound: -0.005010053094811788
Evaluating threshold 0.3 with avar bound: [-0.005010053094811788]
Threshold 0.3 SUFFICIENT with avar bound: -0.005010053094811788
Evaluating threshold 0.4 with avar bound: [-0.005010053094811788]
Threshold 0.4 SUFFICIENT with avar bound: -0.005010053094811788
Evaluating threshold 0.5 with avar bound: [-0.005010053094811788]
Threshold 0.5 SUFFICIENT with avar bound: -0.005010053094811788
Evaluating threshold 0.6 with avar bound: [-0.005010053094811788]
Threshold 0.6 SUFFICIENT with avar bound: -0.005010053094811788
Evaluating threshold 0.7 with avar bound: [-0.005010053094811788]
Threshold 0.7 SUFFICIENT with avar bound: -0.005010053094811788
Evaluating threshold 0.8 with avar bound: [-0.005010053094811788]
Threshold 0.8 SUFFICIENT with avar bound: -0.005010053094811788
Evaluating threshold 0.9 with avar bound: [-0.005010053094811788]
Threshold 0.9 SUFFICIENT with avar bound: -0.005010053094811788

Running BIRL with demonstration 9/10 in world 4
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.184
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.22046469 -0.44841265  0.18014113 -0.28821475 -0.10118432  0.27325729
  0.74154908]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.007623
0.95-VaR bound for 9 demonstrations: -0.006470
0.99-VaR bound for 9 demonstrations: 0.019988
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.006469798579004842]
Threshold 0.1 SUFFICIENT with avar bound: -0.006469798579004842
Evaluating threshold 0.2 with avar bound: [-0.006469798579004842]
Threshold 0.2 SUFFICIENT with avar bound: -0.006469798579004842
Evaluating threshold 0.3 with avar bound: [-0.006469798579004842]
Threshold 0.3 SUFFICIENT with avar bound: -0.006469798579004842
Evaluating threshold 0.4 with avar bound: [-0.006469798579004842]
Threshold 0.4 SUFFICIENT with avar bound: -0.006469798579004842
Evaluating threshold 0.5 with avar bound: [-0.006469798579004842]
Threshold 0.5 SUFFICIENT with avar bound: -0.006469798579004842
Evaluating threshold 0.6 with avar bound: [-0.006469798579004842]
Threshold 0.6 SUFFICIENT with avar bound: -0.006469798579004842
Evaluating threshold 0.7 with avar bound: [-0.006469798579004842]
Threshold 0.7 SUFFICIENT with avar bound: -0.006469798579004842
Evaluating threshold 0.8 with avar bound: [-0.006469798579004842]
Threshold 0.8 SUFFICIENT with avar bound: -0.006469798579004842
Evaluating threshold 0.9 with avar bound: [-0.006469798579004842]
Threshold 0.9 SUFFICIENT with avar bound: -0.006469798579004842

Running BIRL with demonstration 10/10 in world 4
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.28090066 -0.37314615  0.08974618 -0.07732542 -0.28279932  0.26184493
  0.7869466 ]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.007731
0.95-VaR bound for 10 demonstrations: -0.005888
0.99-VaR bound for 10 demonstrations: -0.005030
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.005888151974811744]
Threshold 0.1 SUFFICIENT with avar bound: -0.005888151974811744
Evaluating threshold 0.2 with avar bound: [-0.005888151974811744]
Threshold 0.2 SUFFICIENT with avar bound: -0.005888151974811744
Evaluating threshold 0.3 with avar bound: [-0.005888151974811744]
Threshold 0.3 SUFFICIENT with avar bound: -0.005888151974811744
Evaluating threshold 0.4 with avar bound: [-0.005888151974811744]
Threshold 0.4 SUFFICIENT with avar bound: -0.005888151974811744
Evaluating threshold 0.5 with avar bound: [-0.005888151974811744]
Threshold 0.5 SUFFICIENT with avar bound: -0.005888151974811744
Evaluating threshold 0.6 with avar bound: [-0.005888151974811744]
Threshold 0.6 SUFFICIENT with avar bound: -0.005888151974811744
Evaluating threshold 0.7 with avar bound: [-0.005888151974811744]
Threshold 0.7 SUFFICIENT with avar bound: -0.005888151974811744
Evaluating threshold 0.8 with avar bound: [-0.005888151974811744]
Threshold 0.8 SUFFICIENT with avar bound: -0.005888151974811744
Evaluating threshold 0.9 with avar bound: [-0.005888151974811744]
Threshold 0.9 SUFFICIENT with avar bound: -0.005888151974811744

Saving results to files...
Results saved successfully.

Running world 5/20

Running BIRL with demonstration 1/10 in world 5
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.465
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50925447 -0.27034663 -0.26920052  0.22092121  0.32862041  0.30136812
  0.58947719]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.636974
0.95-VaR bound for 1 demonstrations: 3.319376
0.99-VaR bound for 1 demonstrations: 18.331166
True expected value difference for MAP policy: -0.008566
Evaluating threshold 0.1 with avar bound: [3.3193761708146625]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.3193761708146625]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.3193761708146625]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.3193761708146625]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.3193761708146625]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.3193761708146625]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.3193761708146625]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.3193761708146625]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.3193761708146625]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 5
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.281
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.26801441 -0.58099101  0.18417305  0.24225903  0.32535284 -0.32668948
  0.53425471]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 2.062222
0.95-VaR bound for 2 demonstrations: 3.244407
0.99-VaR bound for 2 demonstrations: 4.566719
True expected value difference for MAP policy: -0.008559
Evaluating threshold 0.1 with avar bound: [3.2444070602976867]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.2444070602976867]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.2444070602976867]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.2444070602976867]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.2444070602976867]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.2444070602976867]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.2444070602976867]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.2444070602976867]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.2444070602976867]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.247
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.20518037 -0.38156554  0.34042358  0.23871643  0.32899715  0.13960943
  0.71533565]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 2.261443
0.95-VaR bound for 3 demonstrations: 4.109699
0.99-VaR bound for 3 demonstrations: 22.288207
True expected value difference for MAP policy: -0.009786
Evaluating threshold 0.1 with avar bound: [4.109698976994701]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [4.109698976994701]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [4.109698976994701]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [4.109698976994701]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [4.109698976994701]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [4.109698976994701]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [4.109698976994701]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [4.109698976994701]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [4.109698976994701]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.25
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38519418 -0.53036795  0.26456034 -0.39076284 -0.03810169  0.03898362
  0.58709117]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: -0.001137
0.95-VaR bound for 4 demonstrations: 0.003036
0.99-VaR bound for 4 demonstrations: 0.008042
True expected value difference for MAP policy: -0.009947
Evaluating threshold 0.1 with avar bound: [0.003036226430717939]
Threshold 0.1 SUFFICIENT with avar bound: 0.003036226430717939
Evaluating threshold 0.2 with avar bound: [0.003036226430717939]
Threshold 0.2 SUFFICIENT with avar bound: 0.003036226430717939
Evaluating threshold 0.3 with avar bound: [0.003036226430717939]
Threshold 0.3 SUFFICIENT with avar bound: 0.003036226430717939
Evaluating threshold 0.4 with avar bound: [0.003036226430717939]
Threshold 0.4 SUFFICIENT with avar bound: 0.003036226430717939
Evaluating threshold 0.5 with avar bound: [0.003036226430717939]
Threshold 0.5 SUFFICIENT with avar bound: 0.003036226430717939
Evaluating threshold 0.6 with avar bound: [0.003036226430717939]
Threshold 0.6 SUFFICIENT with avar bound: 0.003036226430717939
Evaluating threshold 0.7 with avar bound: [0.003036226430717939]
Threshold 0.7 SUFFICIENT with avar bound: 0.003036226430717939
Evaluating threshold 0.8 with avar bound: [0.003036226430717939]
Threshold 0.8 SUFFICIENT with avar bound: 0.003036226430717939
Evaluating threshold 0.9 with avar bound: [0.003036226430717939]
Threshold 0.9 SUFFICIENT with avar bound: 0.003036226430717939

Running BIRL with demonstration 5/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.235
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.08968076 -0.47871718  0.35611292  0.17093523  0.3359778  -0.00548252
  0.70273809]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: 0.000311
0.95-VaR bound for 5 demonstrations: 0.005037
0.99-VaR bound for 5 demonstrations: 0.014739
True expected value difference for MAP policy: -0.009786
Evaluating threshold 0.1 with avar bound: [0.005037064805094041]
Threshold 0.1 SUFFICIENT with avar bound: 0.005037064805094041
Evaluating threshold 0.2 with avar bound: [0.005037064805094041]
Threshold 0.2 SUFFICIENT with avar bound: 0.005037064805094041
Evaluating threshold 0.3 with avar bound: [0.005037064805094041]
Threshold 0.3 SUFFICIENT with avar bound: 0.005037064805094041
Evaluating threshold 0.4 with avar bound: [0.005037064805094041]
Threshold 0.4 SUFFICIENT with avar bound: 0.005037064805094041
Evaluating threshold 0.5 with avar bound: [0.005037064805094041]
Threshold 0.5 SUFFICIENT with avar bound: 0.005037064805094041
Evaluating threshold 0.6 with avar bound: [0.005037064805094041]
Threshold 0.6 SUFFICIENT with avar bound: 0.005037064805094041
Evaluating threshold 0.7 with avar bound: [0.005037064805094041]
Threshold 0.7 SUFFICIENT with avar bound: 0.005037064805094041
Evaluating threshold 0.8 with avar bound: [0.005037064805094041]
Threshold 0.8 SUFFICIENT with avar bound: 0.005037064805094041
Evaluating threshold 0.9 with avar bound: [0.005037064805094041]
Threshold 0.9 SUFFICIENT with avar bound: 0.005037064805094041

Running BIRL with demonstration 6/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.242
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.25785814 -0.44634858  0.30005055 -0.40253376  0.00859197  0.40597521
  0.56331934]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.004783
0.95-VaR bound for 6 demonstrations: -0.002456
0.99-VaR bound for 6 demonstrations: 0.017826
True expected value difference for MAP policy: -0.009863
Evaluating threshold 0.1 with avar bound: [-0.002456272290996992]
Threshold 0.1 SUFFICIENT with avar bound: -0.002456272290996992
Evaluating threshold 0.2 with avar bound: [-0.002456272290996992]
Threshold 0.2 SUFFICIENT with avar bound: -0.002456272290996992
Evaluating threshold 0.3 with avar bound: [-0.002456272290996992]
Threshold 0.3 SUFFICIENT with avar bound: -0.002456272290996992
Evaluating threshold 0.4 with avar bound: [-0.002456272290996992]
Threshold 0.4 SUFFICIENT with avar bound: -0.002456272290996992
Evaluating threshold 0.5 with avar bound: [-0.002456272290996992]
Threshold 0.5 SUFFICIENT with avar bound: -0.002456272290996992
Evaluating threshold 0.6 with avar bound: [-0.002456272290996992]
Threshold 0.6 SUFFICIENT with avar bound: -0.002456272290996992
Evaluating threshold 0.7 with avar bound: [-0.002456272290996992]
Threshold 0.7 SUFFICIENT with avar bound: -0.002456272290996992
Evaluating threshold 0.8 with avar bound: [-0.002456272290996992]
Threshold 0.8 SUFFICIENT with avar bound: -0.002456272290996992
Evaluating threshold 0.9 with avar bound: [-0.002456272290996992]
Threshold 0.9 SUFFICIENT with avar bound: -0.002456272290996992

Running BIRL with demonstration 7/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.22
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.31631043 -0.56750274  0.3832366  -0.46619516 -0.02491166  0.195208
  0.41827427]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.001425
0.95-VaR bound for 7 demonstrations: 0.000438
0.99-VaR bound for 7 demonstrations: 0.010729
True expected value difference for MAP policy: -0.007624
Evaluating threshold 0.1 with avar bound: [0.00043823809650403304]
Threshold 0.1 SUFFICIENT with avar bound: 0.00043823809650403304
Evaluating threshold 0.2 with avar bound: [0.00043823809650403304]
Threshold 0.2 SUFFICIENT with avar bound: 0.00043823809650403304
Evaluating threshold 0.3 with avar bound: [0.00043823809650403304]
Threshold 0.3 SUFFICIENT with avar bound: 0.00043823809650403304
Evaluating threshold 0.4 with avar bound: [0.00043823809650403304]
Threshold 0.4 SUFFICIENT with avar bound: 0.00043823809650403304
Evaluating threshold 0.5 with avar bound: [0.00043823809650403304]
Threshold 0.5 SUFFICIENT with avar bound: 0.00043823809650403304
Evaluating threshold 0.6 with avar bound: [0.00043823809650403304]
Threshold 0.6 SUFFICIENT with avar bound: 0.00043823809650403304
Evaluating threshold 0.7 with avar bound: [0.00043823809650403304]
Threshold 0.7 SUFFICIENT with avar bound: 0.00043823809650403304
Evaluating threshold 0.8 with avar bound: [0.00043823809650403304]
Threshold 0.8 SUFFICIENT with avar bound: 0.00043823809650403304
Evaluating threshold 0.9 with avar bound: [0.00043823809650403304]
Threshold 0.9 SUFFICIENT with avar bound: 0.00043823809650403304

Running BIRL with demonstration 8/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.207
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.29753689 -0.67707432  0.1623263  -0.18677544  0.13623921  0.22932533
  0.56626498]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.006212
0.95-VaR bound for 8 demonstrations: -0.003233
0.99-VaR bound for 8 demonstrations: 0.081702
True expected value difference for MAP policy: -0.009947
Evaluating threshold 0.1 with avar bound: [-0.0032325324359022134]
Threshold 0.1 SUFFICIENT with avar bound: -0.0032325324359022134
Evaluating threshold 0.2 with avar bound: [-0.0032325324359022134]
Threshold 0.2 SUFFICIENT with avar bound: -0.0032325324359022134
Evaluating threshold 0.3 with avar bound: [-0.0032325324359022134]
Threshold 0.3 SUFFICIENT with avar bound: -0.0032325324359022134
Evaluating threshold 0.4 with avar bound: [-0.0032325324359022134]
Threshold 0.4 SUFFICIENT with avar bound: -0.0032325324359022134
Evaluating threshold 0.5 with avar bound: [-0.0032325324359022134]
Threshold 0.5 SUFFICIENT with avar bound: -0.0032325324359022134
Evaluating threshold 0.6 with avar bound: [-0.0032325324359022134]
Threshold 0.6 SUFFICIENT with avar bound: -0.0032325324359022134
Evaluating threshold 0.7 with avar bound: [-0.0032325324359022134]
Threshold 0.7 SUFFICIENT with avar bound: -0.0032325324359022134
Evaluating threshold 0.8 with avar bound: [-0.0032325324359022134]
Threshold 0.8 SUFFICIENT with avar bound: -0.0032325324359022134
Evaluating threshold 0.9 with avar bound: [-0.0032325324359022134]
Threshold 0.9 SUFFICIENT with avar bound: -0.0032325324359022134

Running BIRL with demonstration 9/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.19
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.75139409 -0.41271242  0.05868947 -0.11254665  0.24286548  0.02102149
  0.43536035]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.007751
0.95-VaR bound for 9 demonstrations: -0.005276
0.99-VaR bound for 9 demonstrations: -0.003015
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.005276178709542981]
Threshold 0.1 SUFFICIENT with avar bound: -0.005276178709542981
Evaluating threshold 0.2 with avar bound: [-0.005276178709542981]
Threshold 0.2 SUFFICIENT with avar bound: -0.005276178709542981
Evaluating threshold 0.3 with avar bound: [-0.005276178709542981]
Threshold 0.3 SUFFICIENT with avar bound: -0.005276178709542981
Evaluating threshold 0.4 with avar bound: [-0.005276178709542981]
Threshold 0.4 SUFFICIENT with avar bound: -0.005276178709542981
Evaluating threshold 0.5 with avar bound: [-0.005276178709542981]
Threshold 0.5 SUFFICIENT with avar bound: -0.005276178709542981
Evaluating threshold 0.6 with avar bound: [-0.005276178709542981]
Threshold 0.6 SUFFICIENT with avar bound: -0.005276178709542981
Evaluating threshold 0.7 with avar bound: [-0.005276178709542981]
Threshold 0.7 SUFFICIENT with avar bound: -0.005276178709542981
Evaluating threshold 0.8 with avar bound: [-0.005276178709542981]
Threshold 0.8 SUFFICIENT with avar bound: -0.005276178709542981
Evaluating threshold 0.9 with avar bound: [-0.005276178709542981]
Threshold 0.9 SUFFICIENT with avar bound: -0.005276178709542981

Running BIRL with demonstration 10/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.189
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.69279538 -0.27572384  0.17406766 -0.2202094   0.15038074  0.02689064
  0.58470652]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.005813
0.95-VaR bound for 10 demonstrations: -0.005270
0.99-VaR bound for 10 demonstrations: -0.000680
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.005270081853778445]
Threshold 0.1 SUFFICIENT with avar bound: -0.005270081853778445
Evaluating threshold 0.2 with avar bound: [-0.005270081853778445]
Threshold 0.2 SUFFICIENT with avar bound: -0.005270081853778445
Evaluating threshold 0.3 with avar bound: [-0.005270081853778445]
Threshold 0.3 SUFFICIENT with avar bound: -0.005270081853778445
Evaluating threshold 0.4 with avar bound: [-0.005270081853778445]
Threshold 0.4 SUFFICIENT with avar bound: -0.005270081853778445
Evaluating threshold 0.5 with avar bound: [-0.005270081853778445]
Threshold 0.5 SUFFICIENT with avar bound: -0.005270081853778445
Evaluating threshold 0.6 with avar bound: [-0.005270081853778445]
Threshold 0.6 SUFFICIENT with avar bound: -0.005270081853778445
Evaluating threshold 0.7 with avar bound: [-0.005270081853778445]
Threshold 0.7 SUFFICIENT with avar bound: -0.005270081853778445
Evaluating threshold 0.8 with avar bound: [-0.005270081853778445]
Threshold 0.8 SUFFICIENT with avar bound: -0.005270081853778445
Evaluating threshold 0.9 with avar bound: [-0.005270081853778445]
Threshold 0.9 SUFFICIENT with avar bound: -0.005270081853778445

Running world 6/20

Running BIRL with demonstration 1/10 in world 6
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.488
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.29743438  0.13397052  0.04345473 -0.14110234  0.35226233 -0.36254791
  0.78502024]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.663216
0.95-VaR bound for 1 demonstrations: 3.497424
0.99-VaR bound for 1 demonstrations: 12.314375
True expected value difference for MAP policy: -0.001821
Evaluating threshold 0.1 with avar bound: [3.4974241043753294]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.4974241043753294]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.4974241043753294]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.4974241043753294]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.4974241043753294]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.4974241043753294]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.4974241043753294]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.4974241043753294]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.4974241043753294]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 6
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.367
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.09696512  0.01159861  0.31369554 -0.59236508 -0.31405952  0.61506025
 -0.25343532]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 2.358673
0.95-VaR bound for 2 demonstrations: 3.281966
0.99-VaR bound for 2 demonstrations: 7.953758
True expected value difference for MAP policy: 0.032668
Evaluating threshold 0.1 with avar bound: [3.28196554115139]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.28196554115139]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.28196554115139]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.28196554115139]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.28196554115139]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.28196554115139]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.28196554115139]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.28196554115139]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.28196554115139]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 6
Current demos: [(16, 3), (12, 3), (9, 3)]
MCMC sampling complete.
Acceptance ratio: 0.29
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.1611989   0.48061494  0.04972239 -0.65204936  0.30987933  0.46316225
 -0.06956324]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.309795
0.95-VaR bound for 3 demonstrations: 0.779557
0.99-VaR bound for 3 demonstrations: 3.647397
True expected value difference for MAP policy: 0.094721
Evaluating threshold 0.1 with avar bound: [0.7795571474940073]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.7795571474940073]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.7795571474940073]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.7795571474940073]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.7795571474940073]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.7795571474940073]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [0.7795571474940073]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [0.7795571474940073]
Threshold 0.8 SUFFICIENT with avar bound: 0.7795571474940073
Evaluating threshold 0.9 with avar bound: [0.7795571474940073]
Threshold 0.9 SUFFICIENT with avar bound: 0.7795571474940073

Running BIRL with demonstration 4/10 in world 6
Current demos: [(16, 3), (12, 3), (9, 3), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.153
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.19175968  0.33013185 -0.01642561 -0.26639091  0.13350849  0.61360872
  0.6234317 ]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.029916
0.95-VaR bound for 4 demonstrations: 0.038224
0.99-VaR bound for 4 demonstrations: 0.054152
True expected value difference for MAP policy: -0.008990
Evaluating threshold 0.1 with avar bound: [0.03822371404021907]
Threshold 0.1 SUFFICIENT with avar bound: 0.03822371404021907
Evaluating threshold 0.2 with avar bound: [0.03822371404021907]
Threshold 0.2 SUFFICIENT with avar bound: 0.03822371404021907
Evaluating threshold 0.3 with avar bound: [0.03822371404021907]
Threshold 0.3 SUFFICIENT with avar bound: 0.03822371404021907
Evaluating threshold 0.4 with avar bound: [0.03822371404021907]
Threshold 0.4 SUFFICIENT with avar bound: 0.03822371404021907
Evaluating threshold 0.5 with avar bound: [0.03822371404021907]
Threshold 0.5 SUFFICIENT with avar bound: 0.03822371404021907
Evaluating threshold 0.6 with avar bound: [0.03822371404021907]
Threshold 0.6 SUFFICIENT with avar bound: 0.03822371404021907
Evaluating threshold 0.7 with avar bound: [0.03822371404021907]
Threshold 0.7 SUFFICIENT with avar bound: 0.03822371404021907
Evaluating threshold 0.8 with avar bound: [0.03822371404021907]
Threshold 0.8 SUFFICIENT with avar bound: 0.03822371404021907
Evaluating threshold 0.9 with avar bound: [0.03822371404021907]
Threshold 0.9 SUFFICIENT with avar bound: 0.03822371404021907

Running BIRL with demonstration 5/10 in world 6
Current demos: [(16, 3), (12, 3), (9, 3), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.139
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.31844678 -0.08714925 -0.49880189 -0.25493926 -0.24743635  0.49877402
  0.51691299]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: 0.044438
0.95-VaR bound for 5 demonstrations: 0.092295
0.99-VaR bound for 5 demonstrations: 0.117538
True expected value difference for MAP policy: -0.005897
Evaluating threshold 0.1 with avar bound: [0.0922950491814056]
Threshold 0.1 SUFFICIENT with avar bound: 0.0922950491814056
Evaluating threshold 0.2 with avar bound: [0.0922950491814056]
Threshold 0.2 SUFFICIENT with avar bound: 0.0922950491814056
Evaluating threshold 0.3 with avar bound: [0.0922950491814056]
Threshold 0.3 SUFFICIENT with avar bound: 0.0922950491814056
Evaluating threshold 0.4 with avar bound: [0.0922950491814056]
Threshold 0.4 SUFFICIENT with avar bound: 0.0922950491814056
Evaluating threshold 0.5 with avar bound: [0.0922950491814056]
Threshold 0.5 SUFFICIENT with avar bound: 0.0922950491814056
Evaluating threshold 0.6 with avar bound: [0.0922950491814056]
Threshold 0.6 SUFFICIENT with avar bound: 0.0922950491814056
Evaluating threshold 0.7 with avar bound: [0.0922950491814056]
Threshold 0.7 SUFFICIENT with avar bound: 0.0922950491814056
Evaluating threshold 0.8 with avar bound: [0.0922950491814056]
Threshold 0.8 SUFFICIENT with avar bound: 0.0922950491814056
Evaluating threshold 0.9 with avar bound: [0.0922950491814056]
Threshold 0.9 SUFFICIENT with avar bound: 0.0922950491814056

Running BIRL with demonstration 6/10 in world 6
Current demos: [(16, 3), (12, 3), (9, 3), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.156
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.19710346  0.0470729   0.11642439 -0.71633297 -0.20265915  0.43515529
  0.4492393 ]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: 0.034215
0.95-VaR bound for 6 demonstrations: 0.082465
0.99-VaR bound for 6 demonstrations: 0.093333
True expected value difference for MAP policy: -0.004688
Evaluating threshold 0.1 with avar bound: [0.0824651795920969]
Threshold 0.1 SUFFICIENT with avar bound: 0.0824651795920969
Evaluating threshold 0.2 with avar bound: [0.0824651795920969]
Threshold 0.2 SUFFICIENT with avar bound: 0.0824651795920969
Evaluating threshold 0.3 with avar bound: [0.0824651795920969]
Threshold 0.3 SUFFICIENT with avar bound: 0.0824651795920969
Evaluating threshold 0.4 with avar bound: [0.0824651795920969]
Threshold 0.4 SUFFICIENT with avar bound: 0.0824651795920969
Evaluating threshold 0.5 with avar bound: [0.0824651795920969]
Threshold 0.5 SUFFICIENT with avar bound: 0.0824651795920969
Evaluating threshold 0.6 with avar bound: [0.0824651795920969]
Threshold 0.6 SUFFICIENT with avar bound: 0.0824651795920969
Evaluating threshold 0.7 with avar bound: [0.0824651795920969]
Threshold 0.7 SUFFICIENT with avar bound: 0.0824651795920969
Evaluating threshold 0.8 with avar bound: [0.0824651795920969]
Threshold 0.8 SUFFICIENT with avar bound: 0.0824651795920969
Evaluating threshold 0.9 with avar bound: [0.0824651795920969]
Threshold 0.9 SUFFICIENT with avar bound: 0.0824651795920969

Running BIRL with demonstration 7/10 in world 6
Current demos: [(16, 3), (12, 3), (9, 3), (19, 1), (18, 1), (6, 3), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.141
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.52782332 -0.09483987 -0.63643383 -0.44683783 -0.24492255  0.11948735
  0.18284306]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: 0.002588
0.95-VaR bound for 7 demonstrations: 0.008880
0.99-VaR bound for 7 demonstrations: 0.059507
True expected value difference for MAP policy: -0.005514
Evaluating threshold 0.1 with avar bound: [0.00888007949676085]
Threshold 0.1 SUFFICIENT with avar bound: 0.00888007949676085
Evaluating threshold 0.2 with avar bound: [0.00888007949676085]
Threshold 0.2 SUFFICIENT with avar bound: 0.00888007949676085
Evaluating threshold 0.3 with avar bound: [0.00888007949676085]
Threshold 0.3 SUFFICIENT with avar bound: 0.00888007949676085
Evaluating threshold 0.4 with avar bound: [0.00888007949676085]
Threshold 0.4 SUFFICIENT with avar bound: 0.00888007949676085
Evaluating threshold 0.5 with avar bound: [0.00888007949676085]
Threshold 0.5 SUFFICIENT with avar bound: 0.00888007949676085
Evaluating threshold 0.6 with avar bound: [0.00888007949676085]
Threshold 0.6 SUFFICIENT with avar bound: 0.00888007949676085
Evaluating threshold 0.7 with avar bound: [0.00888007949676085]
Threshold 0.7 SUFFICIENT with avar bound: 0.00888007949676085
Evaluating threshold 0.8 with avar bound: [0.00888007949676085]
Threshold 0.8 SUFFICIENT with avar bound: 0.00888007949676085
Evaluating threshold 0.9 with avar bound: [0.00888007949676085]
Threshold 0.9 SUFFICIENT with avar bound: 0.00888007949676085

Running BIRL with demonstration 8/10 in world 6
Current demos: [(16, 3), (12, 3), (9, 3), (19, 1), (18, 1), (6, 3), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.144
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.45458084  0.46238018 -0.44449832  0.02625529 -0.10698611  0.42015426
  0.4396784 ]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: 0.107978
0.95-VaR bound for 8 demonstrations: 0.170764
0.99-VaR bound for 8 demonstrations: 1.648129
True expected value difference for MAP policy: 0.054585
Evaluating threshold 0.1 with avar bound: [0.1707640215828696]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.1707640215828696]
Threshold 0.2 SUFFICIENT with avar bound: 0.1707640215828696
Evaluating threshold 0.3 with avar bound: [0.1707640215828696]
Threshold 0.3 SUFFICIENT with avar bound: 0.1707640215828696
Evaluating threshold 0.4 with avar bound: [0.1707640215828696]
Threshold 0.4 SUFFICIENT with avar bound: 0.1707640215828696
Evaluating threshold 0.5 with avar bound: [0.1707640215828696]
Threshold 0.5 SUFFICIENT with avar bound: 0.1707640215828696
Evaluating threshold 0.6 with avar bound: [0.1707640215828696]
Threshold 0.6 SUFFICIENT with avar bound: 0.1707640215828696
Evaluating threshold 0.7 with avar bound: [0.1707640215828696]
Threshold 0.7 SUFFICIENT with avar bound: 0.1707640215828696
Evaluating threshold 0.8 with avar bound: [0.1707640215828696]
Threshold 0.8 SUFFICIENT with avar bound: 0.1707640215828696
Evaluating threshold 0.9 with avar bound: [0.1707640215828696]
Threshold 0.9 SUFFICIENT with avar bound: 0.1707640215828696

Running BIRL with demonstration 9/10 in world 6
Current demos: [(16, 3), (12, 3), (9, 3), (19, 1), (18, 1), (6, 3), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.163
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.56788276 -0.14383539 -0.50378478 -0.10892703  0.1255616   0.43099682
  0.43546799]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: 0.065668
0.95-VaR bound for 9 demonstrations: 0.083682
0.99-VaR bound for 9 demonstrations: 0.158168
True expected value difference for MAP policy: -0.007511
Evaluating threshold 0.1 with avar bound: [0.08368190462619025]
Threshold 0.1 SUFFICIENT with avar bound: 0.08368190462619025
Evaluating threshold 0.2 with avar bound: [0.08368190462619025]
Threshold 0.2 SUFFICIENT with avar bound: 0.08368190462619025
Evaluating threshold 0.3 with avar bound: [0.08368190462619025]
Threshold 0.3 SUFFICIENT with avar bound: 0.08368190462619025
Evaluating threshold 0.4 with avar bound: [0.08368190462619025]
Threshold 0.4 SUFFICIENT with avar bound: 0.08368190462619025
Evaluating threshold 0.5 with avar bound: [0.08368190462619025]
Threshold 0.5 SUFFICIENT with avar bound: 0.08368190462619025
Evaluating threshold 0.6 with avar bound: [0.08368190462619025]
Threshold 0.6 SUFFICIENT with avar bound: 0.08368190462619025
Evaluating threshold 0.7 with avar bound: [0.08368190462619025]
Threshold 0.7 SUFFICIENT with avar bound: 0.08368190462619025
Evaluating threshold 0.8 with avar bound: [0.08368190462619025]
Threshold 0.8 SUFFICIENT with avar bound: 0.08368190462619025
Evaluating threshold 0.9 with avar bound: [0.08368190462619025]
Threshold 0.9 SUFFICIENT with avar bound: 0.08368190462619025

Running BIRL with demonstration 10/10 in world 6
Current demos: [(16, 3), (12, 3), (9, 3), (19, 1), (18, 1), (6, 3), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.149
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.4122456  -0.30537687 -0.14009011 -0.12082886  0.1379232   0.55642604
  0.6115071 ]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.004171
0.95-VaR bound for 10 demonstrations: 0.001587
0.99-VaR bound for 10 demonstrations: 0.006715
True expected value difference for MAP policy: -0.009379
Evaluating threshold 0.1 with avar bound: [0.001587316017075843]
Threshold 0.1 SUFFICIENT with avar bound: 0.001587316017075843
Evaluating threshold 0.2 with avar bound: [0.001587316017075843]
Threshold 0.2 SUFFICIENT with avar bound: 0.001587316017075843
Evaluating threshold 0.3 with avar bound: [0.001587316017075843]
Threshold 0.3 SUFFICIENT with avar bound: 0.001587316017075843
Evaluating threshold 0.4 with avar bound: [0.001587316017075843]
Threshold 0.4 SUFFICIENT with avar bound: 0.001587316017075843
Evaluating threshold 0.5 with avar bound: [0.001587316017075843]
Threshold 0.5 SUFFICIENT with avar bound: 0.001587316017075843
Evaluating threshold 0.6 with avar bound: [0.001587316017075843]
Threshold 0.6 SUFFICIENT with avar bound: 0.001587316017075843
Evaluating threshold 0.7 with avar bound: [0.001587316017075843]
Threshold 0.7 SUFFICIENT with avar bound: 0.001587316017075843
Evaluating threshold 0.8 with avar bound: [0.001587316017075843]
Threshold 0.8 SUFFICIENT with avar bound: 0.001587316017075843
Evaluating threshold 0.9 with avar bound: [0.001587316017075843]
Threshold 0.9 SUFFICIENT with avar bound: 0.001587316017075843

Running world 7/20

Running BIRL with demonstration 1/10 in world 7
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.526
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.42781964 -0.18420057 -0.53517352  0.30871256 -0.32856633  0.02785379
  0.54092023]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.942795
0.95-VaR bound for 1 demonstrations: 4.809004
0.99-VaR bound for 1 demonstrations: 22.694488
True expected value difference for MAP policy: -0.004262
Evaluating threshold 0.1 with avar bound: [4.809004047700498]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [4.809004047700498]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [4.809004047700498]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [4.809004047700498]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [4.809004047700498]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [4.809004047700498]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [4.809004047700498]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [4.809004047700498]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [4.809004047700498]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 7
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.375
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50083959 -0.01915709  0.23752108 -0.36473857 -0.60247267  0.16848321
  0.40985645]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 2.678974
0.95-VaR bound for 2 demonstrations: 3.366228
0.99-VaR bound for 2 demonstrations: 6.040631
True expected value difference for MAP policy: -0.006874
Evaluating threshold 0.1 with avar bound: [3.366227668187664]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.366227668187664]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.366227668187664]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.366227668187664]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.366227668187664]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.366227668187664]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.366227668187664]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.366227668187664]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.366227668187664]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.326
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.35229517  0.18492691  0.14328171 -0.18059539 -0.39531465 -0.62512056
  0.49142284]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 2.488596
0.95-VaR bound for 3 demonstrations: 3.035347
0.99-VaR bound for 3 demonstrations: 8.179236
True expected value difference for MAP policy: -0.001791
Evaluating threshold 0.1 with avar bound: [3.035347237608479]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.035347237608479]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.035347237608479]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.035347237608479]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.035347237608479]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.035347237608479]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.035347237608479]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.035347237608479]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.035347237608479]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.24
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.42537063 -0.13346425  0.46357169 -0.1857972  -0.0948289  -0.25525642
  0.69114358]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.034797
0.95-VaR bound for 4 demonstrations: 0.039478
0.99-VaR bound for 4 demonstrations: 0.061424
True expected value difference for MAP policy: -0.007826
Evaluating threshold 0.1 with avar bound: [0.03947755311990867]
Threshold 0.1 SUFFICIENT with avar bound: 0.03947755311990867
Evaluating threshold 0.2 with avar bound: [0.03947755311990867]
Threshold 0.2 SUFFICIENT with avar bound: 0.03947755311990867
Evaluating threshold 0.3 with avar bound: [0.03947755311990867]
Threshold 0.3 SUFFICIENT with avar bound: 0.03947755311990867
Evaluating threshold 0.4 with avar bound: [0.03947755311990867]
Threshold 0.4 SUFFICIENT with avar bound: 0.03947755311990867
Evaluating threshold 0.5 with avar bound: [0.03947755311990867]
Threshold 0.5 SUFFICIENT with avar bound: 0.03947755311990867
Evaluating threshold 0.6 with avar bound: [0.03947755311990867]
Threshold 0.6 SUFFICIENT with avar bound: 0.03947755311990867
Evaluating threshold 0.7 with avar bound: [0.03947755311990867]
Threshold 0.7 SUFFICIENT with avar bound: 0.03947755311990867
Evaluating threshold 0.8 with avar bound: [0.03947755311990867]
Threshold 0.8 SUFFICIENT with avar bound: 0.03947755311990867
Evaluating threshold 0.9 with avar bound: [0.03947755311990867]
Threshold 0.9 SUFFICIENT with avar bound: 0.03947755311990867

Running BIRL with demonstration 5/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.215
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38502857 -0.06032119  0.48025682 -0.11744216  0.38364579 -0.10221754
  0.66786418]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.000783
0.95-VaR bound for 5 demonstrations: 0.006294
0.99-VaR bound for 5 demonstrations: 0.019051
True expected value difference for MAP policy: -0.007826
Evaluating threshold 0.1 with avar bound: [0.006293716022280161]
Threshold 0.1 SUFFICIENT with avar bound: 0.006293716022280161
Evaluating threshold 0.2 with avar bound: [0.006293716022280161]
Threshold 0.2 SUFFICIENT with avar bound: 0.006293716022280161
Evaluating threshold 0.3 with avar bound: [0.006293716022280161]
Threshold 0.3 SUFFICIENT with avar bound: 0.006293716022280161
Evaluating threshold 0.4 with avar bound: [0.006293716022280161]
Threshold 0.4 SUFFICIENT with avar bound: 0.006293716022280161
Evaluating threshold 0.5 with avar bound: [0.006293716022280161]
Threshold 0.5 SUFFICIENT with avar bound: 0.006293716022280161
Evaluating threshold 0.6 with avar bound: [0.006293716022280161]
Threshold 0.6 SUFFICIENT with avar bound: 0.006293716022280161
Evaluating threshold 0.7 with avar bound: [0.006293716022280161]
Threshold 0.7 SUFFICIENT with avar bound: 0.006293716022280161
Evaluating threshold 0.8 with avar bound: [0.006293716022280161]
Threshold 0.8 SUFFICIENT with avar bound: 0.006293716022280161
Evaluating threshold 0.9 with avar bound: [0.006293716022280161]
Threshold 0.9 SUFFICIENT with avar bound: 0.006293716022280161

Running BIRL with demonstration 6/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.205
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.69725812 -0.06041657 -0.04111634 -0.48601296 -0.01906214  0.04972617
  0.51908163]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.002742
0.95-VaR bound for 6 demonstrations: 0.000341
0.99-VaR bound for 6 demonstrations: 0.014777
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.00034100140921622586]
Threshold 0.1 SUFFICIENT with avar bound: 0.00034100140921622586
Evaluating threshold 0.2 with avar bound: [0.00034100140921622586]
Threshold 0.2 SUFFICIENT with avar bound: 0.00034100140921622586
Evaluating threshold 0.3 with avar bound: [0.00034100140921622586]
Threshold 0.3 SUFFICIENT with avar bound: 0.00034100140921622586
Evaluating threshold 0.4 with avar bound: [0.00034100140921622586]
Threshold 0.4 SUFFICIENT with avar bound: 0.00034100140921622586
Evaluating threshold 0.5 with avar bound: [0.00034100140921622586]
Threshold 0.5 SUFFICIENT with avar bound: 0.00034100140921622586
Evaluating threshold 0.6 with avar bound: [0.00034100140921622586]
Threshold 0.6 SUFFICIENT with avar bound: 0.00034100140921622586
Evaluating threshold 0.7 with avar bound: [0.00034100140921622586]
Threshold 0.7 SUFFICIENT with avar bound: 0.00034100140921622586
Evaluating threshold 0.8 with avar bound: [0.00034100140921622586]
Threshold 0.8 SUFFICIENT with avar bound: 0.00034100140921622586
Evaluating threshold 0.9 with avar bound: [0.00034100140921622586]
Threshold 0.9 SUFFICIENT with avar bound: 0.00034100140921622586

Running BIRL with demonstration 7/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.60919049 -0.07688076 -0.01080887 -0.40519143  0.21877461 -0.05737146
  0.63837728]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.006487
0.95-VaR bound for 7 demonstrations: -0.005214
0.99-VaR bound for 7 demonstrations: -0.003501
True expected value difference for MAP policy: -0.008760
Evaluating threshold 0.1 with avar bound: [-0.0052138544114348935]
Threshold 0.1 SUFFICIENT with avar bound: -0.0052138544114348935
Evaluating threshold 0.2 with avar bound: [-0.0052138544114348935]
Threshold 0.2 SUFFICIENT with avar bound: -0.0052138544114348935
Evaluating threshold 0.3 with avar bound: [-0.0052138544114348935]
Threshold 0.3 SUFFICIENT with avar bound: -0.0052138544114348935
Evaluating threshold 0.4 with avar bound: [-0.0052138544114348935]
Threshold 0.4 SUFFICIENT with avar bound: -0.0052138544114348935
Evaluating threshold 0.5 with avar bound: [-0.0052138544114348935]
Threshold 0.5 SUFFICIENT with avar bound: -0.0052138544114348935
Evaluating threshold 0.6 with avar bound: [-0.0052138544114348935]
Threshold 0.6 SUFFICIENT with avar bound: -0.0052138544114348935
Evaluating threshold 0.7 with avar bound: [-0.0052138544114348935]
Threshold 0.7 SUFFICIENT with avar bound: -0.0052138544114348935
Evaluating threshold 0.8 with avar bound: [-0.0052138544114348935]
Threshold 0.8 SUFFICIENT with avar bound: -0.0052138544114348935
Evaluating threshold 0.9 with avar bound: [-0.0052138544114348935]
Threshold 0.9 SUFFICIENT with avar bound: -0.0052138544114348935

Running BIRL with demonstration 8/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.19
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.60279159  0.16681518  0.03080675 -0.52221408  0.03207395 -0.01144646
  0.57792614]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.005552
0.95-VaR bound for 8 demonstrations: -0.003588
0.99-VaR bound for 8 demonstrations: 0.097894
True expected value difference for MAP policy: -0.008526
Evaluating threshold 0.1 with avar bound: [-0.0035883176349280252]
Threshold 0.1 SUFFICIENT with avar bound: -0.0035883176349280252
Evaluating threshold 0.2 with avar bound: [-0.0035883176349280252]
Threshold 0.2 SUFFICIENT with avar bound: -0.0035883176349280252
Evaluating threshold 0.3 with avar bound: [-0.0035883176349280252]
Threshold 0.3 SUFFICIENT with avar bound: -0.0035883176349280252
Evaluating threshold 0.4 with avar bound: [-0.0035883176349280252]
Threshold 0.4 SUFFICIENT with avar bound: -0.0035883176349280252
Evaluating threshold 0.5 with avar bound: [-0.0035883176349280252]
Threshold 0.5 SUFFICIENT with avar bound: -0.0035883176349280252
Evaluating threshold 0.6 with avar bound: [-0.0035883176349280252]
Threshold 0.6 SUFFICIENT with avar bound: -0.0035883176349280252
Evaluating threshold 0.7 with avar bound: [-0.0035883176349280252]
Threshold 0.7 SUFFICIENT with avar bound: -0.0035883176349280252
Evaluating threshold 0.8 with avar bound: [-0.0035883176349280252]
Threshold 0.8 SUFFICIENT with avar bound: -0.0035883176349280252
Evaluating threshold 0.9 with avar bound: [-0.0035883176349280252]
Threshold 0.9 SUFFICIENT with avar bound: -0.0035883176349280252

Running BIRL with demonstration 9/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.188
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.71915931  0.08139069  0.12461849 -0.45854403  0.01615321 -0.05683489
  0.49689226]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.005008
0.95-VaR bound for 9 demonstrations: -0.004502
0.99-VaR bound for 9 demonstrations: 0.015572
True expected value difference for MAP policy: -0.007826
Evaluating threshold 0.1 with avar bound: [-0.00450195782097778]
Threshold 0.1 SUFFICIENT with avar bound: -0.00450195782097778
Evaluating threshold 0.2 with avar bound: [-0.00450195782097778]
Threshold 0.2 SUFFICIENT with avar bound: -0.00450195782097778
Evaluating threshold 0.3 with avar bound: [-0.00450195782097778]
Threshold 0.3 SUFFICIENT with avar bound: -0.00450195782097778
Evaluating threshold 0.4 with avar bound: [-0.00450195782097778]
Threshold 0.4 SUFFICIENT with avar bound: -0.00450195782097778
Evaluating threshold 0.5 with avar bound: [-0.00450195782097778]
Threshold 0.5 SUFFICIENT with avar bound: -0.00450195782097778
Evaluating threshold 0.6 with avar bound: [-0.00450195782097778]
Threshold 0.6 SUFFICIENT with avar bound: -0.00450195782097778
Evaluating threshold 0.7 with avar bound: [-0.00450195782097778]
Threshold 0.7 SUFFICIENT with avar bound: -0.00450195782097778
Evaluating threshold 0.8 with avar bound: [-0.00450195782097778]
Threshold 0.8 SUFFICIENT with avar bound: -0.00450195782097778
Evaluating threshold 0.9 with avar bound: [-0.00450195782097778]
Threshold 0.9 SUFFICIENT with avar bound: -0.00450195782097778

Running BIRL with demonstration 10/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.56656526 -0.28230156  0.27057762 -0.43306187 -0.07558423  0.08661543
  0.57038548]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.006905
0.95-VaR bound for 10 demonstrations: -0.006248
0.99-VaR bound for 10 demonstrations: 0.008693
True expected value difference for MAP policy: -0.007826
Evaluating threshold 0.1 with avar bound: [-0.006248396059707902]
Threshold 0.1 SUFFICIENT with avar bound: -0.006248396059707902
Evaluating threshold 0.2 with avar bound: [-0.006248396059707902]
Threshold 0.2 SUFFICIENT with avar bound: -0.006248396059707902
Evaluating threshold 0.3 with avar bound: [-0.006248396059707902]
Threshold 0.3 SUFFICIENT with avar bound: -0.006248396059707902
Evaluating threshold 0.4 with avar bound: [-0.006248396059707902]
Threshold 0.4 SUFFICIENT with avar bound: -0.006248396059707902
Evaluating threshold 0.5 with avar bound: [-0.006248396059707902]
Threshold 0.5 SUFFICIENT with avar bound: -0.006248396059707902
Evaluating threshold 0.6 with avar bound: [-0.006248396059707902]
Threshold 0.6 SUFFICIENT with avar bound: -0.006248396059707902
Evaluating threshold 0.7 with avar bound: [-0.006248396059707902]
Threshold 0.7 SUFFICIENT with avar bound: -0.006248396059707902
Evaluating threshold 0.8 with avar bound: [-0.006248396059707902]
Threshold 0.8 SUFFICIENT with avar bound: -0.006248396059707902
Evaluating threshold 0.9 with avar bound: [-0.006248396059707902]
Threshold 0.9 SUFFICIENT with avar bound: -0.006248396059707902

Running world 8/20

Running BIRL with demonstration 1/10 in world 8
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.415
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38464257  0.0890172  -0.03694403 -0.37823036 -0.60327431  0.33665232
  0.47162302]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.971931
0.95-VaR bound for 1 demonstrations: 5.034716
0.99-VaR bound for 1 demonstrations: 55.703972
True expected value difference for MAP policy: 0.000774
Evaluating threshold 0.1 with avar bound: [5.034716207569759]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [5.034716207569759]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [5.034716207569759]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [5.034716207569759]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [5.034716207569759]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [5.034716207569759]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [5.034716207569759]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [5.034716207569759]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [5.034716207569759]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 8
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.256
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.0998452  -0.3871147   0.03212537 -0.56427898 -0.04592142  0.4393855
  0.57058035]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 1.438017
0.95-VaR bound for 2 demonstrations: 2.524945
0.99-VaR bound for 2 demonstrations: 8.436196
True expected value difference for MAP policy: 0.009970
Evaluating threshold 0.1 with avar bound: [2.5249451142040735]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.5249451142040735]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.5249451142040735]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.5249451142040735]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.5249451142040735]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.5249451142040735]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.5249451142040735]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.5249451142040735]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.5249451142040735]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.228
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.21498118  0.10492195 -0.40607472 -0.48645574 -0.26826169  0.14122765
  0.67032009]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.004317
0.95-VaR bound for 3 demonstrations: 0.017758
0.99-VaR bound for 3 demonstrations: 0.026242
True expected value difference for MAP policy: 0.011074
Evaluating threshold 0.1 with avar bound: [0.01775812523542052]
Threshold 0.1 SUFFICIENT with avar bound: 0.01775812523542052
Evaluating threshold 0.2 with avar bound: [0.01775812523542052]
Threshold 0.2 SUFFICIENT with avar bound: 0.01775812523542052
Evaluating threshold 0.3 with avar bound: [0.01775812523542052]
Threshold 0.3 SUFFICIENT with avar bound: 0.01775812523542052
Evaluating threshold 0.4 with avar bound: [0.01775812523542052]
Threshold 0.4 SUFFICIENT with avar bound: 0.01775812523542052
Evaluating threshold 0.5 with avar bound: [0.01775812523542052]
Threshold 0.5 SUFFICIENT with avar bound: 0.01775812523542052
Evaluating threshold 0.6 with avar bound: [0.01775812523542052]
Threshold 0.6 SUFFICIENT with avar bound: 0.01775812523542052
Evaluating threshold 0.7 with avar bound: [0.01775812523542052]
Threshold 0.7 SUFFICIENT with avar bound: 0.01775812523542052
Evaluating threshold 0.8 with avar bound: [0.01775812523542052]
Threshold 0.8 SUFFICIENT with avar bound: 0.01775812523542052
Evaluating threshold 0.9 with avar bound: [0.01775812523542052]
Threshold 0.9 SUFFICIENT with avar bound: 0.01775812523542052

Running BIRL with demonstration 4/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.239
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.37223358 -0.20654276 -0.11361436 -0.5584478  -0.33734599  0.16252017
  0.59480666]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.005808
0.95-VaR bound for 4 demonstrations: 0.007576
0.99-VaR bound for 4 demonstrations: 0.044323
True expected value difference for MAP policy: -0.000691
Evaluating threshold 0.1 with avar bound: [0.007575686544321896]
Threshold 0.1 SUFFICIENT with avar bound: 0.007575686544321896
Evaluating threshold 0.2 with avar bound: [0.007575686544321896]
Threshold 0.2 SUFFICIENT with avar bound: 0.007575686544321896
Evaluating threshold 0.3 with avar bound: [0.007575686544321896]
Threshold 0.3 SUFFICIENT with avar bound: 0.007575686544321896
Evaluating threshold 0.4 with avar bound: [0.007575686544321896]
Threshold 0.4 SUFFICIENT with avar bound: 0.007575686544321896
Evaluating threshold 0.5 with avar bound: [0.007575686544321896]
Threshold 0.5 SUFFICIENT with avar bound: 0.007575686544321896
Evaluating threshold 0.6 with avar bound: [0.007575686544321896]
Threshold 0.6 SUFFICIENT with avar bound: 0.007575686544321896
Evaluating threshold 0.7 with avar bound: [0.007575686544321896]
Threshold 0.7 SUFFICIENT with avar bound: 0.007575686544321896
Evaluating threshold 0.8 with avar bound: [0.007575686544321896]
Threshold 0.8 SUFFICIENT with avar bound: 0.007575686544321896
Evaluating threshold 0.9 with avar bound: [0.007575686544321896]
Threshold 0.9 SUFFICIENT with avar bound: 0.007575686544321896

Running BIRL with demonstration 5/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.222
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.66986378 -0.29897806  0.11997289 -0.32906201  0.08445506  0.16984603
  0.55067141]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.000934
0.95-VaR bound for 5 demonstrations: 0.006055
0.99-VaR bound for 5 demonstrations: 0.047836
True expected value difference for MAP policy: -0.000691
Evaluating threshold 0.1 with avar bound: [0.006054989275277985]
Threshold 0.1 SUFFICIENT with avar bound: 0.006054989275277985
Evaluating threshold 0.2 with avar bound: [0.006054989275277985]
Threshold 0.2 SUFFICIENT with avar bound: 0.006054989275277985
Evaluating threshold 0.3 with avar bound: [0.006054989275277985]
Threshold 0.3 SUFFICIENT with avar bound: 0.006054989275277985
Evaluating threshold 0.4 with avar bound: [0.006054989275277985]
Threshold 0.4 SUFFICIENT with avar bound: 0.006054989275277985
Evaluating threshold 0.5 with avar bound: [0.006054989275277985]
Threshold 0.5 SUFFICIENT with avar bound: 0.006054989275277985
Evaluating threshold 0.6 with avar bound: [0.006054989275277985]
Threshold 0.6 SUFFICIENT with avar bound: 0.006054989275277985
Evaluating threshold 0.7 with avar bound: [0.006054989275277985]
Threshold 0.7 SUFFICIENT with avar bound: 0.006054989275277985
Evaluating threshold 0.8 with avar bound: [0.006054989275277985]
Threshold 0.8 SUFFICIENT with avar bound: 0.006054989275277985
Evaluating threshold 0.9 with avar bound: [0.006054989275277985]
Threshold 0.9 SUFFICIENT with avar bound: 0.006054989275277985

Running BIRL with demonstration 6/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.2
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.57651552 -0.38258108 -0.00597224 -0.55312365 -0.16517225  0.0070928
  0.43352964]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.004910
0.95-VaR bound for 6 demonstrations: 0.000556
0.99-VaR bound for 6 demonstrations: 2.817489
True expected value difference for MAP policy: -0.000691
Evaluating threshold 0.1 with avar bound: [0.0005564760311193087]
Threshold 0.1 SUFFICIENT with avar bound: 0.0005564760311193087
Evaluating threshold 0.2 with avar bound: [0.0005564760311193087]
Threshold 0.2 SUFFICIENT with avar bound: 0.0005564760311193087
Evaluating threshold 0.3 with avar bound: [0.0005564760311193087]
Threshold 0.3 SUFFICIENT with avar bound: 0.0005564760311193087
Evaluating threshold 0.4 with avar bound: [0.0005564760311193087]
Threshold 0.4 SUFFICIENT with avar bound: 0.0005564760311193087
Evaluating threshold 0.5 with avar bound: [0.0005564760311193087]
Threshold 0.5 SUFFICIENT with avar bound: 0.0005564760311193087
Evaluating threshold 0.6 with avar bound: [0.0005564760311193087]
Threshold 0.6 SUFFICIENT with avar bound: 0.0005564760311193087
Evaluating threshold 0.7 with avar bound: [0.0005564760311193087]
Threshold 0.7 SUFFICIENT with avar bound: 0.0005564760311193087
Evaluating threshold 0.8 with avar bound: [0.0005564760311193087]
Threshold 0.8 SUFFICIENT with avar bound: 0.0005564760311193087
Evaluating threshold 0.9 with avar bound: [0.0005564760311193087]
Threshold 0.9 SUFFICIENT with avar bound: 0.0005564760311193087

Running BIRL with demonstration 7/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.197
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47286048 -0.27181802  0.1732695  -0.46759659 -0.14281008  0.09606367
  0.65132641]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.004370
0.95-VaR bound for 7 demonstrations: -0.001840
0.99-VaR bound for 7 demonstrations: 0.000076
True expected value difference for MAP policy: -0.000691
Evaluating threshold 0.1 with avar bound: [-0.0018399213479692398]
Threshold 0.1 SUFFICIENT with avar bound: -0.0018399213479692398
Evaluating threshold 0.2 with avar bound: [-0.0018399213479692398]
Threshold 0.2 SUFFICIENT with avar bound: -0.0018399213479692398
Evaluating threshold 0.3 with avar bound: [-0.0018399213479692398]
Threshold 0.3 SUFFICIENT with avar bound: -0.0018399213479692398
Evaluating threshold 0.4 with avar bound: [-0.0018399213479692398]
Threshold 0.4 SUFFICIENT with avar bound: -0.0018399213479692398
Evaluating threshold 0.5 with avar bound: [-0.0018399213479692398]
Threshold 0.5 SUFFICIENT with avar bound: -0.0018399213479692398
Evaluating threshold 0.6 with avar bound: [-0.0018399213479692398]
Threshold 0.6 SUFFICIENT with avar bound: -0.0018399213479692398
Evaluating threshold 0.7 with avar bound: [-0.0018399213479692398]
Threshold 0.7 SUFFICIENT with avar bound: -0.0018399213479692398
Evaluating threshold 0.8 with avar bound: [-0.0018399213479692398]
Threshold 0.8 SUFFICIENT with avar bound: -0.0018399213479692398
Evaluating threshold 0.9 with avar bound: [-0.0018399213479692398]
Threshold 0.9 SUFFICIENT with avar bound: -0.0018399213479692398

Running BIRL with demonstration 8/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.184
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47099487 -0.01296361  0.13785637 -0.10346047  0.13597056  0.32047256
  0.79189436]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.002037
0.95-VaR bound for 8 demonstrations: 0.001604
0.99-VaR bound for 8 demonstrations: 0.025498
True expected value difference for MAP policy: -0.001091
Evaluating threshold 0.1 with avar bound: [0.0016043944114125022]
Threshold 0.1 SUFFICIENT with avar bound: 0.0016043944114125022
Evaluating threshold 0.2 with avar bound: [0.0016043944114125022]
Threshold 0.2 SUFFICIENT with avar bound: 0.0016043944114125022
Evaluating threshold 0.3 with avar bound: [0.0016043944114125022]
Threshold 0.3 SUFFICIENT with avar bound: 0.0016043944114125022
Evaluating threshold 0.4 with avar bound: [0.0016043944114125022]
Threshold 0.4 SUFFICIENT with avar bound: 0.0016043944114125022
Evaluating threshold 0.5 with avar bound: [0.0016043944114125022]
Threshold 0.5 SUFFICIENT with avar bound: 0.0016043944114125022
Evaluating threshold 0.6 with avar bound: [0.0016043944114125022]
Threshold 0.6 SUFFICIENT with avar bound: 0.0016043944114125022
Evaluating threshold 0.7 with avar bound: [0.0016043944114125022]
Threshold 0.7 SUFFICIENT with avar bound: 0.0016043944114125022
Evaluating threshold 0.8 with avar bound: [0.0016043944114125022]
Threshold 0.8 SUFFICIENT with avar bound: 0.0016043944114125022
Evaluating threshold 0.9 with avar bound: [0.0016043944114125022]
Threshold 0.9 SUFFICIENT with avar bound: 0.0016043944114125022

Running BIRL with demonstration 9/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.17
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.25700759  0.07465337  0.21941378 -0.22673309 -0.3236508   0.3299008
  0.78437191]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.005013
0.95-VaR bound for 9 demonstrations: 0.001414
0.99-VaR bound for 9 demonstrations: 0.004993
True expected value difference for MAP policy: -0.000691
Evaluating threshold 0.1 with avar bound: [0.0014139972249285915]
Threshold 0.1 SUFFICIENT with avar bound: 0.0014139972249285915
Evaluating threshold 0.2 with avar bound: [0.0014139972249285915]
Threshold 0.2 SUFFICIENT with avar bound: 0.0014139972249285915
Evaluating threshold 0.3 with avar bound: [0.0014139972249285915]
Threshold 0.3 SUFFICIENT with avar bound: 0.0014139972249285915
Evaluating threshold 0.4 with avar bound: [0.0014139972249285915]
Threshold 0.4 SUFFICIENT with avar bound: 0.0014139972249285915
Evaluating threshold 0.5 with avar bound: [0.0014139972249285915]
Threshold 0.5 SUFFICIENT with avar bound: 0.0014139972249285915
Evaluating threshold 0.6 with avar bound: [0.0014139972249285915]
Threshold 0.6 SUFFICIENT with avar bound: 0.0014139972249285915
Evaluating threshold 0.7 with avar bound: [0.0014139972249285915]
Threshold 0.7 SUFFICIENT with avar bound: 0.0014139972249285915
Evaluating threshold 0.8 with avar bound: [0.0014139972249285915]
Threshold 0.8 SUFFICIENT with avar bound: 0.0014139972249285915
Evaluating threshold 0.9 with avar bound: [0.0014139972249285915]
Threshold 0.9 SUFFICIENT with avar bound: 0.0014139972249285915

Running BIRL with demonstration 10/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.183
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.26585386 -0.34229814  0.29811021 -0.24981355 -0.31601656  0.26246575
  0.70151441]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.005150
0.95-VaR bound for 10 demonstrations: -0.003783
0.99-VaR bound for 10 demonstrations: -0.002214
True expected value difference for MAP policy: -0.005228
Evaluating threshold 0.1 with avar bound: [-0.003782997452108328]
Threshold 0.1 SUFFICIENT with avar bound: -0.003782997452108328
Evaluating threshold 0.2 with avar bound: [-0.003782997452108328]
Threshold 0.2 SUFFICIENT with avar bound: -0.003782997452108328
Evaluating threshold 0.3 with avar bound: [-0.003782997452108328]
Threshold 0.3 SUFFICIENT with avar bound: -0.003782997452108328
Evaluating threshold 0.4 with avar bound: [-0.003782997452108328]
Threshold 0.4 SUFFICIENT with avar bound: -0.003782997452108328
Evaluating threshold 0.5 with avar bound: [-0.003782997452108328]
Threshold 0.5 SUFFICIENT with avar bound: -0.003782997452108328
Evaluating threshold 0.6 with avar bound: [-0.003782997452108328]
Threshold 0.6 SUFFICIENT with avar bound: -0.003782997452108328
Evaluating threshold 0.7 with avar bound: [-0.003782997452108328]
Threshold 0.7 SUFFICIENT with avar bound: -0.003782997452108328
Evaluating threshold 0.8 with avar bound: [-0.003782997452108328]
Threshold 0.8 SUFFICIENT with avar bound: -0.003782997452108328
Evaluating threshold 0.9 with avar bound: [-0.003782997452108328]
Threshold 0.9 SUFFICIENT with avar bound: -0.003782997452108328

Saving results to files...
Results saved successfully.

Running world 9/20

Running BIRL with demonstration 1/10 in world 9
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.387
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.1052824  -0.26267493 -0.15910315 -0.81432366  0.22838118  0.41763918
 -0.07000151]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 1.832756
0.95-VaR bound for 1 demonstrations: 2.298411
0.99-VaR bound for 1 demonstrations: 41.684284
True expected value difference for MAP policy: 0.931855
Evaluating threshold 0.1 with avar bound: [2.298410834646956]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.298410834646956]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.298410834646956]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.298410834646956]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.298410834646956]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.298410834646956]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.298410834646956]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.298410834646956]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.298410834646956]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 9
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.232
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.1362202  -0.16135036  0.14532052 -0.80304551  0.15123342  0.18320857
  0.48267281]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 1.147181
0.95-VaR bound for 2 demonstrations: 1.246616
0.99-VaR bound for 2 demonstrations: 4.030219
True expected value difference for MAP policy: -0.009478
Evaluating threshold 0.1 with avar bound: [1.2466163166779864]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.2466163166779864]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.2466163166779864]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.2466163166779864]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.2466163166779864]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.2466163166779864]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.2466163166779864]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.2466163166779864]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.2466163166779864]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 9
Current demos: [(16, 1), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.231
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.04634939  0.2085843   0.02298174 -0.6168323   0.20321976  0.03171327
  0.7287181 ]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.001280
0.95-VaR bound for 3 demonstrations: 0.008065
0.99-VaR bound for 3 demonstrations: 0.033906
True expected value difference for MAP policy: -0.004156
Evaluating threshold 0.1 with avar bound: [0.008064590782489105]
Threshold 0.1 SUFFICIENT with avar bound: 0.008064590782489105
Evaluating threshold 0.2 with avar bound: [0.008064590782489105]
Threshold 0.2 SUFFICIENT with avar bound: 0.008064590782489105
Evaluating threshold 0.3 with avar bound: [0.008064590782489105]
Threshold 0.3 SUFFICIENT with avar bound: 0.008064590782489105
Evaluating threshold 0.4 with avar bound: [0.008064590782489105]
Threshold 0.4 SUFFICIENT with avar bound: 0.008064590782489105
Evaluating threshold 0.5 with avar bound: [0.008064590782489105]
Threshold 0.5 SUFFICIENT with avar bound: 0.008064590782489105
Evaluating threshold 0.6 with avar bound: [0.008064590782489105]
Threshold 0.6 SUFFICIENT with avar bound: 0.008064590782489105
Evaluating threshold 0.7 with avar bound: [0.008064590782489105]
Threshold 0.7 SUFFICIENT with avar bound: 0.008064590782489105
Evaluating threshold 0.8 with avar bound: [0.008064590782489105]
Threshold 0.8 SUFFICIENT with avar bound: 0.008064590782489105
Evaluating threshold 0.9 with avar bound: [0.008064590782489105]
Threshold 0.9 SUFFICIENT with avar bound: 0.008064590782489105

Running BIRL with demonstration 4/10 in world 9
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.231
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.06406544 -0.18445331 -0.15986124 -0.76700613 -0.04076385 -0.26076731
  0.52759576]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: -0.000012
0.95-VaR bound for 4 demonstrations: 0.003990
0.99-VaR bound for 4 demonstrations: 0.012612
True expected value difference for MAP policy: -0.001270
Evaluating threshold 0.1 with avar bound: [0.003990126717131441]
Threshold 0.1 SUFFICIENT with avar bound: 0.003990126717131441
Evaluating threshold 0.2 with avar bound: [0.003990126717131441]
Threshold 0.2 SUFFICIENT with avar bound: 0.003990126717131441
Evaluating threshold 0.3 with avar bound: [0.003990126717131441]
Threshold 0.3 SUFFICIENT with avar bound: 0.003990126717131441
Evaluating threshold 0.4 with avar bound: [0.003990126717131441]
Threshold 0.4 SUFFICIENT with avar bound: 0.003990126717131441
Evaluating threshold 0.5 with avar bound: [0.003990126717131441]
Threshold 0.5 SUFFICIENT with avar bound: 0.003990126717131441
Evaluating threshold 0.6 with avar bound: [0.003990126717131441]
Threshold 0.6 SUFFICIENT with avar bound: 0.003990126717131441
Evaluating threshold 0.7 with avar bound: [0.003990126717131441]
Threshold 0.7 SUFFICIENT with avar bound: 0.003990126717131441
Evaluating threshold 0.8 with avar bound: [0.003990126717131441]
Threshold 0.8 SUFFICIENT with avar bound: 0.003990126717131441
Evaluating threshold 0.9 with avar bound: [0.003990126717131441]
Threshold 0.9 SUFFICIENT with avar bound: 0.003990126717131441

Running BIRL with demonstration 5/10 in world 9
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.22
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.02823983 -0.33857103 -0.23982152 -0.67817839  0.14859728 -0.21634771
  0.54611756]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.005576
0.95-VaR bound for 5 demonstrations: 0.002931
0.99-VaR bound for 5 demonstrations: 0.006346
True expected value difference for MAP policy: -0.009315
Evaluating threshold 0.1 with avar bound: [0.0029310245825410882]
Threshold 0.1 SUFFICIENT with avar bound: 0.0029310245825410882
Evaluating threshold 0.2 with avar bound: [0.0029310245825410882]
Threshold 0.2 SUFFICIENT with avar bound: 0.0029310245825410882
Evaluating threshold 0.3 with avar bound: [0.0029310245825410882]
Threshold 0.3 SUFFICIENT with avar bound: 0.0029310245825410882
Evaluating threshold 0.4 with avar bound: [0.0029310245825410882]
Threshold 0.4 SUFFICIENT with avar bound: 0.0029310245825410882
Evaluating threshold 0.5 with avar bound: [0.0029310245825410882]
Threshold 0.5 SUFFICIENT with avar bound: 0.0029310245825410882
Evaluating threshold 0.6 with avar bound: [0.0029310245825410882]
Threshold 0.6 SUFFICIENT with avar bound: 0.0029310245825410882
Evaluating threshold 0.7 with avar bound: [0.0029310245825410882]
Threshold 0.7 SUFFICIENT with avar bound: 0.0029310245825410882
Evaluating threshold 0.8 with avar bound: [0.0029310245825410882]
Threshold 0.8 SUFFICIENT with avar bound: 0.0029310245825410882
Evaluating threshold 0.9 with avar bound: [0.0029310245825410882]
Threshold 0.9 SUFFICIENT with avar bound: 0.0029310245825410882

Running BIRL with demonstration 6/10 in world 9
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.24506826 -0.27987001 -0.09264122 -0.48374126  0.34621642 -0.15158267
  0.6900603 ]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.006225
0.95-VaR bound for 6 demonstrations: -0.004492
0.99-VaR bound for 6 demonstrations: -0.000327
True expected value difference for MAP policy: -0.009315
Evaluating threshold 0.1 with avar bound: [-0.004492344568098535]
Threshold 0.1 SUFFICIENT with avar bound: -0.004492344568098535
Evaluating threshold 0.2 with avar bound: [-0.004492344568098535]
Threshold 0.2 SUFFICIENT with avar bound: -0.004492344568098535
Evaluating threshold 0.3 with avar bound: [-0.004492344568098535]
Threshold 0.3 SUFFICIENT with avar bound: -0.004492344568098535
Evaluating threshold 0.4 with avar bound: [-0.004492344568098535]
Threshold 0.4 SUFFICIENT with avar bound: -0.004492344568098535
Evaluating threshold 0.5 with avar bound: [-0.004492344568098535]
Threshold 0.5 SUFFICIENT with avar bound: -0.004492344568098535
Evaluating threshold 0.6 with avar bound: [-0.004492344568098535]
Threshold 0.6 SUFFICIENT with avar bound: -0.004492344568098535
Evaluating threshold 0.7 with avar bound: [-0.004492344568098535]
Threshold 0.7 SUFFICIENT with avar bound: -0.004492344568098535
Evaluating threshold 0.8 with avar bound: [-0.004492344568098535]
Threshold 0.8 SUFFICIENT with avar bound: -0.004492344568098535
Evaluating threshold 0.9 with avar bound: [-0.004492344568098535]
Threshold 0.9 SUFFICIENT with avar bound: -0.004492344568098535

Running BIRL with demonstration 7/10 in world 9
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.203
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.25850599 -0.39404999 -0.05335729 -0.62152513  0.18566685 -0.14981837
  0.57605647]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.006847
0.95-VaR bound for 7 demonstrations: -0.005354
0.99-VaR bound for 7 demonstrations: 0.027758
True expected value difference for MAP policy: -0.009315
Evaluating threshold 0.1 with avar bound: [-0.0053543411242393995]
Threshold 0.1 SUFFICIENT with avar bound: -0.0053543411242393995
Evaluating threshold 0.2 with avar bound: [-0.0053543411242393995]
Threshold 0.2 SUFFICIENT with avar bound: -0.0053543411242393995
Evaluating threshold 0.3 with avar bound: [-0.0053543411242393995]
Threshold 0.3 SUFFICIENT with avar bound: -0.0053543411242393995
Evaluating threshold 0.4 with avar bound: [-0.0053543411242393995]
Threshold 0.4 SUFFICIENT with avar bound: -0.0053543411242393995
Evaluating threshold 0.5 with avar bound: [-0.0053543411242393995]
Threshold 0.5 SUFFICIENT with avar bound: -0.0053543411242393995
Evaluating threshold 0.6 with avar bound: [-0.0053543411242393995]
Threshold 0.6 SUFFICIENT with avar bound: -0.0053543411242393995
Evaluating threshold 0.7 with avar bound: [-0.0053543411242393995]
Threshold 0.7 SUFFICIENT with avar bound: -0.0053543411242393995
Evaluating threshold 0.8 with avar bound: [-0.0053543411242393995]
Threshold 0.8 SUFFICIENT with avar bound: -0.0053543411242393995
Evaluating threshold 0.9 with avar bound: [-0.0053543411242393995]
Threshold 0.9 SUFFICIENT with avar bound: -0.0053543411242393995

Running BIRL with demonstration 8/10 in world 9
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.163
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.36042642 -0.40324483 -0.03131466 -0.22009056  0.17565017  0.56617431
  0.55376854]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: 0.010829
0.95-VaR bound for 8 demonstrations: 0.015110
0.99-VaR bound for 8 demonstrations: 0.042418
True expected value difference for MAP policy: 0.006343
Evaluating threshold 0.1 with avar bound: [0.015110495878104084]
Threshold 0.1 SUFFICIENT with avar bound: 0.015110495878104084
Evaluating threshold 0.2 with avar bound: [0.015110495878104084]
Threshold 0.2 SUFFICIENT with avar bound: 0.015110495878104084
Evaluating threshold 0.3 with avar bound: [0.015110495878104084]
Threshold 0.3 SUFFICIENT with avar bound: 0.015110495878104084
Evaluating threshold 0.4 with avar bound: [0.015110495878104084]
Threshold 0.4 SUFFICIENT with avar bound: 0.015110495878104084
Evaluating threshold 0.5 with avar bound: [0.015110495878104084]
Threshold 0.5 SUFFICIENT with avar bound: 0.015110495878104084
Evaluating threshold 0.6 with avar bound: [0.015110495878104084]
Threshold 0.6 SUFFICIENT with avar bound: 0.015110495878104084
Evaluating threshold 0.7 with avar bound: [0.015110495878104084]
Threshold 0.7 SUFFICIENT with avar bound: 0.015110495878104084
Evaluating threshold 0.8 with avar bound: [0.015110495878104084]
Threshold 0.8 SUFFICIENT with avar bound: 0.015110495878104084
Evaluating threshold 0.9 with avar bound: [0.015110495878104084]
Threshold 0.9 SUFFICIENT with avar bound: 0.015110495878104084

Running BIRL with demonstration 9/10 in world 9
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.147
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.05486515 -0.37271962 -0.15064922 -0.61173361  0.0494731   0.48431061
  0.4734473 ]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: 0.003064
0.95-VaR bound for 9 demonstrations: 0.005552
0.99-VaR bound for 9 demonstrations: 0.041202
True expected value difference for MAP policy: 0.003563
Evaluating threshold 0.1 with avar bound: [0.005552381159384538]
Threshold 0.1 SUFFICIENT with avar bound: 0.005552381159384538
Evaluating threshold 0.2 with avar bound: [0.005552381159384538]
Threshold 0.2 SUFFICIENT with avar bound: 0.005552381159384538
Evaluating threshold 0.3 with avar bound: [0.005552381159384538]
Threshold 0.3 SUFFICIENT with avar bound: 0.005552381159384538
Evaluating threshold 0.4 with avar bound: [0.005552381159384538]
Threshold 0.4 SUFFICIENT with avar bound: 0.005552381159384538
Evaluating threshold 0.5 with avar bound: [0.005552381159384538]
Threshold 0.5 SUFFICIENT with avar bound: 0.005552381159384538
Evaluating threshold 0.6 with avar bound: [0.005552381159384538]
Threshold 0.6 SUFFICIENT with avar bound: 0.005552381159384538
Evaluating threshold 0.7 with avar bound: [0.005552381159384538]
Threshold 0.7 SUFFICIENT with avar bound: 0.005552381159384538
Evaluating threshold 0.8 with avar bound: [0.005552381159384538]
Threshold 0.8 SUFFICIENT with avar bound: 0.005552381159384538
Evaluating threshold 0.9 with avar bound: [0.005552381159384538]
Threshold 0.9 SUFFICIENT with avar bound: 0.005552381159384538

Running BIRL with demonstration 10/10 in world 9
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.152
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.28833274 -0.15638282 -0.17845967 -0.42510147  0.03205619  0.58575783
  0.57940461]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: 0.007142
0.95-VaR bound for 10 demonstrations: 0.008082
0.99-VaR bound for 10 demonstrations: 0.020716
True expected value difference for MAP policy: 0.008428
Evaluating threshold 0.1 with avar bound: [0.008082043631540792]
Threshold 0.1 SUFFICIENT with avar bound: 0.008082043631540792
Evaluating threshold 0.2 with avar bound: [0.008082043631540792]
Threshold 0.2 SUFFICIENT with avar bound: 0.008082043631540792
Evaluating threshold 0.3 with avar bound: [0.008082043631540792]
Threshold 0.3 SUFFICIENT with avar bound: 0.008082043631540792
Evaluating threshold 0.4 with avar bound: [0.008082043631540792]
Threshold 0.4 SUFFICIENT with avar bound: 0.008082043631540792
Evaluating threshold 0.5 with avar bound: [0.008082043631540792]
Threshold 0.5 SUFFICIENT with avar bound: 0.008082043631540792
Evaluating threshold 0.6 with avar bound: [0.008082043631540792]
Threshold 0.6 SUFFICIENT with avar bound: 0.008082043631540792
Evaluating threshold 0.7 with avar bound: [0.008082043631540792]
Threshold 0.7 SUFFICIENT with avar bound: 0.008082043631540792
Evaluating threshold 0.8 with avar bound: [0.008082043631540792]
Threshold 0.8 SUFFICIENT with avar bound: 0.008082043631540792
Evaluating threshold 0.9 with avar bound: [0.008082043631540792]
Threshold 0.9 SUFFICIENT with avar bound: 0.008082043631540792

Running world 10/20

Running BIRL with demonstration 1/10 in world 10
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.319
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.6601682  -0.09431128  0.51605324  0.37666526 -0.31624736 -0.13285228
  0.17156208]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.377906
0.95-VaR bound for 1 demonstrations: 6.976082
0.99-VaR bound for 1 demonstrations: 21.739974
True expected value difference for MAP policy: 1.527273
Evaluating threshold 0.1 with avar bound: [6.976081858188742]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [6.976081858188742]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [6.976081858188742]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [6.976081858188742]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [6.976081858188742]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [6.976081858188742]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [6.976081858188742]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [6.976081858188742]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [6.976081858188742]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 10
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.227
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.55340602 -0.03194035  0.22022917  0.30153765  0.3506481   0.24973839
  0.60660728]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 0.011362
0.95-VaR bound for 2 demonstrations: 0.460721
0.99-VaR bound for 2 demonstrations: 2.657676
True expected value difference for MAP policy: -0.007491
Evaluating threshold 0.1 with avar bound: [0.46072052398889657]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.46072052398889657]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.46072052398889657]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.46072052398889657]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.46072052398889657]
Threshold 0.5 SUFFICIENT with avar bound: 0.46072052398889657
Evaluating threshold 0.6 with avar bound: [0.46072052398889657]
Threshold 0.6 SUFFICIENT with avar bound: 0.46072052398889657
Evaluating threshold 0.7 with avar bound: [0.46072052398889657]
Threshold 0.7 SUFFICIENT with avar bound: 0.46072052398889657
Evaluating threshold 0.8 with avar bound: [0.46072052398889657]
Threshold 0.8 SUFFICIENT with avar bound: 0.46072052398889657
Evaluating threshold 0.9 with avar bound: [0.46072052398889657]
Threshold 0.9 SUFFICIENT with avar bound: 0.46072052398889657

Running BIRL with demonstration 3/10 in world 10
Current demos: [(16, 1), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.228
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.73803493 -0.14814982 -0.02075174  0.02729815  0.03931295  0.19230594
  0.62741786]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.002104
0.95-VaR bound for 3 demonstrations: 0.011797
0.99-VaR bound for 3 demonstrations: 0.022798
True expected value difference for MAP policy: -0.008034
Evaluating threshold 0.1 with avar bound: [0.011797458728204464]
Threshold 0.1 SUFFICIENT with avar bound: 0.011797458728204464
Evaluating threshold 0.2 with avar bound: [0.011797458728204464]
Threshold 0.2 SUFFICIENT with avar bound: 0.011797458728204464
Evaluating threshold 0.3 with avar bound: [0.011797458728204464]
Threshold 0.3 SUFFICIENT with avar bound: 0.011797458728204464
Evaluating threshold 0.4 with avar bound: [0.011797458728204464]
Threshold 0.4 SUFFICIENT with avar bound: 0.011797458728204464
Evaluating threshold 0.5 with avar bound: [0.011797458728204464]
Threshold 0.5 SUFFICIENT with avar bound: 0.011797458728204464
Evaluating threshold 0.6 with avar bound: [0.011797458728204464]
Threshold 0.6 SUFFICIENT with avar bound: 0.011797458728204464
Evaluating threshold 0.7 with avar bound: [0.011797458728204464]
Threshold 0.7 SUFFICIENT with avar bound: 0.011797458728204464
Evaluating threshold 0.8 with avar bound: [0.011797458728204464]
Threshold 0.8 SUFFICIENT with avar bound: 0.011797458728204464
Evaluating threshold 0.9 with avar bound: [0.011797458728204464]
Threshold 0.9 SUFFICIENT with avar bound: 0.011797458728204464

Running BIRL with demonstration 4/10 in world 10
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.219
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.72371875  0.0214069   0.18370758  0.13175402  0.11706005  0.00505244
  0.64104348]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.007221
0.95-VaR bound for 4 demonstrations: 0.018989
0.99-VaR bound for 4 demonstrations: 0.485186
True expected value difference for MAP policy: -0.002150
Evaluating threshold 0.1 with avar bound: [0.018989406422561885]
Threshold 0.1 SUFFICIENT with avar bound: 0.018989406422561885
Evaluating threshold 0.2 with avar bound: [0.018989406422561885]
Threshold 0.2 SUFFICIENT with avar bound: 0.018989406422561885
Evaluating threshold 0.3 with avar bound: [0.018989406422561885]
Threshold 0.3 SUFFICIENT with avar bound: 0.018989406422561885
Evaluating threshold 0.4 with avar bound: [0.018989406422561885]
Threshold 0.4 SUFFICIENT with avar bound: 0.018989406422561885
Evaluating threshold 0.5 with avar bound: [0.018989406422561885]
Threshold 0.5 SUFFICIENT with avar bound: 0.018989406422561885
Evaluating threshold 0.6 with avar bound: [0.018989406422561885]
Threshold 0.6 SUFFICIENT with avar bound: 0.018989406422561885
Evaluating threshold 0.7 with avar bound: [0.018989406422561885]
Threshold 0.7 SUFFICIENT with avar bound: 0.018989406422561885
Evaluating threshold 0.8 with avar bound: [0.018989406422561885]
Threshold 0.8 SUFFICIENT with avar bound: 0.018989406422561885
Evaluating threshold 0.9 with avar bound: [0.018989406422561885]
Threshold 0.9 SUFFICIENT with avar bound: 0.018989406422561885

Running BIRL with demonstration 5/10 in world 10
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.201
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.82999963 -0.05865993 -0.10995098 -0.04205493 -0.32412208 -0.02290492
  0.43384564]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.003130
0.95-VaR bound for 5 demonstrations: 0.001159
0.99-VaR bound for 5 demonstrations: 0.039694
True expected value difference for MAP policy: -0.006935
Evaluating threshold 0.1 with avar bound: [0.0011587580653367605]
Threshold 0.1 SUFFICIENT with avar bound: 0.0011587580653367605
Evaluating threshold 0.2 with avar bound: [0.0011587580653367605]
Threshold 0.2 SUFFICIENT with avar bound: 0.0011587580653367605
Evaluating threshold 0.3 with avar bound: [0.0011587580653367605]
Threshold 0.3 SUFFICIENT with avar bound: 0.0011587580653367605
Evaluating threshold 0.4 with avar bound: [0.0011587580653367605]
Threshold 0.4 SUFFICIENT with avar bound: 0.0011587580653367605
Evaluating threshold 0.5 with avar bound: [0.0011587580653367605]
Threshold 0.5 SUFFICIENT with avar bound: 0.0011587580653367605
Evaluating threshold 0.6 with avar bound: [0.0011587580653367605]
Threshold 0.6 SUFFICIENT with avar bound: 0.0011587580653367605
Evaluating threshold 0.7 with avar bound: [0.0011587580653367605]
Threshold 0.7 SUFFICIENT with avar bound: 0.0011587580653367605
Evaluating threshold 0.8 with avar bound: [0.0011587580653367605]
Threshold 0.8 SUFFICIENT with avar bound: 0.0011587580653367605
Evaluating threshold 0.9 with avar bound: [0.0011587580653367605]
Threshold 0.9 SUFFICIENT with avar bound: 0.0011587580653367605

Running BIRL with demonstration 6/10 in world 10
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.77589854 -0.16020383  0.02429391  0.2995405  -0.10040989  0.20482885
  0.47954612]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.003326
0.95-VaR bound for 6 demonstrations: -0.000138
0.99-VaR bound for 6 demonstrations: 0.009492
True expected value difference for MAP policy: -0.007794
Evaluating threshold 0.1 with avar bound: [-0.0001384777229461625]
Threshold 0.1 SUFFICIENT with avar bound: -0.0001384777229461625
Evaluating threshold 0.2 with avar bound: [-0.0001384777229461625]
Threshold 0.2 SUFFICIENT with avar bound: -0.0001384777229461625
Evaluating threshold 0.3 with avar bound: [-0.0001384777229461625]
Threshold 0.3 SUFFICIENT with avar bound: -0.0001384777229461625
Evaluating threshold 0.4 with avar bound: [-0.0001384777229461625]
Threshold 0.4 SUFFICIENT with avar bound: -0.0001384777229461625
Evaluating threshold 0.5 with avar bound: [-0.0001384777229461625]
Threshold 0.5 SUFFICIENT with avar bound: -0.0001384777229461625
Evaluating threshold 0.6 with avar bound: [-0.0001384777229461625]
Threshold 0.6 SUFFICIENT with avar bound: -0.0001384777229461625
Evaluating threshold 0.7 with avar bound: [-0.0001384777229461625]
Threshold 0.7 SUFFICIENT with avar bound: -0.0001384777229461625
Evaluating threshold 0.8 with avar bound: [-0.0001384777229461625]
Threshold 0.8 SUFFICIENT with avar bound: -0.0001384777229461625
Evaluating threshold 0.9 with avar bound: [-0.0001384777229461625]
Threshold 0.9 SUFFICIENT with avar bound: -0.0001384777229461625

Running BIRL with demonstration 7/10 in world 10
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 0)]
MCMC sampling complete.
Acceptance ratio: 0.147
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.80557994 -0.02673291 -0.16655759  0.24145747 -0.08861091  0.24292598
  0.44431773]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.007409
0.95-VaR bound for 7 demonstrations: -0.007409
0.99-VaR bound for 7 demonstrations: -0.006659
True expected value difference for MAP policy: -0.008463
Evaluating threshold 0.1 with avar bound: [-0.007409121894203792]
Threshold 0.1 SUFFICIENT with avar bound: -0.007409121894203792
Evaluating threshold 0.2 with avar bound: [-0.007409121894203792]
Threshold 0.2 SUFFICIENT with avar bound: -0.007409121894203792
Evaluating threshold 0.3 with avar bound: [-0.007409121894203792]
Threshold 0.3 SUFFICIENT with avar bound: -0.007409121894203792
Evaluating threshold 0.4 with avar bound: [-0.007409121894203792]
Threshold 0.4 SUFFICIENT with avar bound: -0.007409121894203792
Evaluating threshold 0.5 with avar bound: [-0.007409121894203792]
Threshold 0.5 SUFFICIENT with avar bound: -0.007409121894203792
Evaluating threshold 0.6 with avar bound: [-0.007409121894203792]
Threshold 0.6 SUFFICIENT with avar bound: -0.007409121894203792
Evaluating threshold 0.7 with avar bound: [-0.007409121894203792]
Threshold 0.7 SUFFICIENT with avar bound: -0.007409121894203792
Evaluating threshold 0.8 with avar bound: [-0.007409121894203792]
Threshold 0.8 SUFFICIENT with avar bound: -0.007409121894203792
Evaluating threshold 0.9 with avar bound: [-0.007409121894203792]
Threshold 0.9 SUFFICIENT with avar bound: -0.007409121894203792

Running BIRL with demonstration 8/10 in world 10
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 0), (10, 0)]
MCMC sampling complete.
Acceptance ratio: 0.127
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.41832038 -0.41856385 -0.11864541  0.31348827  0.29101284  0.37641614
  0.55774828]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.007071
0.95-VaR bound for 8 demonstrations: -0.003132
0.99-VaR bound for 8 demonstrations: 0.021838
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.003131992080026157]
Threshold 0.1 SUFFICIENT with avar bound: -0.003131992080026157
Evaluating threshold 0.2 with avar bound: [-0.003131992080026157]
Threshold 0.2 SUFFICIENT with avar bound: -0.003131992080026157
Evaluating threshold 0.3 with avar bound: [-0.003131992080026157]
Threshold 0.3 SUFFICIENT with avar bound: -0.003131992080026157
Evaluating threshold 0.4 with avar bound: [-0.003131992080026157]
Threshold 0.4 SUFFICIENT with avar bound: -0.003131992080026157
Evaluating threshold 0.5 with avar bound: [-0.003131992080026157]
Threshold 0.5 SUFFICIENT with avar bound: -0.003131992080026157
Evaluating threshold 0.6 with avar bound: [-0.003131992080026157]
Threshold 0.6 SUFFICIENT with avar bound: -0.003131992080026157
Evaluating threshold 0.7 with avar bound: [-0.003131992080026157]
Threshold 0.7 SUFFICIENT with avar bound: -0.003131992080026157
Evaluating threshold 0.8 with avar bound: [-0.003131992080026157]
Threshold 0.8 SUFFICIENT with avar bound: -0.003131992080026157
Evaluating threshold 0.9 with avar bound: [-0.003131992080026157]
Threshold 0.9 SUFFICIENT with avar bound: -0.003131992080026157

Running BIRL with demonstration 9/10 in world 10
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 0), (10, 0), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.135
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.75368385 -0.3110487  -0.23013011  0.14398062  0.06092678  0.27353187
  0.42777016]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.007170
0.95-VaR bound for 9 demonstrations: -0.006944
0.99-VaR bound for 9 demonstrations: -0.000195
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.006943804177991026]
Threshold 0.1 SUFFICIENT with avar bound: -0.006943804177991026
Evaluating threshold 0.2 with avar bound: [-0.006943804177991026]
Threshold 0.2 SUFFICIENT with avar bound: -0.006943804177991026
Evaluating threshold 0.3 with avar bound: [-0.006943804177991026]
Threshold 0.3 SUFFICIENT with avar bound: -0.006943804177991026
Evaluating threshold 0.4 with avar bound: [-0.006943804177991026]
Threshold 0.4 SUFFICIENT with avar bound: -0.006943804177991026
Evaluating threshold 0.5 with avar bound: [-0.006943804177991026]
Threshold 0.5 SUFFICIENT with avar bound: -0.006943804177991026
Evaluating threshold 0.6 with avar bound: [-0.006943804177991026]
Threshold 0.6 SUFFICIENT with avar bound: -0.006943804177991026
Evaluating threshold 0.7 with avar bound: [-0.006943804177991026]
Threshold 0.7 SUFFICIENT with avar bound: -0.006943804177991026
Evaluating threshold 0.8 with avar bound: [-0.006943804177991026]
Threshold 0.8 SUFFICIENT with avar bound: -0.006943804177991026
Evaluating threshold 0.9 with avar bound: [-0.006943804177991026]
Threshold 0.9 SUFFICIENT with avar bound: -0.006943804177991026

Running BIRL with demonstration 10/10 in world 10
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 0), (10, 0), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.123
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.70808921 -0.23308448 -0.35365154  0.33476536  0.01410869  0.20940909
  0.40384752]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.004752
0.95-VaR bound for 10 demonstrations: -0.001663
0.99-VaR bound for 10 demonstrations: 0.046436
True expected value difference for MAP policy: -0.009003
Evaluating threshold 0.1 with avar bound: [-0.001663213143634346]
Threshold 0.1 SUFFICIENT with avar bound: -0.001663213143634346
Evaluating threshold 0.2 with avar bound: [-0.001663213143634346]
Threshold 0.2 SUFFICIENT with avar bound: -0.001663213143634346
Evaluating threshold 0.3 with avar bound: [-0.001663213143634346]
Threshold 0.3 SUFFICIENT with avar bound: -0.001663213143634346
Evaluating threshold 0.4 with avar bound: [-0.001663213143634346]
Threshold 0.4 SUFFICIENT with avar bound: -0.001663213143634346
Evaluating threshold 0.5 with avar bound: [-0.001663213143634346]
Threshold 0.5 SUFFICIENT with avar bound: -0.001663213143634346
Evaluating threshold 0.6 with avar bound: [-0.001663213143634346]
Threshold 0.6 SUFFICIENT with avar bound: -0.001663213143634346
Evaluating threshold 0.7 with avar bound: [-0.001663213143634346]
Threshold 0.7 SUFFICIENT with avar bound: -0.001663213143634346
Evaluating threshold 0.8 with avar bound: [-0.001663213143634346]
Threshold 0.8 SUFFICIENT with avar bound: -0.001663213143634346
Evaluating threshold 0.9 with avar bound: [-0.001663213143634346]
Threshold 0.9 SUFFICIENT with avar bound: -0.001663213143634346

Running world 11/20

Running BIRL with demonstration 1/10 in world 11
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.377
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.01114186  0.66508858 -0.27166126 -0.4285182  -0.49288408 -0.21140195
  0.11171326]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 1.508498
0.95-VaR bound for 1 demonstrations: 2.087102
0.99-VaR bound for 1 demonstrations: 6.051709
