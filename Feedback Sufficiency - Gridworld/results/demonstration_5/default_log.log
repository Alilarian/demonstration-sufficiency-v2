Config file loaded successfully.
Running experiment with 20 worlds and 10 demonstrations per world.
Feature weights for environment: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Feature weights for environment: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Feature weights for environment: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Feature weights for environment: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Feature weights for environment: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Feature weights for environment: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Feature weights for environment: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Feature weights for environment: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Feature weights for environment: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Feature weights for environment: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Feature weights for environment: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Feature weights for environment: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Feature weights for environment: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Feature weights for environment: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Feature weights for environment: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Feature weights for environment: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Feature weights for environment: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Feature weights for environment: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Feature weights for environment: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Feature weights for environment: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Initialized 20 GridWorld environments.
Generated optimal policies for all environments.
Shuffled demonstration order: [16, 12, 9, 19, 18, 6, 5, 10, 15, 21, 11, 17, 1, 14, 22, 13, 2, 23, 4, 24, 7, 8, 0, 3, 20]

Running world 1/20

Running BIRL with demonstration 1/10 in world 1
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.461
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.00148838 -0.59572823  0.12581923  0.42800038 -0.21112752 -0.46388153
  0.43165954]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.901212
0.9-VaR bound for 1 demonstrations: 2.475100
0.95-VaR bound for 1 demonstrations: 3.782701
0.99-VaR bound for 1 demonstrations: 8.428302
True expected value difference for MAP policy: -0.003580
Evaluating threshold 0.1 with avar bound: [3.7827006716989566]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.7827006716989566]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.7827006716989566]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.7827006716989566]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.7827006716989566]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.7827006716989566]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.7827006716989566]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.7827006716989566]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.7827006716989566]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 1
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.319
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.48812091  0.31626378 -0.21431884  0.10262494  0.34319518 -0.49674799
  0.4906213 ]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.848140
0.9-VaR bound for 2 demonstrations: 2.714375
0.95-VaR bound for 2 demonstrations: 3.496444
0.99-VaR bound for 2 demonstrations: 10.133008
True expected value difference for MAP policy: -0.003031
Evaluating threshold 0.1 with avar bound: [3.4964444253380855]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.4964444253380855]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.4964444253380855]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.4964444253380855]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.4964444253380855]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.4964444253380855]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.4964444253380855]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.4964444253380855]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.4964444253380855]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.259
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34958741 -0.12062512 -0.03507228 -0.37154604  0.19286576 -0.48496088
  0.67199512]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.005237
0.9-VaR bound for 3 demonstrations: 0.008558
0.95-VaR bound for 3 demonstrations: 0.023370
0.99-VaR bound for 3 demonstrations: 1.257575
True expected value difference for MAP policy: -0.005025
Evaluating threshold 0.1 with avar bound: [0.023369715500511052]
Threshold 0.1 SUFFICIENT with avar bound: 0.023369715500511052
Evaluating threshold 0.2 with avar bound: [0.023369715500511052]
Threshold 0.2 SUFFICIENT with avar bound: 0.023369715500511052
Evaluating threshold 0.3 with avar bound: [0.023369715500511052]
Threshold 0.3 SUFFICIENT with avar bound: 0.023369715500511052
Evaluating threshold 0.4 with avar bound: [0.023369715500511052]
Threshold 0.4 SUFFICIENT with avar bound: 0.023369715500511052
Evaluating threshold 0.5 with avar bound: [0.023369715500511052]
Threshold 0.5 SUFFICIENT with avar bound: 0.023369715500511052
Evaluating threshold 0.6 with avar bound: [0.023369715500511052]
Threshold 0.6 SUFFICIENT with avar bound: 0.023369715500511052
Evaluating threshold 0.7 with avar bound: [0.023369715500511052]
Threshold 0.7 SUFFICIENT with avar bound: 0.023369715500511052
Evaluating threshold 0.8 with avar bound: [0.023369715500511052]
Threshold 0.8 SUFFICIENT with avar bound: 0.023369715500511052
Evaluating threshold 0.9 with avar bound: [0.023369715500511052]
Threshold 0.9 SUFFICIENT with avar bound: 0.023369715500511052

Running BIRL with demonstration 4/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.252
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50724481 -0.18095818  0.36457689 -0.23615215  0.18431084 -0.52651781
  0.45834616]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.001200
0.9-VaR bound for 4 demonstrations: 0.004445
0.95-VaR bound for 4 demonstrations: 0.007664
0.99-VaR bound for 4 demonstrations: 0.041141
True expected value difference for MAP policy: -0.004441
Evaluating threshold 0.1 with avar bound: [0.007664278044733169]
Threshold 0.1 SUFFICIENT with avar bound: 0.007664278044733169
Evaluating threshold 0.2 with avar bound: [0.007664278044733169]
Threshold 0.2 SUFFICIENT with avar bound: 0.007664278044733169
Evaluating threshold 0.3 with avar bound: [0.007664278044733169]
Threshold 0.3 SUFFICIENT with avar bound: 0.007664278044733169
Evaluating threshold 0.4 with avar bound: [0.007664278044733169]
Threshold 0.4 SUFFICIENT with avar bound: 0.007664278044733169
Evaluating threshold 0.5 with avar bound: [0.007664278044733169]
Threshold 0.5 SUFFICIENT with avar bound: 0.007664278044733169
Evaluating threshold 0.6 with avar bound: [0.007664278044733169]
Threshold 0.6 SUFFICIENT with avar bound: 0.007664278044733169
Evaluating threshold 0.7 with avar bound: [0.007664278044733169]
Threshold 0.7 SUFFICIENT with avar bound: 0.007664278044733169
Evaluating threshold 0.8 with avar bound: [0.007664278044733169]
Threshold 0.8 SUFFICIENT with avar bound: 0.007664278044733169
Evaluating threshold 0.9 with avar bound: [0.007664278044733169]
Threshold 0.9 SUFFICIENT with avar bound: 0.007664278044733169

Running BIRL with demonstration 5/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.236
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.33763613 -0.27749422  0.18900087 -0.26857905  0.24539702 -0.7026606
  0.38365499]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.000758
0.9-VaR bound for 5 demonstrations: 0.002122
0.95-VaR bound for 5 demonstrations: 0.005454
0.99-VaR bound for 5 demonstrations: 0.054363
True expected value difference for MAP policy: -0.004086
Evaluating threshold 0.1 with avar bound: [0.005453584862109424]
Threshold 0.1 SUFFICIENT with avar bound: 0.005453584862109424
Evaluating threshold 0.2 with avar bound: [0.005453584862109424]
Threshold 0.2 SUFFICIENT with avar bound: 0.005453584862109424
Evaluating threshold 0.3 with avar bound: [0.005453584862109424]
Threshold 0.3 SUFFICIENT with avar bound: 0.005453584862109424
Evaluating threshold 0.4 with avar bound: [0.005453584862109424]
Threshold 0.4 SUFFICIENT with avar bound: 0.005453584862109424
Evaluating threshold 0.5 with avar bound: [0.005453584862109424]
Threshold 0.5 SUFFICIENT with avar bound: 0.005453584862109424
Evaluating threshold 0.6 with avar bound: [0.005453584862109424]
Threshold 0.6 SUFFICIENT with avar bound: 0.005453584862109424
Evaluating threshold 0.7 with avar bound: [0.005453584862109424]
Threshold 0.7 SUFFICIENT with avar bound: 0.005453584862109424
Evaluating threshold 0.8 with avar bound: [0.005453584862109424]
Threshold 0.8 SUFFICIENT with avar bound: 0.005453584862109424
Evaluating threshold 0.9 with avar bound: [0.005453584862109424]
Threshold 0.9 SUFFICIENT with avar bound: 0.005453584862109424

Running BIRL with demonstration 6/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.219
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.35685693 -0.51708911 -0.06452339 -0.60808733  0.21838173  0.05400699
  0.42512491]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.006825
0.9-VaR bound for 6 demonstrations: -0.005735
0.95-VaR bound for 6 demonstrations: -0.003297
0.99-VaR bound for 6 demonstrations: -0.000164
True expected value difference for MAP policy: -0.009817
Evaluating threshold 0.1 with avar bound: [-0.0032970081539264776]
Threshold 0.1 SUFFICIENT with avar bound: -0.0032970081539264776
Evaluating threshold 0.2 with avar bound: [-0.0032970081539264776]
Threshold 0.2 SUFFICIENT with avar bound: -0.0032970081539264776
Evaluating threshold 0.3 with avar bound: [-0.0032970081539264776]
Threshold 0.3 SUFFICIENT with avar bound: -0.0032970081539264776
Evaluating threshold 0.4 with avar bound: [-0.0032970081539264776]
Threshold 0.4 SUFFICIENT with avar bound: -0.0032970081539264776
Evaluating threshold 0.5 with avar bound: [-0.0032970081539264776]
Threshold 0.5 SUFFICIENT with avar bound: -0.0032970081539264776
Evaluating threshold 0.6 with avar bound: [-0.0032970081539264776]
Threshold 0.6 SUFFICIENT with avar bound: -0.0032970081539264776
Evaluating threshold 0.7 with avar bound: [-0.0032970081539264776]
Threshold 0.7 SUFFICIENT with avar bound: -0.0032970081539264776
Evaluating threshold 0.8 with avar bound: [-0.0032970081539264776]
Threshold 0.8 SUFFICIENT with avar bound: -0.0032970081539264776
Evaluating threshold 0.9 with avar bound: [-0.0032970081539264776]
Threshold 0.9 SUFFICIENT with avar bound: -0.0032970081539264776

Running BIRL with demonstration 7/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.188
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.2470117  -0.4540989  -0.17639722 -0.10142955  0.23424988  0.51959407
  0.60541265]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.007560
0.9-VaR bound for 7 demonstrations: -0.007040
0.95-VaR bound for 7 demonstrations: -0.006124
0.99-VaR bound for 7 demonstrations: -0.001428
True expected value difference for MAP policy: -0.009903
Evaluating threshold 0.1 with avar bound: [-0.006124430719442988]
Threshold 0.1 SUFFICIENT with avar bound: -0.006124430719442988
Evaluating threshold 0.2 with avar bound: [-0.006124430719442988]
Threshold 0.2 SUFFICIENT with avar bound: -0.006124430719442988
Evaluating threshold 0.3 with avar bound: [-0.006124430719442988]
Threshold 0.3 SUFFICIENT with avar bound: -0.006124430719442988
Evaluating threshold 0.4 with avar bound: [-0.006124430719442988]
Threshold 0.4 SUFFICIENT with avar bound: -0.006124430719442988
Evaluating threshold 0.5 with avar bound: [-0.006124430719442988]
Threshold 0.5 SUFFICIENT with avar bound: -0.006124430719442988
Evaluating threshold 0.6 with avar bound: [-0.006124430719442988]
Threshold 0.6 SUFFICIENT with avar bound: -0.006124430719442988
Evaluating threshold 0.7 with avar bound: [-0.006124430719442988]
Threshold 0.7 SUFFICIENT with avar bound: -0.006124430719442988
Evaluating threshold 0.8 with avar bound: [-0.006124430719442988]
Threshold 0.8 SUFFICIENT with avar bound: -0.006124430719442988
Evaluating threshold 0.9 with avar bound: [-0.006124430719442988]
Threshold 0.9 SUFFICIENT with avar bound: -0.006124430719442988

Running BIRL with demonstration 8/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.148
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.36889189 -0.65351046  0.03076562 -0.38771514 -0.04306323  0.2858358
  0.44946273]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.008183
0.9-VaR bound for 8 demonstrations: -0.006080
0.95-VaR bound for 8 demonstrations: -0.002361
0.99-VaR bound for 8 demonstrations: -0.000032
True expected value difference for MAP policy: -0.009903
Evaluating threshold 0.1 with avar bound: [-0.0023609119132507015]
Threshold 0.1 SUFFICIENT with avar bound: -0.0023609119132507015
Evaluating threshold 0.2 with avar bound: [-0.0023609119132507015]
Threshold 0.2 SUFFICIENT with avar bound: -0.0023609119132507015
Evaluating threshold 0.3 with avar bound: [-0.0023609119132507015]
Threshold 0.3 SUFFICIENT with avar bound: -0.0023609119132507015
Evaluating threshold 0.4 with avar bound: [-0.0023609119132507015]
Threshold 0.4 SUFFICIENT with avar bound: -0.0023609119132507015
Evaluating threshold 0.5 with avar bound: [-0.0023609119132507015]
Threshold 0.5 SUFFICIENT with avar bound: -0.0023609119132507015
Evaluating threshold 0.6 with avar bound: [-0.0023609119132507015]
Threshold 0.6 SUFFICIENT with avar bound: -0.0023609119132507015
Evaluating threshold 0.7 with avar bound: [-0.0023609119132507015]
Threshold 0.7 SUFFICIENT with avar bound: -0.0023609119132507015
Evaluating threshold 0.8 with avar bound: [-0.0023609119132507015]
Threshold 0.8 SUFFICIENT with avar bound: -0.0023609119132507015
Evaluating threshold 0.9 with avar bound: [-0.0023609119132507015]
Threshold 0.9 SUFFICIENT with avar bound: -0.0023609119132507015

Running BIRL with demonstration 9/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.148
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.37181694 -0.81138964 -0.06994447 -0.26377944 -0.01509347  0.17900194
  0.3108982 ]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.005038
0.9-VaR bound for 9 demonstrations: -0.003660
0.95-VaR bound for 9 demonstrations: -0.001150
0.99-VaR bound for 9 demonstrations: 0.004474
True expected value difference for MAP policy: -0.009971
Evaluating threshold 0.1 with avar bound: [-0.0011496845761590157]
Threshold 0.1 SUFFICIENT with avar bound: -0.0011496845761590157
Evaluating threshold 0.2 with avar bound: [-0.0011496845761590157]
Threshold 0.2 SUFFICIENT with avar bound: -0.0011496845761590157
Evaluating threshold 0.3 with avar bound: [-0.0011496845761590157]
Threshold 0.3 SUFFICIENT with avar bound: -0.0011496845761590157
Evaluating threshold 0.4 with avar bound: [-0.0011496845761590157]
Threshold 0.4 SUFFICIENT with avar bound: -0.0011496845761590157
Evaluating threshold 0.5 with avar bound: [-0.0011496845761590157]
Threshold 0.5 SUFFICIENT with avar bound: -0.0011496845761590157
Evaluating threshold 0.6 with avar bound: [-0.0011496845761590157]
Threshold 0.6 SUFFICIENT with avar bound: -0.0011496845761590157
Evaluating threshold 0.7 with avar bound: [-0.0011496845761590157]
Threshold 0.7 SUFFICIENT with avar bound: -0.0011496845761590157
Evaluating threshold 0.8 with avar bound: [-0.0011496845761590157]
Threshold 0.8 SUFFICIENT with avar bound: -0.0011496845761590157
Evaluating threshold 0.9 with avar bound: [-0.0011496845761590157]
Threshold 0.9 SUFFICIENT with avar bound: -0.0011496845761590157

Running BIRL with demonstration 10/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3), (21, 0)]
MCMC sampling complete.
Acceptance ratio: 0.136
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.17667659 -0.67106275  0.09495026 -0.19649913  0.22358826  0.4068962
  0.50524893]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.009299
0.9-VaR bound for 10 demonstrations: -0.008732
0.95-VaR bound for 10 demonstrations: -0.004867
0.99-VaR bound for 10 demonstrations: 0.007275
True expected value difference for MAP policy: -0.009971
Evaluating threshold 0.1 with avar bound: [-0.004866560201675191]
Threshold 0.1 SUFFICIENT with avar bound: -0.004866560201675191
Evaluating threshold 0.2 with avar bound: [-0.004866560201675191]
Threshold 0.2 SUFFICIENT with avar bound: -0.004866560201675191
Evaluating threshold 0.3 with avar bound: [-0.004866560201675191]
Threshold 0.3 SUFFICIENT with avar bound: -0.004866560201675191
Evaluating threshold 0.4 with avar bound: [-0.004866560201675191]
Threshold 0.4 SUFFICIENT with avar bound: -0.004866560201675191
Evaluating threshold 0.5 with avar bound: [-0.004866560201675191]
Threshold 0.5 SUFFICIENT with avar bound: -0.004866560201675191
Evaluating threshold 0.6 with avar bound: [-0.004866560201675191]
Threshold 0.6 SUFFICIENT with avar bound: -0.004866560201675191
Evaluating threshold 0.7 with avar bound: [-0.004866560201675191]
Threshold 0.7 SUFFICIENT with avar bound: -0.004866560201675191
Evaluating threshold 0.8 with avar bound: [-0.004866560201675191]
Threshold 0.8 SUFFICIENT with avar bound: -0.004866560201675191
Evaluating threshold 0.9 with avar bound: [-0.004866560201675191]
Threshold 0.9 SUFFICIENT with avar bound: -0.004866560201675191

Running world 2/20

Running BIRL with demonstration 1/10 in world 2
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.296
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.16725165  0.02165059  0.24459072 -0.78867134  0.17420181  0.10543217
  0.49826581]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.866279
0.9-VaR bound for 1 demonstrations: 1.989754
0.95-VaR bound for 1 demonstrations: 2.430892
0.99-VaR bound for 1 demonstrations: 5.762405
True expected value difference for MAP policy: -0.001267
Evaluating threshold 0.1 with avar bound: [2.430891519651783]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.430891519651783]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.430891519651783]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.430891519651783]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.430891519651783]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.430891519651783]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.430891519651783]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.430891519651783]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.430891519651783]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 2
Current demos: [(16, 1), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.177
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.08960182 -0.18686963  0.36726993 -0.30506411 -0.61569668  0.25839919
  0.53220992]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.314888
0.9-VaR bound for 2 demonstrations: 1.559980
0.95-VaR bound for 2 demonstrations: 1.963975
0.99-VaR bound for 2 demonstrations: 3.677291
True expected value difference for MAP policy: -0.000999
Evaluating threshold 0.1 with avar bound: [1.963975076506901]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.963975076506901]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.963975076506901]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.963975076506901]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.963975076506901]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.963975076506901]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.963975076506901]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.963975076506901]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.963975076506901]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 2
Current demos: [(16, 1), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.14666884 -0.05458324  0.35035038 -0.29856499 -0.52387603  0.39789688
  0.57519949]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.374018
0.9-VaR bound for 3 demonstrations: 1.732870
0.95-VaR bound for 3 demonstrations: 2.487335
0.99-VaR bound for 3 demonstrations: 3.674783
True expected value difference for MAP policy: -0.007608
Evaluating threshold 0.1 with avar bound: [2.4873350476138305]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.4873350476138305]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.4873350476138305]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.4873350476138305]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.4873350476138305]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.4873350476138305]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.4873350476138305]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.4873350476138305]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.4873350476138305]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 2
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.184
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.21906849  0.13732722  0.29591252 -0.22474682 -0.46024282  0.45724267
  0.61170301]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.001467
0.9-VaR bound for 4 demonstrations: 0.000215
0.95-VaR bound for 4 demonstrations: 0.001440
0.99-VaR bound for 4 demonstrations: 0.035291
True expected value difference for MAP policy: -0.008720
Evaluating threshold 0.1 with avar bound: [0.0014398592776405127]
Threshold 0.1 SUFFICIENT with avar bound: 0.0014398592776405127
Evaluating threshold 0.2 with avar bound: [0.0014398592776405127]
Threshold 0.2 SUFFICIENT with avar bound: 0.0014398592776405127
Evaluating threshold 0.3 with avar bound: [0.0014398592776405127]
Threshold 0.3 SUFFICIENT with avar bound: 0.0014398592776405127
Evaluating threshold 0.4 with avar bound: [0.0014398592776405127]
Threshold 0.4 SUFFICIENT with avar bound: 0.0014398592776405127
Evaluating threshold 0.5 with avar bound: [0.0014398592776405127]
Threshold 0.5 SUFFICIENT with avar bound: 0.0014398592776405127
Evaluating threshold 0.6 with avar bound: [0.0014398592776405127]
Threshold 0.6 SUFFICIENT with avar bound: 0.0014398592776405127
Evaluating threshold 0.7 with avar bound: [0.0014398592776405127]
Threshold 0.7 SUFFICIENT with avar bound: 0.0014398592776405127
Evaluating threshold 0.8 with avar bound: [0.0014398592776405127]
Threshold 0.8 SUFFICIENT with avar bound: 0.0014398592776405127
Evaluating threshold 0.9 with avar bound: [0.0014398592776405127]
Threshold 0.9 SUFFICIENT with avar bound: 0.0014398592776405127

Running BIRL with demonstration 5/10 in world 2
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.156
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.39599036 -0.44687262  0.16795154 -0.19963055 -0.47229961  0.36527965
  0.46791055]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.002457
0.9-VaR bound for 5 demonstrations: 0.002766
0.95-VaR bound for 5 demonstrations: 0.004768
0.99-VaR bound for 5 demonstrations: 0.708354
True expected value difference for MAP policy: -0.009305
Evaluating threshold 0.1 with avar bound: [0.004767891511108393]
Threshold 0.1 SUFFICIENT with avar bound: 0.004767891511108393
Evaluating threshold 0.2 with avar bound: [0.004767891511108393]
Threshold 0.2 SUFFICIENT with avar bound: 0.004767891511108393
Evaluating threshold 0.3 with avar bound: [0.004767891511108393]
Threshold 0.3 SUFFICIENT with avar bound: 0.004767891511108393
Evaluating threshold 0.4 with avar bound: [0.004767891511108393]
Threshold 0.4 SUFFICIENT with avar bound: 0.004767891511108393
Evaluating threshold 0.5 with avar bound: [0.004767891511108393]
Threshold 0.5 SUFFICIENT with avar bound: 0.004767891511108393
Evaluating threshold 0.6 with avar bound: [0.004767891511108393]
Threshold 0.6 SUFFICIENT with avar bound: 0.004767891511108393
Evaluating threshold 0.7 with avar bound: [0.004767891511108393]
Threshold 0.7 SUFFICIENT with avar bound: 0.004767891511108393
Evaluating threshold 0.8 with avar bound: [0.004767891511108393]
Threshold 0.8 SUFFICIENT with avar bound: 0.004767891511108393
Evaluating threshold 0.9 with avar bound: [0.004767891511108393]
Threshold 0.9 SUFFICIENT with avar bound: 0.004767891511108393

Running BIRL with demonstration 6/10 in world 2
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 2)]
MCMC sampling complete.
Acceptance ratio: 0.136
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.04192829 -0.58439455 -0.01007358 -0.24518106 -0.47648034  0.39397769
  0.46287997]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.007445
0.9-VaR bound for 6 demonstrations: -0.006279
0.95-VaR bound for 6 demonstrations: -0.000672
0.99-VaR bound for 6 demonstrations: 0.023023
True expected value difference for MAP policy: -0.007644
Evaluating threshold 0.1 with avar bound: [-0.0006723312713691109]
Threshold 0.1 SUFFICIENT with avar bound: -0.0006723312713691109
Evaluating threshold 0.2 with avar bound: [-0.0006723312713691109]
Threshold 0.2 SUFFICIENT with avar bound: -0.0006723312713691109
Evaluating threshold 0.3 with avar bound: [-0.0006723312713691109]
Threshold 0.3 SUFFICIENT with avar bound: -0.0006723312713691109
Evaluating threshold 0.4 with avar bound: [-0.0006723312713691109]
Threshold 0.4 SUFFICIENT with avar bound: -0.0006723312713691109
Evaluating threshold 0.5 with avar bound: [-0.0006723312713691109]
Threshold 0.5 SUFFICIENT with avar bound: -0.0006723312713691109
Evaluating threshold 0.6 with avar bound: [-0.0006723312713691109]
Threshold 0.6 SUFFICIENT with avar bound: -0.0006723312713691109
Evaluating threshold 0.7 with avar bound: [-0.0006723312713691109]
Threshold 0.7 SUFFICIENT with avar bound: -0.0006723312713691109
Evaluating threshold 0.8 with avar bound: [-0.0006723312713691109]
Threshold 0.8 SUFFICIENT with avar bound: -0.0006723312713691109
Evaluating threshold 0.9 with avar bound: [-0.0006723312713691109]
Threshold 0.9 SUFFICIENT with avar bound: -0.0006723312713691109

Running BIRL with demonstration 7/10 in world 2
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 2), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.142
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.17814516 -0.47450536  0.03319301 -0.23151567 -0.32205049  0.480211
  0.59505341]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.008440
0.9-VaR bound for 7 demonstrations: -0.007067
0.95-VaR bound for 7 demonstrations: -0.005670
0.99-VaR bound for 7 demonstrations: 0.014121
True expected value difference for MAP policy: -0.009305
Evaluating threshold 0.1 with avar bound: [-0.005669682970605272]
Threshold 0.1 SUFFICIENT with avar bound: -0.005669682970605272
Evaluating threshold 0.2 with avar bound: [-0.005669682970605272]
Threshold 0.2 SUFFICIENT with avar bound: -0.005669682970605272
Evaluating threshold 0.3 with avar bound: [-0.005669682970605272]
Threshold 0.3 SUFFICIENT with avar bound: -0.005669682970605272
Evaluating threshold 0.4 with avar bound: [-0.005669682970605272]
Threshold 0.4 SUFFICIENT with avar bound: -0.005669682970605272
Evaluating threshold 0.5 with avar bound: [-0.005669682970605272]
Threshold 0.5 SUFFICIENT with avar bound: -0.005669682970605272
Evaluating threshold 0.6 with avar bound: [-0.005669682970605272]
Threshold 0.6 SUFFICIENT with avar bound: -0.005669682970605272
Evaluating threshold 0.7 with avar bound: [-0.005669682970605272]
Threshold 0.7 SUFFICIENT with avar bound: -0.005669682970605272
Evaluating threshold 0.8 with avar bound: [-0.005669682970605272]
Threshold 0.8 SUFFICIENT with avar bound: -0.005669682970605272
Evaluating threshold 0.9 with avar bound: [-0.005669682970605272]
Threshold 0.9 SUFFICIENT with avar bound: -0.005669682970605272

Running BIRL with demonstration 8/10 in world 2
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 2), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.124
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.09331718 -0.4751205   0.28553411 -0.27546057 -0.37701958  0.3969371
  0.55537494]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.006830
0.9-VaR bound for 8 demonstrations: -0.006590
0.95-VaR bound for 8 demonstrations: -0.005581
0.99-VaR bound for 8 demonstrations: -0.004166
True expected value difference for MAP policy: -0.007486
Evaluating threshold 0.1 with avar bound: [-0.0055810648514460345]
Threshold 0.1 SUFFICIENT with avar bound: -0.0055810648514460345
Evaluating threshold 0.2 with avar bound: [-0.0055810648514460345]
Threshold 0.2 SUFFICIENT with avar bound: -0.0055810648514460345
Evaluating threshold 0.3 with avar bound: [-0.0055810648514460345]
Threshold 0.3 SUFFICIENT with avar bound: -0.0055810648514460345
Evaluating threshold 0.4 with avar bound: [-0.0055810648514460345]
Threshold 0.4 SUFFICIENT with avar bound: -0.0055810648514460345
Evaluating threshold 0.5 with avar bound: [-0.0055810648514460345]
Threshold 0.5 SUFFICIENT with avar bound: -0.0055810648514460345
Evaluating threshold 0.6 with avar bound: [-0.0055810648514460345]
Threshold 0.6 SUFFICIENT with avar bound: -0.0055810648514460345
Evaluating threshold 0.7 with avar bound: [-0.0055810648514460345]
Threshold 0.7 SUFFICIENT with avar bound: -0.0055810648514460345
Evaluating threshold 0.8 with avar bound: [-0.0055810648514460345]
Threshold 0.8 SUFFICIENT with avar bound: -0.0055810648514460345
Evaluating threshold 0.9 with avar bound: [-0.0055810648514460345]
Threshold 0.9 SUFFICIENT with avar bound: -0.0055810648514460345

Running BIRL with demonstration 9/10 in world 2
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 2), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.133
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.29356321 -0.40591798  0.02199508 -0.25357115 -0.12277341  0.45940391
  0.67686325]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.008181
0.9-VaR bound for 9 demonstrations: -0.008181
0.95-VaR bound for 9 demonstrations: -0.008034
0.99-VaR bound for 9 demonstrations: -0.005137
True expected value difference for MAP policy: -0.009920
Evaluating threshold 0.1 with avar bound: [-0.008033563866967882]
Threshold 0.1 SUFFICIENT with avar bound: -0.008033563866967882
Evaluating threshold 0.2 with avar bound: [-0.008033563866967882]
Threshold 0.2 SUFFICIENT with avar bound: -0.008033563866967882
Evaluating threshold 0.3 with avar bound: [-0.008033563866967882]
Threshold 0.3 SUFFICIENT with avar bound: -0.008033563866967882
Evaluating threshold 0.4 with avar bound: [-0.008033563866967882]
Threshold 0.4 SUFFICIENT with avar bound: -0.008033563866967882
Evaluating threshold 0.5 with avar bound: [-0.008033563866967882]
Threshold 0.5 SUFFICIENT with avar bound: -0.008033563866967882
Evaluating threshold 0.6 with avar bound: [-0.008033563866967882]
Threshold 0.6 SUFFICIENT with avar bound: -0.008033563866967882
Evaluating threshold 0.7 with avar bound: [-0.008033563866967882]
Threshold 0.7 SUFFICIENT with avar bound: -0.008033563866967882
Evaluating threshold 0.8 with avar bound: [-0.008033563866967882]
Threshold 0.8 SUFFICIENT with avar bound: -0.008033563866967882
Evaluating threshold 0.9 with avar bound: [-0.008033563866967882]
Threshold 0.9 SUFFICIENT with avar bound: -0.008033563866967882

Running BIRL with demonstration 10/10 in world 2
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 2), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.122
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.21949265 -0.28763723  0.11477281 -0.06469209 -0.24001321  0.54978595
  0.7013266 ]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.008690
0.9-VaR bound for 10 demonstrations: -0.008618
0.95-VaR bound for 10 demonstrations: -0.007321
0.99-VaR bound for 10 demonstrations: -0.005163
True expected value difference for MAP policy: -0.009920
Evaluating threshold 0.1 with avar bound: [-0.007321457152170852]
Threshold 0.1 SUFFICIENT with avar bound: -0.007321457152170852
Evaluating threshold 0.2 with avar bound: [-0.007321457152170852]
Threshold 0.2 SUFFICIENT with avar bound: -0.007321457152170852
Evaluating threshold 0.3 with avar bound: [-0.007321457152170852]
Threshold 0.3 SUFFICIENT with avar bound: -0.007321457152170852
Evaluating threshold 0.4 with avar bound: [-0.007321457152170852]
Threshold 0.4 SUFFICIENT with avar bound: -0.007321457152170852
Evaluating threshold 0.5 with avar bound: [-0.007321457152170852]
Threshold 0.5 SUFFICIENT with avar bound: -0.007321457152170852
Evaluating threshold 0.6 with avar bound: [-0.007321457152170852]
Threshold 0.6 SUFFICIENT with avar bound: -0.007321457152170852
Evaluating threshold 0.7 with avar bound: [-0.007321457152170852]
Threshold 0.7 SUFFICIENT with avar bound: -0.007321457152170852
Evaluating threshold 0.8 with avar bound: [-0.007321457152170852]
Threshold 0.8 SUFFICIENT with avar bound: -0.007321457152170852
Evaluating threshold 0.9 with avar bound: [-0.007321457152170852]
Threshold 0.9 SUFFICIENT with avar bound: -0.007321457152170852

Running world 3/20

Running BIRL with demonstration 1/10 in world 3
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.416
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50916935 -0.14887055 -0.36867357 -0.39424813  0.22919257 -0.1333026
  0.59743913]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.501647
0.9-VaR bound for 1 demonstrations: 2.072789
0.95-VaR bound for 1 demonstrations: 2.969599
0.99-VaR bound for 1 demonstrations: 88.900192
True expected value difference for MAP policy: -0.008378
Evaluating threshold 0.1 with avar bound: [2.9695993131663836]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.9695993131663836]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.9695993131663836]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.9695993131663836]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.9695993131663836]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.9695993131663836]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.9695993131663836]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.9695993131663836]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.9695993131663836]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 3
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.3
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.30402711 -0.11815413 -0.24643296 -0.64498209 -0.38429771  0.38078608
  0.35241063]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.587199
0.9-VaR bound for 2 demonstrations: 2.148796
0.95-VaR bound for 2 demonstrations: 3.021373
0.99-VaR bound for 2 demonstrations: 6.786471
True expected value difference for MAP policy: -0.005018
Evaluating threshold 0.1 with avar bound: [3.0213725651598597]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.0213725651598597]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.0213725651598597]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.0213725651598597]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.0213725651598597]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.0213725651598597]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.0213725651598597]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.0213725651598597]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.0213725651598597]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.272
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.33146149 -0.03827982  0.06682663 -0.25377517  0.11487007  0.63594899
  0.63417193]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.901577
0.9-VaR bound for 3 demonstrations: 1.264544
0.95-VaR bound for 3 demonstrations: 1.702287
0.99-VaR bound for 3 demonstrations: 2.912851
True expected value difference for MAP policy: -0.009414
Evaluating threshold 0.1 with avar bound: [1.7022870141075583]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.7022870141075583]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.7022870141075583]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.7022870141075583]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.7022870141075583]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.7022870141075583]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.7022870141075583]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.7022870141075583]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.7022870141075583]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.244
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.48002274 -0.16878201 -0.42219841 -0.09731288 -0.2204254   0.45763087
  0.54346677]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.000855
0.9-VaR bound for 4 demonstrations: 0.000364
0.95-VaR bound for 4 demonstrations: 0.003045
0.99-VaR bound for 4 demonstrations: 0.011726
True expected value difference for MAP policy: -0.008041
Evaluating threshold 0.1 with avar bound: [0.0030453620934810383]
Threshold 0.1 SUFFICIENT with avar bound: 0.0030453620934810383
Evaluating threshold 0.2 with avar bound: [0.0030453620934810383]
Threshold 0.2 SUFFICIENT with avar bound: 0.0030453620934810383
Evaluating threshold 0.3 with avar bound: [0.0030453620934810383]
Threshold 0.3 SUFFICIENT with avar bound: 0.0030453620934810383
Evaluating threshold 0.4 with avar bound: [0.0030453620934810383]
Threshold 0.4 SUFFICIENT with avar bound: 0.0030453620934810383
Evaluating threshold 0.5 with avar bound: [0.0030453620934810383]
Threshold 0.5 SUFFICIENT with avar bound: 0.0030453620934810383
Evaluating threshold 0.6 with avar bound: [0.0030453620934810383]
Threshold 0.6 SUFFICIENT with avar bound: 0.0030453620934810383
Evaluating threshold 0.7 with avar bound: [0.0030453620934810383]
Threshold 0.7 SUFFICIENT with avar bound: 0.0030453620934810383
Evaluating threshold 0.8 with avar bound: [0.0030453620934810383]
Threshold 0.8 SUFFICIENT with avar bound: 0.0030453620934810383
Evaluating threshold 0.9 with avar bound: [0.0030453620934810383]
Threshold 0.9 SUFFICIENT with avar bound: 0.0030453620934810383

Running BIRL with demonstration 5/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.234
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.11634075  0.31975855 -0.02251687 -0.22907902 -0.3951024   0.5094723
  0.64464499]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.004619
0.9-VaR bound for 5 demonstrations: 0.044933
0.95-VaR bound for 5 demonstrations: 0.044933
0.99-VaR bound for 5 demonstrations: 0.174488
True expected value difference for MAP policy: -0.007023
Evaluating threshold 0.1 with avar bound: [0.044933157499901955]
Threshold 0.1 SUFFICIENT with avar bound: 0.044933157499901955
Evaluating threshold 0.2 with avar bound: [0.044933157499901955]
Threshold 0.2 SUFFICIENT with avar bound: 0.044933157499901955
Evaluating threshold 0.3 with avar bound: [0.044933157499901955]
Threshold 0.3 SUFFICIENT with avar bound: 0.044933157499901955
Evaluating threshold 0.4 with avar bound: [0.044933157499901955]
Threshold 0.4 SUFFICIENT with avar bound: 0.044933157499901955
Evaluating threshold 0.5 with avar bound: [0.044933157499901955]
Threshold 0.5 SUFFICIENT with avar bound: 0.044933157499901955
Evaluating threshold 0.6 with avar bound: [0.044933157499901955]
Threshold 0.6 SUFFICIENT with avar bound: 0.044933157499901955
Evaluating threshold 0.7 with avar bound: [0.044933157499901955]
Threshold 0.7 SUFFICIENT with avar bound: 0.044933157499901955
Evaluating threshold 0.8 with avar bound: [0.044933157499901955]
Threshold 0.8 SUFFICIENT with avar bound: 0.044933157499901955
Evaluating threshold 0.9 with avar bound: [0.044933157499901955]
Threshold 0.9 SUFFICIENT with avar bound: 0.044933157499901955

Running BIRL with demonstration 6/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.226
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.01765652 -0.12685375  0.30701609 -0.40241814 -0.02704531  0.58379183
  0.6211705 ]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: 0.001744
0.9-VaR bound for 6 demonstrations: 0.002192
0.95-VaR bound for 6 demonstrations: 0.004048
0.99-VaR bound for 6 demonstrations: 0.028484
True expected value difference for MAP policy: -0.008395
Evaluating threshold 0.1 with avar bound: [0.004048394879942108]
Threshold 0.1 SUFFICIENT with avar bound: 0.004048394879942108
Evaluating threshold 0.2 with avar bound: [0.004048394879942108]
Threshold 0.2 SUFFICIENT with avar bound: 0.004048394879942108
Evaluating threshold 0.3 with avar bound: [0.004048394879942108]
Threshold 0.3 SUFFICIENT with avar bound: 0.004048394879942108
Evaluating threshold 0.4 with avar bound: [0.004048394879942108]
Threshold 0.4 SUFFICIENT with avar bound: 0.004048394879942108
Evaluating threshold 0.5 with avar bound: [0.004048394879942108]
Threshold 0.5 SUFFICIENT with avar bound: 0.004048394879942108
Evaluating threshold 0.6 with avar bound: [0.004048394879942108]
Threshold 0.6 SUFFICIENT with avar bound: 0.004048394879942108
Evaluating threshold 0.7 with avar bound: [0.004048394879942108]
Threshold 0.7 SUFFICIENT with avar bound: 0.004048394879942108
Evaluating threshold 0.8 with avar bound: [0.004048394879942108]
Threshold 0.8 SUFFICIENT with avar bound: 0.004048394879942108
Evaluating threshold 0.9 with avar bound: [0.004048394879942108]
Threshold 0.9 SUFFICIENT with avar bound: 0.004048394879942108

Running BIRL with demonstration 7/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.31041022 -0.32598445 -0.38312917 -0.18319506  0.07154763  0.58463601
  0.51972388]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: 0.006610
0.9-VaR bound for 7 demonstrations: 0.010849
0.95-VaR bound for 7 demonstrations: 0.013859
0.99-VaR bound for 7 demonstrations: 0.031682
True expected value difference for MAP policy: -0.009272
Evaluating threshold 0.1 with avar bound: [0.013858517869290984]
Threshold 0.1 SUFFICIENT with avar bound: 0.013858517869290984
Evaluating threshold 0.2 with avar bound: [0.013858517869290984]
Threshold 0.2 SUFFICIENT with avar bound: 0.013858517869290984
Evaluating threshold 0.3 with avar bound: [0.013858517869290984]
Threshold 0.3 SUFFICIENT with avar bound: 0.013858517869290984
Evaluating threshold 0.4 with avar bound: [0.013858517869290984]
Threshold 0.4 SUFFICIENT with avar bound: 0.013858517869290984
Evaluating threshold 0.5 with avar bound: [0.013858517869290984]
Threshold 0.5 SUFFICIENT with avar bound: 0.013858517869290984
Evaluating threshold 0.6 with avar bound: [0.013858517869290984]
Threshold 0.6 SUFFICIENT with avar bound: 0.013858517869290984
Evaluating threshold 0.7 with avar bound: [0.013858517869290984]
Threshold 0.7 SUFFICIENT with avar bound: 0.013858517869290984
Evaluating threshold 0.8 with avar bound: [0.013858517869290984]
Threshold 0.8 SUFFICIENT with avar bound: 0.013858517869290984
Evaluating threshold 0.9 with avar bound: [0.013858517869290984]
Threshold 0.9 SUFFICIENT with avar bound: 0.013858517869290984

Running BIRL with demonstration 8/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.212
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.24948414  0.02997985 -0.19762005 -0.21937943 -0.11043417  0.62165042
  0.67158984]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: 0.000509
0.9-VaR bound for 8 demonstrations: 0.003577
0.95-VaR bound for 8 demonstrations: 0.005965
0.99-VaR bound for 8 demonstrations: 0.885626
True expected value difference for MAP policy: -0.008041
Evaluating threshold 0.1 with avar bound: [0.005964900504713337]
Threshold 0.1 SUFFICIENT with avar bound: 0.005964900504713337
Evaluating threshold 0.2 with avar bound: [0.005964900504713337]
Threshold 0.2 SUFFICIENT with avar bound: 0.005964900504713337
Evaluating threshold 0.3 with avar bound: [0.005964900504713337]
Threshold 0.3 SUFFICIENT with avar bound: 0.005964900504713337
Evaluating threshold 0.4 with avar bound: [0.005964900504713337]
Threshold 0.4 SUFFICIENT with avar bound: 0.005964900504713337
Evaluating threshold 0.5 with avar bound: [0.005964900504713337]
Threshold 0.5 SUFFICIENT with avar bound: 0.005964900504713337
Evaluating threshold 0.6 with avar bound: [0.005964900504713337]
Threshold 0.6 SUFFICIENT with avar bound: 0.005964900504713337
Evaluating threshold 0.7 with avar bound: [0.005964900504713337]
Threshold 0.7 SUFFICIENT with avar bound: 0.005964900504713337
Evaluating threshold 0.8 with avar bound: [0.005964900504713337]
Threshold 0.8 SUFFICIENT with avar bound: 0.005964900504713337
Evaluating threshold 0.9 with avar bound: [0.005964900504713337]
Threshold 0.9 SUFFICIENT with avar bound: 0.005964900504713337

Running BIRL with demonstration 9/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.159
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.29965737 -0.04257377 -0.52390318 -0.29167581 -0.20848098  0.50116223
  0.50419809]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: 0.002632
0.9-VaR bound for 9 demonstrations: 0.003797
0.95-VaR bound for 9 demonstrations: 0.007236
0.99-VaR bound for 9 demonstrations: 0.021466
True expected value difference for MAP policy: -0.007807
Evaluating threshold 0.1 with avar bound: [0.007235806770303668]
Threshold 0.1 SUFFICIENT with avar bound: 0.007235806770303668
Evaluating threshold 0.2 with avar bound: [0.007235806770303668]
Threshold 0.2 SUFFICIENT with avar bound: 0.007235806770303668
Evaluating threshold 0.3 with avar bound: [0.007235806770303668]
Threshold 0.3 SUFFICIENT with avar bound: 0.007235806770303668
Evaluating threshold 0.4 with avar bound: [0.007235806770303668]
Threshold 0.4 SUFFICIENT with avar bound: 0.007235806770303668
Evaluating threshold 0.5 with avar bound: [0.007235806770303668]
Threshold 0.5 SUFFICIENT with avar bound: 0.007235806770303668
Evaluating threshold 0.6 with avar bound: [0.007235806770303668]
Threshold 0.6 SUFFICIENT with avar bound: 0.007235806770303668
Evaluating threshold 0.7 with avar bound: [0.007235806770303668]
Threshold 0.7 SUFFICIENT with avar bound: 0.007235806770303668
Evaluating threshold 0.8 with avar bound: [0.007235806770303668]
Threshold 0.8 SUFFICIENT with avar bound: 0.007235806770303668
Evaluating threshold 0.9 with avar bound: [0.007235806770303668]
Threshold 0.9 SUFFICIENT with avar bound: 0.007235806770303668

Running BIRL with demonstration 10/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.149
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.02595737 -0.44666307 -0.56831473 -0.48534929  0.02784899  0.31397104
  0.37672188]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.007125
0.9-VaR bound for 10 demonstrations: -0.006890
0.95-VaR bound for 10 demonstrations: -0.006679
0.99-VaR bound for 10 demonstrations: -0.005677
True expected value difference for MAP policy: -0.010031
Evaluating threshold 0.1 with avar bound: [-0.00667852912614326]
Threshold 0.1 SUFFICIENT with avar bound: -0.00667852912614326
Evaluating threshold 0.2 with avar bound: [-0.00667852912614326]
Threshold 0.2 SUFFICIENT with avar bound: -0.00667852912614326
Evaluating threshold 0.3 with avar bound: [-0.00667852912614326]
Threshold 0.3 SUFFICIENT with avar bound: -0.00667852912614326
Evaluating threshold 0.4 with avar bound: [-0.00667852912614326]
Threshold 0.4 SUFFICIENT with avar bound: -0.00667852912614326
Evaluating threshold 0.5 with avar bound: [-0.00667852912614326]
Threshold 0.5 SUFFICIENT with avar bound: -0.00667852912614326
Evaluating threshold 0.6 with avar bound: [-0.00667852912614326]
Threshold 0.6 SUFFICIENT with avar bound: -0.00667852912614326
Evaluating threshold 0.7 with avar bound: [-0.00667852912614326]
Threshold 0.7 SUFFICIENT with avar bound: -0.00667852912614326
Evaluating threshold 0.8 with avar bound: [-0.00667852912614326]
Threshold 0.8 SUFFICIENT with avar bound: -0.00667852912614326
Evaluating threshold 0.9 with avar bound: [-0.00667852912614326]
Threshold 0.9 SUFFICIENT with avar bound: -0.00667852912614326

Running world 4/20

Running BIRL with demonstration 1/10 in world 4
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.288
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47885084  0.35410376 -0.3666837  -0.20093439 -0.1503243   0.03276516
  0.66843839]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 0.006012
0.9-VaR bound for 1 demonstrations: 0.361170
0.95-VaR bound for 1 demonstrations: 2.003707
0.99-VaR bound for 1 demonstrations: 3.370095
True expected value difference for MAP policy: -0.007534
Evaluating threshold 0.1 with avar bound: [2.0037069077473593]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.0037069077473593]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.0037069077473593]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.0037069077473593]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.0037069077473593]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.0037069077473593]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.0037069077473593]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.0037069077473593]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.0037069077473593]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 4
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.202
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38162966 -0.15989761  0.38143734  0.40040897 -0.17667011 -0.04737147
  0.69965233]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 0.003168
0.9-VaR bound for 2 demonstrations: 0.004419
0.95-VaR bound for 2 demonstrations: 0.009959
0.99-VaR bound for 2 demonstrations: 0.031650
True expected value difference for MAP policy: 0.003645
Evaluating threshold 0.1 with avar bound: [0.009958947425601912]
Threshold 0.1 SUFFICIENT with avar bound: 0.009958947425601912
Evaluating threshold 0.2 with avar bound: [0.009958947425601912]
Threshold 0.2 SUFFICIENT with avar bound: 0.009958947425601912
Evaluating threshold 0.3 with avar bound: [0.009958947425601912]
Threshold 0.3 SUFFICIENT with avar bound: 0.009958947425601912
Evaluating threshold 0.4 with avar bound: [0.009958947425601912]
Threshold 0.4 SUFFICIENT with avar bound: 0.009958947425601912
Evaluating threshold 0.5 with avar bound: [0.009958947425601912]
Threshold 0.5 SUFFICIENT with avar bound: 0.009958947425601912
Evaluating threshold 0.6 with avar bound: [0.009958947425601912]
Threshold 0.6 SUFFICIENT with avar bound: 0.009958947425601912
Evaluating threshold 0.7 with avar bound: [0.009958947425601912]
Threshold 0.7 SUFFICIENT with avar bound: 0.009958947425601912
Evaluating threshold 0.8 with avar bound: [0.009958947425601912]
Threshold 0.8 SUFFICIENT with avar bound: 0.009958947425601912
Evaluating threshold 0.9 with avar bound: [0.009958947425601912]
Threshold 0.9 SUFFICIENT with avar bound: 0.009958947425601912

Running BIRL with demonstration 3/10 in world 4
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.233
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.43535013 -0.35521705  0.42398237 -0.1854395  -0.19425909  0.06711373
  0.65414174]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: -0.004393
0.9-VaR bound for 3 demonstrations: -0.001729
0.95-VaR bound for 3 demonstrations: 0.003700
0.99-VaR bound for 3 demonstrations: 0.070991
True expected value difference for MAP policy: 0.003645
Evaluating threshold 0.1 with avar bound: [0.0037003840463641848]
Threshold 0.1 SUFFICIENT with avar bound: 0.0037003840463641848
Evaluating threshold 0.2 with avar bound: [0.0037003840463641848]
Threshold 0.2 SUFFICIENT with avar bound: 0.0037003840463641848
Evaluating threshold 0.3 with avar bound: [0.0037003840463641848]
Threshold 0.3 SUFFICIENT with avar bound: 0.0037003840463641848
Evaluating threshold 0.4 with avar bound: [0.0037003840463641848]
Threshold 0.4 SUFFICIENT with avar bound: 0.0037003840463641848
Evaluating threshold 0.5 with avar bound: [0.0037003840463641848]
Threshold 0.5 SUFFICIENT with avar bound: 0.0037003840463641848
Evaluating threshold 0.6 with avar bound: [0.0037003840463641848]
Threshold 0.6 SUFFICIENT with avar bound: 0.0037003840463641848
Evaluating threshold 0.7 with avar bound: [0.0037003840463641848]
Threshold 0.7 SUFFICIENT with avar bound: 0.0037003840463641848
Evaluating threshold 0.8 with avar bound: [0.0037003840463641848]
Threshold 0.8 SUFFICIENT with avar bound: 0.0037003840463641848
Evaluating threshold 0.9 with avar bound: [0.0037003840463641848]
Threshold 0.9 SUFFICIENT with avar bound: 0.0037003840463641848

Running BIRL with demonstration 4/10 in world 4
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.209
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.67336017 -0.27551763  0.30394993  0.1092083  -0.20979335 -0.08809369
  0.56088355]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.001579
0.9-VaR bound for 4 demonstrations: 0.005019
0.95-VaR bound for 4 demonstrations: 0.006604
0.99-VaR bound for 4 demonstrations: 0.046034
True expected value difference for MAP policy: 0.003645
Evaluating threshold 0.1 with avar bound: [0.006603505433224572]
Threshold 0.1 SUFFICIENT with avar bound: 0.006603505433224572
Evaluating threshold 0.2 with avar bound: [0.006603505433224572]
Threshold 0.2 SUFFICIENT with avar bound: 0.006603505433224572
Evaluating threshold 0.3 with avar bound: [0.006603505433224572]
Threshold 0.3 SUFFICIENT with avar bound: 0.006603505433224572
Evaluating threshold 0.4 with avar bound: [0.006603505433224572]
Threshold 0.4 SUFFICIENT with avar bound: 0.006603505433224572
Evaluating threshold 0.5 with avar bound: [0.006603505433224572]
Threshold 0.5 SUFFICIENT with avar bound: 0.006603505433224572
Evaluating threshold 0.6 with avar bound: [0.006603505433224572]
Threshold 0.6 SUFFICIENT with avar bound: 0.006603505433224572
Evaluating threshold 0.7 with avar bound: [0.006603505433224572]
Threshold 0.7 SUFFICIENT with avar bound: 0.006603505433224572
Evaluating threshold 0.8 with avar bound: [0.006603505433224572]
Threshold 0.8 SUFFICIENT with avar bound: 0.006603505433224572
Evaluating threshold 0.9 with avar bound: [0.006603505433224572]
Threshold 0.9 SUFFICIENT with avar bound: 0.006603505433224572

Running BIRL with demonstration 5/10 in world 4
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.202
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38369903 -0.44755598  0.32131166  0.14978342  0.08997461 -0.08213755
  0.71550712]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.005173
0.9-VaR bound for 5 demonstrations: -0.003818
0.95-VaR bound for 5 demonstrations: 0.001695
0.99-VaR bound for 5 demonstrations: 0.044474
True expected value difference for MAP policy: 0.001144
Evaluating threshold 0.1 with avar bound: [0.0016954531836910463]
Threshold 0.1 SUFFICIENT with avar bound: 0.0016954531836910463
Evaluating threshold 0.2 with avar bound: [0.0016954531836910463]
Threshold 0.2 SUFFICIENT with avar bound: 0.0016954531836910463
Evaluating threshold 0.3 with avar bound: [0.0016954531836910463]
Threshold 0.3 SUFFICIENT with avar bound: 0.0016954531836910463
Evaluating threshold 0.4 with avar bound: [0.0016954531836910463]
Threshold 0.4 SUFFICIENT with avar bound: 0.0016954531836910463
Evaluating threshold 0.5 with avar bound: [0.0016954531836910463]
Threshold 0.5 SUFFICIENT with avar bound: 0.0016954531836910463
Evaluating threshold 0.6 with avar bound: [0.0016954531836910463]
Threshold 0.6 SUFFICIENT with avar bound: 0.0016954531836910463
Evaluating threshold 0.7 with avar bound: [0.0016954531836910463]
Threshold 0.7 SUFFICIENT with avar bound: 0.0016954531836910463
Evaluating threshold 0.8 with avar bound: [0.0016954531836910463]
Threshold 0.8 SUFFICIENT with avar bound: 0.0016954531836910463
Evaluating threshold 0.9 with avar bound: [0.0016954531836910463]
Threshold 0.9 SUFFICIENT with avar bound: 0.0016954531836910463

Running BIRL with demonstration 6/10 in world 4
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.202
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.72995542 -0.0744518   0.25288376 -0.01879579 -0.17714212 -0.36963266
  0.47886418]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.005003
0.9-VaR bound for 6 demonstrations: -0.003036
0.95-VaR bound for 6 demonstrations: -0.000158
0.99-VaR bound for 6 demonstrations: 0.015544
True expected value difference for MAP policy: 0.003645
Evaluating threshold 0.1 with avar bound: [-0.00015785395523245212]
Threshold 0.1 SUFFICIENT with avar bound: -0.00015785395523245212
Evaluating threshold 0.2 with avar bound: [-0.00015785395523245212]
Threshold 0.2 SUFFICIENT with avar bound: -0.00015785395523245212
Evaluating threshold 0.3 with avar bound: [-0.00015785395523245212]
Threshold 0.3 SUFFICIENT with avar bound: -0.00015785395523245212
Evaluating threshold 0.4 with avar bound: [-0.00015785395523245212]
Threshold 0.4 SUFFICIENT with avar bound: -0.00015785395523245212
Evaluating threshold 0.5 with avar bound: [-0.00015785395523245212]
Threshold 0.5 SUFFICIENT with avar bound: -0.00015785395523245212
Evaluating threshold 0.6 with avar bound: [-0.00015785395523245212]
Threshold 0.6 SUFFICIENT with avar bound: -0.00015785395523245212
Evaluating threshold 0.7 with avar bound: [-0.00015785395523245212]
Threshold 0.7 SUFFICIENT with avar bound: -0.00015785395523245212
Evaluating threshold 0.8 with avar bound: [-0.00015785395523245212]
Threshold 0.8 SUFFICIENT with avar bound: -0.00015785395523245212
Evaluating threshold 0.9 with avar bound: [-0.00015785395523245212]
Threshold 0.9 SUFFICIENT with avar bound: -0.00015785395523245212

Running BIRL with demonstration 7/10 in world 4
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.183
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.6907383  -0.24075     0.25073445  0.07162913 -0.04284813 -0.14069404
  0.6126098 ]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.005161
0.9-VaR bound for 7 demonstrations: -0.002884
0.95-VaR bound for 7 demonstrations: -0.000125
0.99-VaR bound for 7 demonstrations: 0.004826
True expected value difference for MAP policy: 0.003645
Evaluating threshold 0.1 with avar bound: [-0.00012510387426683235]
Threshold 0.1 SUFFICIENT with avar bound: -0.00012510387426683235
Evaluating threshold 0.2 with avar bound: [-0.00012510387426683235]
Threshold 0.2 SUFFICIENT with avar bound: -0.00012510387426683235
Evaluating threshold 0.3 with avar bound: [-0.00012510387426683235]
Threshold 0.3 SUFFICIENT with avar bound: -0.00012510387426683235
Evaluating threshold 0.4 with avar bound: [-0.00012510387426683235]
Threshold 0.4 SUFFICIENT with avar bound: -0.00012510387426683235
Evaluating threshold 0.5 with avar bound: [-0.00012510387426683235]
Threshold 0.5 SUFFICIENT with avar bound: -0.00012510387426683235
Evaluating threshold 0.6 with avar bound: [-0.00012510387426683235]
Threshold 0.6 SUFFICIENT with avar bound: -0.00012510387426683235
Evaluating threshold 0.7 with avar bound: [-0.00012510387426683235]
Threshold 0.7 SUFFICIENT with avar bound: -0.00012510387426683235
Evaluating threshold 0.8 with avar bound: [-0.00012510387426683235]
Threshold 0.8 SUFFICIENT with avar bound: -0.00012510387426683235
Evaluating threshold 0.9 with avar bound: [-0.00012510387426683235]
Threshold 0.9 SUFFICIENT with avar bound: -0.00012510387426683235

Running BIRL with demonstration 8/10 in world 4
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.175
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.53279136 -0.33183227 -0.00763778 -0.17229494  0.04774414 -0.56745292
  0.50199054]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.005708
0.9-VaR bound for 8 demonstrations: -0.005324
0.95-VaR bound for 8 demonstrations: -0.002113
0.99-VaR bound for 8 demonstrations: 0.001097
True expected value difference for MAP policy: 0.001142
Evaluating threshold 0.1 with avar bound: [-0.00211267250874079]
Threshold 0.1 SUFFICIENT with avar bound: -0.00211267250874079
Evaluating threshold 0.2 with avar bound: [-0.00211267250874079]
Threshold 0.2 SUFFICIENT with avar bound: -0.00211267250874079
Evaluating threshold 0.3 with avar bound: [-0.00211267250874079]
Threshold 0.3 SUFFICIENT with avar bound: -0.00211267250874079
Evaluating threshold 0.4 with avar bound: [-0.00211267250874079]
Threshold 0.4 SUFFICIENT with avar bound: -0.00211267250874079
Evaluating threshold 0.5 with avar bound: [-0.00211267250874079]
Threshold 0.5 SUFFICIENT with avar bound: -0.00211267250874079
Evaluating threshold 0.6 with avar bound: [-0.00211267250874079]
Threshold 0.6 SUFFICIENT with avar bound: -0.00211267250874079
Evaluating threshold 0.7 with avar bound: [-0.00211267250874079]
Threshold 0.7 SUFFICIENT with avar bound: -0.00211267250874079
Evaluating threshold 0.8 with avar bound: [-0.00211267250874079]
Threshold 0.8 SUFFICIENT with avar bound: -0.00211267250874079
Evaluating threshold 0.9 with avar bound: [-0.00211267250874079]
Threshold 0.9 SUFFICIENT with avar bound: -0.00211267250874079

Running BIRL with demonstration 9/10 in world 4
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.178
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.39426702 -0.43634148 -0.05429097 -0.29171124  0.10864055 -0.40121758
  0.62716692]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.004146
0.9-VaR bound for 9 demonstrations: -0.004082
0.95-VaR bound for 9 demonstrations: -0.003916
0.99-VaR bound for 9 demonstrations: -0.000275
True expected value difference for MAP policy: 0.001142
Evaluating threshold 0.1 with avar bound: [-0.003916463395432793]
Threshold 0.1 SUFFICIENT with avar bound: -0.003916463395432793
Evaluating threshold 0.2 with avar bound: [-0.003916463395432793]
Threshold 0.2 SUFFICIENT with avar bound: -0.003916463395432793
Evaluating threshold 0.3 with avar bound: [-0.003916463395432793]
Threshold 0.3 SUFFICIENT with avar bound: -0.003916463395432793
Evaluating threshold 0.4 with avar bound: [-0.003916463395432793]
Threshold 0.4 SUFFICIENT with avar bound: -0.003916463395432793
Evaluating threshold 0.5 with avar bound: [-0.003916463395432793]
Threshold 0.5 SUFFICIENT with avar bound: -0.003916463395432793
Evaluating threshold 0.6 with avar bound: [-0.003916463395432793]
Threshold 0.6 SUFFICIENT with avar bound: -0.003916463395432793
Evaluating threshold 0.7 with avar bound: [-0.003916463395432793]
Threshold 0.7 SUFFICIENT with avar bound: -0.003916463395432793
Evaluating threshold 0.8 with avar bound: [-0.003916463395432793]
Threshold 0.8 SUFFICIENT with avar bound: -0.003916463395432793
Evaluating threshold 0.9 with avar bound: [-0.003916463395432793]
Threshold 0.9 SUFFICIENT with avar bound: -0.003916463395432793

Running BIRL with demonstration 10/10 in world 4
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.159
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.53367023 -0.49318743  0.01066171 -0.03074459  0.08994489 -0.40252814
  0.5484381 ]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.003757
0.9-VaR bound for 10 demonstrations: -0.002534
0.95-VaR bound for 10 demonstrations: -0.000096
0.99-VaR bound for 10 demonstrations: 0.001638
True expected value difference for MAP policy: 0.001452
Evaluating threshold 0.1 with avar bound: [-9.590938234677294e-05]
Threshold 0.1 SUFFICIENT with avar bound: -9.590938234677294e-05
Evaluating threshold 0.2 with avar bound: [-9.590938234677294e-05]
Threshold 0.2 SUFFICIENT with avar bound: -9.590938234677294e-05
Evaluating threshold 0.3 with avar bound: [-9.590938234677294e-05]
Threshold 0.3 SUFFICIENT with avar bound: -9.590938234677294e-05
Evaluating threshold 0.4 with avar bound: [-9.590938234677294e-05]
Threshold 0.4 SUFFICIENT with avar bound: -9.590938234677294e-05
Evaluating threshold 0.5 with avar bound: [-9.590938234677294e-05]
Threshold 0.5 SUFFICIENT with avar bound: -9.590938234677294e-05
Evaluating threshold 0.6 with avar bound: [-9.590938234677294e-05]
Threshold 0.6 SUFFICIENT with avar bound: -9.590938234677294e-05
Evaluating threshold 0.7 with avar bound: [-9.590938234677294e-05]
Threshold 0.7 SUFFICIENT with avar bound: -9.590938234677294e-05
Evaluating threshold 0.8 with avar bound: [-9.590938234677294e-05]
Threshold 0.8 SUFFICIENT with avar bound: -9.590938234677294e-05
Evaluating threshold 0.9 with avar bound: [-9.590938234677294e-05]
Threshold 0.9 SUFFICIENT with avar bound: -9.590938234677294e-05

Saving results to files...
Results saved successfully.

Running world 5/20

Running BIRL with demonstration 1/10 in world 5
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.469
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.76405599 -0.25944976 -0.07801442 -0.07339644 -0.21538319  0.4964651
 -0.21110059]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.398167
0.9-VaR bound for 1 demonstrations: 1.785525
0.95-VaR bound for 1 demonstrations: 2.335524
0.99-VaR bound for 1 demonstrations: 5.660665
True expected value difference for MAP policy: 1.522425
Evaluating threshold 0.1 with avar bound: [2.335523718046301]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.335523718046301]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.335523718046301]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.335523718046301]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.335523718046301]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.335523718046301]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.335523718046301]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.335523718046301]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.335523718046301]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 5
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.344
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.04115039  0.79672756 -0.50909747 -0.02374927  0.01158511  0.0036372
  0.32193189]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.294001
0.9-VaR bound for 2 demonstrations: 1.463541
0.95-VaR bound for 2 demonstrations: 1.818714
0.99-VaR bound for 2 demonstrations: 2.825407
True expected value difference for MAP policy: 1.314786
Evaluating threshold 0.1 with avar bound: [1.818713911555795]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.818713911555795]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.818713911555795]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.818713911555795]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.818713911555795]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.818713911555795]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.818713911555795]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.818713911555795]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.818713911555795]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.25
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47736613  0.15018211 -0.2169925   0.05633712 -0.17719706  0.45961146
  0.67577052]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.695143
0.9-VaR bound for 3 demonstrations: 0.949851
0.95-VaR bound for 3 demonstrations: 1.774378
0.99-VaR bound for 3 demonstrations: 5.033253
True expected value difference for MAP policy: -0.008353
Evaluating threshold 0.1 with avar bound: [1.7743776036770083]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.7743776036770083]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.7743776036770083]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.7743776036770083]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.7743776036770083]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.7743776036770083]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.7743776036770083]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.7743776036770083]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.7743776036770083]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.268
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.27757631  0.19203692 -0.38826592  0.1132871  -0.04272034  0.41669061
  0.73961661]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.005375
0.9-VaR bound for 4 demonstrations: 0.008484
0.95-VaR bound for 4 demonstrations: 0.015408
0.99-VaR bound for 4 demonstrations: 0.034257
True expected value difference for MAP policy: -0.004720
Evaluating threshold 0.1 with avar bound: [0.015407713233857397]
Threshold 0.1 SUFFICIENT with avar bound: 0.015407713233857397
Evaluating threshold 0.2 with avar bound: [0.015407713233857397]
Threshold 0.2 SUFFICIENT with avar bound: 0.015407713233857397
Evaluating threshold 0.3 with avar bound: [0.015407713233857397]
Threshold 0.3 SUFFICIENT with avar bound: 0.015407713233857397
Evaluating threshold 0.4 with avar bound: [0.015407713233857397]
Threshold 0.4 SUFFICIENT with avar bound: 0.015407713233857397
Evaluating threshold 0.5 with avar bound: [0.015407713233857397]
Threshold 0.5 SUFFICIENT with avar bound: 0.015407713233857397
Evaluating threshold 0.6 with avar bound: [0.015407713233857397]
Threshold 0.6 SUFFICIENT with avar bound: 0.015407713233857397
Evaluating threshold 0.7 with avar bound: [0.015407713233857397]
Threshold 0.7 SUFFICIENT with avar bound: 0.015407713233857397
Evaluating threshold 0.8 with avar bound: [0.015407713233857397]
Threshold 0.8 SUFFICIENT with avar bound: 0.015407713233857397
Evaluating threshold 0.9 with avar bound: [0.015407713233857397]
Threshold 0.9 SUFFICIENT with avar bound: 0.015407713233857397

Running BIRL with demonstration 5/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.206
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.59120925 -0.19266306 -0.36891751  0.12390153 -0.24601074  0.26248054
  0.57661385]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.003204
0.9-VaR bound for 5 demonstrations: 0.004772
0.95-VaR bound for 5 demonstrations: 0.008622
0.99-VaR bound for 5 demonstrations: 0.019999
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.008622000860900184]
Threshold 0.1 SUFFICIENT with avar bound: 0.008622000860900184
Evaluating threshold 0.2 with avar bound: [0.008622000860900184]
Threshold 0.2 SUFFICIENT with avar bound: 0.008622000860900184
Evaluating threshold 0.3 with avar bound: [0.008622000860900184]
Threshold 0.3 SUFFICIENT with avar bound: 0.008622000860900184
Evaluating threshold 0.4 with avar bound: [0.008622000860900184]
Threshold 0.4 SUFFICIENT with avar bound: 0.008622000860900184
Evaluating threshold 0.5 with avar bound: [0.008622000860900184]
Threshold 0.5 SUFFICIENT with avar bound: 0.008622000860900184
Evaluating threshold 0.6 with avar bound: [0.008622000860900184]
Threshold 0.6 SUFFICIENT with avar bound: 0.008622000860900184
Evaluating threshold 0.7 with avar bound: [0.008622000860900184]
Threshold 0.7 SUFFICIENT with avar bound: 0.008622000860900184
Evaluating threshold 0.8 with avar bound: [0.008622000860900184]
Threshold 0.8 SUFFICIENT with avar bound: 0.008622000860900184
Evaluating threshold 0.9 with avar bound: [0.008622000860900184]
Threshold 0.9 SUFFICIENT with avar bound: 0.008622000860900184

Running BIRL with demonstration 6/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.21
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.49255229 -0.09069448 -0.31946132  0.23061077 -0.43832104  0.24410005
  0.58499549]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: 0.004150
0.9-VaR bound for 6 demonstrations: 0.007070
0.95-VaR bound for 6 demonstrations: 0.010682
0.99-VaR bound for 6 demonstrations: 0.051529
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.010682178941811268]
Threshold 0.1 SUFFICIENT with avar bound: 0.010682178941811268
Evaluating threshold 0.2 with avar bound: [0.010682178941811268]
Threshold 0.2 SUFFICIENT with avar bound: 0.010682178941811268
Evaluating threshold 0.3 with avar bound: [0.010682178941811268]
Threshold 0.3 SUFFICIENT with avar bound: 0.010682178941811268
Evaluating threshold 0.4 with avar bound: [0.010682178941811268]
Threshold 0.4 SUFFICIENT with avar bound: 0.010682178941811268
Evaluating threshold 0.5 with avar bound: [0.010682178941811268]
Threshold 0.5 SUFFICIENT with avar bound: 0.010682178941811268
Evaluating threshold 0.6 with avar bound: [0.010682178941811268]
Threshold 0.6 SUFFICIENT with avar bound: 0.010682178941811268
Evaluating threshold 0.7 with avar bound: [0.010682178941811268]
Threshold 0.7 SUFFICIENT with avar bound: 0.010682178941811268
Evaluating threshold 0.8 with avar bound: [0.010682178941811268]
Threshold 0.8 SUFFICIENT with avar bound: 0.010682178941811268
Evaluating threshold 0.9 with avar bound: [0.010682178941811268]
Threshold 0.9 SUFFICIENT with avar bound: 0.010682178941811268

Running BIRL with demonstration 7/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.184
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.65144278 -0.12240335 -0.07588501  0.24346238 -0.23932956  0.26216847
  0.60794433]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.003476
0.9-VaR bound for 7 demonstrations: -0.001206
0.95-VaR bound for 7 demonstrations: 0.002246
0.99-VaR bound for 7 demonstrations: 0.010476
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.002246158249219173]
Threshold 0.1 SUFFICIENT with avar bound: 0.002246158249219173
Evaluating threshold 0.2 with avar bound: [0.002246158249219173]
Threshold 0.2 SUFFICIENT with avar bound: 0.002246158249219173
Evaluating threshold 0.3 with avar bound: [0.002246158249219173]
Threshold 0.3 SUFFICIENT with avar bound: 0.002246158249219173
Evaluating threshold 0.4 with avar bound: [0.002246158249219173]
Threshold 0.4 SUFFICIENT with avar bound: 0.002246158249219173
Evaluating threshold 0.5 with avar bound: [0.002246158249219173]
Threshold 0.5 SUFFICIENT with avar bound: 0.002246158249219173
Evaluating threshold 0.6 with avar bound: [0.002246158249219173]
Threshold 0.6 SUFFICIENT with avar bound: 0.002246158249219173
Evaluating threshold 0.7 with avar bound: [0.002246158249219173]
Threshold 0.7 SUFFICIENT with avar bound: 0.002246158249219173
Evaluating threshold 0.8 with avar bound: [0.002246158249219173]
Threshold 0.8 SUFFICIENT with avar bound: 0.002246158249219173
Evaluating threshold 0.9 with avar bound: [0.002246158249219173]
Threshold 0.9 SUFFICIENT with avar bound: 0.002246158249219173

Running BIRL with demonstration 8/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.40751872 -0.29071335 -0.15719781  0.00589181 -0.59442873  0.31446578
  0.52195223]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.001017
0.9-VaR bound for 8 demonstrations: 0.002543
0.95-VaR bound for 8 demonstrations: 0.111285
0.99-VaR bound for 8 demonstrations: 0.111285
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.11128540670167254]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.11128540670167254]
Threshold 0.2 SUFFICIENT with avar bound: 0.11128540670167254
Evaluating threshold 0.3 with avar bound: [0.11128540670167254]
Threshold 0.3 SUFFICIENT with avar bound: 0.11128540670167254
Evaluating threshold 0.4 with avar bound: [0.11128540670167254]
Threshold 0.4 SUFFICIENT with avar bound: 0.11128540670167254
Evaluating threshold 0.5 with avar bound: [0.11128540670167254]
Threshold 0.5 SUFFICIENT with avar bound: 0.11128540670167254
Evaluating threshold 0.6 with avar bound: [0.11128540670167254]
Threshold 0.6 SUFFICIENT with avar bound: 0.11128540670167254
Evaluating threshold 0.7 with avar bound: [0.11128540670167254]
Threshold 0.7 SUFFICIENT with avar bound: 0.11128540670167254
Evaluating threshold 0.8 with avar bound: [0.11128540670167254]
Threshold 0.8 SUFFICIENT with avar bound: 0.11128540670167254
Evaluating threshold 0.9 with avar bound: [0.11128540670167254]
Threshold 0.9 SUFFICIENT with avar bound: 0.11128540670167254

Running BIRL with demonstration 9/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.174
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47259337 -0.24738543 -0.31923744  0.10548401 -0.05583285  0.36632568
  0.68198588]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.002323
0.9-VaR bound for 9 demonstrations: -0.000384
0.95-VaR bound for 9 demonstrations: 0.014459
0.99-VaR bound for 9 demonstrations: 0.034127
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.014458956986867692]
Threshold 0.1 SUFFICIENT with avar bound: 0.014458956986867692
Evaluating threshold 0.2 with avar bound: [0.014458956986867692]
Threshold 0.2 SUFFICIENT with avar bound: 0.014458956986867692
Evaluating threshold 0.3 with avar bound: [0.014458956986867692]
Threshold 0.3 SUFFICIENT with avar bound: 0.014458956986867692
Evaluating threshold 0.4 with avar bound: [0.014458956986867692]
Threshold 0.4 SUFFICIENT with avar bound: 0.014458956986867692
Evaluating threshold 0.5 with avar bound: [0.014458956986867692]
Threshold 0.5 SUFFICIENT with avar bound: 0.014458956986867692
Evaluating threshold 0.6 with avar bound: [0.014458956986867692]
Threshold 0.6 SUFFICIENT with avar bound: 0.014458956986867692
Evaluating threshold 0.7 with avar bound: [0.014458956986867692]
Threshold 0.7 SUFFICIENT with avar bound: 0.014458956986867692
Evaluating threshold 0.8 with avar bound: [0.014458956986867692]
Threshold 0.8 SUFFICIENT with avar bound: 0.014458956986867692
Evaluating threshold 0.9 with avar bound: [0.014458956986867692]
Threshold 0.9 SUFFICIENT with avar bound: 0.014458956986867692

Running BIRL with demonstration 10/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.19
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.42685111 -0.13773122 -0.40200648  0.15666014 -0.35405434  0.34319088
  0.60789981]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.003687
0.9-VaR bound for 10 demonstrations: -0.002299
0.95-VaR bound for 10 demonstrations: 0.001462
0.99-VaR bound for 10 demonstrations: 0.037897
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.001461907284554964]
Threshold 0.1 SUFFICIENT with avar bound: 0.001461907284554964
Evaluating threshold 0.2 with avar bound: [0.001461907284554964]
Threshold 0.2 SUFFICIENT with avar bound: 0.001461907284554964
Evaluating threshold 0.3 with avar bound: [0.001461907284554964]
Threshold 0.3 SUFFICIENT with avar bound: 0.001461907284554964
Evaluating threshold 0.4 with avar bound: [0.001461907284554964]
Threshold 0.4 SUFFICIENT with avar bound: 0.001461907284554964
Evaluating threshold 0.5 with avar bound: [0.001461907284554964]
Threshold 0.5 SUFFICIENT with avar bound: 0.001461907284554964
Evaluating threshold 0.6 with avar bound: [0.001461907284554964]
Threshold 0.6 SUFFICIENT with avar bound: 0.001461907284554964
Evaluating threshold 0.7 with avar bound: [0.001461907284554964]
Threshold 0.7 SUFFICIENT with avar bound: 0.001461907284554964
Evaluating threshold 0.8 with avar bound: [0.001461907284554964]
Threshold 0.8 SUFFICIENT with avar bound: 0.001461907284554964
Evaluating threshold 0.9 with avar bound: [0.001461907284554964]
Threshold 0.9 SUFFICIENT with avar bound: 0.001461907284554964

Running world 6/20

Running BIRL with demonstration 1/10 in world 6
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.407
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.22887056  0.37917635  0.23123026 -0.72732464 -0.19002153  0.23949729
  0.35764208]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.791918
0.9-VaR bound for 1 demonstrations: 2.162949
0.95-VaR bound for 1 demonstrations: 2.745320
0.99-VaR bound for 1 demonstrations: 11.476567
True expected value difference for MAP policy: -0.000923
Evaluating threshold 0.1 with avar bound: [2.745319756724053]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.745319756724053]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.745319756724053]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.745319756724053]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.745319756724053]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.745319756724053]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.745319756724053]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.745319756724053]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.745319756724053]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 6
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.335
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.19873893 -0.12630962 -0.46077863 -0.53014519  0.27067522 -0.18272655
  0.58696148]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.609400
0.9-VaR bound for 2 demonstrations: 1.994229
0.95-VaR bound for 2 demonstrations: 3.238872
0.99-VaR bound for 2 demonstrations: 28.705122
True expected value difference for MAP policy: -0.007367
Evaluating threshold 0.1 with avar bound: [3.238872179350128]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.238872179350128]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.238872179350128]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.238872179350128]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.238872179350128]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.238872179350128]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.238872179350128]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.238872179350128]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.238872179350128]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.271
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.11477624  0.10668032  0.1067769  -0.38756444  0.47482867 -0.07743452
  0.76313816]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.490765
0.9-VaR bound for 3 demonstrations: 2.049469
0.95-VaR bound for 3 demonstrations: 2.572457
0.99-VaR bound for 3 demonstrations: 2.907877
True expected value difference for MAP policy: -0.007263
Evaluating threshold 0.1 with avar bound: [2.572456781716719]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.572456781716719]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.572456781716719]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.572456781716719]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.572456781716719]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.572456781716719]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.572456781716719]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.572456781716719]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.572456781716719]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.227
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.45545582  0.0367552   0.06756006 -0.50743271  0.30354991 -0.24889304
  0.61242668]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.005849
0.9-VaR bound for 4 demonstrations: -0.003016
0.95-VaR bound for 4 demonstrations: -0.000718
0.99-VaR bound for 4 demonstrations: 0.003415
True expected value difference for MAP policy: -0.007263
Evaluating threshold 0.1 with avar bound: [-0.00071793389152807]
Threshold 0.1 SUFFICIENT with avar bound: -0.00071793389152807
Evaluating threshold 0.2 with avar bound: [-0.00071793389152807]
Threshold 0.2 SUFFICIENT with avar bound: -0.00071793389152807
Evaluating threshold 0.3 with avar bound: [-0.00071793389152807]
Threshold 0.3 SUFFICIENT with avar bound: -0.00071793389152807
Evaluating threshold 0.4 with avar bound: [-0.00071793389152807]
Threshold 0.4 SUFFICIENT with avar bound: -0.00071793389152807
Evaluating threshold 0.5 with avar bound: [-0.00071793389152807]
Threshold 0.5 SUFFICIENT with avar bound: -0.00071793389152807
Evaluating threshold 0.6 with avar bound: [-0.00071793389152807]
Threshold 0.6 SUFFICIENT with avar bound: -0.00071793389152807
Evaluating threshold 0.7 with avar bound: [-0.00071793389152807]
Threshold 0.7 SUFFICIENT with avar bound: -0.00071793389152807
Evaluating threshold 0.8 with avar bound: [-0.00071793389152807]
Threshold 0.8 SUFFICIENT with avar bound: -0.00071793389152807
Evaluating threshold 0.9 with avar bound: [-0.00071793389152807]
Threshold 0.9 SUFFICIENT with avar bound: -0.00071793389152807

Running BIRL with demonstration 5/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.226
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.53972571 -0.24390256 -0.24454307 -0.09944164  0.44398397 -0.09859758
  0.61047073]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.005220
0.9-VaR bound for 5 demonstrations: -0.003051
0.95-VaR bound for 5 demonstrations: 0.000829
0.99-VaR bound for 5 demonstrations: 0.029788
True expected value difference for MAP policy: -0.007367
Evaluating threshold 0.1 with avar bound: [0.0008293646842588611]
Threshold 0.1 SUFFICIENT with avar bound: 0.0008293646842588611
Evaluating threshold 0.2 with avar bound: [0.0008293646842588611]
Threshold 0.2 SUFFICIENT with avar bound: 0.0008293646842588611
Evaluating threshold 0.3 with avar bound: [0.0008293646842588611]
Threshold 0.3 SUFFICIENT with avar bound: 0.0008293646842588611
Evaluating threshold 0.4 with avar bound: [0.0008293646842588611]
Threshold 0.4 SUFFICIENT with avar bound: 0.0008293646842588611
Evaluating threshold 0.5 with avar bound: [0.0008293646842588611]
Threshold 0.5 SUFFICIENT with avar bound: 0.0008293646842588611
Evaluating threshold 0.6 with avar bound: [0.0008293646842588611]
Threshold 0.6 SUFFICIENT with avar bound: 0.0008293646842588611
Evaluating threshold 0.7 with avar bound: [0.0008293646842588611]
Threshold 0.7 SUFFICIENT with avar bound: 0.0008293646842588611
Evaluating threshold 0.8 with avar bound: [0.0008293646842588611]
Threshold 0.8 SUFFICIENT with avar bound: 0.0008293646842588611
Evaluating threshold 0.9 with avar bound: [0.0008293646842588611]
Threshold 0.9 SUFFICIENT with avar bound: 0.0008293646842588611

Running BIRL with demonstration 6/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.22
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.37887492  0.0768209  -0.41170222  0.06192651  0.43337779 -0.12522933
  0.68827323]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.004987
0.9-VaR bound for 6 demonstrations: -0.004175
0.95-VaR bound for 6 demonstrations: -0.001952
0.99-VaR bound for 6 demonstrations: 0.004275
True expected value difference for MAP policy: -0.007367
Evaluating threshold 0.1 with avar bound: [-0.0019517446699031083]
Threshold 0.1 SUFFICIENT with avar bound: -0.0019517446699031083
Evaluating threshold 0.2 with avar bound: [-0.0019517446699031083]
Threshold 0.2 SUFFICIENT with avar bound: -0.0019517446699031083
Evaluating threshold 0.3 with avar bound: [-0.0019517446699031083]
Threshold 0.3 SUFFICIENT with avar bound: -0.0019517446699031083
Evaluating threshold 0.4 with avar bound: [-0.0019517446699031083]
Threshold 0.4 SUFFICIENT with avar bound: -0.0019517446699031083
Evaluating threshold 0.5 with avar bound: [-0.0019517446699031083]
Threshold 0.5 SUFFICIENT with avar bound: -0.0019517446699031083
Evaluating threshold 0.6 with avar bound: [-0.0019517446699031083]
Threshold 0.6 SUFFICIENT with avar bound: -0.0019517446699031083
Evaluating threshold 0.7 with avar bound: [-0.0019517446699031083]
Threshold 0.7 SUFFICIENT with avar bound: -0.0019517446699031083
Evaluating threshold 0.8 with avar bound: [-0.0019517446699031083]
Threshold 0.8 SUFFICIENT with avar bound: -0.0019517446699031083
Evaluating threshold 0.9 with avar bound: [-0.0019517446699031083]
Threshold 0.9 SUFFICIENT with avar bound: -0.0019517446699031083

Running BIRL with demonstration 7/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 0)]
MCMC sampling complete.
Acceptance ratio: 0.102
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.44659219 -0.24357702  0.05955497 -0.03722228  0.21486569  0.59242446
  0.58237389]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: 0.015100
0.9-VaR bound for 7 demonstrations: 0.015654
0.95-VaR bound for 7 demonstrations: 0.027231
0.99-VaR bound for 7 demonstrations: 0.027231
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.02723078057299903]
Threshold 0.1 SUFFICIENT with avar bound: 0.02723078057299903
Evaluating threshold 0.2 with avar bound: [0.02723078057299903]
Threshold 0.2 SUFFICIENT with avar bound: 0.02723078057299903
Evaluating threshold 0.3 with avar bound: [0.02723078057299903]
Threshold 0.3 SUFFICIENT with avar bound: 0.02723078057299903
Evaluating threshold 0.4 with avar bound: [0.02723078057299903]
Threshold 0.4 SUFFICIENT with avar bound: 0.02723078057299903
Evaluating threshold 0.5 with avar bound: [0.02723078057299903]
Threshold 0.5 SUFFICIENT with avar bound: 0.02723078057299903
Evaluating threshold 0.6 with avar bound: [0.02723078057299903]
Threshold 0.6 SUFFICIENT with avar bound: 0.02723078057299903
Evaluating threshold 0.7 with avar bound: [0.02723078057299903]
Threshold 0.7 SUFFICIENT with avar bound: 0.02723078057299903
Evaluating threshold 0.8 with avar bound: [0.02723078057299903]
Threshold 0.8 SUFFICIENT with avar bound: 0.02723078057299903
Evaluating threshold 0.9 with avar bound: [0.02723078057299903]
Threshold 0.9 SUFFICIENT with avar bound: 0.02723078057299903

Running BIRL with demonstration 8/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 0), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.106
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.66299944 -0.13080231 -0.28071362 -0.35028794  0.16550964  0.39497486
  0.39802279]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: 0.005085
0.9-VaR bound for 8 demonstrations: 0.052888
0.95-VaR bound for 8 demonstrations: 0.085644
0.99-VaR bound for 8 demonstrations: 0.096078
True expected value difference for MAP policy: -0.009253
Evaluating threshold 0.1 with avar bound: [0.08564359329175993]
Threshold 0.1 SUFFICIENT with avar bound: 0.08564359329175993
Evaluating threshold 0.2 with avar bound: [0.08564359329175993]
Threshold 0.2 SUFFICIENT with avar bound: 0.08564359329175993
Evaluating threshold 0.3 with avar bound: [0.08564359329175993]
Threshold 0.3 SUFFICIENT with avar bound: 0.08564359329175993
Evaluating threshold 0.4 with avar bound: [0.08564359329175993]
Threshold 0.4 SUFFICIENT with avar bound: 0.08564359329175993
Evaluating threshold 0.5 with avar bound: [0.08564359329175993]
Threshold 0.5 SUFFICIENT with avar bound: 0.08564359329175993
Evaluating threshold 0.6 with avar bound: [0.08564359329175993]
Threshold 0.6 SUFFICIENT with avar bound: 0.08564359329175993
Evaluating threshold 0.7 with avar bound: [0.08564359329175993]
Threshold 0.7 SUFFICIENT with avar bound: 0.08564359329175993
Evaluating threshold 0.8 with avar bound: [0.08564359329175993]
Threshold 0.8 SUFFICIENT with avar bound: 0.08564359329175993
Evaluating threshold 0.9 with avar bound: [0.08564359329175993]
Threshold 0.9 SUFFICIENT with avar bound: 0.08564359329175993

Running BIRL with demonstration 9/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 0), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.099
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.49857549 -0.18439666  0.21289855 -0.3568631   0.32024346  0.46463589
  0.47571095]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: 0.001748
0.9-VaR bound for 9 demonstrations: 0.003073
0.95-VaR bound for 9 demonstrations: 0.012968
0.99-VaR bound for 9 demonstrations: 0.012968
True expected value difference for MAP policy: -0.009890
Evaluating threshold 0.1 with avar bound: [0.012967634939167428]
Threshold 0.1 SUFFICIENT with avar bound: 0.012967634939167428
Evaluating threshold 0.2 with avar bound: [0.012967634939167428]
Threshold 0.2 SUFFICIENT with avar bound: 0.012967634939167428
Evaluating threshold 0.3 with avar bound: [0.012967634939167428]
Threshold 0.3 SUFFICIENT with avar bound: 0.012967634939167428
Evaluating threshold 0.4 with avar bound: [0.012967634939167428]
Threshold 0.4 SUFFICIENT with avar bound: 0.012967634939167428
Evaluating threshold 0.5 with avar bound: [0.012967634939167428]
Threshold 0.5 SUFFICIENT with avar bound: 0.012967634939167428
Evaluating threshold 0.6 with avar bound: [0.012967634939167428]
Threshold 0.6 SUFFICIENT with avar bound: 0.012967634939167428
Evaluating threshold 0.7 with avar bound: [0.012967634939167428]
Threshold 0.7 SUFFICIENT with avar bound: 0.012967634939167428
Evaluating threshold 0.8 with avar bound: [0.012967634939167428]
Threshold 0.8 SUFFICIENT with avar bound: 0.012967634939167428
Evaluating threshold 0.9 with avar bound: [0.012967634939167428]
Threshold 0.9 SUFFICIENT with avar bound: 0.012967634939167428

Running BIRL with demonstration 10/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 0), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.096
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.80825003 -0.09272594 -0.35355324 -0.29356286  0.0830308   0.24230147
  0.2476906 ]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: 0.002221
0.9-VaR bound for 10 demonstrations: 0.008935
0.95-VaR bound for 10 demonstrations: 0.020397
0.99-VaR bound for 10 demonstrations: 0.043224
True expected value difference for MAP policy: -0.009253
Evaluating threshold 0.1 with avar bound: [0.02039731436354254]
Threshold 0.1 SUFFICIENT with avar bound: 0.02039731436354254
Evaluating threshold 0.2 with avar bound: [0.02039731436354254]
Threshold 0.2 SUFFICIENT with avar bound: 0.02039731436354254
Evaluating threshold 0.3 with avar bound: [0.02039731436354254]
Threshold 0.3 SUFFICIENT with avar bound: 0.02039731436354254
Evaluating threshold 0.4 with avar bound: [0.02039731436354254]
Threshold 0.4 SUFFICIENT with avar bound: 0.02039731436354254
Evaluating threshold 0.5 with avar bound: [0.02039731436354254]
Threshold 0.5 SUFFICIENT with avar bound: 0.02039731436354254
Evaluating threshold 0.6 with avar bound: [0.02039731436354254]
Threshold 0.6 SUFFICIENT with avar bound: 0.02039731436354254
Evaluating threshold 0.7 with avar bound: [0.02039731436354254]
Threshold 0.7 SUFFICIENT with avar bound: 0.02039731436354254
Evaluating threshold 0.8 with avar bound: [0.02039731436354254]
Threshold 0.8 SUFFICIENT with avar bound: 0.02039731436354254
Evaluating threshold 0.9 with avar bound: [0.02039731436354254]
Threshold 0.9 SUFFICIENT with avar bound: 0.02039731436354254

Running world 7/20

Running BIRL with demonstration 1/10 in world 7
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.353
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.04630779 -0.05716546  0.06283111 -0.31022902  0.14002808  0.51526457
  0.78057188]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 2.041894
0.9-VaR bound for 1 demonstrations: 2.364472
0.95-VaR bound for 1 demonstrations: 2.818063
0.99-VaR bound for 1 demonstrations: 8.530091
True expected value difference for MAP policy: -0.009935
Evaluating threshold 0.1 with avar bound: [2.8180626539022295]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.8180626539022295]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.8180626539022295]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.8180626539022295]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.8180626539022295]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.8180626539022295]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.8180626539022295]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.8180626539022295]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.8180626539022295]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 7
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.291
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.06508638 -0.7230849  -0.18211808 -0.43532497  0.0693228   0.17732054
  0.46258939]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.895121
0.9-VaR bound for 2 demonstrations: 2.256817
0.95-VaR bound for 2 demonstrations: 3.285939
0.99-VaR bound for 2 demonstrations: 13.234618
True expected value difference for MAP policy: -0.010038
Evaluating threshold 0.1 with avar bound: [3.2859390298062294]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.2859390298062294]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.2859390298062294]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.2859390298062294]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.2859390298062294]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.2859390298062294]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.2859390298062294]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.2859390298062294]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.2859390298062294]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 7
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.233
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.23258996 -0.64969881 -0.07824082 -0.17755326  0.24252992  0.27048098
  0.59511836]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.453133
0.9-VaR bound for 3 demonstrations: 2.015432
0.95-VaR bound for 3 demonstrations: 2.480470
0.99-VaR bound for 3 demonstrations: 9.831382
True expected value difference for MAP policy: -0.009872
Evaluating threshold 0.1 with avar bound: [2.480470447816323]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.480470447816323]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.480470447816323]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.480470447816323]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.480470447816323]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.480470447816323]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.480470447816323]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.480470447816323]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.480470447816323]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 7
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.232
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.13797296 -0.60792142 -0.02717865 -0.39913862 -0.00268068  0.2726447
  0.61400518]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.007821
0.9-VaR bound for 4 demonstrations: 0.011911
0.95-VaR bound for 4 demonstrations: 0.019592
0.99-VaR bound for 4 demonstrations: 0.044789
True expected value difference for MAP policy: -0.009935
Evaluating threshold 0.1 with avar bound: [0.019591782723833672]
Threshold 0.1 SUFFICIENT with avar bound: 0.019591782723833672
Evaluating threshold 0.2 with avar bound: [0.019591782723833672]
Threshold 0.2 SUFFICIENT with avar bound: 0.019591782723833672
Evaluating threshold 0.3 with avar bound: [0.019591782723833672]
Threshold 0.3 SUFFICIENT with avar bound: 0.019591782723833672
Evaluating threshold 0.4 with avar bound: [0.019591782723833672]
Threshold 0.4 SUFFICIENT with avar bound: 0.019591782723833672
Evaluating threshold 0.5 with avar bound: [0.019591782723833672]
Threshold 0.5 SUFFICIENT with avar bound: 0.019591782723833672
Evaluating threshold 0.6 with avar bound: [0.019591782723833672]
Threshold 0.6 SUFFICIENT with avar bound: 0.019591782723833672
Evaluating threshold 0.7 with avar bound: [0.019591782723833672]
Threshold 0.7 SUFFICIENT with avar bound: 0.019591782723833672
Evaluating threshold 0.8 with avar bound: [0.019591782723833672]
Threshold 0.8 SUFFICIENT with avar bound: 0.019591782723833672
Evaluating threshold 0.9 with avar bound: [0.019591782723833672]
Threshold 0.9 SUFFICIENT with avar bound: 0.019591782723833672

Running BIRL with demonstration 5/10 in world 7
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.213
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.08036081 -0.51652971 -0.23558181 -0.32307799  0.34233933  0.07111798
  0.66678861]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.006645
0.9-VaR bound for 5 demonstrations: -0.006320
0.95-VaR bound for 5 demonstrations: -0.004653
0.99-VaR bound for 5 demonstrations: 0.085049
True expected value difference for MAP policy: -0.009872
Evaluating threshold 0.1 with avar bound: [-0.004653362097070705]
Threshold 0.1 SUFFICIENT with avar bound: -0.004653362097070705
Evaluating threshold 0.2 with avar bound: [-0.004653362097070705]
Threshold 0.2 SUFFICIENT with avar bound: -0.004653362097070705
Evaluating threshold 0.3 with avar bound: [-0.004653362097070705]
Threshold 0.3 SUFFICIENT with avar bound: -0.004653362097070705
Evaluating threshold 0.4 with avar bound: [-0.004653362097070705]
Threshold 0.4 SUFFICIENT with avar bound: -0.004653362097070705
Evaluating threshold 0.5 with avar bound: [-0.004653362097070705]
Threshold 0.5 SUFFICIENT with avar bound: -0.004653362097070705
Evaluating threshold 0.6 with avar bound: [-0.004653362097070705]
Threshold 0.6 SUFFICIENT with avar bound: -0.004653362097070705
Evaluating threshold 0.7 with avar bound: [-0.004653362097070705]
Threshold 0.7 SUFFICIENT with avar bound: -0.004653362097070705
Evaluating threshold 0.8 with avar bound: [-0.004653362097070705]
Threshold 0.8 SUFFICIENT with avar bound: -0.004653362097070705
Evaluating threshold 0.9 with avar bound: [-0.004653362097070705]
Threshold 0.9 SUFFICIENT with avar bound: -0.004653362097070705

Running BIRL with demonstration 6/10 in world 7
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.196
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.113892   -0.57205098 -0.20118386 -0.55257615  0.12357131  0.10011725
  0.53728727]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.008146
0.9-VaR bound for 6 demonstrations: -0.007312
0.95-VaR bound for 6 demonstrations: -0.002350
0.99-VaR bound for 6 demonstrations: 0.001365
True expected value difference for MAP policy: -0.009935
Evaluating threshold 0.1 with avar bound: [-0.002349848047874109]
Threshold 0.1 SUFFICIENT with avar bound: -0.002349848047874109
Evaluating threshold 0.2 with avar bound: [-0.002349848047874109]
Threshold 0.2 SUFFICIENT with avar bound: -0.002349848047874109
Evaluating threshold 0.3 with avar bound: [-0.002349848047874109]
Threshold 0.3 SUFFICIENT with avar bound: -0.002349848047874109
Evaluating threshold 0.4 with avar bound: [-0.002349848047874109]
Threshold 0.4 SUFFICIENT with avar bound: -0.002349848047874109
Evaluating threshold 0.5 with avar bound: [-0.002349848047874109]
Threshold 0.5 SUFFICIENT with avar bound: -0.002349848047874109
Evaluating threshold 0.6 with avar bound: [-0.002349848047874109]
Threshold 0.6 SUFFICIENT with avar bound: -0.002349848047874109
Evaluating threshold 0.7 with avar bound: [-0.002349848047874109]
Threshold 0.7 SUFFICIENT with avar bound: -0.002349848047874109
Evaluating threshold 0.8 with avar bound: [-0.002349848047874109]
Threshold 0.8 SUFFICIENT with avar bound: -0.002349848047874109
Evaluating threshold 0.9 with avar bound: [-0.002349848047874109]
Threshold 0.9 SUFFICIENT with avar bound: -0.002349848047874109

Running BIRL with demonstration 7/10 in world 7
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.194
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.15378436 -0.54667704 -0.25131249 -0.56250241  0.06728614  0.18316405
  0.50975598]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.008502
0.9-VaR bound for 7 demonstrations: -0.008106
0.95-VaR bound for 7 demonstrations: -0.007413
0.99-VaR bound for 7 demonstrations: -0.006945
True expected value difference for MAP policy: -0.009935
Evaluating threshold 0.1 with avar bound: [-0.007413345170256414]
Threshold 0.1 SUFFICIENT with avar bound: -0.007413345170256414
Evaluating threshold 0.2 with avar bound: [-0.007413345170256414]
Threshold 0.2 SUFFICIENT with avar bound: -0.007413345170256414
Evaluating threshold 0.3 with avar bound: [-0.007413345170256414]
Threshold 0.3 SUFFICIENT with avar bound: -0.007413345170256414
Evaluating threshold 0.4 with avar bound: [-0.007413345170256414]
Threshold 0.4 SUFFICIENT with avar bound: -0.007413345170256414
Evaluating threshold 0.5 with avar bound: [-0.007413345170256414]
Threshold 0.5 SUFFICIENT with avar bound: -0.007413345170256414
Evaluating threshold 0.6 with avar bound: [-0.007413345170256414]
Threshold 0.6 SUFFICIENT with avar bound: -0.007413345170256414
Evaluating threshold 0.7 with avar bound: [-0.007413345170256414]
Threshold 0.7 SUFFICIENT with avar bound: -0.007413345170256414
Evaluating threshold 0.8 with avar bound: [-0.007413345170256414]
Threshold 0.8 SUFFICIENT with avar bound: -0.007413345170256414
Evaluating threshold 0.9 with avar bound: [-0.007413345170256414]
Threshold 0.9 SUFFICIENT with avar bound: -0.007413345170256414

Running BIRL with demonstration 8/10 in world 7
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.19
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.19623058 -0.2315887  -0.22512717 -0.47319017  0.12430185  0.38067878
  0.68767854]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.008477
0.9-VaR bound for 8 demonstrations: -0.007871
0.95-VaR bound for 8 demonstrations: -0.003231
0.99-VaR bound for 8 demonstrations: 0.001575
True expected value difference for MAP policy: -0.009935
Evaluating threshold 0.1 with avar bound: [-0.0032309604793730943]
Threshold 0.1 SUFFICIENT with avar bound: -0.0032309604793730943
Evaluating threshold 0.2 with avar bound: [-0.0032309604793730943]
Threshold 0.2 SUFFICIENT with avar bound: -0.0032309604793730943
Evaluating threshold 0.3 with avar bound: [-0.0032309604793730943]
Threshold 0.3 SUFFICIENT with avar bound: -0.0032309604793730943
Evaluating threshold 0.4 with avar bound: [-0.0032309604793730943]
Threshold 0.4 SUFFICIENT with avar bound: -0.0032309604793730943
Evaluating threshold 0.5 with avar bound: [-0.0032309604793730943]
Threshold 0.5 SUFFICIENT with avar bound: -0.0032309604793730943
Evaluating threshold 0.6 with avar bound: [-0.0032309604793730943]
Threshold 0.6 SUFFICIENT with avar bound: -0.0032309604793730943
Evaluating threshold 0.7 with avar bound: [-0.0032309604793730943]
Threshold 0.7 SUFFICIENT with avar bound: -0.0032309604793730943
Evaluating threshold 0.8 with avar bound: [-0.0032309604793730943]
Threshold 0.8 SUFFICIENT with avar bound: -0.0032309604793730943
Evaluating threshold 0.9 with avar bound: [-0.0032309604793730943]
Threshold 0.9 SUFFICIENT with avar bound: -0.0032309604793730943

Running BIRL with demonstration 9/10 in world 7
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.177
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.02912289 -0.1982073   0.00823813 -0.42275307  0.08923951  0.41902583
  0.77300153]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.009031
0.9-VaR bound for 9 demonstrations: -0.008864
0.95-VaR bound for 9 demonstrations: -0.007790
0.99-VaR bound for 9 demonstrations: -0.006706
True expected value difference for MAP policy: -0.009935
Evaluating threshold 0.1 with avar bound: [-0.007790414943556192]
Threshold 0.1 SUFFICIENT with avar bound: -0.007790414943556192
Evaluating threshold 0.2 with avar bound: [-0.007790414943556192]
Threshold 0.2 SUFFICIENT with avar bound: -0.007790414943556192
Evaluating threshold 0.3 with avar bound: [-0.007790414943556192]
Threshold 0.3 SUFFICIENT with avar bound: -0.007790414943556192
Evaluating threshold 0.4 with avar bound: [-0.007790414943556192]
Threshold 0.4 SUFFICIENT with avar bound: -0.007790414943556192
Evaluating threshold 0.5 with avar bound: [-0.007790414943556192]
Threshold 0.5 SUFFICIENT with avar bound: -0.007790414943556192
Evaluating threshold 0.6 with avar bound: [-0.007790414943556192]
Threshold 0.6 SUFFICIENT with avar bound: -0.007790414943556192
Evaluating threshold 0.7 with avar bound: [-0.007790414943556192]
Threshold 0.7 SUFFICIENT with avar bound: -0.007790414943556192
Evaluating threshold 0.8 with avar bound: [-0.007790414943556192]
Threshold 0.8 SUFFICIENT with avar bound: -0.007790414943556192
Evaluating threshold 0.9 with avar bound: [-0.007790414943556192]
Threshold 0.9 SUFFICIENT with avar bound: -0.007790414943556192

Running BIRL with demonstration 10/10 in world 7
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.173
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.05148721 -0.27017428 -0.12280205 -0.51532816  0.02811726  0.39453753
  0.69804085]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.008406
0.9-VaR bound for 10 demonstrations: -0.008406
0.95-VaR bound for 10 demonstrations: -0.007775
0.99-VaR bound for 10 demonstrations: -0.006127
True expected value difference for MAP policy: -0.009935
Evaluating threshold 0.1 with avar bound: [-0.007775270659844815]
Threshold 0.1 SUFFICIENT with avar bound: -0.007775270659844815
Evaluating threshold 0.2 with avar bound: [-0.007775270659844815]
Threshold 0.2 SUFFICIENT with avar bound: -0.007775270659844815
Evaluating threshold 0.3 with avar bound: [-0.007775270659844815]
Threshold 0.3 SUFFICIENT with avar bound: -0.007775270659844815
Evaluating threshold 0.4 with avar bound: [-0.007775270659844815]
Threshold 0.4 SUFFICIENT with avar bound: -0.007775270659844815
Evaluating threshold 0.5 with avar bound: [-0.007775270659844815]
Threshold 0.5 SUFFICIENT with avar bound: -0.007775270659844815
Evaluating threshold 0.6 with avar bound: [-0.007775270659844815]
Threshold 0.6 SUFFICIENT with avar bound: -0.007775270659844815
Evaluating threshold 0.7 with avar bound: [-0.007775270659844815]
Threshold 0.7 SUFFICIENT with avar bound: -0.007775270659844815
Evaluating threshold 0.8 with avar bound: [-0.007775270659844815]
Threshold 0.8 SUFFICIENT with avar bound: -0.007775270659844815
Evaluating threshold 0.9 with avar bound: [-0.007775270659844815]
Threshold 0.9 SUFFICIENT with avar bound: -0.007775270659844815

Running world 8/20

Running BIRL with demonstration 1/10 in world 8
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.405
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.25638268 -0.26704687  0.69643059 -0.20534319 -0.44433379  0.3503332
 -0.12492649]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 2.229277
0.9-VaR bound for 1 demonstrations: 2.809268
0.95-VaR bound for 1 demonstrations: 3.756510
0.99-VaR bound for 1 demonstrations: 15.030431
True expected value difference for MAP policy: 3.252245
Evaluating threshold 0.1 with avar bound: [3.7565099926014414]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.7565099926014414]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.7565099926014414]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.7565099926014414]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.7565099926014414]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.7565099926014414]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.7565099926014414]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.7565099926014414]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.7565099926014414]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 8
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.245
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.10912582 -0.12914198  0.70234913 -0.29573231 -0.52090027  0.25574786
  0.23220236]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.580280
0.9-VaR bound for 2 demonstrations: 1.720262
0.95-VaR bound for 2 demonstrations: 2.248400
0.99-VaR bound for 2 demonstrations: 3.783199
True expected value difference for MAP policy: 3.256268
Evaluating threshold 0.1 with avar bound: [2.2483997208444277]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.2483997208444277]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.2483997208444277]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.2483997208444277]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.2483997208444277]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.2483997208444277]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.2483997208444277]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.2483997208444277]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.2483997208444277]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 8
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.237
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.65426857  0.12123002 -0.33637922  0.13878589 -0.29590331  0.02092813
  0.5803677 ]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.009425
0.9-VaR bound for 3 demonstrations: 0.618522
0.95-VaR bound for 3 demonstrations: 1.173705
0.99-VaR bound for 3 demonstrations: 2.092822
True expected value difference for MAP policy: 0.009771
Evaluating threshold 0.1 with avar bound: [1.1737047678289274]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.1737047678289274]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.1737047678289274]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.1737047678289274]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.1737047678289274]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.1737047678289274]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.1737047678289274]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.1737047678289274]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.1737047678289274]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 8
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.256
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.51788683  0.14742067 -0.20065822 -0.43456248 -0.12958213 -0.09788547
  0.67422475]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.001372
0.9-VaR bound for 4 demonstrations: 0.001980
0.95-VaR bound for 4 demonstrations: 0.005305
0.99-VaR bound for 4 demonstrations: 0.016887
True expected value difference for MAP policy: 0.007890
Evaluating threshold 0.1 with avar bound: [0.005304950526909743]
Threshold 0.1 SUFFICIENT with avar bound: 0.005304950526909743
Evaluating threshold 0.2 with avar bound: [0.005304950526909743]
Threshold 0.2 SUFFICIENT with avar bound: 0.005304950526909743
Evaluating threshold 0.3 with avar bound: [0.005304950526909743]
Threshold 0.3 SUFFICIENT with avar bound: 0.005304950526909743
Evaluating threshold 0.4 with avar bound: [0.005304950526909743]
Threshold 0.4 SUFFICIENT with avar bound: 0.005304950526909743
Evaluating threshold 0.5 with avar bound: [0.005304950526909743]
Threshold 0.5 SUFFICIENT with avar bound: 0.005304950526909743
Evaluating threshold 0.6 with avar bound: [0.005304950526909743]
Threshold 0.6 SUFFICIENT with avar bound: 0.005304950526909743
Evaluating threshold 0.7 with avar bound: [0.005304950526909743]
Threshold 0.7 SUFFICIENT with avar bound: 0.005304950526909743
Evaluating threshold 0.8 with avar bound: [0.005304950526909743]
Threshold 0.8 SUFFICIENT with avar bound: 0.005304950526909743
Evaluating threshold 0.9 with avar bound: [0.005304950526909743]
Threshold 0.9 SUFFICIENT with avar bound: 0.005304950526909743

Running BIRL with demonstration 5/10 in world 8
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.224
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.43513275  0.33434643 -0.10487659 -0.58061709 -0.25767186 -0.25207522
  0.46991483]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.002718
0.9-VaR bound for 5 demonstrations: -0.000372
0.95-VaR bound for 5 demonstrations: 0.005255
0.99-VaR bound for 5 demonstrations: 0.028085
True expected value difference for MAP policy: 0.009215
Evaluating threshold 0.1 with avar bound: [0.005255084637628877]
Threshold 0.1 SUFFICIENT with avar bound: 0.005255084637628877
Evaluating threshold 0.2 with avar bound: [0.005255084637628877]
Threshold 0.2 SUFFICIENT with avar bound: 0.005255084637628877
Evaluating threshold 0.3 with avar bound: [0.005255084637628877]
Threshold 0.3 SUFFICIENT with avar bound: 0.005255084637628877
Evaluating threshold 0.4 with avar bound: [0.005255084637628877]
Threshold 0.4 SUFFICIENT with avar bound: 0.005255084637628877
Evaluating threshold 0.5 with avar bound: [0.005255084637628877]
Threshold 0.5 SUFFICIENT with avar bound: 0.005255084637628877
Evaluating threshold 0.6 with avar bound: [0.005255084637628877]
Threshold 0.6 SUFFICIENT with avar bound: 0.005255084637628877
Evaluating threshold 0.7 with avar bound: [0.005255084637628877]
Threshold 0.7 SUFFICIENT with avar bound: 0.005255084637628877
Evaluating threshold 0.8 with avar bound: [0.005255084637628877]
Threshold 0.8 SUFFICIENT with avar bound: 0.005255084637628877
Evaluating threshold 0.9 with avar bound: [0.005255084637628877]
Threshold 0.9 SUFFICIENT with avar bound: 0.005255084637628877

Running BIRL with demonstration 6/10 in world 8
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.19
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.52082467  0.2307588   0.09180528 -0.21786844  0.41111096  0.11004291
  0.66217484]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.003388
0.9-VaR bound for 6 demonstrations: -0.002543
0.95-VaR bound for 6 demonstrations: -0.001051
0.99-VaR bound for 6 demonstrations: 0.012780
True expected value difference for MAP policy: 0.004521
Evaluating threshold 0.1 with avar bound: [-0.0010506048406405287]
Threshold 0.1 SUFFICIENT with avar bound: -0.0010506048406405287
Evaluating threshold 0.2 with avar bound: [-0.0010506048406405287]
Threshold 0.2 SUFFICIENT with avar bound: -0.0010506048406405287
Evaluating threshold 0.3 with avar bound: [-0.0010506048406405287]
Threshold 0.3 SUFFICIENT with avar bound: -0.0010506048406405287
Evaluating threshold 0.4 with avar bound: [-0.0010506048406405287]
Threshold 0.4 SUFFICIENT with avar bound: -0.0010506048406405287
Evaluating threshold 0.5 with avar bound: [-0.0010506048406405287]
Threshold 0.5 SUFFICIENT with avar bound: -0.0010506048406405287
Evaluating threshold 0.6 with avar bound: [-0.0010506048406405287]
Threshold 0.6 SUFFICIENT with avar bound: -0.0010506048406405287
Evaluating threshold 0.7 with avar bound: [-0.0010506048406405287]
Threshold 0.7 SUFFICIENT with avar bound: -0.0010506048406405287
Evaluating threshold 0.8 with avar bound: [-0.0010506048406405287]
Threshold 0.8 SUFFICIENT with avar bound: -0.0010506048406405287
Evaluating threshold 0.9 with avar bound: [-0.0010506048406405287]
Threshold 0.9 SUFFICIENT with avar bound: -0.0010506048406405287

Running BIRL with demonstration 7/10 in world 8
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.49970342  0.11419166  0.17665293 -0.0648237   0.29725633 -0.39752434
  0.67487885]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.000931
0.9-VaR bound for 7 demonstrations: 0.001374
0.95-VaR bound for 7 demonstrations: 0.004599
0.99-VaR bound for 7 demonstrations: 0.054917
True expected value difference for MAP policy: 0.004774
Evaluating threshold 0.1 with avar bound: [0.004599237711040868]
Threshold 0.1 SUFFICIENT with avar bound: 0.004599237711040868
Evaluating threshold 0.2 with avar bound: [0.004599237711040868]
Threshold 0.2 SUFFICIENT with avar bound: 0.004599237711040868
Evaluating threshold 0.3 with avar bound: [0.004599237711040868]
Threshold 0.3 SUFFICIENT with avar bound: 0.004599237711040868
Evaluating threshold 0.4 with avar bound: [0.004599237711040868]
Threshold 0.4 SUFFICIENT with avar bound: 0.004599237711040868
Evaluating threshold 0.5 with avar bound: [0.004599237711040868]
Threshold 0.5 SUFFICIENT with avar bound: 0.004599237711040868
Evaluating threshold 0.6 with avar bound: [0.004599237711040868]
Threshold 0.6 SUFFICIENT with avar bound: 0.004599237711040868
Evaluating threshold 0.7 with avar bound: [0.004599237711040868]
Threshold 0.7 SUFFICIENT with avar bound: 0.004599237711040868
Evaluating threshold 0.8 with avar bound: [0.004599237711040868]
Threshold 0.8 SUFFICIENT with avar bound: 0.004599237711040868
Evaluating threshold 0.9 with avar bound: [0.004599237711040868]
Threshold 0.9 SUFFICIENT with avar bound: 0.004599237711040868

Running BIRL with demonstration 8/10 in world 8
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.196
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.5281581   0.08553962  0.32091392 -0.1799276   0.04779917 -0.28653913
  0.70283915]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: 0.001412
0.9-VaR bound for 8 demonstrations: 0.004055
0.95-VaR bound for 8 demonstrations: 0.013358
0.99-VaR bound for 8 demonstrations: 0.033033
True expected value difference for MAP policy: 0.009020
Evaluating threshold 0.1 with avar bound: [0.013358181877492048]
Threshold 0.1 SUFFICIENT with avar bound: 0.013358181877492048
Evaluating threshold 0.2 with avar bound: [0.013358181877492048]
Threshold 0.2 SUFFICIENT with avar bound: 0.013358181877492048
Evaluating threshold 0.3 with avar bound: [0.013358181877492048]
Threshold 0.3 SUFFICIENT with avar bound: 0.013358181877492048
Evaluating threshold 0.4 with avar bound: [0.013358181877492048]
Threshold 0.4 SUFFICIENT with avar bound: 0.013358181877492048
Evaluating threshold 0.5 with avar bound: [0.013358181877492048]
Threshold 0.5 SUFFICIENT with avar bound: 0.013358181877492048
Evaluating threshold 0.6 with avar bound: [0.013358181877492048]
Threshold 0.6 SUFFICIENT with avar bound: 0.013358181877492048
Evaluating threshold 0.7 with avar bound: [0.013358181877492048]
Threshold 0.7 SUFFICIENT with avar bound: 0.013358181877492048
Evaluating threshold 0.8 with avar bound: [0.013358181877492048]
Threshold 0.8 SUFFICIENT with avar bound: 0.013358181877492048
Evaluating threshold 0.9 with avar bound: [0.013358181877492048]
Threshold 0.9 SUFFICIENT with avar bound: 0.013358181877492048

Running BIRL with demonstration 9/10 in world 8
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.191
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.76117914  0.02818981 -0.21304904 -0.0023154   0.04819123 -0.30499932
  0.52827022]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.003224
0.9-VaR bound for 9 demonstrations: -0.002115
0.95-VaR bound for 9 demonstrations: -0.000038
0.99-VaR bound for 9 demonstrations: 0.009530
True expected value difference for MAP policy: 0.004500
Evaluating threshold 0.1 with avar bound: [-3.782817562284177e-05]
Threshold 0.1 SUFFICIENT with avar bound: -3.782817562284177e-05
Evaluating threshold 0.2 with avar bound: [-3.782817562284177e-05]
Threshold 0.2 SUFFICIENT with avar bound: -3.782817562284177e-05
Evaluating threshold 0.3 with avar bound: [-3.782817562284177e-05]
Threshold 0.3 SUFFICIENT with avar bound: -3.782817562284177e-05
Evaluating threshold 0.4 with avar bound: [-3.782817562284177e-05]
Threshold 0.4 SUFFICIENT with avar bound: -3.782817562284177e-05
Evaluating threshold 0.5 with avar bound: [-3.782817562284177e-05]
Threshold 0.5 SUFFICIENT with avar bound: -3.782817562284177e-05
Evaluating threshold 0.6 with avar bound: [-3.782817562284177e-05]
Threshold 0.6 SUFFICIENT with avar bound: -3.782817562284177e-05
Evaluating threshold 0.7 with avar bound: [-3.782817562284177e-05]
Threshold 0.7 SUFFICIENT with avar bound: -3.782817562284177e-05
Evaluating threshold 0.8 with avar bound: [-3.782817562284177e-05]
Threshold 0.8 SUFFICIENT with avar bound: -3.782817562284177e-05
Evaluating threshold 0.9 with avar bound: [-3.782817562284177e-05]
Threshold 0.9 SUFFICIENT with avar bound: -3.782817562284177e-05

Running BIRL with demonstration 10/10 in world 8
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.177
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.32568516  0.25425323  0.25078574 -0.1334205   0.36110764 -0.37361914
  0.6918092 ]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.002176
0.9-VaR bound for 10 demonstrations: 0.007816
0.95-VaR bound for 10 demonstrations: 0.010445
0.99-VaR bound for 10 demonstrations: 0.045633
True expected value difference for MAP policy: 0.004774
Evaluating threshold 0.1 with avar bound: [0.01044512992365531]
Threshold 0.1 SUFFICIENT with avar bound: 0.01044512992365531
Evaluating threshold 0.2 with avar bound: [0.01044512992365531]
Threshold 0.2 SUFFICIENT with avar bound: 0.01044512992365531
Evaluating threshold 0.3 with avar bound: [0.01044512992365531]
Threshold 0.3 SUFFICIENT with avar bound: 0.01044512992365531
Evaluating threshold 0.4 with avar bound: [0.01044512992365531]
Threshold 0.4 SUFFICIENT with avar bound: 0.01044512992365531
Evaluating threshold 0.5 with avar bound: [0.01044512992365531]
Threshold 0.5 SUFFICIENT with avar bound: 0.01044512992365531
Evaluating threshold 0.6 with avar bound: [0.01044512992365531]
Threshold 0.6 SUFFICIENT with avar bound: 0.01044512992365531
Evaluating threshold 0.7 with avar bound: [0.01044512992365531]
Threshold 0.7 SUFFICIENT with avar bound: 0.01044512992365531
Evaluating threshold 0.8 with avar bound: [0.01044512992365531]
Threshold 0.8 SUFFICIENT with avar bound: 0.01044512992365531
Evaluating threshold 0.9 with avar bound: [0.01044512992365531]
Threshold 0.9 SUFFICIENT with avar bound: 0.01044512992365531

Saving results to files...
Results saved successfully.

Running world 9/20

Running BIRL with demonstration 1/10 in world 9
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.538
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34187387 -0.24561933  0.14300094  0.05950605 -0.25858611  0.84641246
  0.12458866]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.739385
0.9-VaR bound for 1 demonstrations: 2.175313
0.95-VaR bound for 1 demonstrations: 3.296845
0.99-VaR bound for 1 demonstrations: 10.038806
True expected value difference for MAP policy: 0.955008
Evaluating threshold 0.1 with avar bound: [3.2968450586023543]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.2968450586023543]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.2968450586023543]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.2968450586023543]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.2968450586023543]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.2968450586023543]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.2968450586023543]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.2968450586023543]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.2968450586023543]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 9
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.409
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.00418852 -0.26231672 -0.46326928 -0.07164415  0.21485592  0.80099043
  0.1538582 ]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.237281
0.9-VaR bound for 2 demonstrations: 1.368512
0.95-VaR bound for 2 demonstrations: 1.747679
0.99-VaR bound for 2 demonstrations: 2.863611
True expected value difference for MAP policy: 0.931029
Evaluating threshold 0.1 with avar bound: [1.7476788029213333]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.7476788029213333]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.7476788029213333]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.7476788029213333]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.7476788029213333]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.7476788029213333]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.7476788029213333]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.7476788029213333]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.7476788029213333]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.388
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.1175007  -0.1619625  -0.22447729  0.18195055  0.18442487  0.90091852
 -0.17549634]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.127237
0.9-VaR bound for 3 demonstrations: 1.478126
0.95-VaR bound for 3 demonstrations: 2.231280
0.99-VaR bound for 3 demonstrations: 5.121627
True expected value difference for MAP policy: 0.930649
Evaluating threshold 0.1 with avar bound: [2.231280497935346]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.231280497935346]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.231280497935346]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.231280497935346]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.231280497935346]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.231280497935346]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.231280497935346]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.231280497935346]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.231280497935346]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.236
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.04352169 -0.65899748 -0.39596748  0.24826597  0.21602185  0.02359038
  0.5460586 ]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.000648
0.9-VaR bound for 4 demonstrations: 0.002726
0.95-VaR bound for 4 demonstrations: 0.021323
0.99-VaR bound for 4 demonstrations: 0.054664
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.021323239103277405]
Threshold 0.1 SUFFICIENT with avar bound: 0.021323239103277405
Evaluating threshold 0.2 with avar bound: [0.021323239103277405]
Threshold 0.2 SUFFICIENT with avar bound: 0.021323239103277405
Evaluating threshold 0.3 with avar bound: [0.021323239103277405]
Threshold 0.3 SUFFICIENT with avar bound: 0.021323239103277405
Evaluating threshold 0.4 with avar bound: [0.021323239103277405]
Threshold 0.4 SUFFICIENT with avar bound: 0.021323239103277405
Evaluating threshold 0.5 with avar bound: [0.021323239103277405]
Threshold 0.5 SUFFICIENT with avar bound: 0.021323239103277405
Evaluating threshold 0.6 with avar bound: [0.021323239103277405]
Threshold 0.6 SUFFICIENT with avar bound: 0.021323239103277405
Evaluating threshold 0.7 with avar bound: [0.021323239103277405]
Threshold 0.7 SUFFICIENT with avar bound: 0.021323239103277405
Evaluating threshold 0.8 with avar bound: [0.021323239103277405]
Threshold 0.8 SUFFICIENT with avar bound: 0.021323239103277405
Evaluating threshold 0.9 with avar bound: [0.021323239103277405]
Threshold 0.9 SUFFICIENT with avar bound: 0.021323239103277405

Running BIRL with demonstration 5/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.229
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.42772634 -0.45913538 -0.34095999  0.27224095  0.15860256  0.2454005
  0.57489116]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.002210
0.9-VaR bound for 5 demonstrations: 0.004341
0.95-VaR bound for 5 demonstrations: 0.007917
0.99-VaR bound for 5 demonstrations: 0.041946
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.00791680419121498]
Threshold 0.1 SUFFICIENT with avar bound: 0.00791680419121498
Evaluating threshold 0.2 with avar bound: [0.00791680419121498]
Threshold 0.2 SUFFICIENT with avar bound: 0.00791680419121498
Evaluating threshold 0.3 with avar bound: [0.00791680419121498]
Threshold 0.3 SUFFICIENT with avar bound: 0.00791680419121498
Evaluating threshold 0.4 with avar bound: [0.00791680419121498]
Threshold 0.4 SUFFICIENT with avar bound: 0.00791680419121498
Evaluating threshold 0.5 with avar bound: [0.00791680419121498]
Threshold 0.5 SUFFICIENT with avar bound: 0.00791680419121498
Evaluating threshold 0.6 with avar bound: [0.00791680419121498]
Threshold 0.6 SUFFICIENT with avar bound: 0.00791680419121498
Evaluating threshold 0.7 with avar bound: [0.00791680419121498]
Threshold 0.7 SUFFICIENT with avar bound: 0.00791680419121498
Evaluating threshold 0.8 with avar bound: [0.00791680419121498]
Threshold 0.8 SUFFICIENT with avar bound: 0.00791680419121498
Evaluating threshold 0.9 with avar bound: [0.00791680419121498]
Threshold 0.9 SUFFICIENT with avar bound: 0.00791680419121498

Running BIRL with demonstration 6/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.216
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.0386465  -0.59695859 -0.21078349  0.46561753  0.10712298  0.12056763
  0.59573958]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.001712
0.9-VaR bound for 6 demonstrations: 0.001374
0.95-VaR bound for 6 demonstrations: 0.001584
0.99-VaR bound for 6 demonstrations: 0.040497
True expected value difference for MAP policy: -0.008923
Evaluating threshold 0.1 with avar bound: [0.0015844249457349618]
Threshold 0.1 SUFFICIENT with avar bound: 0.0015844249457349618
Evaluating threshold 0.2 with avar bound: [0.0015844249457349618]
Threshold 0.2 SUFFICIENT with avar bound: 0.0015844249457349618
Evaluating threshold 0.3 with avar bound: [0.0015844249457349618]
Threshold 0.3 SUFFICIENT with avar bound: 0.0015844249457349618
Evaluating threshold 0.4 with avar bound: [0.0015844249457349618]
Threshold 0.4 SUFFICIENT with avar bound: 0.0015844249457349618
Evaluating threshold 0.5 with avar bound: [0.0015844249457349618]
Threshold 0.5 SUFFICIENT with avar bound: 0.0015844249457349618
Evaluating threshold 0.6 with avar bound: [0.0015844249457349618]
Threshold 0.6 SUFFICIENT with avar bound: 0.0015844249457349618
Evaluating threshold 0.7 with avar bound: [0.0015844249457349618]
Threshold 0.7 SUFFICIENT with avar bound: 0.0015844249457349618
Evaluating threshold 0.8 with avar bound: [0.0015844249457349618]
Threshold 0.8 SUFFICIENT with avar bound: 0.0015844249457349618
Evaluating threshold 0.9 with avar bound: [0.0015844249457349618]
Threshold 0.9 SUFFICIENT with avar bound: 0.0015844249457349618

Running BIRL with demonstration 7/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.207
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.04960006 -0.58411667 -0.41081254  0.3143497   0.09664337  0.2104883
  0.57889517]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.006570
0.9-VaR bound for 7 demonstrations: -0.006217
0.95-VaR bound for 7 demonstrations: -0.003908
0.99-VaR bound for 7 demonstrations: 0.009908
True expected value difference for MAP policy: -0.007882
Evaluating threshold 0.1 with avar bound: [-0.003907522340040375]
Threshold 0.1 SUFFICIENT with avar bound: -0.003907522340040375
Evaluating threshold 0.2 with avar bound: [-0.003907522340040375]
Threshold 0.2 SUFFICIENT with avar bound: -0.003907522340040375
Evaluating threshold 0.3 with avar bound: [-0.003907522340040375]
Threshold 0.3 SUFFICIENT with avar bound: -0.003907522340040375
Evaluating threshold 0.4 with avar bound: [-0.003907522340040375]
Threshold 0.4 SUFFICIENT with avar bound: -0.003907522340040375
Evaluating threshold 0.5 with avar bound: [-0.003907522340040375]
Threshold 0.5 SUFFICIENT with avar bound: -0.003907522340040375
Evaluating threshold 0.6 with avar bound: [-0.003907522340040375]
Threshold 0.6 SUFFICIENT with avar bound: -0.003907522340040375
Evaluating threshold 0.7 with avar bound: [-0.003907522340040375]
Threshold 0.7 SUFFICIENT with avar bound: -0.003907522340040375
Evaluating threshold 0.8 with avar bound: [-0.003907522340040375]
Threshold 0.8 SUFFICIENT with avar bound: -0.003907522340040375
Evaluating threshold 0.9 with avar bound: [-0.003907522340040375]
Threshold 0.9 SUFFICIENT with avar bound: -0.003907522340040375

Running BIRL with demonstration 8/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.168
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.05699767 -0.60225655 -0.36681334  0.48357876 -0.02110231  0.17575881
  0.48404691]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: 0.007703
0.9-VaR bound for 8 demonstrations: 0.008458
0.95-VaR bound for 8 demonstrations: 0.009057
0.99-VaR bound for 8 demonstrations: 0.030615
True expected value difference for MAP policy: 0.003830
Evaluating threshold 0.1 with avar bound: [0.009057357312894794]
Threshold 0.1 SUFFICIENT with avar bound: 0.009057357312894794
Evaluating threshold 0.2 with avar bound: [0.009057357312894794]
Threshold 0.2 SUFFICIENT with avar bound: 0.009057357312894794
Evaluating threshold 0.3 with avar bound: [0.009057357312894794]
Threshold 0.3 SUFFICIENT with avar bound: 0.009057357312894794
Evaluating threshold 0.4 with avar bound: [0.009057357312894794]
Threshold 0.4 SUFFICIENT with avar bound: 0.009057357312894794
Evaluating threshold 0.5 with avar bound: [0.009057357312894794]
Threshold 0.5 SUFFICIENT with avar bound: 0.009057357312894794
Evaluating threshold 0.6 with avar bound: [0.009057357312894794]
Threshold 0.6 SUFFICIENT with avar bound: 0.009057357312894794
Evaluating threshold 0.7 with avar bound: [0.009057357312894794]
Threshold 0.7 SUFFICIENT with avar bound: 0.009057357312894794
Evaluating threshold 0.8 with avar bound: [0.009057357312894794]
Threshold 0.8 SUFFICIENT with avar bound: 0.009057357312894794
Evaluating threshold 0.9 with avar bound: [0.009057357312894794]
Threshold 0.9 SUFFICIENT with avar bound: 0.009057357312894794

Running BIRL with demonstration 9/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.168
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38701323 -0.74867312 -0.21194934  0.06331903  0.03646328  0.17669819
  0.45631752]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.007997
0.9-VaR bound for 9 demonstrations: -0.007560
0.95-VaR bound for 9 demonstrations: -0.005565
0.99-VaR bound for 9 demonstrations: -0.004217
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.005564984811817195]
Threshold 0.1 SUFFICIENT with avar bound: -0.005564984811817195
Evaluating threshold 0.2 with avar bound: [-0.005564984811817195]
Threshold 0.2 SUFFICIENT with avar bound: -0.005564984811817195
Evaluating threshold 0.3 with avar bound: [-0.005564984811817195]
Threshold 0.3 SUFFICIENT with avar bound: -0.005564984811817195
Evaluating threshold 0.4 with avar bound: [-0.005564984811817195]
Threshold 0.4 SUFFICIENT with avar bound: -0.005564984811817195
Evaluating threshold 0.5 with avar bound: [-0.005564984811817195]
Threshold 0.5 SUFFICIENT with avar bound: -0.005564984811817195
Evaluating threshold 0.6 with avar bound: [-0.005564984811817195]
Threshold 0.6 SUFFICIENT with avar bound: -0.005564984811817195
Evaluating threshold 0.7 with avar bound: [-0.005564984811817195]
Threshold 0.7 SUFFICIENT with avar bound: -0.005564984811817195
Evaluating threshold 0.8 with avar bound: [-0.005564984811817195]
Threshold 0.8 SUFFICIENT with avar bound: -0.005564984811817195
Evaluating threshold 0.9 with avar bound: [-0.005564984811817195]
Threshold 0.9 SUFFICIENT with avar bound: -0.005564984811817195

Running BIRL with demonstration 10/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.192
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.0536883  -0.57751241 -0.43469514 -0.02638453  0.18016761  0.19987959
  0.63366297]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.008656
0.9-VaR bound for 10 demonstrations: -0.008163
0.95-VaR bound for 10 demonstrations: -0.006575
0.99-VaR bound for 10 demonstrations: -0.005535
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.006575002293684941]
Threshold 0.1 SUFFICIENT with avar bound: -0.006575002293684941
Evaluating threshold 0.2 with avar bound: [-0.006575002293684941]
Threshold 0.2 SUFFICIENT with avar bound: -0.006575002293684941
Evaluating threshold 0.3 with avar bound: [-0.006575002293684941]
Threshold 0.3 SUFFICIENT with avar bound: -0.006575002293684941
Evaluating threshold 0.4 with avar bound: [-0.006575002293684941]
Threshold 0.4 SUFFICIENT with avar bound: -0.006575002293684941
Evaluating threshold 0.5 with avar bound: [-0.006575002293684941]
Threshold 0.5 SUFFICIENT with avar bound: -0.006575002293684941
Evaluating threshold 0.6 with avar bound: [-0.006575002293684941]
Threshold 0.6 SUFFICIENT with avar bound: -0.006575002293684941
Evaluating threshold 0.7 with avar bound: [-0.006575002293684941]
Threshold 0.7 SUFFICIENT with avar bound: -0.006575002293684941
Evaluating threshold 0.8 with avar bound: [-0.006575002293684941]
Threshold 0.8 SUFFICIENT with avar bound: -0.006575002293684941
Evaluating threshold 0.9 with avar bound: [-0.006575002293684941]
Threshold 0.9 SUFFICIENT with avar bound: -0.006575002293684941

Running world 10/20

Running BIRL with demonstration 1/10 in world 10
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.383
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.03582675  0.12298116 -0.13367734 -0.12249174  0.84954254 -0.45011484
 -0.16245713]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 0.936807
0.9-VaR bound for 1 demonstrations: 1.043766
0.95-VaR bound for 1 demonstrations: 1.334022
0.99-VaR bound for 1 demonstrations: 3.079690
True expected value difference for MAP policy: 0.274357
Evaluating threshold 0.1 with avar bound: [1.3340217609067184]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3340217609067184]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3340217609067184]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3340217609067184]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3340217609067184]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3340217609067184]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3340217609067184]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3340217609067184]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3340217609067184]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 10
Current demos: [(16, 1), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.308
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.3753782  -0.13702046 -0.04396792  0.14673545  0.83231793 -0.28038909
 -0.21326264]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 0.381315
0.9-VaR bound for 2 demonstrations: 0.581769
0.95-VaR bound for 2 demonstrations: 1.238664
0.99-VaR bound for 2 demonstrations: 315.344397
True expected value difference for MAP policy: 0.194714
Evaluating threshold 0.1 with avar bound: [1.2386641147704407]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.2386641147704407]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.2386641147704407]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.2386641147704407]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.2386641147704407]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.2386641147704407]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.2386641147704407]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.2386641147704407]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.2386641147704407]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 10
Current demos: [(16, 1), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.197
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.41948862  0.50693745 -0.04319856 -0.32343967  0.29352045 -0.14714552
  0.59393461]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.878453
0.9-VaR bound for 3 demonstrations: 2.111160
0.95-VaR bound for 3 demonstrations: 2.452345
0.99-VaR bound for 3 demonstrations: 3.711129
True expected value difference for MAP policy: -0.009471
Evaluating threshold 0.1 with avar bound: [2.4523450664992934]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.4523450664992934]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.4523450664992934]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.4523450664992934]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.4523450664992934]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.4523450664992934]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.4523450664992934]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.4523450664992934]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.4523450664992934]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 10
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.183
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.46826948  0.34904137 -0.20695572 -0.1359724   0.32635467 -0.15257961
  0.68394937]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.005101
0.9-VaR bound for 4 demonstrations: -0.004364
0.95-VaR bound for 4 demonstrations: -0.000100
0.99-VaR bound for 4 demonstrations: 0.023869
True expected value difference for MAP policy: -0.009845
Evaluating threshold 0.1 with avar bound: [-0.0001003242804243377]
Threshold 0.1 SUFFICIENT with avar bound: -0.0001003242804243377
Evaluating threshold 0.2 with avar bound: [-0.0001003242804243377]
Threshold 0.2 SUFFICIENT with avar bound: -0.0001003242804243377
Evaluating threshold 0.3 with avar bound: [-0.0001003242804243377]
Threshold 0.3 SUFFICIENT with avar bound: -0.0001003242804243377
Evaluating threshold 0.4 with avar bound: [-0.0001003242804243377]
Threshold 0.4 SUFFICIENT with avar bound: -0.0001003242804243377
Evaluating threshold 0.5 with avar bound: [-0.0001003242804243377]
Threshold 0.5 SUFFICIENT with avar bound: -0.0001003242804243377
Evaluating threshold 0.6 with avar bound: [-0.0001003242804243377]
Threshold 0.6 SUFFICIENT with avar bound: -0.0001003242804243377
Evaluating threshold 0.7 with avar bound: [-0.0001003242804243377]
Threshold 0.7 SUFFICIENT with avar bound: -0.0001003242804243377
Evaluating threshold 0.8 with avar bound: [-0.0001003242804243377]
Threshold 0.8 SUFFICIENT with avar bound: -0.0001003242804243377
Evaluating threshold 0.9 with avar bound: [-0.0001003242804243377]
Threshold 0.9 SUFFICIENT with avar bound: -0.0001003242804243377

Running BIRL with demonstration 5/10 in world 10
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.25309396 -0.14981455 -0.39550392  0.06880435  0.44342793 -0.08503097
  0.74059643]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.006475
0.9-VaR bound for 5 demonstrations: -0.006102
0.95-VaR bound for 5 demonstrations: -0.001956
0.99-VaR bound for 5 demonstrations: 0.019246
True expected value difference for MAP policy: -0.009791
Evaluating threshold 0.1 with avar bound: [-0.0019560337498463333]
Threshold 0.1 SUFFICIENT with avar bound: -0.0019560337498463333
Evaluating threshold 0.2 with avar bound: [-0.0019560337498463333]
Threshold 0.2 SUFFICIENT with avar bound: -0.0019560337498463333
Evaluating threshold 0.3 with avar bound: [-0.0019560337498463333]
Threshold 0.3 SUFFICIENT with avar bound: -0.0019560337498463333
Evaluating threshold 0.4 with avar bound: [-0.0019560337498463333]
Threshold 0.4 SUFFICIENT with avar bound: -0.0019560337498463333
Evaluating threshold 0.5 with avar bound: [-0.0019560337498463333]
Threshold 0.5 SUFFICIENT with avar bound: -0.0019560337498463333
Evaluating threshold 0.6 with avar bound: [-0.0019560337498463333]
Threshold 0.6 SUFFICIENT with avar bound: -0.0019560337498463333
Evaluating threshold 0.7 with avar bound: [-0.0019560337498463333]
Threshold 0.7 SUFFICIENT with avar bound: -0.0019560337498463333
Evaluating threshold 0.8 with avar bound: [-0.0019560337498463333]
Threshold 0.8 SUFFICIENT with avar bound: -0.0019560337498463333
Evaluating threshold 0.9 with avar bound: [-0.0019560337498463333]
Threshold 0.9 SUFFICIENT with avar bound: -0.0019560337498463333

Running BIRL with demonstration 6/10 in world 10
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.181
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.27798148 -0.052216   -0.6115506  -0.37317709  0.18436615 -0.22084053
  0.56919512]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.006372
0.9-VaR bound for 6 demonstrations: -0.005648
0.95-VaR bound for 6 demonstrations: -0.004375
0.99-VaR bound for 6 demonstrations: 0.002319
True expected value difference for MAP policy: -0.008309
Evaluating threshold 0.1 with avar bound: [-0.004375044952770319]
Threshold 0.1 SUFFICIENT with avar bound: -0.004375044952770319
Evaluating threshold 0.2 with avar bound: [-0.004375044952770319]
Threshold 0.2 SUFFICIENT with avar bound: -0.004375044952770319
Evaluating threshold 0.3 with avar bound: [-0.004375044952770319]
Threshold 0.3 SUFFICIENT with avar bound: -0.004375044952770319
Evaluating threshold 0.4 with avar bound: [-0.004375044952770319]
Threshold 0.4 SUFFICIENT with avar bound: -0.004375044952770319
Evaluating threshold 0.5 with avar bound: [-0.004375044952770319]
Threshold 0.5 SUFFICIENT with avar bound: -0.004375044952770319
Evaluating threshold 0.6 with avar bound: [-0.004375044952770319]
Threshold 0.6 SUFFICIENT with avar bound: -0.004375044952770319
Evaluating threshold 0.7 with avar bound: [-0.004375044952770319]
Threshold 0.7 SUFFICIENT with avar bound: -0.004375044952770319
Evaluating threshold 0.8 with avar bound: [-0.004375044952770319]
Threshold 0.8 SUFFICIENT with avar bound: -0.004375044952770319
Evaluating threshold 0.9 with avar bound: [-0.004375044952770319]
Threshold 0.9 SUFFICIENT with avar bound: -0.004375044952770319

Running BIRL with demonstration 7/10 in world 10
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.176
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.42190611  0.16057763 -0.38428088 -0.11809841  0.40161485  0.01960899
  0.68768599]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.006041
0.9-VaR bound for 7 demonstrations: -0.005514
0.95-VaR bound for 7 demonstrations: -0.004346
0.99-VaR bound for 7 demonstrations: 0.039749
True expected value difference for MAP policy: -0.009471
Evaluating threshold 0.1 with avar bound: [-0.00434645978691054]
Threshold 0.1 SUFFICIENT with avar bound: -0.00434645978691054
Evaluating threshold 0.2 with avar bound: [-0.00434645978691054]
Threshold 0.2 SUFFICIENT with avar bound: -0.00434645978691054
Evaluating threshold 0.3 with avar bound: [-0.00434645978691054]
Threshold 0.3 SUFFICIENT with avar bound: -0.00434645978691054
Evaluating threshold 0.4 with avar bound: [-0.00434645978691054]
Threshold 0.4 SUFFICIENT with avar bound: -0.00434645978691054
Evaluating threshold 0.5 with avar bound: [-0.00434645978691054]
Threshold 0.5 SUFFICIENT with avar bound: -0.00434645978691054
Evaluating threshold 0.6 with avar bound: [-0.00434645978691054]
Threshold 0.6 SUFFICIENT with avar bound: -0.00434645978691054
Evaluating threshold 0.7 with avar bound: [-0.00434645978691054]
Threshold 0.7 SUFFICIENT with avar bound: -0.00434645978691054
Evaluating threshold 0.8 with avar bound: [-0.00434645978691054]
Threshold 0.8 SUFFICIENT with avar bound: -0.00434645978691054
Evaluating threshold 0.9 with avar bound: [-0.00434645978691054]
Threshold 0.9 SUFFICIENT with avar bound: -0.00434645978691054

Running BIRL with demonstration 8/10 in world 10
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.174
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.4269528   0.40296412 -0.43067524  0.11070007  0.28309342 -0.11872386
  0.6027921 ]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.005960
0.9-VaR bound for 8 demonstrations: -0.004819
0.95-VaR bound for 8 demonstrations: -0.003394
0.99-VaR bound for 8 demonstrations: 0.020119
True expected value difference for MAP policy: -0.009718
Evaluating threshold 0.1 with avar bound: [-0.003393604851896699]
Threshold 0.1 SUFFICIENT with avar bound: -0.003393604851896699
Evaluating threshold 0.2 with avar bound: [-0.003393604851896699]
Threshold 0.2 SUFFICIENT with avar bound: -0.003393604851896699
Evaluating threshold 0.3 with avar bound: [-0.003393604851896699]
Threshold 0.3 SUFFICIENT with avar bound: -0.003393604851896699
Evaluating threshold 0.4 with avar bound: [-0.003393604851896699]
Threshold 0.4 SUFFICIENT with avar bound: -0.003393604851896699
Evaluating threshold 0.5 with avar bound: [-0.003393604851896699]
Threshold 0.5 SUFFICIENT with avar bound: -0.003393604851896699
Evaluating threshold 0.6 with avar bound: [-0.003393604851896699]
Threshold 0.6 SUFFICIENT with avar bound: -0.003393604851896699
Evaluating threshold 0.7 with avar bound: [-0.003393604851896699]
Threshold 0.7 SUFFICIENT with avar bound: -0.003393604851896699
Evaluating threshold 0.8 with avar bound: [-0.003393604851896699]
Threshold 0.8 SUFFICIENT with avar bound: -0.003393604851896699
Evaluating threshold 0.9 with avar bound: [-0.003393604851896699]
Threshold 0.9 SUFFICIENT with avar bound: -0.003393604851896699

Running BIRL with demonstration 9/10 in world 10
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.174
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34151869  0.03038845 -0.57605795  0.02841089  0.36291918 -0.05221498
  0.64448029]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.007352
0.9-VaR bound for 9 demonstrations: -0.006289
0.95-VaR bound for 9 demonstrations: -0.006289
0.99-VaR bound for 9 demonstrations: -0.003765
True expected value difference for MAP policy: -0.009791
Evaluating threshold 0.1 with avar bound: [-0.006289302535967215]
Threshold 0.1 SUFFICIENT with avar bound: -0.006289302535967215
Evaluating threshold 0.2 with avar bound: [-0.006289302535967215]
Threshold 0.2 SUFFICIENT with avar bound: -0.006289302535967215
Evaluating threshold 0.3 with avar bound: [-0.006289302535967215]
Threshold 0.3 SUFFICIENT with avar bound: -0.006289302535967215
Evaluating threshold 0.4 with avar bound: [-0.006289302535967215]
Threshold 0.4 SUFFICIENT with avar bound: -0.006289302535967215
Evaluating threshold 0.5 with avar bound: [-0.006289302535967215]
Threshold 0.5 SUFFICIENT with avar bound: -0.006289302535967215
Evaluating threshold 0.6 with avar bound: [-0.006289302535967215]
Threshold 0.6 SUFFICIENT with avar bound: -0.006289302535967215
Evaluating threshold 0.7 with avar bound: [-0.006289302535967215]
Threshold 0.7 SUFFICIENT with avar bound: -0.006289302535967215
Evaluating threshold 0.8 with avar bound: [-0.006289302535967215]
Threshold 0.8 SUFFICIENT with avar bound: -0.006289302535967215
Evaluating threshold 0.9 with avar bound: [-0.006289302535967215]
Threshold 0.9 SUFFICIENT with avar bound: -0.006289302535967215

Running BIRL with demonstration 10/10 in world 10
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.193
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.67128368 -0.08708503 -0.52084573 -0.12388079  0.11641793 -0.18435692
  0.45566116]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.006171
0.9-VaR bound for 10 demonstrations: -0.005559
0.95-VaR bound for 10 demonstrations: -0.004769
0.99-VaR bound for 10 demonstrations: -0.003133
True expected value difference for MAP policy: -0.009845
Evaluating threshold 0.1 with avar bound: [-0.004769075646724287]
Threshold 0.1 SUFFICIENT with avar bound: -0.004769075646724287
Evaluating threshold 0.2 with avar bound: [-0.004769075646724287]
Threshold 0.2 SUFFICIENT with avar bound: -0.004769075646724287
Evaluating threshold 0.3 with avar bound: [-0.004769075646724287]
Threshold 0.3 SUFFICIENT with avar bound: -0.004769075646724287
Evaluating threshold 0.4 with avar bound: [-0.004769075646724287]
Threshold 0.4 SUFFICIENT with avar bound: -0.004769075646724287
Evaluating threshold 0.5 with avar bound: [-0.004769075646724287]
Threshold 0.5 SUFFICIENT with avar bound: -0.004769075646724287
Evaluating threshold 0.6 with avar bound: [-0.004769075646724287]
Threshold 0.6 SUFFICIENT with avar bound: -0.004769075646724287
Evaluating threshold 0.7 with avar bound: [-0.004769075646724287]
Threshold 0.7 SUFFICIENT with avar bound: -0.004769075646724287
Evaluating threshold 0.8 with avar bound: [-0.004769075646724287]
Threshold 0.8 SUFFICIENT with avar bound: -0.004769075646724287
Evaluating threshold 0.9 with avar bound: [-0.004769075646724287]
Threshold 0.9 SUFFICIENT with avar bound: -0.004769075646724287

Running world 11/20

Running BIRL with demonstration 1/10 in world 11
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.348
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.33123739 -0.05023069 -0.56788657  0.0510785   0.21851672 -0.10454734
  0.70991183]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.877673
0.9-VaR bound for 1 demonstrations: 2.289146
0.95-VaR bound for 1 demonstrations: 2.627551
0.99-VaR bound for 1 demonstrations: 3.372684
True expected value difference for MAP policy: 0.010242
Evaluating threshold 0.1 with avar bound: [2.6275506206940094]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.6275506206940094]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.6275506206940094]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.6275506206940094]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.6275506206940094]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.6275506206940094]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.6275506206940094]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.6275506206940094]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.6275506206940094]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 11
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.296
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.52132761 -0.36440866 -0.27449063 -0.05447466  0.45473242 -0.07511296
  0.55198526]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.587689
0.9-VaR bound for 2 demonstrations: 2.046989
0.95-VaR bound for 2 demonstrations: 3.111159
0.99-VaR bound for 2 demonstrations: 7.993116
True expected value difference for MAP policy: -0.009340
Evaluating threshold 0.1 with avar bound: [3.1111587300012333]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.1111587300012333]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.1111587300012333]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.1111587300012333]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.1111587300012333]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.1111587300012333]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.1111587300012333]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.1111587300012333]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.1111587300012333]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 11
Current demos: [(16, 3), (12, 1), (9, 2)]
MCMC sampling complete.
Acceptance ratio: 0.245
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.15481208 -0.12522922  0.04823854  0.10287486  0.93513223  0.01723367
 -0.2695763 ]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.193423
0.9-VaR bound for 3 demonstrations: 0.231796
0.95-VaR bound for 3 demonstrations: 0.609415
0.99-VaR bound for 3 demonstrations: 1.192697
True expected value difference for MAP policy: 0.589890
Evaluating threshold 0.1 with avar bound: [0.609415232231341]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.609415232231341]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.609415232231341]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.609415232231341]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.609415232231341]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.609415232231341]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [0.609415232231341]
Threshold 0.7 SUFFICIENT with avar bound: 0.609415232231341
Evaluating threshold 0.8 with avar bound: [0.609415232231341]
Threshold 0.8 SUFFICIENT with avar bound: 0.609415232231341
Evaluating threshold 0.9 with avar bound: [0.609415232231341]
Threshold 0.9 SUFFICIENT with avar bound: 0.609415232231341

Running BIRL with demonstration 4/10 in world 11
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.128
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.72598415 -0.46856598  0.02290226  0.02635574  0.34585823  0.02575097
  0.36317044]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.024827
0.9-VaR bound for 4 demonstrations: 0.029811
0.95-VaR bound for 4 demonstrations: 0.032439
0.99-VaR bound for 4 demonstrations: 0.046210
True expected value difference for MAP policy: -0.009624
Evaluating threshold 0.1 with avar bound: [0.03243905763525578]
Threshold 0.1 SUFFICIENT with avar bound: 0.03243905763525578
Evaluating threshold 0.2 with avar bound: [0.03243905763525578]
Threshold 0.2 SUFFICIENT with avar bound: 0.03243905763525578
Evaluating threshold 0.3 with avar bound: [0.03243905763525578]
Threshold 0.3 SUFFICIENT with avar bound: 0.03243905763525578
Evaluating threshold 0.4 with avar bound: [0.03243905763525578]
Threshold 0.4 SUFFICIENT with avar bound: 0.03243905763525578
Evaluating threshold 0.5 with avar bound: [0.03243905763525578]
Threshold 0.5 SUFFICIENT with avar bound: 0.03243905763525578
Evaluating threshold 0.6 with avar bound: [0.03243905763525578]
Threshold 0.6 SUFFICIENT with avar bound: 0.03243905763525578
Evaluating threshold 0.7 with avar bound: [0.03243905763525578]
Threshold 0.7 SUFFICIENT with avar bound: 0.03243905763525578
Evaluating threshold 0.8 with avar bound: [0.03243905763525578]
Threshold 0.8 SUFFICIENT with avar bound: 0.03243905763525578
Evaluating threshold 0.9 with avar bound: [0.03243905763525578]
Threshold 0.9 SUFFICIENT with avar bound: 0.03243905763525578

Running BIRL with demonstration 5/10 in world 11
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.131
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.72088156 -0.37046396 -0.19739467 -0.05323159  0.38584759  0.20426629
  0.3326934 ]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.012433
0.9-VaR bound for 5 demonstrations: 0.034744
0.95-VaR bound for 5 demonstrations: 0.034744
0.99-VaR bound for 5 demonstrations: 0.118360
True expected value difference for MAP policy: -0.007467
Evaluating threshold 0.1 with avar bound: [0.03474383030548764]
Threshold 0.1 SUFFICIENT with avar bound: 0.03474383030548764
Evaluating threshold 0.2 with avar bound: [0.03474383030548764]
Threshold 0.2 SUFFICIENT with avar bound: 0.03474383030548764
Evaluating threshold 0.3 with avar bound: [0.03474383030548764]
Threshold 0.3 SUFFICIENT with avar bound: 0.03474383030548764
Evaluating threshold 0.4 with avar bound: [0.03474383030548764]
Threshold 0.4 SUFFICIENT with avar bound: 0.03474383030548764
Evaluating threshold 0.5 with avar bound: [0.03474383030548764]
Threshold 0.5 SUFFICIENT with avar bound: 0.03474383030548764
Evaluating threshold 0.6 with avar bound: [0.03474383030548764]
Threshold 0.6 SUFFICIENT with avar bound: 0.03474383030548764
Evaluating threshold 0.7 with avar bound: [0.03474383030548764]
Threshold 0.7 SUFFICIENT with avar bound: 0.03474383030548764
Evaluating threshold 0.8 with avar bound: [0.03474383030548764]
Threshold 0.8 SUFFICIENT with avar bound: 0.03474383030548764
Evaluating threshold 0.9 with avar bound: [0.03474383030548764]
Threshold 0.9 SUFFICIENT with avar bound: 0.03474383030548764

Running BIRL with demonstration 6/10 in world 11
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.125
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.56507695 -0.32369456 -0.09017879  0.23901846  0.53044781 -0.00224868
  0.47881928]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.003481
0.9-VaR bound for 6 demonstrations: -0.003086
0.95-VaR bound for 6 demonstrations: -0.001026
0.99-VaR bound for 6 demonstrations: 0.021684
True expected value difference for MAP policy: -0.007914
Evaluating threshold 0.1 with avar bound: [-0.0010261763940482504]
Threshold 0.1 SUFFICIENT with avar bound: -0.0010261763940482504
Evaluating threshold 0.2 with avar bound: [-0.0010261763940482504]
Threshold 0.2 SUFFICIENT with avar bound: -0.0010261763940482504
Evaluating threshold 0.3 with avar bound: [-0.0010261763940482504]
Threshold 0.3 SUFFICIENT with avar bound: -0.0010261763940482504
Evaluating threshold 0.4 with avar bound: [-0.0010261763940482504]
Threshold 0.4 SUFFICIENT with avar bound: -0.0010261763940482504
Evaluating threshold 0.5 with avar bound: [-0.0010261763940482504]
Threshold 0.5 SUFFICIENT with avar bound: -0.0010261763940482504
Evaluating threshold 0.6 with avar bound: [-0.0010261763940482504]
Threshold 0.6 SUFFICIENT with avar bound: -0.0010261763940482504
Evaluating threshold 0.7 with avar bound: [-0.0010261763940482504]
Threshold 0.7 SUFFICIENT with avar bound: -0.0010261763940482504
Evaluating threshold 0.8 with avar bound: [-0.0010261763940482504]
Threshold 0.8 SUFFICIENT with avar bound: -0.0010261763940482504
Evaluating threshold 0.9 with avar bound: [-0.0010261763940482504]
Threshold 0.9 SUFFICIENT with avar bound: -0.0010261763940482504

Running BIRL with demonstration 7/10 in world 11
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.114
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62720422 -0.06951758 -0.036325    0.1557194   0.29696365  0.46807971
  0.51858279]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.008373
0.9-VaR bound for 7 demonstrations: -0.005385
0.95-VaR bound for 7 demonstrations: -0.001166
0.99-VaR bound for 7 demonstrations: 0.002394
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.001165944649742196]
Threshold 0.1 SUFFICIENT with avar bound: -0.001165944649742196
Evaluating threshold 0.2 with avar bound: [-0.001165944649742196]
Threshold 0.2 SUFFICIENT with avar bound: -0.001165944649742196
Evaluating threshold 0.3 with avar bound: [-0.001165944649742196]
Threshold 0.3 SUFFICIENT with avar bound: -0.001165944649742196
Evaluating threshold 0.4 with avar bound: [-0.001165944649742196]
Threshold 0.4 SUFFICIENT with avar bound: -0.001165944649742196
Evaluating threshold 0.5 with avar bound: [-0.001165944649742196]
Threshold 0.5 SUFFICIENT with avar bound: -0.001165944649742196
Evaluating threshold 0.6 with avar bound: [-0.001165944649742196]
Threshold 0.6 SUFFICIENT with avar bound: -0.001165944649742196
Evaluating threshold 0.7 with avar bound: [-0.001165944649742196]
Threshold 0.7 SUFFICIENT with avar bound: -0.001165944649742196
Evaluating threshold 0.8 with avar bound: [-0.001165944649742196]
Threshold 0.8 SUFFICIENT with avar bound: -0.001165944649742196
Evaluating threshold 0.9 with avar bound: [-0.001165944649742196]
Threshold 0.9 SUFFICIENT with avar bound: -0.001165944649742196

Running BIRL with demonstration 8/10 in world 11
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.127
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.6761304  -0.11380427 -0.21368743  0.27048737  0.23421642  0.36177468
  0.47469177]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.007340
0.9-VaR bound for 8 demonstrations: -0.002413
0.95-VaR bound for 8 demonstrations: -0.002413
0.99-VaR bound for 8 demonstrations: 0.012512
True expected value difference for MAP policy: -0.009635
Evaluating threshold 0.1 with avar bound: [-0.0024133585226643784]
Threshold 0.1 SUFFICIENT with avar bound: -0.0024133585226643784
Evaluating threshold 0.2 with avar bound: [-0.0024133585226643784]
Threshold 0.2 SUFFICIENT with avar bound: -0.0024133585226643784
Evaluating threshold 0.3 with avar bound: [-0.0024133585226643784]
Threshold 0.3 SUFFICIENT with avar bound: -0.0024133585226643784
Evaluating threshold 0.4 with avar bound: [-0.0024133585226643784]
Threshold 0.4 SUFFICIENT with avar bound: -0.0024133585226643784
Evaluating threshold 0.5 with avar bound: [-0.0024133585226643784]
Threshold 0.5 SUFFICIENT with avar bound: -0.0024133585226643784
Evaluating threshold 0.6 with avar bound: [-0.0024133585226643784]
Threshold 0.6 SUFFICIENT with avar bound: -0.0024133585226643784
Evaluating threshold 0.7 with avar bound: [-0.0024133585226643784]
Threshold 0.7 SUFFICIENT with avar bound: -0.0024133585226643784
Evaluating threshold 0.8 with avar bound: [-0.0024133585226643784]
Threshold 0.8 SUFFICIENT with avar bound: -0.0024133585226643784
Evaluating threshold 0.9 with avar bound: [-0.0024133585226643784]
Threshold 0.9 SUFFICIENT with avar bound: -0.0024133585226643784

Running BIRL with demonstration 9/10 in world 11
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.123
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.75194459 -0.24918909 -0.04082321  0.13977486  0.28632651  0.25372262
  0.45268372]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.006576
0.9-VaR bound for 9 demonstrations: -0.004988
0.95-VaR bound for 9 demonstrations: -0.003249
0.99-VaR bound for 9 demonstrations: 0.121971
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.0032487409465710073]
Threshold 0.1 SUFFICIENT with avar bound: -0.0032487409465710073
Evaluating threshold 0.2 with avar bound: [-0.0032487409465710073]
Threshold 0.2 SUFFICIENT with avar bound: -0.0032487409465710073
Evaluating threshold 0.3 with avar bound: [-0.0032487409465710073]
Threshold 0.3 SUFFICIENT with avar bound: -0.0032487409465710073
Evaluating threshold 0.4 with avar bound: [-0.0032487409465710073]
Threshold 0.4 SUFFICIENT with avar bound: -0.0032487409465710073
Evaluating threshold 0.5 with avar bound: [-0.0032487409465710073]
Threshold 0.5 SUFFICIENT with avar bound: -0.0032487409465710073
Evaluating threshold 0.6 with avar bound: [-0.0032487409465710073]
Threshold 0.6 SUFFICIENT with avar bound: -0.0032487409465710073
Evaluating threshold 0.7 with avar bound: [-0.0032487409465710073]
Threshold 0.7 SUFFICIENT with avar bound: -0.0032487409465710073
Evaluating threshold 0.8 with avar bound: [-0.0032487409465710073]
Threshold 0.8 SUFFICIENT with avar bound: -0.0032487409465710073
Evaluating threshold 0.9 with avar bound: [-0.0032487409465710073]
Threshold 0.9 SUFFICIENT with avar bound: -0.0032487409465710073

Running BIRL with demonstration 10/10 in world 11
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.122
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.77385322 -0.11478218  0.06136442  0.11634928  0.18629193  0.35446585
  0.45860961]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.007418
0.9-VaR bound for 10 demonstrations: -0.006204
0.95-VaR bound for 10 demonstrations: -0.003668
0.99-VaR bound for 10 demonstrations: 0.000432
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.0036677864152125364]
Threshold 0.1 SUFFICIENT with avar bound: -0.0036677864152125364
Evaluating threshold 0.2 with avar bound: [-0.0036677864152125364]
Threshold 0.2 SUFFICIENT with avar bound: -0.0036677864152125364
Evaluating threshold 0.3 with avar bound: [-0.0036677864152125364]
Threshold 0.3 SUFFICIENT with avar bound: -0.0036677864152125364
Evaluating threshold 0.4 with avar bound: [-0.0036677864152125364]
Threshold 0.4 SUFFICIENT with avar bound: -0.0036677864152125364
Evaluating threshold 0.5 with avar bound: [-0.0036677864152125364]
Threshold 0.5 SUFFICIENT with avar bound: -0.0036677864152125364
Evaluating threshold 0.6 with avar bound: [-0.0036677864152125364]
Threshold 0.6 SUFFICIENT with avar bound: -0.0036677864152125364
Evaluating threshold 0.7 with avar bound: [-0.0036677864152125364]
Threshold 0.7 SUFFICIENT with avar bound: -0.0036677864152125364
Evaluating threshold 0.8 with avar bound: [-0.0036677864152125364]
Threshold 0.8 SUFFICIENT with avar bound: -0.0036677864152125364
Evaluating threshold 0.9 with avar bound: [-0.0036677864152125364]
Threshold 0.9 SUFFICIENT with avar bound: -0.0036677864152125364

Running world 12/20

Running BIRL with demonstration 1/10 in world 12
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.336
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.3843499  -0.01668293 -0.53344321 -0.4404298  -0.08281411  0.29179378
  0.53052331]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.854242
0.9-VaR bound for 1 demonstrations: 2.123230
0.95-VaR bound for 1 demonstrations: 2.744790
0.99-VaR bound for 1 demonstrations: 11.279964
True expected value difference for MAP policy: -0.007751
Evaluating threshold 0.1 with avar bound: [2.744790017769627]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.744790017769627]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.744790017769627]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.744790017769627]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.744790017769627]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.744790017769627]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.744790017769627]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.744790017769627]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.744790017769627]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 12
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.252
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.35385101  0.37573609  0.07105656  0.28298323  0.08067797 -0.54771397
  0.5847938 ]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 2.152522
0.9-VaR bound for 2 demonstrations: 2.858356
0.95-VaR bound for 2 demonstrations: 3.028209
0.99-VaR bound for 2 demonstrations: 19.514594
True expected value difference for MAP policy: 0.010570
Evaluating threshold 0.1 with avar bound: [3.028209068812711]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.028209068812711]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.028209068812711]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.028209068812711]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.028209068812711]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.028209068812711]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.028209068812711]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.028209068812711]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.028209068812711]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.239
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61833679  0.01601984  0.02105254  0.11691356  0.03241341 -0.7094229
  0.31457832]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.423444
0.9-VaR bound for 3 demonstrations: 1.847939
0.95-VaR bound for 3 demonstrations: 2.896664
0.99-VaR bound for 3 demonstrations: 6.561331
True expected value difference for MAP policy: 0.009636
Evaluating threshold 0.1 with avar bound: [2.896663711013256]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.896663711013256]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.896663711013256]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.896663711013256]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.896663711013256]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.896663711013256]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.896663711013256]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.896663711013256]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.896663711013256]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.252
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.52355359 -0.05143103  0.28547697  0.0674098   0.04723389 -0.71357709
  0.35465758]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.006459
0.9-VaR bound for 4 demonstrations: 0.008248
0.95-VaR bound for 4 demonstrations: 0.015119
0.99-VaR bound for 4 demonstrations: 0.221570
True expected value difference for MAP policy: 0.009368
Evaluating threshold 0.1 with avar bound: [0.015118855530414406]
Threshold 0.1 SUFFICIENT with avar bound: 0.015118855530414406
Evaluating threshold 0.2 with avar bound: [0.015118855530414406]
Threshold 0.2 SUFFICIENT with avar bound: 0.015118855530414406
Evaluating threshold 0.3 with avar bound: [0.015118855530414406]
Threshold 0.3 SUFFICIENT with avar bound: 0.015118855530414406
Evaluating threshold 0.4 with avar bound: [0.015118855530414406]
Threshold 0.4 SUFFICIENT with avar bound: 0.015118855530414406
Evaluating threshold 0.5 with avar bound: [0.015118855530414406]
Threshold 0.5 SUFFICIENT with avar bound: 0.015118855530414406
Evaluating threshold 0.6 with avar bound: [0.015118855530414406]
Threshold 0.6 SUFFICIENT with avar bound: 0.015118855530414406
Evaluating threshold 0.7 with avar bound: [0.015118855530414406]
Threshold 0.7 SUFFICIENT with avar bound: 0.015118855530414406
Evaluating threshold 0.8 with avar bound: [0.015118855530414406]
Threshold 0.8 SUFFICIENT with avar bound: 0.015118855530414406
Evaluating threshold 0.9 with avar bound: [0.015118855530414406]
Threshold 0.9 SUFFICIENT with avar bound: 0.015118855530414406

Running BIRL with demonstration 5/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.202
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.72269987 -0.2293973  -0.41910995  0.26363156 -0.00295719 -0.15783159
  0.39370989]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.002454
0.9-VaR bound for 5 demonstrations: 0.005205
0.95-VaR bound for 5 demonstrations: 0.024341
0.99-VaR bound for 5 demonstrations: 0.137883
True expected value difference for MAP policy: -0.000250
Evaluating threshold 0.1 with avar bound: [0.024341234633713255]
Threshold 0.1 SUFFICIENT with avar bound: 0.024341234633713255
Evaluating threshold 0.2 with avar bound: [0.024341234633713255]
Threshold 0.2 SUFFICIENT with avar bound: 0.024341234633713255
Evaluating threshold 0.3 with avar bound: [0.024341234633713255]
Threshold 0.3 SUFFICIENT with avar bound: 0.024341234633713255
Evaluating threshold 0.4 with avar bound: [0.024341234633713255]
Threshold 0.4 SUFFICIENT with avar bound: 0.024341234633713255
Evaluating threshold 0.5 with avar bound: [0.024341234633713255]
Threshold 0.5 SUFFICIENT with avar bound: 0.024341234633713255
Evaluating threshold 0.6 with avar bound: [0.024341234633713255]
Threshold 0.6 SUFFICIENT with avar bound: 0.024341234633713255
Evaluating threshold 0.7 with avar bound: [0.024341234633713255]
Threshold 0.7 SUFFICIENT with avar bound: 0.024341234633713255
Evaluating threshold 0.8 with avar bound: [0.024341234633713255]
Threshold 0.8 SUFFICIENT with avar bound: 0.024341234633713255
Evaluating threshold 0.9 with avar bound: [0.024341234633713255]
Threshold 0.9 SUFFICIENT with avar bound: 0.024341234633713255

Running BIRL with demonstration 6/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.31930019  0.08262432 -0.57033942  0.51305401 -0.07973584 -0.22088223
  0.49755641]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: 0.023451
0.9-VaR bound for 6 demonstrations: 0.030344
0.95-VaR bound for 6 demonstrations: 0.051750
0.99-VaR bound for 6 demonstrations: 0.116648
True expected value difference for MAP policy: 0.012418
Evaluating threshold 0.1 with avar bound: [0.05175007183401549]
Threshold 0.1 SUFFICIENT with avar bound: 0.05175007183401549
Evaluating threshold 0.2 with avar bound: [0.05175007183401549]
Threshold 0.2 SUFFICIENT with avar bound: 0.05175007183401549
Evaluating threshold 0.3 with avar bound: [0.05175007183401549]
Threshold 0.3 SUFFICIENT with avar bound: 0.05175007183401549
Evaluating threshold 0.4 with avar bound: [0.05175007183401549]
Threshold 0.4 SUFFICIENT with avar bound: 0.05175007183401549
Evaluating threshold 0.5 with avar bound: [0.05175007183401549]
Threshold 0.5 SUFFICIENT with avar bound: 0.05175007183401549
Evaluating threshold 0.6 with avar bound: [0.05175007183401549]
Threshold 0.6 SUFFICIENT with avar bound: 0.05175007183401549
Evaluating threshold 0.7 with avar bound: [0.05175007183401549]
Threshold 0.7 SUFFICIENT with avar bound: 0.05175007183401549
Evaluating threshold 0.8 with avar bound: [0.05175007183401549]
Threshold 0.8 SUFFICIENT with avar bound: 0.05175007183401549
Evaluating threshold 0.9 with avar bound: [0.05175007183401549]
Threshold 0.9 SUFFICIENT with avar bound: 0.05175007183401549

Running BIRL with demonstration 7/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.221
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.58859935 -0.08018248 -0.38692238  0.37429481 -0.26170197 -0.16286123
  0.51215656]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: 0.003354
0.9-VaR bound for 7 demonstrations: 0.004287
0.95-VaR bound for 7 demonstrations: 0.009046
0.99-VaR bound for 7 demonstrations: 0.096584
True expected value difference for MAP policy: 0.002478
Evaluating threshold 0.1 with avar bound: [0.009046003043443628]
Threshold 0.1 SUFFICIENT with avar bound: 0.009046003043443628
Evaluating threshold 0.2 with avar bound: [0.009046003043443628]
Threshold 0.2 SUFFICIENT with avar bound: 0.009046003043443628
Evaluating threshold 0.3 with avar bound: [0.009046003043443628]
Threshold 0.3 SUFFICIENT with avar bound: 0.009046003043443628
Evaluating threshold 0.4 with avar bound: [0.009046003043443628]
Threshold 0.4 SUFFICIENT with avar bound: 0.009046003043443628
Evaluating threshold 0.5 with avar bound: [0.009046003043443628]
Threshold 0.5 SUFFICIENT with avar bound: 0.009046003043443628
Evaluating threshold 0.6 with avar bound: [0.009046003043443628]
Threshold 0.6 SUFFICIENT with avar bound: 0.009046003043443628
Evaluating threshold 0.7 with avar bound: [0.009046003043443628]
Threshold 0.7 SUFFICIENT with avar bound: 0.009046003043443628
Evaluating threshold 0.8 with avar bound: [0.009046003043443628]
Threshold 0.8 SUFFICIENT with avar bound: 0.009046003043443628
Evaluating threshold 0.9 with avar bound: [0.009046003043443628]
Threshold 0.9 SUFFICIENT with avar bound: 0.009046003043443628

Running BIRL with demonstration 8/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.43272812 -0.66807527 -0.3848534  -0.1364166   0.26356636  0.09722712
  0.34753394]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.007282
0.9-VaR bound for 8 demonstrations: -0.004156
0.95-VaR bound for 8 demonstrations: -0.001232
0.99-VaR bound for 8 demonstrations: -0.001066
True expected value difference for MAP policy: -0.009617
Evaluating threshold 0.1 with avar bound: [-0.001231501747701372]
Threshold 0.1 SUFFICIENT with avar bound: -0.001231501747701372
Evaluating threshold 0.2 with avar bound: [-0.001231501747701372]
Threshold 0.2 SUFFICIENT with avar bound: -0.001231501747701372
Evaluating threshold 0.3 with avar bound: [-0.001231501747701372]
Threshold 0.3 SUFFICIENT with avar bound: -0.001231501747701372
Evaluating threshold 0.4 with avar bound: [-0.001231501747701372]
Threshold 0.4 SUFFICIENT with avar bound: -0.001231501747701372
Evaluating threshold 0.5 with avar bound: [-0.001231501747701372]
Threshold 0.5 SUFFICIENT with avar bound: -0.001231501747701372
Evaluating threshold 0.6 with avar bound: [-0.001231501747701372]
Threshold 0.6 SUFFICIENT with avar bound: -0.001231501747701372
Evaluating threshold 0.7 with avar bound: [-0.001231501747701372]
Threshold 0.7 SUFFICIENT with avar bound: -0.001231501747701372
Evaluating threshold 0.8 with avar bound: [-0.001231501747701372]
Threshold 0.8 SUFFICIENT with avar bound: -0.001231501747701372
Evaluating threshold 0.9 with avar bound: [-0.001231501747701372]
Threshold 0.9 SUFFICIENT with avar bound: -0.001231501747701372

Running BIRL with demonstration 9/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.192
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.43790264 -0.58592077 -0.18565819 -0.04800966  0.16056403  0.16803287
  0.61167669]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.008194
0.9-VaR bound for 9 demonstrations: -0.007110
0.95-VaR bound for 9 demonstrations: -0.002686
0.99-VaR bound for 9 demonstrations: 0.021510
True expected value difference for MAP policy: -0.009617
Evaluating threshold 0.1 with avar bound: [-0.002685729784361496]
Threshold 0.1 SUFFICIENT with avar bound: -0.002685729784361496
Evaluating threshold 0.2 with avar bound: [-0.002685729784361496]
Threshold 0.2 SUFFICIENT with avar bound: -0.002685729784361496
Evaluating threshold 0.3 with avar bound: [-0.002685729784361496]
Threshold 0.3 SUFFICIENT with avar bound: -0.002685729784361496
Evaluating threshold 0.4 with avar bound: [-0.002685729784361496]
Threshold 0.4 SUFFICIENT with avar bound: -0.002685729784361496
Evaluating threshold 0.5 with avar bound: [-0.002685729784361496]
Threshold 0.5 SUFFICIENT with avar bound: -0.002685729784361496
Evaluating threshold 0.6 with avar bound: [-0.002685729784361496]
Threshold 0.6 SUFFICIENT with avar bound: -0.002685729784361496
Evaluating threshold 0.7 with avar bound: [-0.002685729784361496]
Threshold 0.7 SUFFICIENT with avar bound: -0.002685729784361496
Evaluating threshold 0.8 with avar bound: [-0.002685729784361496]
Threshold 0.8 SUFFICIENT with avar bound: -0.002685729784361496
Evaluating threshold 0.9 with avar bound: [-0.002685729784361496]
Threshold 0.9 SUFFICIENT with avar bound: -0.002685729784361496

Running BIRL with demonstration 10/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.182
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.22511003 -0.32503285 -0.04468442  0.16698867  0.28073925  0.40832388
  0.75382643]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.008847
0.9-VaR bound for 10 demonstrations: -0.008509
0.95-VaR bound for 10 demonstrations: -0.007548
0.99-VaR bound for 10 demonstrations: -0.004972
True expected value difference for MAP policy: -0.009617
Evaluating threshold 0.1 with avar bound: [-0.007547707830135624]
Threshold 0.1 SUFFICIENT with avar bound: -0.007547707830135624
Evaluating threshold 0.2 with avar bound: [-0.007547707830135624]
Threshold 0.2 SUFFICIENT with avar bound: -0.007547707830135624
Evaluating threshold 0.3 with avar bound: [-0.007547707830135624]
Threshold 0.3 SUFFICIENT with avar bound: -0.007547707830135624
Evaluating threshold 0.4 with avar bound: [-0.007547707830135624]
Threshold 0.4 SUFFICIENT with avar bound: -0.007547707830135624
Evaluating threshold 0.5 with avar bound: [-0.007547707830135624]
Threshold 0.5 SUFFICIENT with avar bound: -0.007547707830135624
Evaluating threshold 0.6 with avar bound: [-0.007547707830135624]
Threshold 0.6 SUFFICIENT with avar bound: -0.007547707830135624
Evaluating threshold 0.7 with avar bound: [-0.007547707830135624]
Threshold 0.7 SUFFICIENT with avar bound: -0.007547707830135624
Evaluating threshold 0.8 with avar bound: [-0.007547707830135624]
Threshold 0.8 SUFFICIENT with avar bound: -0.007547707830135624
Evaluating threshold 0.9 with avar bound: [-0.007547707830135624]
Threshold 0.9 SUFFICIENT with avar bound: -0.007547707830135624

Saving results to files...
Results saved successfully.

Running world 13/20

Running BIRL with demonstration 1/10 in world 13
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.377
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.03014206  0.37985901 -0.55504742  0.18336521  0.28745226  0.03046864
  0.65539379]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.934042
0.9-VaR bound for 1 demonstrations: 2.377847
0.95-VaR bound for 1 demonstrations: 3.497244
0.99-VaR bound for 1 demonstrations: 165.971958
True expected value difference for MAP policy: 0.007844
Evaluating threshold 0.1 with avar bound: [3.4972442416685414]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.4972442416685414]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.4972442416685414]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.4972442416685414]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.4972442416685414]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.4972442416685414]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.4972442416685414]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.4972442416685414]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.4972442416685414]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 13
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.284
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.30135215 -0.07358192 -0.25150557 -0.01047186  0.61231162 -0.44072397
  0.52081161]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.391327
0.9-VaR bound for 2 demonstrations: 1.689136
0.95-VaR bound for 2 demonstrations: 2.278801
0.99-VaR bound for 2 demonstrations: 7.496446
True expected value difference for MAP policy: 0.023229
Evaluating threshold 0.1 with avar bound: [2.2788009088122507]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.2788009088122507]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.2788009088122507]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.2788009088122507]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.2788009088122507]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.2788009088122507]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.2788009088122507]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.2788009088122507]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.2788009088122507]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 13
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.252
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.16793468 -0.41972292 -0.24230385 -0.30443965  0.54670439 -0.09575573
  0.57981127]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.433316
0.9-VaR bound for 3 demonstrations: 2.014050
0.95-VaR bound for 3 demonstrations: 2.296688
0.99-VaR bound for 3 demonstrations: 5.776085
True expected value difference for MAP policy: 0.003971
Evaluating threshold 0.1 with avar bound: [2.2966877775138315]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.2966877775138315]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.2966877775138315]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.2966877775138315]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.2966877775138315]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.2966877775138315]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.2966877775138315]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.2966877775138315]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.2966877775138315]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 13
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.259
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.10071667 -0.12214245 -0.16365956 -0.0233884   0.62436591 -0.30502899
  0.6817114 ]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.001560
0.9-VaR bound for 4 demonstrations: 0.000528
0.95-VaR bound for 4 demonstrations: 0.010457
0.99-VaR bound for 4 demonstrations: 0.027244
True expected value difference for MAP policy: 0.008381
Evaluating threshold 0.1 with avar bound: [0.010456795199555762]
Threshold 0.1 SUFFICIENT with avar bound: 0.010456795199555762
Evaluating threshold 0.2 with avar bound: [0.010456795199555762]
Threshold 0.2 SUFFICIENT with avar bound: 0.010456795199555762
Evaluating threshold 0.3 with avar bound: [0.010456795199555762]
Threshold 0.3 SUFFICIENT with avar bound: 0.010456795199555762
Evaluating threshold 0.4 with avar bound: [0.010456795199555762]
Threshold 0.4 SUFFICIENT with avar bound: 0.010456795199555762
Evaluating threshold 0.5 with avar bound: [0.010456795199555762]
Threshold 0.5 SUFFICIENT with avar bound: 0.010456795199555762
Evaluating threshold 0.6 with avar bound: [0.010456795199555762]
Threshold 0.6 SUFFICIENT with avar bound: 0.010456795199555762
Evaluating threshold 0.7 with avar bound: [0.010456795199555762]
Threshold 0.7 SUFFICIENT with avar bound: 0.010456795199555762
Evaluating threshold 0.8 with avar bound: [0.010456795199555762]
Threshold 0.8 SUFFICIENT with avar bound: 0.010456795199555762
Evaluating threshold 0.9 with avar bound: [0.010456795199555762]
Threshold 0.9 SUFFICIENT with avar bound: 0.010456795199555762

Running BIRL with demonstration 5/10 in world 13
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.222
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.51996181 -0.18494331 -0.32873418 -0.05582686  0.59171119  0.05295283
  0.4809644 ]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.000208
0.9-VaR bound for 5 demonstrations: 0.001894
0.95-VaR bound for 5 demonstrations: 0.003966
0.99-VaR bound for 5 demonstrations: 0.035328
True expected value difference for MAP policy: 0.000746
Evaluating threshold 0.1 with avar bound: [0.003966230197483659]
Threshold 0.1 SUFFICIENT with avar bound: 0.003966230197483659
Evaluating threshold 0.2 with avar bound: [0.003966230197483659]
Threshold 0.2 SUFFICIENT with avar bound: 0.003966230197483659
Evaluating threshold 0.3 with avar bound: [0.003966230197483659]
Threshold 0.3 SUFFICIENT with avar bound: 0.003966230197483659
Evaluating threshold 0.4 with avar bound: [0.003966230197483659]
Threshold 0.4 SUFFICIENT with avar bound: 0.003966230197483659
Evaluating threshold 0.5 with avar bound: [0.003966230197483659]
Threshold 0.5 SUFFICIENT with avar bound: 0.003966230197483659
Evaluating threshold 0.6 with avar bound: [0.003966230197483659]
Threshold 0.6 SUFFICIENT with avar bound: 0.003966230197483659
Evaluating threshold 0.7 with avar bound: [0.003966230197483659]
Threshold 0.7 SUFFICIENT with avar bound: 0.003966230197483659
Evaluating threshold 0.8 with avar bound: [0.003966230197483659]
Threshold 0.8 SUFFICIENT with avar bound: 0.003966230197483659
Evaluating threshold 0.9 with avar bound: [0.003966230197483659]
Threshold 0.9 SUFFICIENT with avar bound: 0.003966230197483659

Running BIRL with demonstration 6/10 in world 13
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 0)]
MCMC sampling complete.
Acceptance ratio: 0.117
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.49534823 -0.48324131 -0.6094876  -0.03288822  0.20469496  0.23032932
  0.23151581]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: 0.155453
0.9-VaR bound for 6 demonstrations: 0.269569
0.95-VaR bound for 6 demonstrations: 0.574806
0.99-VaR bound for 6 demonstrations: 5.384943
True expected value difference for MAP policy: -0.006124
Evaluating threshold 0.1 with avar bound: [0.5748061363596917]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.5748061363596917]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.5748061363596917]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.5748061363596917]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.5748061363596917]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.5748061363596917]
Threshold 0.6 SUFFICIENT with avar bound: 0.5748061363596917
Evaluating threshold 0.7 with avar bound: [0.5748061363596917]
Threshold 0.7 SUFFICIENT with avar bound: 0.5748061363596917
Evaluating threshold 0.8 with avar bound: [0.5748061363596917]
Threshold 0.8 SUFFICIENT with avar bound: 0.5748061363596917
Evaluating threshold 0.9 with avar bound: [0.5748061363596917]
Threshold 0.9 SUFFICIENT with avar bound: 0.5748061363596917

Running BIRL with demonstration 7/10 in world 13
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 0), (5, 0)]
MCMC sampling complete.
Acceptance ratio: 0.106
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.24735502 -0.23399495 -0.48523635 -0.77253929 -0.22734659 -0.0099116
  0.00242292]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: 0.026593
0.9-VaR bound for 7 demonstrations: 0.035863
0.95-VaR bound for 7 demonstrations: 0.060982
0.99-VaR bound for 7 demonstrations: 0.086652
True expected value difference for MAP policy: -0.006560
Evaluating threshold 0.1 with avar bound: [0.06098189434288102]
Threshold 0.1 SUFFICIENT with avar bound: 0.06098189434288102
Evaluating threshold 0.2 with avar bound: [0.06098189434288102]
Threshold 0.2 SUFFICIENT with avar bound: 0.06098189434288102
Evaluating threshold 0.3 with avar bound: [0.06098189434288102]
Threshold 0.3 SUFFICIENT with avar bound: 0.06098189434288102
Evaluating threshold 0.4 with avar bound: [0.06098189434288102]
Threshold 0.4 SUFFICIENT with avar bound: 0.06098189434288102
Evaluating threshold 0.5 with avar bound: [0.06098189434288102]
Threshold 0.5 SUFFICIENT with avar bound: 0.06098189434288102
Evaluating threshold 0.6 with avar bound: [0.06098189434288102]
Threshold 0.6 SUFFICIENT with avar bound: 0.06098189434288102
Evaluating threshold 0.7 with avar bound: [0.06098189434288102]
Threshold 0.7 SUFFICIENT with avar bound: 0.06098189434288102
Evaluating threshold 0.8 with avar bound: [0.06098189434288102]
Threshold 0.8 SUFFICIENT with avar bound: 0.06098189434288102
Evaluating threshold 0.9 with avar bound: [0.06098189434288102]
Threshold 0.9 SUFFICIENT with avar bound: 0.06098189434288102

Running BIRL with demonstration 8/10 in world 13
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 0), (5, 0), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.095
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.37280784 -0.15071086  0.05661396 -0.07617852  0.46664959  0.54572579
  0.56010156]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.009294
0.9-VaR bound for 8 demonstrations: -0.009129
0.95-VaR bound for 8 demonstrations: -0.008961
0.99-VaR bound for 8 demonstrations: -0.008518
True expected value difference for MAP policy: -0.007822
Evaluating threshold 0.1 with avar bound: [-0.008960635577523966]
Threshold 0.1 SUFFICIENT with avar bound: -0.008960635577523966
Evaluating threshold 0.2 with avar bound: [-0.008960635577523966]
Threshold 0.2 SUFFICIENT with avar bound: -0.008960635577523966
Evaluating threshold 0.3 with avar bound: [-0.008960635577523966]
Threshold 0.3 SUFFICIENT with avar bound: -0.008960635577523966
Evaluating threshold 0.4 with avar bound: [-0.008960635577523966]
Threshold 0.4 SUFFICIENT with avar bound: -0.008960635577523966
Evaluating threshold 0.5 with avar bound: [-0.008960635577523966]
Threshold 0.5 SUFFICIENT with avar bound: -0.008960635577523966
Evaluating threshold 0.6 with avar bound: [-0.008960635577523966]
Threshold 0.6 SUFFICIENT with avar bound: -0.008960635577523966
Evaluating threshold 0.7 with avar bound: [-0.008960635577523966]
Threshold 0.7 SUFFICIENT with avar bound: -0.008960635577523966
Evaluating threshold 0.8 with avar bound: [-0.008960635577523966]
Threshold 0.8 SUFFICIENT with avar bound: -0.008960635577523966
Evaluating threshold 0.9 with avar bound: [-0.008960635577523966]
Threshold 0.9 SUFFICIENT with avar bound: -0.008960635577523966

Running BIRL with demonstration 9/10 in world 13
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 0), (5, 0), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.102
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.77697146  0.05351527 -0.60373905  0.03747428 -0.09945554  0.09245618
  0.09542928]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: 0.239717
0.9-VaR bound for 9 demonstrations: 0.239717
0.95-VaR bound for 9 demonstrations: 15.051578
0.99-VaR bound for 9 demonstrations: 15.051578
True expected value difference for MAP policy: -0.006192
Evaluating threshold 0.1 with avar bound: [15.05157824359339]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [15.05157824359339]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [15.05157824359339]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [15.05157824359339]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [15.05157824359339]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [15.05157824359339]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [15.05157824359339]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [15.05157824359339]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [15.05157824359339]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 10/10 in world 13
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 0), (5, 0), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.102
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.53448266 -0.44189571 -0.0752609   0.14337781  0.29687028  0.44856516
  0.45110132]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.006826
0.9-VaR bound for 10 demonstrations: -0.005841
0.95-VaR bound for 10 demonstrations: -0.004911
0.99-VaR bound for 10 demonstrations: -0.004911
True expected value difference for MAP policy: -0.007822
Evaluating threshold 0.1 with avar bound: [-0.0049114513485669]
Threshold 0.1 SUFFICIENT with avar bound: -0.0049114513485669
Evaluating threshold 0.2 with avar bound: [-0.0049114513485669]
Threshold 0.2 SUFFICIENT with avar bound: -0.0049114513485669
Evaluating threshold 0.3 with avar bound: [-0.0049114513485669]
Threshold 0.3 SUFFICIENT with avar bound: -0.0049114513485669
Evaluating threshold 0.4 with avar bound: [-0.0049114513485669]
Threshold 0.4 SUFFICIENT with avar bound: -0.0049114513485669
Evaluating threshold 0.5 with avar bound: [-0.0049114513485669]
Threshold 0.5 SUFFICIENT with avar bound: -0.0049114513485669
Evaluating threshold 0.6 with avar bound: [-0.0049114513485669]
Threshold 0.6 SUFFICIENT with avar bound: -0.0049114513485669
Evaluating threshold 0.7 with avar bound: [-0.0049114513485669]
Threshold 0.7 SUFFICIENT with avar bound: -0.0049114513485669
Evaluating threshold 0.8 with avar bound: [-0.0049114513485669]
Threshold 0.8 SUFFICIENT with avar bound: -0.0049114513485669
Evaluating threshold 0.9 with avar bound: [-0.0049114513485669]
Threshold 0.9 SUFFICIENT with avar bound: -0.0049114513485669

Running world 14/20

Running BIRL with demonstration 1/10 in world 14
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.342
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.43052426  0.58866124 -0.35811816 -0.50646321 -0.22866189 -0.17504744
 -0.02110279]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.020253
0.9-VaR bound for 1 demonstrations: 1.231623
0.95-VaR bound for 1 demonstrations: 1.507417
0.99-VaR bound for 1 demonstrations: 2.579972
True expected value difference for MAP policy: 1.575789
Evaluating threshold 0.1 with avar bound: [1.5074170644307925]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.5074170644307925]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.5074170644307925]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.5074170644307925]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.5074170644307925]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.5074170644307925]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.5074170644307925]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.5074170644307925]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.5074170644307925]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 14
Current demos: [(16, 1), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.295
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50708268  0.09751514 -0.17148813 -0.10110542 -0.49498822  0.47234495
  0.47497829]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.750958
0.9-VaR bound for 2 demonstrations: 2.042471
0.95-VaR bound for 2 demonstrations: 2.558963
0.99-VaR bound for 2 demonstrations: 3.831264
True expected value difference for MAP policy: -0.006054
Evaluating threshold 0.1 with avar bound: [2.5589626137352015]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.5589626137352015]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.5589626137352015]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.5589626137352015]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.5589626137352015]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.5589626137352015]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.5589626137352015]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.5589626137352015]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.5589626137352015]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 14
Current demos: [(16, 1), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.224
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.15670358  0.47079404 -0.34021677 -0.40120216 -0.01430705  0.28988218
  0.62677745]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.002447
0.9-VaR bound for 3 demonstrations: 0.068893
0.95-VaR bound for 3 demonstrations: 0.859926
0.99-VaR bound for 3 demonstrations: 2.763445
True expected value difference for MAP policy: -0.002676
Evaluating threshold 0.1 with avar bound: [0.8599258786336078]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.8599258786336078]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.8599258786336078]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.8599258786336078]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.8599258786336078]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.8599258786336078]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [0.8599258786336078]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [0.8599258786336078]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [0.8599258786336078]
Threshold 0.9 SUFFICIENT with avar bound: 0.8599258786336078

Running BIRL with demonstration 4/10 in world 14
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.21
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.22885707  0.40296298 -0.2203539  -0.15259681 -0.1155727   0.42730418
  0.71934535]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.000208
0.9-VaR bound for 4 demonstrations: 0.001822
0.95-VaR bound for 4 demonstrations: 0.026172
0.99-VaR bound for 4 demonstrations: 0.028989
True expected value difference for MAP policy: -0.005153
Evaluating threshold 0.1 with avar bound: [0.02617211235853364]
Threshold 0.1 SUFFICIENT with avar bound: 0.02617211235853364
Evaluating threshold 0.2 with avar bound: [0.02617211235853364]
Threshold 0.2 SUFFICIENT with avar bound: 0.02617211235853364
Evaluating threshold 0.3 with avar bound: [0.02617211235853364]
Threshold 0.3 SUFFICIENT with avar bound: 0.02617211235853364
Evaluating threshold 0.4 with avar bound: [0.02617211235853364]
Threshold 0.4 SUFFICIENT with avar bound: 0.02617211235853364
Evaluating threshold 0.5 with avar bound: [0.02617211235853364]
Threshold 0.5 SUFFICIENT with avar bound: 0.02617211235853364
Evaluating threshold 0.6 with avar bound: [0.02617211235853364]
Threshold 0.6 SUFFICIENT with avar bound: 0.02617211235853364
Evaluating threshold 0.7 with avar bound: [0.02617211235853364]
Threshold 0.7 SUFFICIENT with avar bound: 0.02617211235853364
Evaluating threshold 0.8 with avar bound: [0.02617211235853364]
Threshold 0.8 SUFFICIENT with avar bound: 0.02617211235853364
Evaluating threshold 0.9 with avar bound: [0.02617211235853364]
Threshold 0.9 SUFFICIENT with avar bound: 0.02617211235853364

Running BIRL with demonstration 5/10 in world 14
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.179
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.42885861  0.33390162 -0.45546097 -0.01845349 -0.42030217  0.32114756
  0.46584881]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.001514
0.9-VaR bound for 5 demonstrations: 0.003555
0.95-VaR bound for 5 demonstrations: 0.005268
0.99-VaR bound for 5 demonstrations: 0.042861
True expected value difference for MAP policy: -0.005635
Evaluating threshold 0.1 with avar bound: [0.00526768801442408]
Threshold 0.1 SUFFICIENT with avar bound: 0.00526768801442408
Evaluating threshold 0.2 with avar bound: [0.00526768801442408]
Threshold 0.2 SUFFICIENT with avar bound: 0.00526768801442408
Evaluating threshold 0.3 with avar bound: [0.00526768801442408]
Threshold 0.3 SUFFICIENT with avar bound: 0.00526768801442408
Evaluating threshold 0.4 with avar bound: [0.00526768801442408]
Threshold 0.4 SUFFICIENT with avar bound: 0.00526768801442408
Evaluating threshold 0.5 with avar bound: [0.00526768801442408]
Threshold 0.5 SUFFICIENT with avar bound: 0.00526768801442408
Evaluating threshold 0.6 with avar bound: [0.00526768801442408]
Threshold 0.6 SUFFICIENT with avar bound: 0.00526768801442408
Evaluating threshold 0.7 with avar bound: [0.00526768801442408]
Threshold 0.7 SUFFICIENT with avar bound: 0.00526768801442408
Evaluating threshold 0.8 with avar bound: [0.00526768801442408]
Threshold 0.8 SUFFICIENT with avar bound: 0.00526768801442408
Evaluating threshold 0.9 with avar bound: [0.00526768801442408]
Threshold 0.9 SUFFICIENT with avar bound: 0.00526768801442408

Running BIRL with demonstration 6/10 in world 14
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.14
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.5538199  -0.39436184 -0.48411541 -0.08509118  0.0355442   0.34099765
  0.42262423]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.005427
0.9-VaR bound for 6 demonstrations: -0.003638
0.95-VaR bound for 6 demonstrations: 0.001430
0.99-VaR bound for 6 demonstrations: 0.001430
True expected value difference for MAP policy: -0.009257
Evaluating threshold 0.1 with avar bound: [0.001430488842718228]
Threshold 0.1 SUFFICIENT with avar bound: 0.001430488842718228
Evaluating threshold 0.2 with avar bound: [0.001430488842718228]
Threshold 0.2 SUFFICIENT with avar bound: 0.001430488842718228
Evaluating threshold 0.3 with avar bound: [0.001430488842718228]
Threshold 0.3 SUFFICIENT with avar bound: 0.001430488842718228
Evaluating threshold 0.4 with avar bound: [0.001430488842718228]
Threshold 0.4 SUFFICIENT with avar bound: 0.001430488842718228
Evaluating threshold 0.5 with avar bound: [0.001430488842718228]
Threshold 0.5 SUFFICIENT with avar bound: 0.001430488842718228
Evaluating threshold 0.6 with avar bound: [0.001430488842718228]
Threshold 0.6 SUFFICIENT with avar bound: 0.001430488842718228
Evaluating threshold 0.7 with avar bound: [0.001430488842718228]
Threshold 0.7 SUFFICIENT with avar bound: 0.001430488842718228
Evaluating threshold 0.8 with avar bound: [0.001430488842718228]
Threshold 0.8 SUFFICIENT with avar bound: 0.001430488842718228
Evaluating threshold 0.9 with avar bound: [0.001430488842718228]
Threshold 0.9 SUFFICIENT with avar bound: 0.001430488842718228

Running BIRL with demonstration 7/10 in world 14
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.132
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.29223687 -0.01214213 -0.41043031 -0.2050613   0.42216172  0.25096809
  0.68025106]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.006801
0.9-VaR bound for 7 demonstrations: -0.005918
0.95-VaR bound for 7 demonstrations: -0.005573
0.99-VaR bound for 7 demonstrations: -0.003709
True expected value difference for MAP policy: -0.007406
Evaluating threshold 0.1 with avar bound: [-0.005572526251509725]
Threshold 0.1 SUFFICIENT with avar bound: -0.005572526251509725
Evaluating threshold 0.2 with avar bound: [-0.005572526251509725]
Threshold 0.2 SUFFICIENT with avar bound: -0.005572526251509725
Evaluating threshold 0.3 with avar bound: [-0.005572526251509725]
Threshold 0.3 SUFFICIENT with avar bound: -0.005572526251509725
Evaluating threshold 0.4 with avar bound: [-0.005572526251509725]
Threshold 0.4 SUFFICIENT with avar bound: -0.005572526251509725
Evaluating threshold 0.5 with avar bound: [-0.005572526251509725]
Threshold 0.5 SUFFICIENT with avar bound: -0.005572526251509725
Evaluating threshold 0.6 with avar bound: [-0.005572526251509725]
Threshold 0.6 SUFFICIENT with avar bound: -0.005572526251509725
Evaluating threshold 0.7 with avar bound: [-0.005572526251509725]
Threshold 0.7 SUFFICIENT with avar bound: -0.005572526251509725
Evaluating threshold 0.8 with avar bound: [-0.005572526251509725]
Threshold 0.8 SUFFICIENT with avar bound: -0.005572526251509725
Evaluating threshold 0.9 with avar bound: [-0.005572526251509725]
Threshold 0.9 SUFFICIENT with avar bound: -0.005572526251509725

Running BIRL with demonstration 8/10 in world 14
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.137
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.56190767 -0.48636411 -0.4948745  -0.21729275  0.14648846  0.22495602
  0.28901338]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.008603
0.9-VaR bound for 8 demonstrations: -0.008244
0.95-VaR bound for 8 demonstrations: -0.007104
0.99-VaR bound for 8 demonstrations: -0.006170
True expected value difference for MAP policy: -0.009530
Evaluating threshold 0.1 with avar bound: [-0.007103659605607719]
Threshold 0.1 SUFFICIENT with avar bound: -0.007103659605607719
Evaluating threshold 0.2 with avar bound: [-0.007103659605607719]
Threshold 0.2 SUFFICIENT with avar bound: -0.007103659605607719
Evaluating threshold 0.3 with avar bound: [-0.007103659605607719]
Threshold 0.3 SUFFICIENT with avar bound: -0.007103659605607719
Evaluating threshold 0.4 with avar bound: [-0.007103659605607719]
Threshold 0.4 SUFFICIENT with avar bound: -0.007103659605607719
Evaluating threshold 0.5 with avar bound: [-0.007103659605607719]
Threshold 0.5 SUFFICIENT with avar bound: -0.007103659605607719
Evaluating threshold 0.6 with avar bound: [-0.007103659605607719]
Threshold 0.6 SUFFICIENT with avar bound: -0.007103659605607719
Evaluating threshold 0.7 with avar bound: [-0.007103659605607719]
Threshold 0.7 SUFFICIENT with avar bound: -0.007103659605607719
Evaluating threshold 0.8 with avar bound: [-0.007103659605607719]
Threshold 0.8 SUFFICIENT with avar bound: -0.007103659605607719
Evaluating threshold 0.9 with avar bound: [-0.007103659605607719]
Threshold 0.9 SUFFICIENT with avar bound: -0.007103659605607719

Running BIRL with demonstration 9/10 in world 14
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.126
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.28073231 -0.09735861 -0.53849488 -0.26245893  0.36700985  0.4116452
  0.49869955]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.008408
0.9-VaR bound for 9 demonstrations: -0.007888
0.95-VaR bound for 9 demonstrations: -0.001104
0.99-VaR bound for 9 demonstrations: 0.004494
True expected value difference for MAP policy: -0.007406
Evaluating threshold 0.1 with avar bound: [-0.001104335642046147]
Threshold 0.1 SUFFICIENT with avar bound: -0.001104335642046147
Evaluating threshold 0.2 with avar bound: [-0.001104335642046147]
Threshold 0.2 SUFFICIENT with avar bound: -0.001104335642046147
Evaluating threshold 0.3 with avar bound: [-0.001104335642046147]
Threshold 0.3 SUFFICIENT with avar bound: -0.001104335642046147
Evaluating threshold 0.4 with avar bound: [-0.001104335642046147]
Threshold 0.4 SUFFICIENT with avar bound: -0.001104335642046147
Evaluating threshold 0.5 with avar bound: [-0.001104335642046147]
Threshold 0.5 SUFFICIENT with avar bound: -0.001104335642046147
Evaluating threshold 0.6 with avar bound: [-0.001104335642046147]
Threshold 0.6 SUFFICIENT with avar bound: -0.001104335642046147
Evaluating threshold 0.7 with avar bound: [-0.001104335642046147]
Threshold 0.7 SUFFICIENT with avar bound: -0.001104335642046147
Evaluating threshold 0.8 with avar bound: [-0.001104335642046147]
Threshold 0.8 SUFFICIENT with avar bound: -0.001104335642046147
Evaluating threshold 0.9 with avar bound: [-0.001104335642046147]
Threshold 0.9 SUFFICIENT with avar bound: -0.001104335642046147

Running BIRL with demonstration 10/10 in world 14
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.131
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.54510607 -0.42945266 -0.53915796 -0.21811989  0.18195692  0.15790584
  0.34945618]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.007283
0.9-VaR bound for 10 demonstrations: -0.007257
0.95-VaR bound for 10 demonstrations: -0.005588
0.99-VaR bound for 10 demonstrations: -0.004590
True expected value difference for MAP policy: -0.009530
Evaluating threshold 0.1 with avar bound: [-0.0055875032888540455]
Threshold 0.1 SUFFICIENT with avar bound: -0.0055875032888540455
Evaluating threshold 0.2 with avar bound: [-0.0055875032888540455]
Threshold 0.2 SUFFICIENT with avar bound: -0.0055875032888540455
Evaluating threshold 0.3 with avar bound: [-0.0055875032888540455]
Threshold 0.3 SUFFICIENT with avar bound: -0.0055875032888540455
Evaluating threshold 0.4 with avar bound: [-0.0055875032888540455]
Threshold 0.4 SUFFICIENT with avar bound: -0.0055875032888540455
Evaluating threshold 0.5 with avar bound: [-0.0055875032888540455]
Threshold 0.5 SUFFICIENT with avar bound: -0.0055875032888540455
Evaluating threshold 0.6 with avar bound: [-0.0055875032888540455]
Threshold 0.6 SUFFICIENT with avar bound: -0.0055875032888540455
Evaluating threshold 0.7 with avar bound: [-0.0055875032888540455]
Threshold 0.7 SUFFICIENT with avar bound: -0.0055875032888540455
Evaluating threshold 0.8 with avar bound: [-0.0055875032888540455]
Threshold 0.8 SUFFICIENT with avar bound: -0.0055875032888540455
Evaluating threshold 0.9 with avar bound: [-0.0055875032888540455]
Threshold 0.9 SUFFICIENT with avar bound: -0.0055875032888540455

Running world 15/20

Running BIRL with demonstration 1/10 in world 15
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.316
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.21039168 -0.25930477 -0.12224786  0.79724467  0.01610013 -0.29895293
  0.38512427]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 0.766883
0.9-VaR bound for 1 demonstrations: 0.952243
0.95-VaR bound for 1 demonstrations: 1.260253
0.99-VaR bound for 1 demonstrations: 2.610427
True expected value difference for MAP policy: 0.649891
Evaluating threshold 0.1 with avar bound: [1.2602533963461549]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.2602533963461549]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.2602533963461549]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.2602533963461549]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.2602533963461549]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.2602533963461549]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.2602533963461549]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.2602533963461549]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.2602533963461549]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 15
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.195
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.12733203 -0.08622796 -0.18327226  0.54437728 -0.13649833 -0.69891581
 -0.37323028]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.164961
0.9-VaR bound for 2 demonstrations: 1.224401
0.95-VaR bound for 2 demonstrations: 2.543438
0.99-VaR bound for 2 demonstrations: 17.235583
True expected value difference for MAP policy: 0.657042
Evaluating threshold 0.1 with avar bound: [2.5434384505743135]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.5434384505743135]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.5434384505743135]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.5434384505743135]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.5434384505743135]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.5434384505743135]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.5434384505743135]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.5434384505743135]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.5434384505743135]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 15
Current demos: [(16, 1), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.19
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.78268814  0.00856931 -0.07780078  0.03644402 -0.11857606 -0.29805871
  0.52635105]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.000509
0.9-VaR bound for 3 demonstrations: 0.006488
0.95-VaR bound for 3 demonstrations: 0.200709
0.99-VaR bound for 3 demonstrations: 0.897273
True expected value difference for MAP policy: -0.004731
Evaluating threshold 0.1 with avar bound: [0.2007086310295708]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.2007086310295708]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.2007086310295708]
Threshold 0.3 SUFFICIENT with avar bound: 0.2007086310295708
Evaluating threshold 0.4 with avar bound: [0.2007086310295708]
Threshold 0.4 SUFFICIENT with avar bound: 0.2007086310295708
Evaluating threshold 0.5 with avar bound: [0.2007086310295708]
Threshold 0.5 SUFFICIENT with avar bound: 0.2007086310295708
Evaluating threshold 0.6 with avar bound: [0.2007086310295708]
Threshold 0.6 SUFFICIENT with avar bound: 0.2007086310295708
Evaluating threshold 0.7 with avar bound: [0.2007086310295708]
Threshold 0.7 SUFFICIENT with avar bound: 0.2007086310295708
Evaluating threshold 0.8 with avar bound: [0.2007086310295708]
Threshold 0.8 SUFFICIENT with avar bound: 0.2007086310295708
Evaluating threshold 0.9 with avar bound: [0.2007086310295708]
Threshold 0.9 SUFFICIENT with avar bound: 0.2007086310295708

Running BIRL with demonstration 4/10 in world 15
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.21
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.52363859  0.18309939  0.19261334  0.13056843 -0.14795244  0.03368361
  0.78428612]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.000269
0.9-VaR bound for 4 demonstrations: 0.002156
0.95-VaR bound for 4 demonstrations: 0.006481
0.99-VaR bound for 4 demonstrations: 0.031020
True expected value difference for MAP policy: -0.003926
Evaluating threshold 0.1 with avar bound: [0.006481316757996979]
Threshold 0.1 SUFFICIENT with avar bound: 0.006481316757996979
Evaluating threshold 0.2 with avar bound: [0.006481316757996979]
Threshold 0.2 SUFFICIENT with avar bound: 0.006481316757996979
Evaluating threshold 0.3 with avar bound: [0.006481316757996979]
Threshold 0.3 SUFFICIENT with avar bound: 0.006481316757996979
Evaluating threshold 0.4 with avar bound: [0.006481316757996979]
Threshold 0.4 SUFFICIENT with avar bound: 0.006481316757996979
Evaluating threshold 0.5 with avar bound: [0.006481316757996979]
Threshold 0.5 SUFFICIENT with avar bound: 0.006481316757996979
Evaluating threshold 0.6 with avar bound: [0.006481316757996979]
Threshold 0.6 SUFFICIENT with avar bound: 0.006481316757996979
Evaluating threshold 0.7 with avar bound: [0.006481316757996979]
Threshold 0.7 SUFFICIENT with avar bound: 0.006481316757996979
Evaluating threshold 0.8 with avar bound: [0.006481316757996979]
Threshold 0.8 SUFFICIENT with avar bound: 0.006481316757996979
Evaluating threshold 0.9 with avar bound: [0.006481316757996979]
Threshold 0.9 SUFFICIENT with avar bound: 0.006481316757996979

Running BIRL with demonstration 5/10 in world 15
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.179
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.68894957  0.24624684 -0.03038999  0.23091101 -0.26564438 -0.21197351
  0.54310941]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.000883
0.9-VaR bound for 5 demonstrations: 0.000740
0.95-VaR bound for 5 demonstrations: 0.003473
0.99-VaR bound for 5 demonstrations: 0.025525
True expected value difference for MAP policy: -0.004210
Evaluating threshold 0.1 with avar bound: [0.003472610314713429]
Threshold 0.1 SUFFICIENT with avar bound: 0.003472610314713429
Evaluating threshold 0.2 with avar bound: [0.003472610314713429]
Threshold 0.2 SUFFICIENT with avar bound: 0.003472610314713429
Evaluating threshold 0.3 with avar bound: [0.003472610314713429]
Threshold 0.3 SUFFICIENT with avar bound: 0.003472610314713429
Evaluating threshold 0.4 with avar bound: [0.003472610314713429]
Threshold 0.4 SUFFICIENT with avar bound: 0.003472610314713429
Evaluating threshold 0.5 with avar bound: [0.003472610314713429]
Threshold 0.5 SUFFICIENT with avar bound: 0.003472610314713429
Evaluating threshold 0.6 with avar bound: [0.003472610314713429]
Threshold 0.6 SUFFICIENT with avar bound: 0.003472610314713429
Evaluating threshold 0.7 with avar bound: [0.003472610314713429]
Threshold 0.7 SUFFICIENT with avar bound: 0.003472610314713429
Evaluating threshold 0.8 with avar bound: [0.003472610314713429]
Threshold 0.8 SUFFICIENT with avar bound: 0.003472610314713429
Evaluating threshold 0.9 with avar bound: [0.003472610314713429]
Threshold 0.9 SUFFICIENT with avar bound: 0.003472610314713429

Running BIRL with demonstration 6/10 in world 15
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.178
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.7933674   0.224064    0.03516034  0.10828879 -0.27529205  0.21173997
  0.43218197]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.004239
0.9-VaR bound for 6 demonstrations: -0.002985
0.95-VaR bound for 6 demonstrations: -0.001066
0.99-VaR bound for 6 demonstrations: 0.005697
True expected value difference for MAP policy: -0.007757
Evaluating threshold 0.1 with avar bound: [-0.0010662146228891803]
Threshold 0.1 SUFFICIENT with avar bound: -0.0010662146228891803
Evaluating threshold 0.2 with avar bound: [-0.0010662146228891803]
Threshold 0.2 SUFFICIENT with avar bound: -0.0010662146228891803
Evaluating threshold 0.3 with avar bound: [-0.0010662146228891803]
Threshold 0.3 SUFFICIENT with avar bound: -0.0010662146228891803
Evaluating threshold 0.4 with avar bound: [-0.0010662146228891803]
Threshold 0.4 SUFFICIENT with avar bound: -0.0010662146228891803
Evaluating threshold 0.5 with avar bound: [-0.0010662146228891803]
Threshold 0.5 SUFFICIENT with avar bound: -0.0010662146228891803
Evaluating threshold 0.6 with avar bound: [-0.0010662146228891803]
Threshold 0.6 SUFFICIENT with avar bound: -0.0010662146228891803
Evaluating threshold 0.7 with avar bound: [-0.0010662146228891803]
Threshold 0.7 SUFFICIENT with avar bound: -0.0010662146228891803
Evaluating threshold 0.8 with avar bound: [-0.0010662146228891803]
Threshold 0.8 SUFFICIENT with avar bound: -0.0010662146228891803
Evaluating threshold 0.9 with avar bound: [-0.0010662146228891803]
Threshold 0.9 SUFFICIENT with avar bound: -0.0010662146228891803

Running BIRL with demonstration 7/10 in world 15
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.146
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.72884228 -0.02719789  0.13494058  0.06979695  0.10117521  0.31806204
  0.57755411]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.005204
0.9-VaR bound for 7 demonstrations: -0.004738
0.95-VaR bound for 7 demonstrations: -0.002771
0.99-VaR bound for 7 demonstrations: 0.007536
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.0027705841109232072]
Threshold 0.1 SUFFICIENT with avar bound: -0.0027705841109232072
Evaluating threshold 0.2 with avar bound: [-0.0027705841109232072]
Threshold 0.2 SUFFICIENT with avar bound: -0.0027705841109232072
Evaluating threshold 0.3 with avar bound: [-0.0027705841109232072]
Threshold 0.3 SUFFICIENT with avar bound: -0.0027705841109232072
Evaluating threshold 0.4 with avar bound: [-0.0027705841109232072]
Threshold 0.4 SUFFICIENT with avar bound: -0.0027705841109232072
Evaluating threshold 0.5 with avar bound: [-0.0027705841109232072]
Threshold 0.5 SUFFICIENT with avar bound: -0.0027705841109232072
Evaluating threshold 0.6 with avar bound: [-0.0027705841109232072]
Threshold 0.6 SUFFICIENT with avar bound: -0.0027705841109232072
Evaluating threshold 0.7 with avar bound: [-0.0027705841109232072]
Threshold 0.7 SUFFICIENT with avar bound: -0.0027705841109232072
Evaluating threshold 0.8 with avar bound: [-0.0027705841109232072]
Threshold 0.8 SUFFICIENT with avar bound: -0.0027705841109232072
Evaluating threshold 0.9 with avar bound: [-0.0027705841109232072]
Threshold 0.9 SUFFICIENT with avar bound: -0.0027705841109232072

Running BIRL with demonstration 8/10 in world 15
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.146
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.87471765 -0.10825946  0.02163976 -0.07916583  0.19322134  0.19853502
  0.37371482]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.008334
0.9-VaR bound for 8 demonstrations: -0.007877
0.95-VaR bound for 8 demonstrations: -0.007646
0.99-VaR bound for 8 demonstrations: 0.039679
True expected value difference for MAP policy: -0.009963
Evaluating threshold 0.1 with avar bound: [-0.007646463753995361]
Threshold 0.1 SUFFICIENT with avar bound: -0.007646463753995361
Evaluating threshold 0.2 with avar bound: [-0.007646463753995361]
Threshold 0.2 SUFFICIENT with avar bound: -0.007646463753995361
Evaluating threshold 0.3 with avar bound: [-0.007646463753995361]
Threshold 0.3 SUFFICIENT with avar bound: -0.007646463753995361
Evaluating threshold 0.4 with avar bound: [-0.007646463753995361]
Threshold 0.4 SUFFICIENT with avar bound: -0.007646463753995361
Evaluating threshold 0.5 with avar bound: [-0.007646463753995361]
Threshold 0.5 SUFFICIENT with avar bound: -0.007646463753995361
Evaluating threshold 0.6 with avar bound: [-0.007646463753995361]
Threshold 0.6 SUFFICIENT with avar bound: -0.007646463753995361
Evaluating threshold 0.7 with avar bound: [-0.007646463753995361]
Threshold 0.7 SUFFICIENT with avar bound: -0.007646463753995361
Evaluating threshold 0.8 with avar bound: [-0.007646463753995361]
Threshold 0.8 SUFFICIENT with avar bound: -0.007646463753995361
Evaluating threshold 0.9 with avar bound: [-0.007646463753995361]
Threshold 0.9 SUFFICIENT with avar bound: -0.007646463753995361

Running BIRL with demonstration 9/10 in world 15
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.164
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.90838942 -0.09526898  0.01434466  0.12170022  0.05606036  0.16924399
  0.34489052]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.008600
0.9-VaR bound for 9 demonstrations: -0.008260
0.95-VaR bound for 9 demonstrations: -0.006036
0.99-VaR bound for 9 demonstrations: 0.028303
True expected value difference for MAP policy: -0.009842
Evaluating threshold 0.1 with avar bound: [-0.00603565034990908]
Threshold 0.1 SUFFICIENT with avar bound: -0.00603565034990908
Evaluating threshold 0.2 with avar bound: [-0.00603565034990908]
Threshold 0.2 SUFFICIENT with avar bound: -0.00603565034990908
Evaluating threshold 0.3 with avar bound: [-0.00603565034990908]
Threshold 0.3 SUFFICIENT with avar bound: -0.00603565034990908
Evaluating threshold 0.4 with avar bound: [-0.00603565034990908]
Threshold 0.4 SUFFICIENT with avar bound: -0.00603565034990908
Evaluating threshold 0.5 with avar bound: [-0.00603565034990908]
Threshold 0.5 SUFFICIENT with avar bound: -0.00603565034990908
Evaluating threshold 0.6 with avar bound: [-0.00603565034990908]
Threshold 0.6 SUFFICIENT with avar bound: -0.00603565034990908
Evaluating threshold 0.7 with avar bound: [-0.00603565034990908]
Threshold 0.7 SUFFICIENT with avar bound: -0.00603565034990908
Evaluating threshold 0.8 with avar bound: [-0.00603565034990908]
Threshold 0.8 SUFFICIENT with avar bound: -0.00603565034990908
Evaluating threshold 0.9 with avar bound: [-0.00603565034990908]
Threshold 0.9 SUFFICIENT with avar bound: -0.00603565034990908

Running BIRL with demonstration 10/10 in world 15
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.162
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.84568152 -0.21512942 -0.03017546 -0.15829426  0.0376985   0.28883298
  0.35739167]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.004776
0.9-VaR bound for 10 demonstrations: -0.003852
0.95-VaR bound for 10 demonstrations: -0.002415
0.99-VaR bound for 10 demonstrations: 0.001926
True expected value difference for MAP policy: -0.009640
Evaluating threshold 0.1 with avar bound: [-0.0024152407617715104]
Threshold 0.1 SUFFICIENT with avar bound: -0.0024152407617715104
Evaluating threshold 0.2 with avar bound: [-0.0024152407617715104]
Threshold 0.2 SUFFICIENT with avar bound: -0.0024152407617715104
Evaluating threshold 0.3 with avar bound: [-0.0024152407617715104]
Threshold 0.3 SUFFICIENT with avar bound: -0.0024152407617715104
Evaluating threshold 0.4 with avar bound: [-0.0024152407617715104]
Threshold 0.4 SUFFICIENT with avar bound: -0.0024152407617715104
Evaluating threshold 0.5 with avar bound: [-0.0024152407617715104]
Threshold 0.5 SUFFICIENT with avar bound: -0.0024152407617715104
Evaluating threshold 0.6 with avar bound: [-0.0024152407617715104]
Threshold 0.6 SUFFICIENT with avar bound: -0.0024152407617715104
Evaluating threshold 0.7 with avar bound: [-0.0024152407617715104]
Threshold 0.7 SUFFICIENT with avar bound: -0.0024152407617715104
Evaluating threshold 0.8 with avar bound: [-0.0024152407617715104]
Threshold 0.8 SUFFICIENT with avar bound: -0.0024152407617715104
Evaluating threshold 0.9 with avar bound: [-0.0024152407617715104]
Threshold 0.9 SUFFICIENT with avar bound: -0.0024152407617715104

Running world 16/20

Running BIRL with demonstration 1/10 in world 16
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.359
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.22440807 -0.20424025 -0.28962968 -0.13130801 -0.27928603  0.84619932
 -0.11289738]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 0.762032
0.9-VaR bound for 1 demonstrations: 0.972114
0.95-VaR bound for 1 demonstrations: 1.334103
0.99-VaR bound for 1 demonstrations: 2.208214
True expected value difference for MAP policy: 0.517117
Evaluating threshold 0.1 with avar bound: [1.334103091246061]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.334103091246061]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.334103091246061]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.334103091246061]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.334103091246061]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.334103091246061]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.334103091246061]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.334103091246061]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.334103091246061]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 16
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.23
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.32655436 -0.778009   -0.01668059 -0.06071617 -0.32809008  0.07725747
  0.41290161]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 0.000062
0.9-VaR bound for 2 demonstrations: 0.002308
0.95-VaR bound for 2 demonstrations: 0.088584
0.99-VaR bound for 2 demonstrations: 0.944863
True expected value difference for MAP policy: -0.005387
Evaluating threshold 0.1 with avar bound: [0.08858362910381666]
Threshold 0.1 SUFFICIENT with avar bound: 0.08858362910381666
Evaluating threshold 0.2 with avar bound: [0.08858362910381666]
Threshold 0.2 SUFFICIENT with avar bound: 0.08858362910381666
Evaluating threshold 0.3 with avar bound: [0.08858362910381666]
Threshold 0.3 SUFFICIENT with avar bound: 0.08858362910381666
Evaluating threshold 0.4 with avar bound: [0.08858362910381666]
Threshold 0.4 SUFFICIENT with avar bound: 0.08858362910381666
Evaluating threshold 0.5 with avar bound: [0.08858362910381666]
Threshold 0.5 SUFFICIENT with avar bound: 0.08858362910381666
Evaluating threshold 0.6 with avar bound: [0.08858362910381666]
Threshold 0.6 SUFFICIENT with avar bound: 0.08858362910381666
Evaluating threshold 0.7 with avar bound: [0.08858362910381666]
Threshold 0.7 SUFFICIENT with avar bound: 0.08858362910381666
Evaluating threshold 0.8 with avar bound: [0.08858362910381666]
Threshold 0.8 SUFFICIENT with avar bound: 0.08858362910381666
Evaluating threshold 0.9 with avar bound: [0.08858362910381666]
Threshold 0.9 SUFFICIENT with avar bound: 0.08858362910381666

Running BIRL with demonstration 3/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2)]
MCMC sampling complete.
Acceptance ratio: 0.143
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.88900559 -0.07334732  0.15323411 -0.27328761  0.16957484  0.08530347
  0.26474535]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 3.944038
0.9-VaR bound for 3 demonstrations: 5.427345
0.95-VaR bound for 3 demonstrations: 5.427345
0.99-VaR bound for 3 demonstrations: 54.605819
True expected value difference for MAP policy: -0.009266
Evaluating threshold 0.1 with avar bound: [5.427344653976578]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [5.427344653976578]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [5.427344653976578]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [5.427344653976578]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [5.427344653976578]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [5.427344653976578]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [5.427344653976578]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [5.427344653976578]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [5.427344653976578]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.131
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.91492913 -0.13340211  0.15433192 -0.09257605  0.10598669  0.13601859
  0.28807233]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.007898
0.9-VaR bound for 4 demonstrations: -0.006970
0.95-VaR bound for 4 demonstrations: 0.004851
0.99-VaR bound for 4 demonstrations: 0.005975
True expected value difference for MAP policy: -0.009510
Evaluating threshold 0.1 with avar bound: [0.004850645799364675]
Threshold 0.1 SUFFICIENT with avar bound: 0.004850645799364675
Evaluating threshold 0.2 with avar bound: [0.004850645799364675]
Threshold 0.2 SUFFICIENT with avar bound: 0.004850645799364675
Evaluating threshold 0.3 with avar bound: [0.004850645799364675]
Threshold 0.3 SUFFICIENT with avar bound: 0.004850645799364675
Evaluating threshold 0.4 with avar bound: [0.004850645799364675]
Threshold 0.4 SUFFICIENT with avar bound: 0.004850645799364675
Evaluating threshold 0.5 with avar bound: [0.004850645799364675]
Threshold 0.5 SUFFICIENT with avar bound: 0.004850645799364675
Evaluating threshold 0.6 with avar bound: [0.004850645799364675]
Threshold 0.6 SUFFICIENT with avar bound: 0.004850645799364675
Evaluating threshold 0.7 with avar bound: [0.004850645799364675]
Threshold 0.7 SUFFICIENT with avar bound: 0.004850645799364675
Evaluating threshold 0.8 with avar bound: [0.004850645799364675]
Threshold 0.8 SUFFICIENT with avar bound: 0.004850645799364675
Evaluating threshold 0.9 with avar bound: [0.004850645799364675]
Threshold 0.9 SUFFICIENT with avar bound: 0.004850645799364675

Running BIRL with demonstration 5/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.147
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.74935958  0.14449652  0.30688009 -0.08070185  0.17393925  0.27967682
  0.45652909]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.008353
0.9-VaR bound for 5 demonstrations: -0.008059
0.95-VaR bound for 5 demonstrations: -0.007143
0.99-VaR bound for 5 demonstrations: 0.007445
True expected value difference for MAP policy: -0.009491
Evaluating threshold 0.1 with avar bound: [-0.007142984431076754]
Threshold 0.1 SUFFICIENT with avar bound: -0.007142984431076754
Evaluating threshold 0.2 with avar bound: [-0.007142984431076754]
Threshold 0.2 SUFFICIENT with avar bound: -0.007142984431076754
Evaluating threshold 0.3 with avar bound: [-0.007142984431076754]
Threshold 0.3 SUFFICIENT with avar bound: -0.007142984431076754
Evaluating threshold 0.4 with avar bound: [-0.007142984431076754]
Threshold 0.4 SUFFICIENT with avar bound: -0.007142984431076754
Evaluating threshold 0.5 with avar bound: [-0.007142984431076754]
Threshold 0.5 SUFFICIENT with avar bound: -0.007142984431076754
Evaluating threshold 0.6 with avar bound: [-0.007142984431076754]
Threshold 0.6 SUFFICIENT with avar bound: -0.007142984431076754
Evaluating threshold 0.7 with avar bound: [-0.007142984431076754]
Threshold 0.7 SUFFICIENT with avar bound: -0.007142984431076754
Evaluating threshold 0.8 with avar bound: [-0.007142984431076754]
Threshold 0.8 SUFFICIENT with avar bound: -0.007142984431076754
Evaluating threshold 0.9 with avar bound: [-0.007142984431076754]
Threshold 0.9 SUFFICIENT with avar bound: -0.007142984431076754

Running BIRL with demonstration 6/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.116
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.80530589  0.04593261  0.17023211 -0.02846844  0.24693035  0.29627403
  0.41331623]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.008150
0.9-VaR bound for 6 demonstrations: -0.007864
0.95-VaR bound for 6 demonstrations: -0.007864
0.99-VaR bound for 6 demonstrations: -0.006721
True expected value difference for MAP policy: -0.009798
Evaluating threshold 0.1 with avar bound: [-0.007863581593653836]
Threshold 0.1 SUFFICIENT with avar bound: -0.007863581593653836
Evaluating threshold 0.2 with avar bound: [-0.007863581593653836]
Threshold 0.2 SUFFICIENT with avar bound: -0.007863581593653836
Evaluating threshold 0.3 with avar bound: [-0.007863581593653836]
Threshold 0.3 SUFFICIENT with avar bound: -0.007863581593653836
Evaluating threshold 0.4 with avar bound: [-0.007863581593653836]
Threshold 0.4 SUFFICIENT with avar bound: -0.007863581593653836
Evaluating threshold 0.5 with avar bound: [-0.007863581593653836]
Threshold 0.5 SUFFICIENT with avar bound: -0.007863581593653836
Evaluating threshold 0.6 with avar bound: [-0.007863581593653836]
Threshold 0.6 SUFFICIENT with avar bound: -0.007863581593653836
Evaluating threshold 0.7 with avar bound: [-0.007863581593653836]
Threshold 0.7 SUFFICIENT with avar bound: -0.007863581593653836
Evaluating threshold 0.8 with avar bound: [-0.007863581593653836]
Threshold 0.8 SUFFICIENT with avar bound: -0.007863581593653836
Evaluating threshold 0.9 with avar bound: [-0.007863581593653836]
Threshold 0.9 SUFFICIENT with avar bound: -0.007863581593653836

Running BIRL with demonstration 7/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 1), (6, 3), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.131
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.73648585  0.08578206  0.2764661  -0.21049376  0.2769414   0.24782206
  0.4374661 ]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.007325
0.9-VaR bound for 7 demonstrations: -0.006116
0.95-VaR bound for 7 demonstrations: -0.005567
0.99-VaR bound for 7 demonstrations: -0.003286
True expected value difference for MAP policy: -0.009510
Evaluating threshold 0.1 with avar bound: [-0.005566908449092749]
Threshold 0.1 SUFFICIENT with avar bound: -0.005566908449092749
Evaluating threshold 0.2 with avar bound: [-0.005566908449092749]
Threshold 0.2 SUFFICIENT with avar bound: -0.005566908449092749
Evaluating threshold 0.3 with avar bound: [-0.005566908449092749]
Threshold 0.3 SUFFICIENT with avar bound: -0.005566908449092749
Evaluating threshold 0.4 with avar bound: [-0.005566908449092749]
Threshold 0.4 SUFFICIENT with avar bound: -0.005566908449092749
Evaluating threshold 0.5 with avar bound: [-0.005566908449092749]
Threshold 0.5 SUFFICIENT with avar bound: -0.005566908449092749
Evaluating threshold 0.6 with avar bound: [-0.005566908449092749]
Threshold 0.6 SUFFICIENT with avar bound: -0.005566908449092749
Evaluating threshold 0.7 with avar bound: [-0.005566908449092749]
Threshold 0.7 SUFFICIENT with avar bound: -0.005566908449092749
Evaluating threshold 0.8 with avar bound: [-0.005566908449092749]
Threshold 0.8 SUFFICIENT with avar bound: -0.005566908449092749
Evaluating threshold 0.9 with avar bound: [-0.005566908449092749]
Threshold 0.9 SUFFICIENT with avar bound: -0.005566908449092749

Running BIRL with demonstration 8/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 1), (6, 3), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.135
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.68326202  0.11757193  0.27831296 -0.30020009  0.25899237  0.28044012
  0.45390302]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.008186
0.9-VaR bound for 8 demonstrations: -0.008186
0.95-VaR bound for 8 demonstrations: -0.007768
0.99-VaR bound for 8 demonstrations: -0.006174
True expected value difference for MAP policy: -0.009510
Evaluating threshold 0.1 with avar bound: [-0.007768220352761811]
Threshold 0.1 SUFFICIENT with avar bound: -0.007768220352761811
Evaluating threshold 0.2 with avar bound: [-0.007768220352761811]
Threshold 0.2 SUFFICIENT with avar bound: -0.007768220352761811
Evaluating threshold 0.3 with avar bound: [-0.007768220352761811]
Threshold 0.3 SUFFICIENT with avar bound: -0.007768220352761811
Evaluating threshold 0.4 with avar bound: [-0.007768220352761811]
Threshold 0.4 SUFFICIENT with avar bound: -0.007768220352761811
Evaluating threshold 0.5 with avar bound: [-0.007768220352761811]
Threshold 0.5 SUFFICIENT with avar bound: -0.007768220352761811
Evaluating threshold 0.6 with avar bound: [-0.007768220352761811]
Threshold 0.6 SUFFICIENT with avar bound: -0.007768220352761811
Evaluating threshold 0.7 with avar bound: [-0.007768220352761811]
Threshold 0.7 SUFFICIENT with avar bound: -0.007768220352761811
Evaluating threshold 0.8 with avar bound: [-0.007768220352761811]
Threshold 0.8 SUFFICIENT with avar bound: -0.007768220352761811
Evaluating threshold 0.9 with avar bound: [-0.007768220352761811]
Threshold 0.9 SUFFICIENT with avar bound: -0.007768220352761811

Running BIRL with demonstration 9/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 1), (6, 3), (5, 1), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.122
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.68453127  0.00998214  0.21464024  0.02162255  0.34379058  0.4078569
  0.44748198]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.008926
0.9-VaR bound for 9 demonstrations: -0.008462
0.95-VaR bound for 9 demonstrations: -0.006546
0.99-VaR bound for 9 demonstrations: -0.004689
True expected value difference for MAP policy: -0.009798
Evaluating threshold 0.1 with avar bound: [-0.006545507425901048]
Threshold 0.1 SUFFICIENT with avar bound: -0.006545507425901048
Evaluating threshold 0.2 with avar bound: [-0.006545507425901048]
Threshold 0.2 SUFFICIENT with avar bound: -0.006545507425901048
Evaluating threshold 0.3 with avar bound: [-0.006545507425901048]
Threshold 0.3 SUFFICIENT with avar bound: -0.006545507425901048
Evaluating threshold 0.4 with avar bound: [-0.006545507425901048]
Threshold 0.4 SUFFICIENT with avar bound: -0.006545507425901048
Evaluating threshold 0.5 with avar bound: [-0.006545507425901048]
Threshold 0.5 SUFFICIENT with avar bound: -0.006545507425901048
Evaluating threshold 0.6 with avar bound: [-0.006545507425901048]
Threshold 0.6 SUFFICIENT with avar bound: -0.006545507425901048
Evaluating threshold 0.7 with avar bound: [-0.006545507425901048]
Threshold 0.7 SUFFICIENT with avar bound: -0.006545507425901048
Evaluating threshold 0.8 with avar bound: [-0.006545507425901048]
Threshold 0.8 SUFFICIENT with avar bound: -0.006545507425901048
Evaluating threshold 0.9 with avar bound: [-0.006545507425901048]
Threshold 0.9 SUFFICIENT with avar bound: -0.006545507425901048

Running BIRL with demonstration 10/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 1), (6, 3), (5, 1), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.146
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.82854077  0.02803594  0.20012117 -0.03191252 -0.0169724   0.30038
  0.42561846]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.007796
0.9-VaR bound for 10 demonstrations: -0.007050
0.95-VaR bound for 10 demonstrations: -0.006704
0.99-VaR bound for 10 demonstrations: -0.006651
True expected value difference for MAP policy: -0.009780
Evaluating threshold 0.1 with avar bound: [-0.0067038022866837315]
Threshold 0.1 SUFFICIENT with avar bound: -0.0067038022866837315
Evaluating threshold 0.2 with avar bound: [-0.0067038022866837315]
Threshold 0.2 SUFFICIENT with avar bound: -0.0067038022866837315
Evaluating threshold 0.3 with avar bound: [-0.0067038022866837315]
Threshold 0.3 SUFFICIENT with avar bound: -0.0067038022866837315
Evaluating threshold 0.4 with avar bound: [-0.0067038022866837315]
Threshold 0.4 SUFFICIENT with avar bound: -0.0067038022866837315
Evaluating threshold 0.5 with avar bound: [-0.0067038022866837315]
Threshold 0.5 SUFFICIENT with avar bound: -0.0067038022866837315
Evaluating threshold 0.6 with avar bound: [-0.0067038022866837315]
Threshold 0.6 SUFFICIENT with avar bound: -0.0067038022866837315
Evaluating threshold 0.7 with avar bound: [-0.0067038022866837315]
Threshold 0.7 SUFFICIENT with avar bound: -0.0067038022866837315
Evaluating threshold 0.8 with avar bound: [-0.0067038022866837315]
Threshold 0.8 SUFFICIENT with avar bound: -0.0067038022866837315
Evaluating threshold 0.9 with avar bound: [-0.0067038022866837315]
Threshold 0.9 SUFFICIENT with avar bound: -0.0067038022866837315

Saving results to files...
Results saved successfully.

Running world 17/20

Running BIRL with demonstration 1/10 in world 17
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.378
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.29168244 -0.57087974  0.19552105  0.17216885 -0.51961117  0.06924894
  0.49634252]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 2.956284
0.9-VaR bound for 1 demonstrations: 3.600736
0.95-VaR bound for 1 demonstrations: 6.087119
0.99-VaR bound for 1 demonstrations: 11.818410
True expected value difference for MAP policy: -0.000451
Evaluating threshold 0.1 with avar bound: [6.08711853940158]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [6.08711853940158]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [6.08711853940158]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [6.08711853940158]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [6.08711853940158]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [6.08711853940158]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [6.08711853940158]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [6.08711853940158]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [6.08711853940158]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 17
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.264
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.461062    0.02321688  0.65297572  0.59134605  0.08910588 -0.04230645
 -0.03294971]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 0.930091
0.9-VaR bound for 2 demonstrations: 1.105088
0.95-VaR bound for 2 demonstrations: 1.568820
0.99-VaR bound for 2 demonstrations: 3.633059
True expected value difference for MAP policy: 0.955539
Evaluating threshold 0.1 with avar bound: [1.5688199738426785]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.5688199738426785]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.5688199738426785]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.5688199738426785]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.5688199738426785]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.5688199738426785]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.5688199738426785]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.5688199738426785]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.5688199738426785]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.207
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.49872675 -0.36027289  0.34236172 -0.08481998 -0.31715725 -0.26097569
  0.57303758]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.431907
0.9-VaR bound for 3 demonstrations: 1.548547
0.95-VaR bound for 3 demonstrations: 2.043138
0.99-VaR bound for 3 demonstrations: 5.103443
True expected value difference for MAP policy: -0.007013
Evaluating threshold 0.1 with avar bound: [2.043138049879364]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.043138049879364]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.043138049879364]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.043138049879364]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.043138049879364]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.043138049879364]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.043138049879364]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.043138049879364]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.043138049879364]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.21
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.4032693  -0.68510488  0.2414925  -0.05097048 -0.07974905 -0.22097891
  0.50189338]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.003929
0.9-VaR bound for 4 demonstrations: 0.007951
0.95-VaR bound for 4 demonstrations: 0.014181
0.99-VaR bound for 4 demonstrations: 0.530235
True expected value difference for MAP policy: -0.007013
Evaluating threshold 0.1 with avar bound: [0.01418056169670217]
Threshold 0.1 SUFFICIENT with avar bound: 0.01418056169670217
Evaluating threshold 0.2 with avar bound: [0.01418056169670217]
Threshold 0.2 SUFFICIENT with avar bound: 0.01418056169670217
Evaluating threshold 0.3 with avar bound: [0.01418056169670217]
Threshold 0.3 SUFFICIENT with avar bound: 0.01418056169670217
Evaluating threshold 0.4 with avar bound: [0.01418056169670217]
Threshold 0.4 SUFFICIENT with avar bound: 0.01418056169670217
Evaluating threshold 0.5 with avar bound: [0.01418056169670217]
Threshold 0.5 SUFFICIENT with avar bound: 0.01418056169670217
Evaluating threshold 0.6 with avar bound: [0.01418056169670217]
Threshold 0.6 SUFFICIENT with avar bound: 0.01418056169670217
Evaluating threshold 0.7 with avar bound: [0.01418056169670217]
Threshold 0.7 SUFFICIENT with avar bound: 0.01418056169670217
Evaluating threshold 0.8 with avar bound: [0.01418056169670217]
Threshold 0.8 SUFFICIENT with avar bound: 0.01418056169670217
Evaluating threshold 0.9 with avar bound: [0.01418056169670217]
Threshold 0.9 SUFFICIENT with avar bound: 0.01418056169670217

Running BIRL with demonstration 5/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.188
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.52560023 -0.19093442  0.32176505  0.15208545 -0.15402588  0.11949258
  0.72292687]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.004194
0.9-VaR bound for 5 demonstrations: 0.014166
0.95-VaR bound for 5 demonstrations: 0.054343
0.99-VaR bound for 5 demonstrations: 0.065753
True expected value difference for MAP policy: -0.007232
Evaluating threshold 0.1 with avar bound: [0.054343261460715046]
Threshold 0.1 SUFFICIENT with avar bound: 0.054343261460715046
Evaluating threshold 0.2 with avar bound: [0.054343261460715046]
Threshold 0.2 SUFFICIENT with avar bound: 0.054343261460715046
Evaluating threshold 0.3 with avar bound: [0.054343261460715046]
Threshold 0.3 SUFFICIENT with avar bound: 0.054343261460715046
Evaluating threshold 0.4 with avar bound: [0.054343261460715046]
Threshold 0.4 SUFFICIENT with avar bound: 0.054343261460715046
Evaluating threshold 0.5 with avar bound: [0.054343261460715046]
Threshold 0.5 SUFFICIENT with avar bound: 0.054343261460715046
Evaluating threshold 0.6 with avar bound: [0.054343261460715046]
Threshold 0.6 SUFFICIENT with avar bound: 0.054343261460715046
Evaluating threshold 0.7 with avar bound: [0.054343261460715046]
Threshold 0.7 SUFFICIENT with avar bound: 0.054343261460715046
Evaluating threshold 0.8 with avar bound: [0.054343261460715046]
Threshold 0.8 SUFFICIENT with avar bound: 0.054343261460715046
Evaluating threshold 0.9 with avar bound: [0.054343261460715046]
Threshold 0.9 SUFFICIENT with avar bound: 0.054343261460715046

Running BIRL with demonstration 6/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.155
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.67106017 -0.4534084  -0.15193974 -0.19124685 -0.34085845  0.27348099
  0.30571505]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.002947
0.9-VaR bound for 6 demonstrations: 0.001625
0.95-VaR bound for 6 demonstrations: 0.010374
0.99-VaR bound for 6 demonstrations: 0.324140
True expected value difference for MAP policy: -0.007632
Evaluating threshold 0.1 with avar bound: [0.010373608955165809]
Threshold 0.1 SUFFICIENT with avar bound: 0.010373608955165809
Evaluating threshold 0.2 with avar bound: [0.010373608955165809]
Threshold 0.2 SUFFICIENT with avar bound: 0.010373608955165809
Evaluating threshold 0.3 with avar bound: [0.010373608955165809]
Threshold 0.3 SUFFICIENT with avar bound: 0.010373608955165809
Evaluating threshold 0.4 with avar bound: [0.010373608955165809]
Threshold 0.4 SUFFICIENT with avar bound: 0.010373608955165809
Evaluating threshold 0.5 with avar bound: [0.010373608955165809]
Threshold 0.5 SUFFICIENT with avar bound: 0.010373608955165809
Evaluating threshold 0.6 with avar bound: [0.010373608955165809]
Threshold 0.6 SUFFICIENT with avar bound: 0.010373608955165809
Evaluating threshold 0.7 with avar bound: [0.010373608955165809]
Threshold 0.7 SUFFICIENT with avar bound: 0.010373608955165809
Evaluating threshold 0.8 with avar bound: [0.010373608955165809]
Threshold 0.8 SUFFICIENT with avar bound: 0.010373608955165809
Evaluating threshold 0.9 with avar bound: [0.010373608955165809]
Threshold 0.9 SUFFICIENT with avar bound: 0.010373608955165809

Running BIRL with demonstration 7/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.159
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.74513422 -0.40469776 -0.16547343  0.0309116  -0.23116673 -0.02190723
  0.44580237]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: 0.007651
0.9-VaR bound for 7 demonstrations: 0.010180
0.95-VaR bound for 7 demonstrations: 0.040041
0.99-VaR bound for 7 demonstrations: 0.907676
True expected value difference for MAP policy: -0.007857
Evaluating threshold 0.1 with avar bound: [0.040041124561416924]
Threshold 0.1 SUFFICIENT with avar bound: 0.040041124561416924
Evaluating threshold 0.2 with avar bound: [0.040041124561416924]
Threshold 0.2 SUFFICIENT with avar bound: 0.040041124561416924
Evaluating threshold 0.3 with avar bound: [0.040041124561416924]
Threshold 0.3 SUFFICIENT with avar bound: 0.040041124561416924
Evaluating threshold 0.4 with avar bound: [0.040041124561416924]
Threshold 0.4 SUFFICIENT with avar bound: 0.040041124561416924
Evaluating threshold 0.5 with avar bound: [0.040041124561416924]
Threshold 0.5 SUFFICIENT with avar bound: 0.040041124561416924
Evaluating threshold 0.6 with avar bound: [0.040041124561416924]
Threshold 0.6 SUFFICIENT with avar bound: 0.040041124561416924
Evaluating threshold 0.7 with avar bound: [0.040041124561416924]
Threshold 0.7 SUFFICIENT with avar bound: 0.040041124561416924
Evaluating threshold 0.8 with avar bound: [0.040041124561416924]
Threshold 0.8 SUFFICIENT with avar bound: 0.040041124561416924
Evaluating threshold 0.9 with avar bound: [0.040041124561416924]
Threshold 0.9 SUFFICIENT with avar bound: 0.040041124561416924

Running BIRL with demonstration 8/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.148
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.70250781 -0.30050911 -0.1524051   0.23279395  0.07191454  0.1346844
  0.56164502]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.006893
0.9-VaR bound for 8 demonstrations: -0.004615
0.95-VaR bound for 8 demonstrations: 0.005499
0.99-VaR bound for 8 demonstrations: 0.039025
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [0.005499212514245622]
Threshold 0.1 SUFFICIENT with avar bound: 0.005499212514245622
Evaluating threshold 0.2 with avar bound: [0.005499212514245622]
Threshold 0.2 SUFFICIENT with avar bound: 0.005499212514245622
Evaluating threshold 0.3 with avar bound: [0.005499212514245622]
Threshold 0.3 SUFFICIENT with avar bound: 0.005499212514245622
Evaluating threshold 0.4 with avar bound: [0.005499212514245622]
Threshold 0.4 SUFFICIENT with avar bound: 0.005499212514245622
Evaluating threshold 0.5 with avar bound: [0.005499212514245622]
Threshold 0.5 SUFFICIENT with avar bound: 0.005499212514245622
Evaluating threshold 0.6 with avar bound: [0.005499212514245622]
Threshold 0.6 SUFFICIENT with avar bound: 0.005499212514245622
Evaluating threshold 0.7 with avar bound: [0.005499212514245622]
Threshold 0.7 SUFFICIENT with avar bound: 0.005499212514245622
Evaluating threshold 0.8 with avar bound: [0.005499212514245622]
Threshold 0.8 SUFFICIENT with avar bound: 0.005499212514245622
Evaluating threshold 0.9 with avar bound: [0.005499212514245622]
Threshold 0.9 SUFFICIENT with avar bound: 0.005499212514245622

Running BIRL with demonstration 9/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.144
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.76820133 -0.28234027 -0.05015288  0.17899465 -0.28625656  0.22417132
  0.40422851]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.004473
0.9-VaR bound for 9 demonstrations: -0.000148
0.95-VaR bound for 9 demonstrations: 0.004934
0.99-VaR bound for 9 demonstrations: 1.324996
True expected value difference for MAP policy: -0.007857
Evaluating threshold 0.1 with avar bound: [0.0049342211220492135]
Threshold 0.1 SUFFICIENT with avar bound: 0.0049342211220492135
Evaluating threshold 0.2 with avar bound: [0.0049342211220492135]
Threshold 0.2 SUFFICIENT with avar bound: 0.0049342211220492135
Evaluating threshold 0.3 with avar bound: [0.0049342211220492135]
Threshold 0.3 SUFFICIENT with avar bound: 0.0049342211220492135
Evaluating threshold 0.4 with avar bound: [0.0049342211220492135]
Threshold 0.4 SUFFICIENT with avar bound: 0.0049342211220492135
Evaluating threshold 0.5 with avar bound: [0.0049342211220492135]
Threshold 0.5 SUFFICIENT with avar bound: 0.0049342211220492135
Evaluating threshold 0.6 with avar bound: [0.0049342211220492135]
Threshold 0.6 SUFFICIENT with avar bound: 0.0049342211220492135
Evaluating threshold 0.7 with avar bound: [0.0049342211220492135]
Threshold 0.7 SUFFICIENT with avar bound: 0.0049342211220492135
Evaluating threshold 0.8 with avar bound: [0.0049342211220492135]
Threshold 0.8 SUFFICIENT with avar bound: 0.0049342211220492135
Evaluating threshold 0.9 with avar bound: [0.0049342211220492135]
Threshold 0.9 SUFFICIENT with avar bound: 0.0049342211220492135

Running BIRL with demonstration 10/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.159
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34923822 -0.17441211  0.12697328  0.39398756  0.16654613  0.43199953
  0.67963481]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.003790
0.9-VaR bound for 10 demonstrations: -0.001004
0.95-VaR bound for 10 demonstrations: 0.001671
0.99-VaR bound for 10 demonstrations: 0.013488
True expected value difference for MAP policy: -0.007857
Evaluating threshold 0.1 with avar bound: [0.0016705087892482247]
Threshold 0.1 SUFFICIENT with avar bound: 0.0016705087892482247
Evaluating threshold 0.2 with avar bound: [0.0016705087892482247]
Threshold 0.2 SUFFICIENT with avar bound: 0.0016705087892482247
Evaluating threshold 0.3 with avar bound: [0.0016705087892482247]
Threshold 0.3 SUFFICIENT with avar bound: 0.0016705087892482247
Evaluating threshold 0.4 with avar bound: [0.0016705087892482247]
Threshold 0.4 SUFFICIENT with avar bound: 0.0016705087892482247
Evaluating threshold 0.5 with avar bound: [0.0016705087892482247]
Threshold 0.5 SUFFICIENT with avar bound: 0.0016705087892482247
Evaluating threshold 0.6 with avar bound: [0.0016705087892482247]
Threshold 0.6 SUFFICIENT with avar bound: 0.0016705087892482247
Evaluating threshold 0.7 with avar bound: [0.0016705087892482247]
Threshold 0.7 SUFFICIENT with avar bound: 0.0016705087892482247
Evaluating threshold 0.8 with avar bound: [0.0016705087892482247]
Threshold 0.8 SUFFICIENT with avar bound: 0.0016705087892482247
Evaluating threshold 0.9 with avar bound: [0.0016705087892482247]
Threshold 0.9 SUFFICIENT with avar bound: 0.0016705087892482247

Running world 18/20

Running BIRL with demonstration 1/10 in world 18
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.284
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 9.64273013e-02 -8.10189383e-01 -2.65934354e-01 -2.48052426e-01
  9.42209173e-02 -3.30858424e-04  4.39506725e-01]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 2.208745
0.9-VaR bound for 1 demonstrations: 2.497434
0.95-VaR bound for 1 demonstrations: 3.105481
0.99-VaR bound for 1 demonstrations: 53.254720
True expected value difference for MAP policy: -0.000231
Evaluating threshold 0.1 with avar bound: [3.1054814899508507]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.1054814899508507]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.1054814899508507]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.1054814899508507]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.1054814899508507]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.1054814899508507]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.1054814899508507]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.1054814899508507]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.1054814899508507]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 18
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.00201175 -0.8434899  -0.00783162  0.21183733  0.04022202  0.0646024
  0.48764031]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 0.001460
0.9-VaR bound for 2 demonstrations: 0.004049
0.95-VaR bound for 2 demonstrations: 0.020557
0.99-VaR bound for 2 demonstrations: 2.021926
True expected value difference for MAP policy: -0.005138
Evaluating threshold 0.1 with avar bound: [0.020556845808249093]
Threshold 0.1 SUFFICIENT with avar bound: 0.020556845808249093
Evaluating threshold 0.2 with avar bound: [0.020556845808249093]
Threshold 0.2 SUFFICIENT with avar bound: 0.020556845808249093
Evaluating threshold 0.3 with avar bound: [0.020556845808249093]
Threshold 0.3 SUFFICIENT with avar bound: 0.020556845808249093
Evaluating threshold 0.4 with avar bound: [0.020556845808249093]
Threshold 0.4 SUFFICIENT with avar bound: 0.020556845808249093
Evaluating threshold 0.5 with avar bound: [0.020556845808249093]
Threshold 0.5 SUFFICIENT with avar bound: 0.020556845808249093
Evaluating threshold 0.6 with avar bound: [0.020556845808249093]
Threshold 0.6 SUFFICIENT with avar bound: 0.020556845808249093
Evaluating threshold 0.7 with avar bound: [0.020556845808249093]
Threshold 0.7 SUFFICIENT with avar bound: 0.020556845808249093
Evaluating threshold 0.8 with avar bound: [0.020556845808249093]
Threshold 0.8 SUFFICIENT with avar bound: 0.020556845808249093
Evaluating threshold 0.9 with avar bound: [0.020556845808249093]
Threshold 0.9 SUFFICIENT with avar bound: 0.020556845808249093

Running BIRL with demonstration 3/10 in world 18
Current demos: [(16, 1), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.192
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.02509735 -0.78299575 -0.04720944  0.05246544  0.16592988 -0.05421515
  0.59231277]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: -0.005877
0.9-VaR bound for 3 demonstrations: -0.005145
0.95-VaR bound for 3 demonstrations: -0.003639
0.99-VaR bound for 3 demonstrations: 0.009022
True expected value difference for MAP policy: -0.009516
Evaluating threshold 0.1 with avar bound: [-0.0036390782475282683]
Threshold 0.1 SUFFICIENT with avar bound: -0.0036390782475282683
Evaluating threshold 0.2 with avar bound: [-0.0036390782475282683]
Threshold 0.2 SUFFICIENT with avar bound: -0.0036390782475282683
Evaluating threshold 0.3 with avar bound: [-0.0036390782475282683]
Threshold 0.3 SUFFICIENT with avar bound: -0.0036390782475282683
Evaluating threshold 0.4 with avar bound: [-0.0036390782475282683]
Threshold 0.4 SUFFICIENT with avar bound: -0.0036390782475282683
Evaluating threshold 0.5 with avar bound: [-0.0036390782475282683]
Threshold 0.5 SUFFICIENT with avar bound: -0.0036390782475282683
Evaluating threshold 0.6 with avar bound: [-0.0036390782475282683]
Threshold 0.6 SUFFICIENT with avar bound: -0.0036390782475282683
Evaluating threshold 0.7 with avar bound: [-0.0036390782475282683]
Threshold 0.7 SUFFICIENT with avar bound: -0.0036390782475282683
Evaluating threshold 0.8 with avar bound: [-0.0036390782475282683]
Threshold 0.8 SUFFICIENT with avar bound: -0.0036390782475282683
Evaluating threshold 0.9 with avar bound: [-0.0036390782475282683]
Threshold 0.9 SUFFICIENT with avar bound: -0.0036390782475282683

Running BIRL with demonstration 4/10 in world 18
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.211
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.11568547 -0.73047864  0.08656698 -0.3678789   0.2335161   0.02449371
  0.50503405]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.003017
0.9-VaR bound for 4 demonstrations: -0.002044
0.95-VaR bound for 4 demonstrations: 0.000003
0.99-VaR bound for 4 demonstrations: 0.038939
True expected value difference for MAP policy: -0.005387
Evaluating threshold 0.1 with avar bound: [3.2841234404123623e-06]
Threshold 0.1 SUFFICIENT with avar bound: 3.2841234404123623e-06
Evaluating threshold 0.2 with avar bound: [3.2841234404123623e-06]
Threshold 0.2 SUFFICIENT with avar bound: 3.2841234404123623e-06
Evaluating threshold 0.3 with avar bound: [3.2841234404123623e-06]
Threshold 0.3 SUFFICIENT with avar bound: 3.2841234404123623e-06
Evaluating threshold 0.4 with avar bound: [3.2841234404123623e-06]
Threshold 0.4 SUFFICIENT with avar bound: 3.2841234404123623e-06
Evaluating threshold 0.5 with avar bound: [3.2841234404123623e-06]
Threshold 0.5 SUFFICIENT with avar bound: 3.2841234404123623e-06
Evaluating threshold 0.6 with avar bound: [3.2841234404123623e-06]
Threshold 0.6 SUFFICIENT with avar bound: 3.2841234404123623e-06
Evaluating threshold 0.7 with avar bound: [3.2841234404123623e-06]
Threshold 0.7 SUFFICIENT with avar bound: 3.2841234404123623e-06
Evaluating threshold 0.8 with avar bound: [3.2841234404123623e-06]
Threshold 0.8 SUFFICIENT with avar bound: 3.2841234404123623e-06
Evaluating threshold 0.9 with avar bound: [3.2841234404123623e-06]
Threshold 0.9 SUFFICIENT with avar bound: 3.2841234404123623e-06

Running BIRL with demonstration 5/10 in world 18
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [-9.29555438e-02 -7.34899661e-01  2.84573152e-01 -2.23292356e-01
  3.93377653e-04 -2.53735913e-01  5.06022067e-01]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.006175
0.9-VaR bound for 5 demonstrations: -0.004800
0.95-VaR bound for 5 demonstrations: -0.003490
0.99-VaR bound for 5 demonstrations: 0.002538
True expected value difference for MAP policy: -0.003537
Evaluating threshold 0.1 with avar bound: [-0.003490300774091679]
Threshold 0.1 SUFFICIENT with avar bound: -0.003490300774091679
Evaluating threshold 0.2 with avar bound: [-0.003490300774091679]
Threshold 0.2 SUFFICIENT with avar bound: -0.003490300774091679
Evaluating threshold 0.3 with avar bound: [-0.003490300774091679]
Threshold 0.3 SUFFICIENT with avar bound: -0.003490300774091679
Evaluating threshold 0.4 with avar bound: [-0.003490300774091679]
Threshold 0.4 SUFFICIENT with avar bound: -0.003490300774091679
Evaluating threshold 0.5 with avar bound: [-0.003490300774091679]
Threshold 0.5 SUFFICIENT with avar bound: -0.003490300774091679
Evaluating threshold 0.6 with avar bound: [-0.003490300774091679]
Threshold 0.6 SUFFICIENT with avar bound: -0.003490300774091679
Evaluating threshold 0.7 with avar bound: [-0.003490300774091679]
Threshold 0.7 SUFFICIENT with avar bound: -0.003490300774091679
Evaluating threshold 0.8 with avar bound: [-0.003490300774091679]
Threshold 0.8 SUFFICIENT with avar bound: -0.003490300774091679
Evaluating threshold 0.9 with avar bound: [-0.003490300774091679]
Threshold 0.9 SUFFICIENT with avar bound: -0.003490300774091679

Running BIRL with demonstration 6/10 in world 18
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.188
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.15916326 -0.69947366  0.06478269 -0.1420982   0.30333367 -0.09917475
  0.59930628]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.004900
0.9-VaR bound for 6 demonstrations: -0.002867
0.95-VaR bound for 6 demonstrations: 0.034054
0.99-VaR bound for 6 demonstrations: 6.742355
True expected value difference for MAP policy: -0.008933
Evaluating threshold 0.1 with avar bound: [0.03405372287036137]
Threshold 0.1 SUFFICIENT with avar bound: 0.03405372287036137
Evaluating threshold 0.2 with avar bound: [0.03405372287036137]
Threshold 0.2 SUFFICIENT with avar bound: 0.03405372287036137
Evaluating threshold 0.3 with avar bound: [0.03405372287036137]
Threshold 0.3 SUFFICIENT with avar bound: 0.03405372287036137
Evaluating threshold 0.4 with avar bound: [0.03405372287036137]
Threshold 0.4 SUFFICIENT with avar bound: 0.03405372287036137
Evaluating threshold 0.5 with avar bound: [0.03405372287036137]
Threshold 0.5 SUFFICIENT with avar bound: 0.03405372287036137
Evaluating threshold 0.6 with avar bound: [0.03405372287036137]
Threshold 0.6 SUFFICIENT with avar bound: 0.03405372287036137
Evaluating threshold 0.7 with avar bound: [0.03405372287036137]
Threshold 0.7 SUFFICIENT with avar bound: 0.03405372287036137
Evaluating threshold 0.8 with avar bound: [0.03405372287036137]
Threshold 0.8 SUFFICIENT with avar bound: 0.03405372287036137
Evaluating threshold 0.9 with avar bound: [0.03405372287036137]
Threshold 0.9 SUFFICIENT with avar bound: 0.03405372287036137

Running BIRL with demonstration 7/10 in world 18
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.174
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.06652271 -0.58722021  0.04282664  0.41704152  0.35788962  0.25005609
  0.53326951]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.007579
0.9-VaR bound for 7 demonstrations: -0.006003
0.95-VaR bound for 7 demonstrations: -0.004351
0.99-VaR bound for 7 demonstrations: 0.002337
True expected value difference for MAP policy: -0.009391
Evaluating threshold 0.1 with avar bound: [-0.004350555661642921]
Threshold 0.1 SUFFICIENT with avar bound: -0.004350555661642921
Evaluating threshold 0.2 with avar bound: [-0.004350555661642921]
Threshold 0.2 SUFFICIENT with avar bound: -0.004350555661642921
Evaluating threshold 0.3 with avar bound: [-0.004350555661642921]
Threshold 0.3 SUFFICIENT with avar bound: -0.004350555661642921
Evaluating threshold 0.4 with avar bound: [-0.004350555661642921]
Threshold 0.4 SUFFICIENT with avar bound: -0.004350555661642921
Evaluating threshold 0.5 with avar bound: [-0.004350555661642921]
Threshold 0.5 SUFFICIENT with avar bound: -0.004350555661642921
Evaluating threshold 0.6 with avar bound: [-0.004350555661642921]
Threshold 0.6 SUFFICIENT with avar bound: -0.004350555661642921
Evaluating threshold 0.7 with avar bound: [-0.004350555661642921]
Threshold 0.7 SUFFICIENT with avar bound: -0.004350555661642921
Evaluating threshold 0.8 with avar bound: [-0.004350555661642921]
Threshold 0.8 SUFFICIENT with avar bound: -0.004350555661642921
Evaluating threshold 0.9 with avar bound: [-0.004350555661642921]
Threshold 0.9 SUFFICIENT with avar bound: -0.004350555661642921

Running BIRL with demonstration 8/10 in world 18
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.154
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.03847566 -0.72272235  0.03875547  0.37220966  0.26145746  0.03316387
  0.51642053]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.006495
0.9-VaR bound for 8 demonstrations: -0.005363
0.95-VaR bound for 8 demonstrations: -0.004133
0.99-VaR bound for 8 demonstrations: 0.005157
True expected value difference for MAP policy: -0.005138
Evaluating threshold 0.1 with avar bound: [-0.004133131220971354]
Threshold 0.1 SUFFICIENT with avar bound: -0.004133131220971354
Evaluating threshold 0.2 with avar bound: [-0.004133131220971354]
Threshold 0.2 SUFFICIENT with avar bound: -0.004133131220971354
Evaluating threshold 0.3 with avar bound: [-0.004133131220971354]
Threshold 0.3 SUFFICIENT with avar bound: -0.004133131220971354
Evaluating threshold 0.4 with avar bound: [-0.004133131220971354]
Threshold 0.4 SUFFICIENT with avar bound: -0.004133131220971354
Evaluating threshold 0.5 with avar bound: [-0.004133131220971354]
Threshold 0.5 SUFFICIENT with avar bound: -0.004133131220971354
Evaluating threshold 0.6 with avar bound: [-0.004133131220971354]
Threshold 0.6 SUFFICIENT with avar bound: -0.004133131220971354
Evaluating threshold 0.7 with avar bound: [-0.004133131220971354]
Threshold 0.7 SUFFICIENT with avar bound: -0.004133131220971354
Evaluating threshold 0.8 with avar bound: [-0.004133131220971354]
Threshold 0.8 SUFFICIENT with avar bound: -0.004133131220971354
Evaluating threshold 0.9 with avar bound: [-0.004133131220971354]
Threshold 0.9 SUFFICIENT with avar bound: -0.004133131220971354

Running BIRL with demonstration 9/10 in world 18
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.15
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.05431985 -0.76007146 -0.07877619  0.30322208  0.14938992 -0.26288714
  0.47933747]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.007858
0.9-VaR bound for 9 demonstrations: -0.007434
0.95-VaR bound for 9 demonstrations: -0.005268
0.99-VaR bound for 9 demonstrations: 0.005248
True expected value difference for MAP policy: -0.005138
Evaluating threshold 0.1 with avar bound: [-0.005268321326027587]
Threshold 0.1 SUFFICIENT with avar bound: -0.005268321326027587
Evaluating threshold 0.2 with avar bound: [-0.005268321326027587]
Threshold 0.2 SUFFICIENT with avar bound: -0.005268321326027587
Evaluating threshold 0.3 with avar bound: [-0.005268321326027587]
Threshold 0.3 SUFFICIENT with avar bound: -0.005268321326027587
Evaluating threshold 0.4 with avar bound: [-0.005268321326027587]
Threshold 0.4 SUFFICIENT with avar bound: -0.005268321326027587
Evaluating threshold 0.5 with avar bound: [-0.005268321326027587]
Threshold 0.5 SUFFICIENT with avar bound: -0.005268321326027587
Evaluating threshold 0.6 with avar bound: [-0.005268321326027587]
Threshold 0.6 SUFFICIENT with avar bound: -0.005268321326027587
Evaluating threshold 0.7 with avar bound: [-0.005268321326027587]
Threshold 0.7 SUFFICIENT with avar bound: -0.005268321326027587
Evaluating threshold 0.8 with avar bound: [-0.005268321326027587]
Threshold 0.8 SUFFICIENT with avar bound: -0.005268321326027587
Evaluating threshold 0.9 with avar bound: [-0.005268321326027587]
Threshold 0.9 SUFFICIENT with avar bound: -0.005268321326027587

Running BIRL with demonstration 10/10 in world 18
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.173
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.20166356 -0.60264197 -0.08541555  0.25527962  0.17389572  0.19646157
  0.67442872]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.008558
0.9-VaR bound for 10 demonstrations: -0.007742
0.95-VaR bound for 10 demonstrations: -0.006167
0.99-VaR bound for 10 demonstrations: -0.003961
True expected value difference for MAP policy: -0.009391
Evaluating threshold 0.1 with avar bound: [-0.006167343602266168]
Threshold 0.1 SUFFICIENT with avar bound: -0.006167343602266168
Evaluating threshold 0.2 with avar bound: [-0.006167343602266168]
Threshold 0.2 SUFFICIENT with avar bound: -0.006167343602266168
Evaluating threshold 0.3 with avar bound: [-0.006167343602266168]
Threshold 0.3 SUFFICIENT with avar bound: -0.006167343602266168
Evaluating threshold 0.4 with avar bound: [-0.006167343602266168]
Threshold 0.4 SUFFICIENT with avar bound: -0.006167343602266168
Evaluating threshold 0.5 with avar bound: [-0.006167343602266168]
Threshold 0.5 SUFFICIENT with avar bound: -0.006167343602266168
Evaluating threshold 0.6 with avar bound: [-0.006167343602266168]
Threshold 0.6 SUFFICIENT with avar bound: -0.006167343602266168
Evaluating threshold 0.7 with avar bound: [-0.006167343602266168]
Threshold 0.7 SUFFICIENT with avar bound: -0.006167343602266168
Evaluating threshold 0.8 with avar bound: [-0.006167343602266168]
Threshold 0.8 SUFFICIENT with avar bound: -0.006167343602266168
Evaluating threshold 0.9 with avar bound: [-0.006167343602266168]
Threshold 0.9 SUFFICIENT with avar bound: -0.006167343602266168

Running world 19/20

Running BIRL with demonstration 1/10 in world 19
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.339
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.16925059 -0.27345792  0.30058875 -0.58945782 -0.14383176 -0.02819596
  0.66127022]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.846163
0.9-VaR bound for 1 demonstrations: 2.548833
0.95-VaR bound for 1 demonstrations: 4.019809
0.99-VaR bound for 1 demonstrations: 81.505998
True expected value difference for MAP policy: -0.002866
Evaluating threshold 0.1 with avar bound: [4.019808729476213]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [4.019808729476213]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [4.019808729476213]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [4.019808729476213]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [4.019808729476213]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [4.019808729476213]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [4.019808729476213]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [4.019808729476213]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [4.019808729476213]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 19
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.217
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.65976364 -0.03898901  0.25530344 -0.14181042  0.06847744  0.34607925
  0.59450967]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 2.080812
0.9-VaR bound for 2 demonstrations: 2.389376
0.95-VaR bound for 2 demonstrations: 3.764681
0.99-VaR bound for 2 demonstrations: 54.338849
True expected value difference for MAP policy: -0.009217
Evaluating threshold 0.1 with avar bound: [3.764680806971388]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.764680806971388]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.764680806971388]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.764680806971388]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.764680806971388]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.764680806971388]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.764680806971388]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.764680806971388]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.764680806971388]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 19
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.221
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.80696629  0.0519706   0.10332333 -0.32211487  0.34004162  0.00203048
  0.340644  ]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.254411
0.9-VaR bound for 3 demonstrations: 0.839232
0.95-VaR bound for 3 demonstrations: 2.831300
0.99-VaR bound for 3 demonstrations: 5.677728
True expected value difference for MAP policy: -0.005587
Evaluating threshold 0.1 with avar bound: [2.8313002598517842]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.8313002598517842]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.8313002598517842]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.8313002598517842]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.8313002598517842]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.8313002598517842]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.8313002598517842]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.8313002598517842]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.8313002598517842]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 19
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.212
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.76090678 -0.21489394  0.27431876 -0.20627659  0.26197346 -0.20628257
  0.38191368]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.004799
0.9-VaR bound for 4 demonstrations: -0.002056
0.95-VaR bound for 4 demonstrations: -0.000205
0.99-VaR bound for 4 demonstrations: 0.006158
True expected value difference for MAP policy: -0.008180
Evaluating threshold 0.1 with avar bound: [-0.00020543021846114345]
Threshold 0.1 SUFFICIENT with avar bound: -0.00020543021846114345
Evaluating threshold 0.2 with avar bound: [-0.00020543021846114345]
Threshold 0.2 SUFFICIENT with avar bound: -0.00020543021846114345
Evaluating threshold 0.3 with avar bound: [-0.00020543021846114345]
Threshold 0.3 SUFFICIENT with avar bound: -0.00020543021846114345
Evaluating threshold 0.4 with avar bound: [-0.00020543021846114345]
Threshold 0.4 SUFFICIENT with avar bound: -0.00020543021846114345
Evaluating threshold 0.5 with avar bound: [-0.00020543021846114345]
Threshold 0.5 SUFFICIENT with avar bound: -0.00020543021846114345
Evaluating threshold 0.6 with avar bound: [-0.00020543021846114345]
Threshold 0.6 SUFFICIENT with avar bound: -0.00020543021846114345
Evaluating threshold 0.7 with avar bound: [-0.00020543021846114345]
Threshold 0.7 SUFFICIENT with avar bound: -0.00020543021846114345
Evaluating threshold 0.8 with avar bound: [-0.00020543021846114345]
Threshold 0.8 SUFFICIENT with avar bound: -0.00020543021846114345
Evaluating threshold 0.9 with avar bound: [-0.00020543021846114345]
Threshold 0.9 SUFFICIENT with avar bound: -0.00020543021846114345

Running BIRL with demonstration 5/10 in world 19
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.221
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.78123849 -0.33284362  0.20700599  0.01924938 -0.06477057  0.02010088
  0.48068727]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.006343
0.9-VaR bound for 5 demonstrations: -0.006103
0.95-VaR bound for 5 demonstrations: -0.004689
0.99-VaR bound for 5 demonstrations: 0.015261
True expected value difference for MAP policy: -0.009605
Evaluating threshold 0.1 with avar bound: [-0.004688992093576895]
Threshold 0.1 SUFFICIENT with avar bound: -0.004688992093576895
Evaluating threshold 0.2 with avar bound: [-0.004688992093576895]
Threshold 0.2 SUFFICIENT with avar bound: -0.004688992093576895
Evaluating threshold 0.3 with avar bound: [-0.004688992093576895]
Threshold 0.3 SUFFICIENT with avar bound: -0.004688992093576895
Evaluating threshold 0.4 with avar bound: [-0.004688992093576895]
Threshold 0.4 SUFFICIENT with avar bound: -0.004688992093576895
Evaluating threshold 0.5 with avar bound: [-0.004688992093576895]
Threshold 0.5 SUFFICIENT with avar bound: -0.004688992093576895
Evaluating threshold 0.6 with avar bound: [-0.004688992093576895]
Threshold 0.6 SUFFICIENT with avar bound: -0.004688992093576895
Evaluating threshold 0.7 with avar bound: [-0.004688992093576895]
Threshold 0.7 SUFFICIENT with avar bound: -0.004688992093576895
Evaluating threshold 0.8 with avar bound: [-0.004688992093576895]
Threshold 0.8 SUFFICIENT with avar bound: -0.004688992093576895
Evaluating threshold 0.9 with avar bound: [-0.004688992093576895]
Threshold 0.9 SUFFICIENT with avar bound: -0.004688992093576895

Running BIRL with demonstration 6/10 in world 19
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.2
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.81103566  0.13575978  0.24244375  0.0824636  -0.10366116 -0.0421408
  0.49567099]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.005536
0.9-VaR bound for 6 demonstrations: -0.003371
0.95-VaR bound for 6 demonstrations: -0.002732
0.99-VaR bound for 6 demonstrations: 0.003746
True expected value difference for MAP policy: -0.009889
Evaluating threshold 0.1 with avar bound: [-0.002732127331366222]
Threshold 0.1 SUFFICIENT with avar bound: -0.002732127331366222
Evaluating threshold 0.2 with avar bound: [-0.002732127331366222]
Threshold 0.2 SUFFICIENT with avar bound: -0.002732127331366222
Evaluating threshold 0.3 with avar bound: [-0.002732127331366222]
Threshold 0.3 SUFFICIENT with avar bound: -0.002732127331366222
Evaluating threshold 0.4 with avar bound: [-0.002732127331366222]
Threshold 0.4 SUFFICIENT with avar bound: -0.002732127331366222
Evaluating threshold 0.5 with avar bound: [-0.002732127331366222]
Threshold 0.5 SUFFICIENT with avar bound: -0.002732127331366222
Evaluating threshold 0.6 with avar bound: [-0.002732127331366222]
Threshold 0.6 SUFFICIENT with avar bound: -0.002732127331366222
Evaluating threshold 0.7 with avar bound: [-0.002732127331366222]
Threshold 0.7 SUFFICIENT with avar bound: -0.002732127331366222
Evaluating threshold 0.8 with avar bound: [-0.002732127331366222]
Threshold 0.8 SUFFICIENT with avar bound: -0.002732127331366222
Evaluating threshold 0.9 with avar bound: [-0.002732127331366222]
Threshold 0.9 SUFFICIENT with avar bound: -0.002732127331366222

Running BIRL with demonstration 7/10 in world 19
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.202
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62380721  0.27221458  0.2502074  -0.00343446 -0.53454438  0.13823186
  0.41146385]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.008028
0.9-VaR bound for 7 demonstrations: -0.007387
0.95-VaR bound for 7 demonstrations: -0.005649
0.99-VaR bound for 7 demonstrations: 0.005917
True expected value difference for MAP policy: -0.009569
Evaluating threshold 0.1 with avar bound: [-0.005648614483938091]
Threshold 0.1 SUFFICIENT with avar bound: -0.005648614483938091
Evaluating threshold 0.2 with avar bound: [-0.005648614483938091]
Threshold 0.2 SUFFICIENT with avar bound: -0.005648614483938091
Evaluating threshold 0.3 with avar bound: [-0.005648614483938091]
Threshold 0.3 SUFFICIENT with avar bound: -0.005648614483938091
Evaluating threshold 0.4 with avar bound: [-0.005648614483938091]
Threshold 0.4 SUFFICIENT with avar bound: -0.005648614483938091
Evaluating threshold 0.5 with avar bound: [-0.005648614483938091]
Threshold 0.5 SUFFICIENT with avar bound: -0.005648614483938091
Evaluating threshold 0.6 with avar bound: [-0.005648614483938091]
Threshold 0.6 SUFFICIENT with avar bound: -0.005648614483938091
Evaluating threshold 0.7 with avar bound: [-0.005648614483938091]
Threshold 0.7 SUFFICIENT with avar bound: -0.005648614483938091
Evaluating threshold 0.8 with avar bound: [-0.005648614483938091]
Threshold 0.8 SUFFICIENT with avar bound: -0.005648614483938091
Evaluating threshold 0.9 with avar bound: [-0.005648614483938091]
Threshold 0.9 SUFFICIENT with avar bound: -0.005648614483938091

Running BIRL with demonstration 8/10 in world 19
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.178
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.43502218  0.24454115 -0.17880878 -0.16072062  0.11243615  0.06430506
  0.82241997]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.006978
0.9-VaR bound for 8 demonstrations: -0.006361
0.95-VaR bound for 8 demonstrations: -0.003243
0.99-VaR bound for 8 demonstrations: 0.085529
True expected value difference for MAP policy: -0.009697
Evaluating threshold 0.1 with avar bound: [-0.003242771704539985]
Threshold 0.1 SUFFICIENT with avar bound: -0.003242771704539985
Evaluating threshold 0.2 with avar bound: [-0.003242771704539985]
Threshold 0.2 SUFFICIENT with avar bound: -0.003242771704539985
Evaluating threshold 0.3 with avar bound: [-0.003242771704539985]
Threshold 0.3 SUFFICIENT with avar bound: -0.003242771704539985
Evaluating threshold 0.4 with avar bound: [-0.003242771704539985]
Threshold 0.4 SUFFICIENT with avar bound: -0.003242771704539985
Evaluating threshold 0.5 with avar bound: [-0.003242771704539985]
Threshold 0.5 SUFFICIENT with avar bound: -0.003242771704539985
Evaluating threshold 0.6 with avar bound: [-0.003242771704539985]
Threshold 0.6 SUFFICIENT with avar bound: -0.003242771704539985
Evaluating threshold 0.7 with avar bound: [-0.003242771704539985]
Threshold 0.7 SUFFICIENT with avar bound: -0.003242771704539985
Evaluating threshold 0.8 with avar bound: [-0.003242771704539985]
Threshold 0.8 SUFFICIENT with avar bound: -0.003242771704539985
Evaluating threshold 0.9 with avar bound: [-0.003242771704539985]
Threshold 0.9 SUFFICIENT with avar bound: -0.003242771704539985

Running BIRL with demonstration 9/10 in world 19
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.165
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.46872085  0.28203735 -0.13386715 -0.10159529  0.02170661  0.2112349
  0.79209995]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.008794
0.9-VaR bound for 9 demonstrations: -0.008593
0.95-VaR bound for 9 demonstrations: -0.007029
0.99-VaR bound for 9 demonstrations: -0.005852
True expected value difference for MAP policy: -0.009697
Evaluating threshold 0.1 with avar bound: [-0.007028991218522721]
Threshold 0.1 SUFFICIENT with avar bound: -0.007028991218522721
Evaluating threshold 0.2 with avar bound: [-0.007028991218522721]
Threshold 0.2 SUFFICIENT with avar bound: -0.007028991218522721
Evaluating threshold 0.3 with avar bound: [-0.007028991218522721]
Threshold 0.3 SUFFICIENT with avar bound: -0.007028991218522721
Evaluating threshold 0.4 with avar bound: [-0.007028991218522721]
Threshold 0.4 SUFFICIENT with avar bound: -0.007028991218522721
Evaluating threshold 0.5 with avar bound: [-0.007028991218522721]
Threshold 0.5 SUFFICIENT with avar bound: -0.007028991218522721
Evaluating threshold 0.6 with avar bound: [-0.007028991218522721]
Threshold 0.6 SUFFICIENT with avar bound: -0.007028991218522721
Evaluating threshold 0.7 with avar bound: [-0.007028991218522721]
Threshold 0.7 SUFFICIENT with avar bound: -0.007028991218522721
Evaluating threshold 0.8 with avar bound: [-0.007028991218522721]
Threshold 0.8 SUFFICIENT with avar bound: -0.007028991218522721
Evaluating threshold 0.9 with avar bound: [-0.007028991218522721]
Threshold 0.9 SUFFICIENT with avar bound: -0.007028991218522721

Running BIRL with demonstration 10/10 in world 19
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.171
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61089562  0.08263271 -0.27192115 -0.2701073  -0.01454615 -0.05924654
  0.68509677]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.008697
0.9-VaR bound for 10 demonstrations: -0.008410
0.95-VaR bound for 10 demonstrations: -0.006441
0.99-VaR bound for 10 demonstrations: -0.001724
True expected value difference for MAP policy: -0.009697
Evaluating threshold 0.1 with avar bound: [-0.006440942777109288]
Threshold 0.1 SUFFICIENT with avar bound: -0.006440942777109288
Evaluating threshold 0.2 with avar bound: [-0.006440942777109288]
Threshold 0.2 SUFFICIENT with avar bound: -0.006440942777109288
Evaluating threshold 0.3 with avar bound: [-0.006440942777109288]
Threshold 0.3 SUFFICIENT with avar bound: -0.006440942777109288
Evaluating threshold 0.4 with avar bound: [-0.006440942777109288]
Threshold 0.4 SUFFICIENT with avar bound: -0.006440942777109288
Evaluating threshold 0.5 with avar bound: [-0.006440942777109288]
Threshold 0.5 SUFFICIENT with avar bound: -0.006440942777109288
Evaluating threshold 0.6 with avar bound: [-0.006440942777109288]
Threshold 0.6 SUFFICIENT with avar bound: -0.006440942777109288
Evaluating threshold 0.7 with avar bound: [-0.006440942777109288]
Threshold 0.7 SUFFICIENT with avar bound: -0.006440942777109288
Evaluating threshold 0.8 with avar bound: [-0.006440942777109288]
Threshold 0.8 SUFFICIENT with avar bound: -0.006440942777109288
Evaluating threshold 0.9 with avar bound: [-0.006440942777109288]
Threshold 0.9 SUFFICIENT with avar bound: -0.006440942777109288

Running world 20/20

Running BIRL with demonstration 1/10 in world 20
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.279
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.34802936 -0.02430702 -0.45147245 -0.51722393  0.10876761 -0.00764208
  0.62852842]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 2.072549
0.9-VaR bound for 1 demonstrations: 2.534698
0.95-VaR bound for 1 demonstrations: 2.734964
0.99-VaR bound for 1 demonstrations: 64.991209
True expected value difference for MAP policy: 0.007303
Evaluating threshold 0.1 with avar bound: [2.734964074525317]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.734964074525317]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.734964074525317]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.734964074525317]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.734964074525317]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.734964074525317]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.734964074525317]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.734964074525317]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.734964074525317]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 20
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.219
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.14670459  0.14094014  0.01444636 -0.46619953  0.16666538  0.35229247
  0.76757775]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.315463
0.9-VaR bound for 2 demonstrations: 1.574913
0.95-VaR bound for 2 demonstrations: 2.810014
0.99-VaR bound for 2 demonstrations: 12.463069
True expected value difference for MAP policy: -0.009905
Evaluating threshold 0.1 with avar bound: [2.8100138472837632]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.8100138472837632]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.8100138472837632]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.8100138472837632]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.8100138472837632]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.8100138472837632]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.8100138472837632]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.8100138472837632]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.8100138472837632]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.223
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.01007915  0.474599   -0.30477851 -0.38930576  0.2675519   0.19027906
  0.64993472]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.002977
0.9-VaR bound for 3 demonstrations: 0.008500
0.95-VaR bound for 3 demonstrations: 0.165384
0.99-VaR bound for 3 demonstrations: 1.422361
True expected value difference for MAP policy: -0.007980
Evaluating threshold 0.1 with avar bound: [0.1653843998363141]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.1653843998363141]
Threshold 0.2 SUFFICIENT with avar bound: 0.1653843998363141
Evaluating threshold 0.3 with avar bound: [0.1653843998363141]
Threshold 0.3 SUFFICIENT with avar bound: 0.1653843998363141
Evaluating threshold 0.4 with avar bound: [0.1653843998363141]
Threshold 0.4 SUFFICIENT with avar bound: 0.1653843998363141
Evaluating threshold 0.5 with avar bound: [0.1653843998363141]
Threshold 0.5 SUFFICIENT with avar bound: 0.1653843998363141
Evaluating threshold 0.6 with avar bound: [0.1653843998363141]
Threshold 0.6 SUFFICIENT with avar bound: 0.1653843998363141
Evaluating threshold 0.7 with avar bound: [0.1653843998363141]
Threshold 0.7 SUFFICIENT with avar bound: 0.1653843998363141
Evaluating threshold 0.8 with avar bound: [0.1653843998363141]
Threshold 0.8 SUFFICIENT with avar bound: 0.1653843998363141
Evaluating threshold 0.9 with avar bound: [0.1653843998363141]
Threshold 0.9 SUFFICIENT with avar bound: 0.1653843998363141

Running BIRL with demonstration 4/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.214
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.27506303 -0.05565448 -0.44538923 -0.38010179  0.24003616  0.11413665
  0.71256539]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.001474
0.9-VaR bound for 4 demonstrations: 0.000785
0.95-VaR bound for 4 demonstrations: 0.008400
0.99-VaR bound for 4 demonstrations: 0.044419
True expected value difference for MAP policy: -0.009138
Evaluating threshold 0.1 with avar bound: [0.008400240614682888]
Threshold 0.1 SUFFICIENT with avar bound: 0.008400240614682888
Evaluating threshold 0.2 with avar bound: [0.008400240614682888]
Threshold 0.2 SUFFICIENT with avar bound: 0.008400240614682888
Evaluating threshold 0.3 with avar bound: [0.008400240614682888]
Threshold 0.3 SUFFICIENT with avar bound: 0.008400240614682888
Evaluating threshold 0.4 with avar bound: [0.008400240614682888]
Threshold 0.4 SUFFICIENT with avar bound: 0.008400240614682888
Evaluating threshold 0.5 with avar bound: [0.008400240614682888]
Threshold 0.5 SUFFICIENT with avar bound: 0.008400240614682888
Evaluating threshold 0.6 with avar bound: [0.008400240614682888]
Threshold 0.6 SUFFICIENT with avar bound: 0.008400240614682888
Evaluating threshold 0.7 with avar bound: [0.008400240614682888]
Threshold 0.7 SUFFICIENT with avar bound: 0.008400240614682888
Evaluating threshold 0.8 with avar bound: [0.008400240614682888]
Threshold 0.8 SUFFICIENT with avar bound: 0.008400240614682888
Evaluating threshold 0.9 with avar bound: [0.008400240614682888]
Threshold 0.9 SUFFICIENT with avar bound: 0.008400240614682888

Running BIRL with demonstration 5/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.22
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.37395689  0.21589938  0.11109442 -0.67186893  0.05884887 -0.18958765
  0.55712405]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.001612
0.9-VaR bound for 5 demonstrations: 0.000088
0.95-VaR bound for 5 demonstrations: 0.003570
0.99-VaR bound for 5 demonstrations: 0.035804
True expected value difference for MAP policy: -0.005178
Evaluating threshold 0.1 with avar bound: [0.00356985338179411]
Threshold 0.1 SUFFICIENT with avar bound: 0.00356985338179411
Evaluating threshold 0.2 with avar bound: [0.00356985338179411]
Threshold 0.2 SUFFICIENT with avar bound: 0.00356985338179411
Evaluating threshold 0.3 with avar bound: [0.00356985338179411]
Threshold 0.3 SUFFICIENT with avar bound: 0.00356985338179411
Evaluating threshold 0.4 with avar bound: [0.00356985338179411]
Threshold 0.4 SUFFICIENT with avar bound: 0.00356985338179411
Evaluating threshold 0.5 with avar bound: [0.00356985338179411]
Threshold 0.5 SUFFICIENT with avar bound: 0.00356985338179411
Evaluating threshold 0.6 with avar bound: [0.00356985338179411]
Threshold 0.6 SUFFICIENT with avar bound: 0.00356985338179411
Evaluating threshold 0.7 with avar bound: [0.00356985338179411]
Threshold 0.7 SUFFICIENT with avar bound: 0.00356985338179411
Evaluating threshold 0.8 with avar bound: [0.00356985338179411]
Threshold 0.8 SUFFICIENT with avar bound: 0.00356985338179411
Evaluating threshold 0.9 with avar bound: [0.00356985338179411]
Threshold 0.9 SUFFICIENT with avar bound: 0.00356985338179411

Running BIRL with demonstration 6/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.183
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.10967604 -0.21048089  0.32734855 -0.4412079   0.16173342  0.40581668
  0.67156728]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.007317
0.9-VaR bound for 6 demonstrations: -0.006324
0.95-VaR bound for 6 demonstrations: -0.005755
0.99-VaR bound for 6 demonstrations: 0.004926
True expected value difference for MAP policy: -0.008619
Evaluating threshold 0.1 with avar bound: [-0.00575505139055632]
Threshold 0.1 SUFFICIENT with avar bound: -0.00575505139055632
Evaluating threshold 0.2 with avar bound: [-0.00575505139055632]
Threshold 0.2 SUFFICIENT with avar bound: -0.00575505139055632
Evaluating threshold 0.3 with avar bound: [-0.00575505139055632]
Threshold 0.3 SUFFICIENT with avar bound: -0.00575505139055632
Evaluating threshold 0.4 with avar bound: [-0.00575505139055632]
Threshold 0.4 SUFFICIENT with avar bound: -0.00575505139055632
Evaluating threshold 0.5 with avar bound: [-0.00575505139055632]
Threshold 0.5 SUFFICIENT with avar bound: -0.00575505139055632
Evaluating threshold 0.6 with avar bound: [-0.00575505139055632]
Threshold 0.6 SUFFICIENT with avar bound: -0.00575505139055632
Evaluating threshold 0.7 with avar bound: [-0.00575505139055632]
Threshold 0.7 SUFFICIENT with avar bound: -0.00575505139055632
Evaluating threshold 0.8 with avar bound: [-0.00575505139055632]
Threshold 0.8 SUFFICIENT with avar bound: -0.00575505139055632
Evaluating threshold 0.9 with avar bound: [-0.00575505139055632]
Threshold 0.9 SUFFICIENT with avar bound: -0.00575505139055632

Running BIRL with demonstration 7/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.164
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.28757916 -0.21753319  0.17523238 -0.47475813  0.3399849   0.21506947
  0.6723327 ]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.008646
0.9-VaR bound for 7 demonstrations: -0.008554
0.95-VaR bound for 7 demonstrations: -0.007683
0.99-VaR bound for 7 demonstrations: -0.006362
True expected value difference for MAP policy: -0.009939
Evaluating threshold 0.1 with avar bound: [-0.007683135540536559]
Threshold 0.1 SUFFICIENT with avar bound: -0.007683135540536559
Evaluating threshold 0.2 with avar bound: [-0.007683135540536559]
Threshold 0.2 SUFFICIENT with avar bound: -0.007683135540536559
Evaluating threshold 0.3 with avar bound: [-0.007683135540536559]
Threshold 0.3 SUFFICIENT with avar bound: -0.007683135540536559
Evaluating threshold 0.4 with avar bound: [-0.007683135540536559]
Threshold 0.4 SUFFICIENT with avar bound: -0.007683135540536559
Evaluating threshold 0.5 with avar bound: [-0.007683135540536559]
Threshold 0.5 SUFFICIENT with avar bound: -0.007683135540536559
Evaluating threshold 0.6 with avar bound: [-0.007683135540536559]
Threshold 0.6 SUFFICIENT with avar bound: -0.007683135540536559
Evaluating threshold 0.7 with avar bound: [-0.007683135540536559]
Threshold 0.7 SUFFICIENT with avar bound: -0.007683135540536559
Evaluating threshold 0.8 with avar bound: [-0.007683135540536559]
Threshold 0.8 SUFFICIENT with avar bound: -0.007683135540536559
Evaluating threshold 0.9 with avar bound: [-0.007683135540536559]
Threshold 0.9 SUFFICIENT with avar bound: -0.007683135540536559

Running BIRL with demonstration 8/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.181
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34576489 -0.248643    0.17328284 -0.18049362  0.43021614  0.21122377
  0.72547709]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.007998
0.9-VaR bound for 8 demonstrations: -0.007055
0.95-VaR bound for 8 demonstrations: -0.005982
0.99-VaR bound for 8 demonstrations: -0.003596
True expected value difference for MAP policy: -0.010100
Evaluating threshold 0.1 with avar bound: [-0.005981956378525705]
Threshold 0.1 SUFFICIENT with avar bound: -0.005981956378525705
Evaluating threshold 0.2 with avar bound: [-0.005981956378525705]
Threshold 0.2 SUFFICIENT with avar bound: -0.005981956378525705
Evaluating threshold 0.3 with avar bound: [-0.005981956378525705]
Threshold 0.3 SUFFICIENT with avar bound: -0.005981956378525705
Evaluating threshold 0.4 with avar bound: [-0.005981956378525705]
Threshold 0.4 SUFFICIENT with avar bound: -0.005981956378525705
Evaluating threshold 0.5 with avar bound: [-0.005981956378525705]
Threshold 0.5 SUFFICIENT with avar bound: -0.005981956378525705
Evaluating threshold 0.6 with avar bound: [-0.005981956378525705]
Threshold 0.6 SUFFICIENT with avar bound: -0.005981956378525705
Evaluating threshold 0.7 with avar bound: [-0.005981956378525705]
Threshold 0.7 SUFFICIENT with avar bound: -0.005981956378525705
Evaluating threshold 0.8 with avar bound: [-0.005981956378525705]
Threshold 0.8 SUFFICIENT with avar bound: -0.005981956378525705
Evaluating threshold 0.9 with avar bound: [-0.005981956378525705]
Threshold 0.9 SUFFICIENT with avar bound: -0.005981956378525705

Running BIRL with demonstration 9/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.172
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.36932521 -0.32931618  0.25306953 -0.35972835  0.03734795  0.36852178
  0.65153503]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.008017
0.9-VaR bound for 9 demonstrations: -0.007414
0.95-VaR bound for 9 demonstrations: -0.006806
0.99-VaR bound for 9 demonstrations: -0.005575
True expected value difference for MAP policy: -0.009078
Evaluating threshold 0.1 with avar bound: [-0.00680563426647901]
Threshold 0.1 SUFFICIENT with avar bound: -0.00680563426647901
Evaluating threshold 0.2 with avar bound: [-0.00680563426647901]
Threshold 0.2 SUFFICIENT with avar bound: -0.00680563426647901
Evaluating threshold 0.3 with avar bound: [-0.00680563426647901]
Threshold 0.3 SUFFICIENT with avar bound: -0.00680563426647901
Evaluating threshold 0.4 with avar bound: [-0.00680563426647901]
Threshold 0.4 SUFFICIENT with avar bound: -0.00680563426647901
Evaluating threshold 0.5 with avar bound: [-0.00680563426647901]
Threshold 0.5 SUFFICIENT with avar bound: -0.00680563426647901
Evaluating threshold 0.6 with avar bound: [-0.00680563426647901]
Threshold 0.6 SUFFICIENT with avar bound: -0.00680563426647901
Evaluating threshold 0.7 with avar bound: [-0.00680563426647901]
Threshold 0.7 SUFFICIENT with avar bound: -0.00680563426647901
Evaluating threshold 0.8 with avar bound: [-0.00680563426647901]
Threshold 0.8 SUFFICIENT with avar bound: -0.00680563426647901
Evaluating threshold 0.9 with avar bound: [-0.00680563426647901]
Threshold 0.9 SUFFICIENT with avar bound: -0.00680563426647901

Running BIRL with demonstration 10/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.165
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.26773648 -0.32259635  0.14433359 -0.1891392   0.37154693  0.38577346
  0.69337917]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.007511
0.9-VaR bound for 10 demonstrations: -0.007151
0.95-VaR bound for 10 demonstrations: -0.006692
0.99-VaR bound for 10 demonstrations: -0.006058
True expected value difference for MAP policy: -0.009078
Evaluating threshold 0.1 with avar bound: [-0.006691901069883214]
Threshold 0.1 SUFFICIENT with avar bound: -0.006691901069883214
Evaluating threshold 0.2 with avar bound: [-0.006691901069883214]
Threshold 0.2 SUFFICIENT with avar bound: -0.006691901069883214
Evaluating threshold 0.3 with avar bound: [-0.006691901069883214]
Threshold 0.3 SUFFICIENT with avar bound: -0.006691901069883214
Evaluating threshold 0.4 with avar bound: [-0.006691901069883214]
Threshold 0.4 SUFFICIENT with avar bound: -0.006691901069883214
Evaluating threshold 0.5 with avar bound: [-0.006691901069883214]
Threshold 0.5 SUFFICIENT with avar bound: -0.006691901069883214
Evaluating threshold 0.6 with avar bound: [-0.006691901069883214]
Threshold 0.6 SUFFICIENT with avar bound: -0.006691901069883214
Evaluating threshold 0.7 with avar bound: [-0.006691901069883214]
Threshold 0.7 SUFFICIENT with avar bound: -0.006691901069883214
Evaluating threshold 0.8 with avar bound: [-0.006691901069883214]
Threshold 0.8 SUFFICIENT with avar bound: -0.006691901069883214
Evaluating threshold 0.9 with avar bound: [-0.006691901069883214]
Threshold 0.9 SUFFICIENT with avar bound: -0.006691901069883214

Saving results to files...
Results saved successfully.
