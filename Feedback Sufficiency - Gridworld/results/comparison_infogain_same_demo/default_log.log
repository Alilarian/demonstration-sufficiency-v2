Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6242
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.66565254  0.23600169 -0.70796179]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000034

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6122
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.97581919  0.06795926 -0.20774612]
True reward weights: [-0.81171049  0.57756385 -0.08686821]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002847

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6216
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.98715414  0.04858105 -0.15220575]
True reward weights: [-0.81171049  0.57756385 -0.08686821]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000111

Running experiment 2/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6260
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.39634733  0.29242791 -0.87028427]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000027

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99785676  0.02080596 -0.06204029]
True reward weights: [0.31724843 0.84960006 0.42134686]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003205

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.99493778 -0.02927958  0.09613281]
True reward weights: [0.31724843 0.84960006 0.42134686]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.001903

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6252
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.3702342   0.29361876 -0.88131417]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000057

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6184
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.17416277  0.31001848 -0.93464211]
True reward weights: [-0.99423742  0.04270462 -0.09832732]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.005041

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6226
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.99993752  0.00378946 -0.01051689]
True reward weights: [-0.99423742  0.04270462 -0.09832732]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.001114

Running experiment 4/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6054
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.93019376 -0.11582435  0.34831637]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000034

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6098
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.37085238 -0.29374614  0.88101176]
True reward weights: [-0.87945174 -0.16923055  0.44488836]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.004319

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6286
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.3781388  -0.29230273  0.87839067]
True reward weights: [-0.87945174 -0.16923055  0.44488836]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.003765

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6226
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.17638602 -0.31414488  0.93284563]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000033

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.30209779 -0.30391616  0.90353301]
True reward weights: [ 0.85944816 -0.37069874 -0.35203877]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003055

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6066
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.92074111 -0.12055964  0.37108111]
True reward weights: [ 0.85944816 -0.37069874 -0.35203877]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000925

Running experiment 6/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6258
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.93851182 -0.10889352  0.32762442]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000041

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6230
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.63697725  0.24387499 -0.73128994]
True reward weights: [-0.96858853  0.19766135  0.15088488]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003112

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6174
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.99912331  0.01546818 -0.03890177]
True reward weights: [-0.96858853  0.19766135  0.15088488]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000524

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6228
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98776666  0.05195598 -0.14702924]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000058

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.84261533 -0.17093521  0.51066677]
True reward weights: [-0.56501489  0.44600793  0.69414343]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.004802

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6168
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93831011  0.11097636 -0.32750325]
True reward weights: [-0.56501489  0.44600793  0.69414343]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000858

Running experiment 8/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6250
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.19281033  0.30862065 -0.93143839]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000010

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6226
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.84769684  0.16796193 -0.50318869]
True reward weights: [0.05021879 0.90980976 0.41197607]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000864

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6168
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.69694655 -0.22619632  0.68051504]
True reward weights: [0.05021879 0.90980976 0.41197607]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000551

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6234
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.81323204 -0.18451933  0.55191146]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000020

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6258
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.93185733 -0.11674234  0.34353042]
True reward weights: [-0.77108225 -0.63241031 -0.07409024]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001631

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6284
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.2516911  -0.30475932  0.91857136]
True reward weights: [-0.77108225 -0.63241031 -0.07409024]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.002243

Running experiment 10/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6376
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99045075  0.04377162 -0.1307339 ]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000032

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6192
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.14899143  0.31167166 -0.93843611]
True reward weights: [-0.57001786 -0.07862122  0.81786206]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.004412

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6064
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93900754 -0.10635054  0.32703883]
True reward weights: [-0.57001786 -0.07862122  0.81786206]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.002664

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6268
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.94293581 -0.10647841  0.31549074]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000044

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6174
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.27265234 -0.30368407  0.91292754]
True reward weights: [-0.78493563 -0.51330683  0.34697571]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.004358

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6200
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.46377499 -0.27981566  0.84060452]
True reward weights: [-0.78493563 -0.51330683  0.34697571]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.001262

Running experiment 12/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6206
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.88029635  0.15227619 -0.44932204]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000038

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6194
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.94396401 -0.32933927 -0.02162384]
True reward weights: [-0.68374268 -0.19802441 -0.70234057]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003196

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.92855803  0.11884128 -0.3516486 ]
True reward weights: [-0.68374268 -0.19802441 -0.70234057]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000752

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6242
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.89578753 -0.14165952  0.42130427]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000024

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6286
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.42515369  0.28690564 -0.85844597]
True reward weights: [-0.22986308  0.21404359  0.94939365]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002517

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6122
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.29634709  0.30094172 -0.90642842]
True reward weights: [-0.22986308  0.21404359  0.94939365]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000600

Running experiment 14/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6148
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98817196  0.04701686 -0.14596435]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000016

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6262
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.18403108  0.312155   -0.93203638]
True reward weights: [-0.51340957  0.14259791 -0.846213  ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001151

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6184
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.97902336  0.0671761  -0.19235547]
True reward weights: [-0.51340957  0.14259791 -0.846213  ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.003121

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6162
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.93762273 -0.10746352  0.3306285 ]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000054

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6326
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.58860507 -0.25647844  0.76665695]
True reward weights: [0.2098604  0.32407286 0.9224616 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.004255

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6166
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.6479427  -0.24333677  0.72177384]
True reward weights: [0.2098604  0.32407286 0.9224616 ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000127

Running experiment 16/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6218
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.77374769 -0.20102191  0.60075344]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000030

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6242
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.98339768  0.05601464 -0.17260175]
True reward weights: [-0.16903235  0.72986897 -0.66235893]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002713

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6198
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.21605687  0.31003464 -0.92584985]
True reward weights: [-0.16903235  0.72986897 -0.66235893]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000670

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6154
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98376676  0.05909968 -0.16944083]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000028

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6236
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.40698299  0.28712359 -0.86713603]
True reward weights: [0.2125519  0.24385407 0.946233  ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002901

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6192
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.8717375  -0.28053708  0.40171218]
True reward weights: [0.2125519  0.24385407 0.946233  ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000234

Running experiment 18/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6178
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.81975797  0.18354461 -0.54250185]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000024

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6104
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.69654948  0.22737805 -0.68052777]
True reward weights: [ 0.37297526  0.91653922 -0.14437909]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002608

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6212
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.49084819  0.2736548  -0.82715241]
True reward weights: [ 0.37297526  0.91653922 -0.14437909]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.001416

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6316
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.24015569 -0.30630896  0.92114063]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000016

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6216
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.56046149 -0.25917438  0.7865822 ]
True reward weights: [-0.70593171 -0.64393732 -0.29496636]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001854

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6232
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.35646536 -0.29286696  0.88722116]
True reward weights: [-0.70593171 -0.64393732 -0.29496636]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000051

Running experiment 20/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.55646309  0.26324684 -0.78806721]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000011

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.75186113  0.21114879 -0.62459669]
True reward weights: [-0.98151025  0.18175097  0.06003511]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000480

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.6262348  -0.24440702  0.74033451]
True reward weights: [-0.98151025  0.18175097  0.06003511]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.002913

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6170
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.76933766  0.20211844 -0.60602615]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000011

Running PBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6282
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.98328742  0.05760787 -0.17270546]
True reward weights: [-0.80733967 -0.42150955 -0.41295564]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000298

Running PBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6144
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.66797343  0.23826144 -0.70501275]
True reward weights: [-0.80733967 -0.42150955 -0.41295564]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.003072

Running experiment 22/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6218
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.74652803 -0.21016146  0.63129079]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000037

Running PBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6182
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.83810433 -0.17398256  0.51702146]
True reward weights: [ 0.37355169 -0.53981969  0.75435657]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.004348

Running PBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.48196256 -0.27891363  0.8306138 ]
True reward weights: [ 0.37355169 -0.53981969  0.75435657]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.001858

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6294
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.35697243 0.314856   0.87945232]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000012

Running PBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6066
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88100839 -0.15022529  0.44861629]
True reward weights: [-0.20766229  0.66978557  0.71292613]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000141

Running PBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6272
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.73226781 -0.21583018  0.64591113]
True reward weights: [-0.20766229  0.66978557  0.71292613]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.003302

Running experiment 24/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6144
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.250292    0.30340129 -0.91940283]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000041

Running PBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.80602254  0.18965078 -0.56067837]
True reward weights: [-0.69560676  0.30425356 -0.65081565]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003401

Running PBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6174
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.87070615 -0.15284505  0.46744968]
True reward weights: [-0.69560676  0.30425356 -0.65081565]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.001594

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6140
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.53710912  0.26471379 -0.80089974]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000018

Running PBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.98522689 -0.05423689  0.16243871]
True reward weights: [-0.63949202 -0.64421742 -0.41956391]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000840

Running PBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6204
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94791982  0.10148406 -0.30190892]
True reward weights: [-0.63949202 -0.64421742 -0.41956391]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.002630

Running experiment 26/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6216
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.41741631  0.28604743 -0.86251985]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000013

Running PBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.98369039  0.0551149  -0.17121787]
True reward weights: [-0.11286574  0.53936037 -0.83447691]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001750

Running PBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6276
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.61084388  0.2487905  -0.75164688]
True reward weights: [-0.11286574  0.53936037 -0.83447691]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000558

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6244
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.21234358  0.30959715 -0.9268548 ]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000056

Running PBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6152
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99202038  0.04172144 -0.11897429]
True reward weights: [ 0.30304432  0.79004738 -0.53290644]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.005348

Running PBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6284
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.77298177  0.60880775  0.17847216]
True reward weights: [ 0.30304432  0.79004738 -0.53290644]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.002222

Running experiment 28/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6030
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.60285867  0.25454375 -0.75615402]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000015

Running PBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6278
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.83514383  0.17286767 -0.52216047]
True reward weights: [-0.8699241  -0.38919605  0.30291665]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001669

Running PBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6188
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.67321804 -0.2322041   0.70203898]
True reward weights: [-0.8699241  -0.38919605  0.30291665]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000987

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6136
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.09870707 -0.31257092  0.944752  ]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000051

Running PBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6232
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.86452688 -0.15634704  0.47764932]
True reward weights: [ 0.41208302 -0.88654257 -0.21030894]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003089

Running PBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6128
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.46640548 -0.27762679  0.83987457]
True reward weights: [ 0.41208302 -0.88654257 -0.21030894]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000729

Running experiment 30/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.71821358 -0.22022852  0.660052  ]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000014

Running PBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6162
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.44452814 -0.28222267  0.85014416]
True reward weights: [0.20697054 0.13294416 0.96927243]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002647

Running PBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6158
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.04504153 -0.3131784   0.94862561]
True reward weights: [0.20697054 0.13294416 0.96927243]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000298

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6220
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99420882  0.03357572 -0.10208569]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000026

Running PBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6038
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.8218904   0.17827715 -0.54102997]
True reward weights: [-0.97202202 -0.04240265 -0.23103076]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002706

Running PBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6244
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.86608422 -0.15815509  0.47422051]
True reward weights: [-0.97202202 -0.04240265 -0.23103076]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.001797

Running experiment 32/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.9996003   0.00613587 -0.0275968 ]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000049

Running PBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6096
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88249619  0.15093446 -0.44544278]
True reward weights: [-0.97861965  0.11872296 -0.16795366]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.004792

Running PBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.98840342 -0.04620458  0.14465065]
True reward weights: [-0.97861965  0.11872296 -0.16795366]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.001731

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.76197433  0.2071449  -0.61358464]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000029

Running PBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6152
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.49092021  0.27495777 -0.82667743]
True reward weights: [-0.47979194  0.81209309 -0.33212122]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002871

Running PBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6140
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.23242194  0.16225926 -0.95898487]
True reward weights: [-0.47979194  0.81209309 -0.33212122]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000288

Running experiment 34/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6280
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.05648804 -0.31337839  0.94794677]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000039

Running PBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.42012008 -0.28657274  0.86103147]
True reward weights: [-0.44756344  0.27455027  0.85106352]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.004302

Running PBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6188
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.00501825 -0.31764151  0.9481976 ]
True reward weights: [-0.44756344  0.27455027  0.85106352]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000286

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6262
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.81041334 -0.18260295  0.55667439]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000041

Running PBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6150
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.93546689 -0.11020548  0.33579228]
True reward weights: [-0.02926999 -0.78457998 -0.61933636]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003391

Running PBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.61250453 -0.25261435  0.74901549]
True reward weights: [-0.02926999 -0.78457998 -0.61933636]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.001494

Running experiment 36/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6280
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.57408815 -0.25669375  0.77751599]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000043

Running PBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.23877468 -0.30738515  0.92114115]
True reward weights: [-0.36686873  0.1971421   0.90914373]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003954

Running PBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6118
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.6322996  -0.24667364  0.73440406]
True reward weights: [-0.36686873  0.1971421   0.90914373]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000694

Saving results to files...
Results saved successfully.

Running experiment 37/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6246
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.87173998  0.15744886 -0.46398196]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000022

Running PBIRL with 2 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.27236829  0.30229949 -0.91347169]
True reward weights: [-0.20007737  0.86256968  0.46469624]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001363

Running PBIRL with 3 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6172
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.95718944 -0.09234492  0.27433699]
True reward weights: [-0.20007737  0.86256968  0.46469624]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000904

Running experiment 38/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6270
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.52145402  0.2684906  -0.80993734]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000030

Running PBIRL with 2 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6314
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.36805535  0.29530653 -0.88166281]
True reward weights: [-0.25283116  0.9604467  -0.11669849]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003149

Running PBIRL with 3 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6094
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94036497  0.10971165 -0.32198925]
True reward weights: [-0.25283116  0.9604467  -0.11669849]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.001437

Saving results to files...
Results saved successfully.

Running experiment 39/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6180
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.03581309 0.54427526 0.83814191]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000027

Running PBIRL with 2 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6094
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.33783314  0.2978833  -0.89282378]
True reward weights: [-0.19117192  0.30535317  0.93285194]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002097

Running PBIRL with 3 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6158
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.8208225  -0.18247592  0.5412513 ]
True reward weights: [-0.19117192  0.30535317  0.93285194]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000179

Running experiment 40/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6290
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.86131585 -0.16229399  0.48145163]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000017

Running PBIRL with 2 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6234
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.74164624 -0.21254936  0.63622608]
True reward weights: [0.54666945 0.79082017 0.27523804]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001935

Running PBIRL with 3 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6096
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.81674032  0.18526367 -0.54645459]
True reward weights: [0.54666945 0.79082017 0.27523804]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000978

Saving results to files...
Results saved successfully.

Running experiment 41/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6136
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.83503591  0.17520192 -0.52155471]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000048

Running PBIRL with 2 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6198
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.97280174  0.07327139 -0.2197455 ]
True reward weights: [-0.23199216  0.10334845  0.96721184]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003836

Running PBIRL with 3 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6108
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.88131926  0.14889339 -0.44844968]
True reward weights: [-0.23199216  0.10334845  0.96721184]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000974

Running experiment 42/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6344
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.42850977  0.28846594 -0.85625158]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000004

Running PBIRL with 2 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6216
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.41727517  0.38445762 -0.82345235]
True reward weights: [-0.89514409  0.25990856 -0.36216653]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000707

Running PBIRL with 3 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6182
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.75459092 -0.20588446  0.62306029]
True reward weights: [-0.89514409  0.25990856 -0.36216653]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.002859

Saving results to files...
Results saved successfully.

Running experiment 43/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.9222486  -0.11986673  0.36754521]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000030

Running PBIRL with 2 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6174
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.4661631  -0.28162438  0.83867733]
True reward weights: [ 0.56281962 -0.74358802  0.36098606]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003267

Running PBIRL with 3 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6188
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89802007 -0.14055576  0.41689812]
True reward weights: [ 0.56281962 -0.74358802  0.36098606]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.001819

Running experiment 44/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6328
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.08442636 -0.31798802  0.94432823]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000027

Running PBIRL with 2 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6258
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.66538734 -0.23314143  0.70915778]
True reward weights: [-0.39247681 -0.55948759  0.73002438]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002760

Running PBIRL with 3 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6354
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.9371561  -0.10804097  0.33176135]
True reward weights: [-0.39247681 -0.55948759  0.73002438]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000566

Saving results to files...
Results saved successfully.

Running experiment 45/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6228
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.39224233 -0.29193863  0.87230602]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000025

Running PBIRL with 2 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6142
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.31520961 -0.30284689  0.8994035 ]
True reward weights: [-0.68200004 -0.73023355 -0.04043399]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003280

Running PBIRL with 3 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6028
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.8680513  -0.15597189  0.47133821]
True reward weights: [-0.68200004 -0.73023355 -0.04043399]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000130

Running experiment 46/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6176
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.81561364 -0.18272736  0.54898552]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000017

Running PBIRL with 2 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6068
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.3131639  -0.29958641  0.90120827]
True reward weights: [-0.23842    -0.96339024 -0.12261792]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001750

Running PBIRL with 3 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6342
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93585333 -0.10873256  0.33519513]
True reward weights: [-0.23842    -0.96339024 -0.12261792]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000683

Saving results to files...
Results saved successfully.

Running experiment 47/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6174
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.9257673  -0.12163396  0.35799454]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000017

Running PBIRL with 2 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6218
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.95641672  0.09502799 -0.27611001]
True reward weights: [0.33808639 0.91063162 0.23758713]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000944

Running PBIRL with 3 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6140
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83372781  0.51297828  0.20433118]
True reward weights: [0.33808639 0.91063162 0.23758713]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.001707

Running experiment 48/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6176
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.96904747  0.07881133 -0.23395677]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000014

Running PBIRL with 2 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6110
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.10899252  0.31442077 -0.94300594]
True reward weights: [-0.36559004  0.3943498   0.84310863]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002062

Running PBIRL with 3 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6226
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.95623024  0.09116094 -0.27805291]
True reward weights: [-0.36559004  0.3943498   0.84310863]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.003218

Saving results to files...
Results saved successfully.

Running experiment 49/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6132
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.89056024 -0.14242387  0.43199294]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000015

Running PBIRL with 2 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.79535111 -0.19035985  0.57548218]
True reward weights: [-0.76545664 -0.46645762  0.44327579]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001748

Running PBIRL with 3 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6154
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.64574733  0.24103204 -0.72450945]
True reward weights: [-0.76545664 -0.46645762  0.44327579]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000520

Running experiment 50/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6266
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.69181295 -0.22814707  0.68508668]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000019

Running PBIRL with 2 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6172
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99998139 -0.00318249  0.00520454]
True reward weights: [-0.84811568 -0.07543789  0.52441292]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001808

Running PBIRL with 3 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93483773 -0.10952715  0.33776059]
True reward weights: [-0.84811568 -0.07543789  0.52441292]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000762

Saving results to files...
Results saved successfully.
