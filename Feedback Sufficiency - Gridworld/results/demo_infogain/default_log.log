Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2900
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.84631891 -0.2023471   0.49274736]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.007446

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.3040
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.20420241  0.44182669  0.87355054]
True reward weights: [-0.68660059 -0.15967258  0.70928436]
MAP Policy for current environment:
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.4728
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.09556431  0.05191295  0.99406866]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000005

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.4750
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.02609878  0.30420526  0.95224892]
True reward weights: [-0.26051131 -0.95221697  0.15942613]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001923

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2972
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.87975737 -0.02721103  0.47464358]
True reward weights: [-0.26051131 -0.95221697  0.15942613]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.166555

Running experiment 2/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.4940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.7081626  0.10630762 0.69800031]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000003

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2944
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92195632 -0.38600474  0.03157334]
True reward weights: [0.03766305 0.16257302 0.98597744]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.014520

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2968
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.77527543  0.00180211  0.63162074]
True reward weights: [0.03766305 0.16257302 0.98597744]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.140578

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [(0, 1), (2, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2974
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.89837999 -0.11479331  0.42395269]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.002943

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.76772949 -0.10199488  0.63260452]
True reward weights: [-0.07957521  0.54332835  0.83574044]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.028034

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2942
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.84900168  0.10539847  0.51777148]
True reward weights: [-0.07957521  0.54332835  0.83574044]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.005734

Running experiment 4/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4824
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.37133616 -0.82915737  0.41786064]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000003

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.4837526  -0.76140911  0.43155485]
True reward weights: [ 0.50073236 -0.72822004  0.46793448]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000605

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2978
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.42531679  0.39759113  0.81303562]
True reward weights: [ 0.50073236 -0.72822004  0.46793448]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.167135

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.4802
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.20020814 0.38679111 0.90017184]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000008

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.4936
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.44187297 -0.36751189  0.81834179]
True reward weights: [-0.11675117 -0.972031   -0.20377658]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001503

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.3008
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.45258232  0.36271617  0.81462029]
True reward weights: [-0.11675117 -0.972031   -0.20377658]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.155927

Running experiment 6/50...
Shuffled Demos: [(0, 1), (2, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2928
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.81233223 -0.07824687  0.57792195]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.003621

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2946
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-8.52864912e-01 -4.60155105e-04  5.22131430e-01]
True reward weights: [-0.87859588 -0.37843154  0.29130543]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.033952

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2990
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.91420096 -0.39382054  0.09561376]
True reward weights: [-0.87859588 -0.37843154  0.29130543]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.009770

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2950
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.6669219   0.05723272  0.74292637]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.007112

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92066692 -0.39005047 -0.01526609]
True reward weights: [-0.88184794 -0.42078919  0.21279256]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.047346

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2956
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.33019427  0.43764268  0.83632567]
True reward weights: [-0.88184794 -0.42078919  0.21279256]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.014545

Running experiment 8/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.4980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.33745659 -0.9272853  -0.16206488]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000007

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.4842
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.74833305 -0.65494749  0.10507819]
True reward weights: [-0.34912119 -0.86536564  0.35952288]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001019

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.3032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.45654834  0.38125796  0.80386938]
True reward weights: [-0.34912119 -0.86536564  0.35952288]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.177122

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.4894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.22458718 -0.82658585  0.51605856]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000010

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.4766
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.16381004 0.3753808  0.9122804 ]
True reward weights: [ 0.47763442 -0.50797167  0.71681946]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002542

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.2962
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.88672562 -0.02977573  0.4613362 ]
True reward weights: [ 0.47763442 -0.50797167  0.71681946]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.190842

Running experiment 10/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.4814
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.07800502 0.46038509 0.88428547]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000012

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.4762
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.14789481 0.09496852 0.98443289]
True reward weights: [ 0.2673841  -0.80300132  0.53262992]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002075

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.42799723  0.19208066  0.88313271]
True reward weights: [ 0.2673841  -0.80300132  0.53262992]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.164248

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.4798
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.24872321 -0.96038331 -0.12570065]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000013

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.3020
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92215839 -0.29049364  0.25541603]
True reward weights: [-0.4191512  -0.37399804  0.82730752]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004680

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2972
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.57345791  0.24219398  0.78261619]
True reward weights: [-0.4191512  -0.37399804  0.82730752]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.151800

Running experiment 12/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.4828
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.17986233 -0.52848981  0.82966744]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000008

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2890
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.70538087  0.07976112  0.70432663]
True reward weights: [ 0.13475555 -0.95164621  0.27606237]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.003049

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2978
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.42241334  0.27798359  0.86272365]
True reward weights: [ 0.13475555 -0.95164621  0.27606237]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.137278

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.4856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.88968305 -0.26299456  0.37322639]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000008

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.4748
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.569891   -0.52534599  0.63185112]
True reward weights: [0.24771375 0.46762763 0.84850592]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000088

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.2946
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.62195173 -0.04016401  0.78202487]
True reward weights: [0.24771375 0.46762763 0.84850592]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.170031

Running experiment 14/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2958
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.68043065  0.08117093  0.7283031 ]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.003636

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.70916631 -0.02843044  0.70446778]
True reward weights: [-0.65764634 -0.24180739  0.71346372]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.036990

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.3038
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.84077705  0.06457533  0.5375165 ]
True reward weights: [-0.65764634 -0.24180739  0.71346372]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023448

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.4820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.71924289 -0.44139157  0.53652879]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000012

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.4778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.12911874 -0.50558214  0.85306216]
True reward weights: [ 0.17002044 -0.55616307  0.81349597]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001062

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.2976
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.9533043  -0.27200893  0.13123286]
True reward weights: [ 0.17002044 -0.55616307  0.81349597]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.165782

Running experiment 16/50...
Shuffled Demos: [(0, 1), (2, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.3024
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.66661736 -0.05443656  0.74340969]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.001678

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2964
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.91091261 -0.21301937  0.35335671]
True reward weights: [-0.82622962 -0.20861007  0.52328429]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.019570

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2910
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.54407794  0.37124674  0.75243275]
True reward weights: [-0.82622962 -0.20861007  0.52328429]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.004850

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.4886
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.35015762 -0.23278501  0.90730413]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000005

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.2976
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.70798725 -0.00819532  0.70617766]
True reward weights: [-0.83990942 -0.28012138  0.46484855]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.030710

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.74650133 -0.14420069  0.64957057]
True reward weights: [-0.83990942 -0.28012138  0.46484855]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.123736

Running experiment 18/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.2906
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.93419521 -0.35463025  0.03894468]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.006363

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.2948
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.42415898  0.33687187  0.8405989 ]
True reward weights: [-0.85029128 -0.48488017 -0.20468503]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.048466

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.2940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.53264027  0.26914212  0.80240692]
True reward weights: [-0.85029128 -0.48488017 -0.20468503]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.015404

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.3080
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.53761474  0.20521655  0.81783651]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.003916

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.2980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.8279168  -0.04882162  0.55872195]
True reward weights: [-0.49983377  0.25339022  0.82822678]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.035690

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.2954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.58317459  0.35960174  0.72841882]
True reward weights: [-0.49983377  0.25339022  0.82822678]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.014881

Running experiment 20/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.4834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.06209007 -0.23606509  0.96975156]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000010

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2910
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.72958296 -0.08559592  0.67851459]
True reward weights: [-0.05207344 -0.99857047 -0.0120568 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.014160

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2930
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.66357669  0.01199468  0.74801211]
True reward weights: [-0.05207344 -0.99857047 -0.0120568 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.135182

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.4904
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.13356844 -0.95454812  0.26645328]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000016

Running PBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.3010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.81212947  0.12204563  0.5705704 ]
True reward weights: [-0.93874629 -0.31083484  0.14878541]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.009328

Running PBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.2916
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.79273287  0.1429902   0.59256088]
True reward weights: [-0.93874629 -0.31083484  0.14878541]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.149141

Running experiment 22/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.4836
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.61925726 -0.70724191 -0.34107084]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000004

Running PBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2964
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92779454 -0.1293143   0.34996445]
True reward weights: [ 0.65736506 -0.15593317  0.73726252]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.010350

Running PBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2884
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.48145355  0.07978101  0.87283301]
True reward weights: [ 0.65736506 -0.15593317  0.73726252]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.142339

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.4784
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.35566181 -0.47877484  0.80267012]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000010

Running PBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.4838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.26452039 -0.72269008  0.63855149]
True reward weights: [ 0.32191816 -0.85446693  0.40774374]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000012

Running PBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.3036
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.84855511  0.10111297  0.51935574]
True reward weights: [ 0.32191816 -0.85446693  0.40774374]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.167879

Running experiment 24/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.4718
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.85324265 -0.49346083  0.16874062]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000004

Running PBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.3020
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.85592385 -0.29793701  0.42264395]
True reward weights: [-0.18680223 -0.8586472   0.47731531]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004551

Running PBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.2980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93631949 -0.03285253  0.3496091 ]
True reward weights: [-0.18680223 -0.8586472   0.47731531]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.143792

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.4774
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.80487522 -0.50091261  0.31821761]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000004

Running PBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.3026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89132244 -0.14222997  0.43048222]
True reward weights: [-0.86516724 -0.1932446   0.46275499]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002416

Running PBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.2948
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.57306109  0.10526488  0.81272399]
True reward weights: [-0.86516724 -0.1932446   0.46275499]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.136764

Running experiment 26/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.4976
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.62415509 -0.4680193   0.62561039]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000006

Running PBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.4854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.21787122 -0.96717086 -0.13081534]
True reward weights: [0.6606246  0.18591373 0.72733158]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000739

Running PBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.3058
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.39945377  0.27867275  0.87337173]
True reward weights: [0.6606246  0.18591373 0.72733158]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.149577

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.4864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.11365353 -0.80926676  0.57634208]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000012

Running PBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.4872
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.21506733 -0.6961319   0.68494264]
True reward weights: [-0.5135777  -0.79442775  0.32422598]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001397

Running PBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.3040
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.91332706 -0.02163294  0.40665182]
True reward weights: [-0.5135777  -0.79442775  0.32422598]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.173282

Running experiment 28/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.4896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.14362224 -0.96788386  0.20633344]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000004

Running PBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.4934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.32353781 -0.01345788  0.94611953]
True reward weights: [-0.215271   -0.76528761  0.60662449]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000729

Running PBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.3026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.52231771  0.25502417  0.81372408]
True reward weights: [-0.215271   -0.76528761  0.60662449]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.157564

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.4748
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.37922486 -0.90855575  0.17525684]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000004

Running PBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.4894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.33077986 -0.94307755 -0.03448806]
True reward weights: [-0.38029986 -0.92466132 -0.01932518]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000696

Running PBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.3008
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.48900439  0.2021804   0.84852683]
True reward weights: [-0.38029986 -0.92466132 -0.01932518]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.177587

Running experiment 30/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.4742
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.66280549 -0.08319158  0.74415592]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000006

Running PBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.4832
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.35724857  0.18599019  0.91530383]
True reward weights: [-0.61871515 -0.73080316  0.28830244]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000809

Running PBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.2938
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.78742438 -0.10562455  0.60729425]
True reward weights: [-0.61871515 -0.73080316  0.28830244]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.174883

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.4838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.42436367 -0.86103408  0.28024237]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000002

Running PBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.2980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.39778297  0.26465709  0.87847899]
True reward weights: [-0.02226277  0.50565341  0.86244941]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003884

Running PBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.3018
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.54679288  0.2481713   0.79964277]
True reward weights: [-0.02226277  0.50565341  0.86244941]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.132420

Running experiment 32/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.4808
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.00661    -0.99925578  0.03800255]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000003

Running PBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.4820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.3525375  -0.68099413  0.64184446]
True reward weights: [0.19130935 0.46643825 0.86361802]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001185

Running PBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.2950
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.96395851 -0.17250334  0.20255022]
True reward weights: [0.19130935 0.46643825 0.86361802]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.157631

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.4778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.23909823 -0.00827995  0.97096008]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000013

Running PBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.4864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.56374053 -0.61470954  0.55166003]
True reward weights: [ 0.16518687 -0.98264416  0.08440226]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002991

Running PBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.2966
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.42674678  0.21909952  0.87742953]
True reward weights: [ 0.16518687 -0.98264416  0.08440226]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.171524

Running experiment 34/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2902
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.21855657  0.37637147  0.9003208 ]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.004502

Running PBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2916
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.80760735 -0.15801659  0.5681559 ]
True reward weights: [-0.7858951  -0.59691592 -0.16143195]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.033871

Running PBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.90037017 -0.07549391  0.42852565]
True reward weights: [-0.7858951  -0.59691592 -0.16143195]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.004091

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.4818
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.77311279  0.21548131  0.59654373]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000003

Running PBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.4730
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.36942552 -0.77326522  0.51535007]
True reward weights: [-0.3845391  -0.90483788  0.18275145]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000196

Running PBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.3006
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.60830871  0.29570591  0.73655857]
True reward weights: [-0.3845391  -0.90483788  0.18275145]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.158467

Running experiment 36/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.2972
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.77388105  0.23392123  0.58854819]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.002506

Running PBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.2918
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.64752763  0.00622208  0.76201657]
True reward weights: [-0.88715808 -0.33554009 -0.3168018 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.026111

Running PBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.3006
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.74021061  0.09255033  0.66597499]
True reward weights: [-0.88715808 -0.33554009 -0.3168018 ]
MAP Policy for current environment:
