Config file loaded successfully.
Running experiment with 20 worlds and 10 demonstrations per world.
Feature weights for environment: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Feature weights for environment: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Feature weights for environment: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Feature weights for environment: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Feature weights for environment: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Feature weights for environment: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Feature weights for environment: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Feature weights for environment: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Feature weights for environment: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Feature weights for environment: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Feature weights for environment: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Feature weights for environment: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Feature weights for environment: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Feature weights for environment: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Feature weights for environment: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Feature weights for environment: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Feature weights for environment: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Feature weights for environment: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Feature weights for environment: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Feature weights for environment: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Initialized 20 GridWorld environments.
Generated optimal policies for all environments.
Shuffled demonstration order: [16, 12, 9, 19, 18, 6, 5, 10, 15, 21, 11, 17, 1, 14, 22, 13, 2, 23, 4, 24, 7, 8, 0, 3, 20]

Running world 1/20

Running BIRL with demonstration 1/10 in world 1
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.386
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.07112989 -0.39454978  0.27323888  0.38768392  0.19831108 -0.30767051
  0.6930543 ]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.821448
0.95-VaR bound for 1 demonstrations: 3.971145
0.99-VaR bound for 1 demonstrations: 7.825100
True expected value difference for MAP policy: -0.007981
Evaluating threshold 0.1 with avar bound: [3.9711448374993497]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.9711448374993497]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.9711448374993497]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.9711448374993497]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.9711448374993497]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.9711448374993497]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.9711448374993497]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.9711448374993497]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.9711448374993497]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 1
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.233
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.00790286 -0.67806103 -0.04415556 -0.08344164 -0.53757189  0.25963854
  0.41816606]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 0.009497
0.95-VaR bound for 2 demonstrations: 0.038871
0.99-VaR bound for 2 demonstrations: 0.072335
True expected value difference for MAP policy: 0.001114
Evaluating threshold 0.1 with avar bound: [0.03887052178909441]
Threshold 0.1 SUFFICIENT with avar bound: 0.03887052178909441
Evaluating threshold 0.2 with avar bound: [0.03887052178909441]
Threshold 0.2 SUFFICIENT with avar bound: 0.03887052178909441
Evaluating threshold 0.3 with avar bound: [0.03887052178909441]
Threshold 0.3 SUFFICIENT with avar bound: 0.03887052178909441
Evaluating threshold 0.4 with avar bound: [0.03887052178909441]
Threshold 0.4 SUFFICIENT with avar bound: 0.03887052178909441
Evaluating threshold 0.5 with avar bound: [0.03887052178909441]
Threshold 0.5 SUFFICIENT with avar bound: 0.03887052178909441
Evaluating threshold 0.6 with avar bound: [0.03887052178909441]
Threshold 0.6 SUFFICIENT with avar bound: 0.03887052178909441
Evaluating threshold 0.7 with avar bound: [0.03887052178909441]
Threshold 0.7 SUFFICIENT with avar bound: 0.03887052178909441
Evaluating threshold 0.8 with avar bound: [0.03887052178909441]
Threshold 0.8 SUFFICIENT with avar bound: 0.03887052178909441
Evaluating threshold 0.9 with avar bound: [0.03887052178909441]
Threshold 0.9 SUFFICIENT with avar bound: 0.03887052178909441

Running BIRL with demonstration 3/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.225
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.06441959 -0.61376175  0.120033   -0.07161967 -0.3856871   0.00236191
  0.67145306]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.009147
0.95-VaR bound for 3 demonstrations: 0.009147
0.99-VaR bound for 3 demonstrations: 0.013402
True expected value difference for MAP policy: -0.002914
Evaluating threshold 0.1 with avar bound: [0.009146751182217134]
Threshold 0.1 SUFFICIENT with avar bound: 0.009146751182217134
Evaluating threshold 0.2 with avar bound: [0.009146751182217134]
Threshold 0.2 SUFFICIENT with avar bound: 0.009146751182217134
Evaluating threshold 0.3 with avar bound: [0.009146751182217134]
Threshold 0.3 SUFFICIENT with avar bound: 0.009146751182217134
Evaluating threshold 0.4 with avar bound: [0.009146751182217134]
Threshold 0.4 SUFFICIENT with avar bound: 0.009146751182217134
Evaluating threshold 0.5 with avar bound: [0.009146751182217134]
Threshold 0.5 SUFFICIENT with avar bound: 0.009146751182217134
Evaluating threshold 0.6 with avar bound: [0.009146751182217134]
Threshold 0.6 SUFFICIENT with avar bound: 0.009146751182217134
Evaluating threshold 0.7 with avar bound: [0.009146751182217134]
Threshold 0.7 SUFFICIENT with avar bound: 0.009146751182217134
Evaluating threshold 0.8 with avar bound: [0.009146751182217134]
Threshold 0.8 SUFFICIENT with avar bound: 0.009146751182217134
Evaluating threshold 0.9 with avar bound: [0.009146751182217134]
Threshold 0.9 SUFFICIENT with avar bound: 0.009146751182217134

Running BIRL with demonstration 4/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.23
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.33891831 -0.40526667  0.44009888 -0.10126048 -0.20774668  0.18633075
  0.66262717]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.006179
0.95-VaR bound for 4 demonstrations: 0.007642
0.99-VaR bound for 4 demonstrations: 0.013011
True expected value difference for MAP policy: -0.002914
Evaluating threshold 0.1 with avar bound: [0.007642177629708097]
Threshold 0.1 SUFFICIENT with avar bound: 0.007642177629708097
Evaluating threshold 0.2 with avar bound: [0.007642177629708097]
Threshold 0.2 SUFFICIENT with avar bound: 0.007642177629708097
Evaluating threshold 0.3 with avar bound: [0.007642177629708097]
Threshold 0.3 SUFFICIENT with avar bound: 0.007642177629708097
Evaluating threshold 0.4 with avar bound: [0.007642177629708097]
Threshold 0.4 SUFFICIENT with avar bound: 0.007642177629708097
Evaluating threshold 0.5 with avar bound: [0.007642177629708097]
Threshold 0.5 SUFFICIENT with avar bound: 0.007642177629708097
Evaluating threshold 0.6 with avar bound: [0.007642177629708097]
Threshold 0.6 SUFFICIENT with avar bound: 0.007642177629708097
Evaluating threshold 0.7 with avar bound: [0.007642177629708097]
Threshold 0.7 SUFFICIENT with avar bound: 0.007642177629708097
Evaluating threshold 0.8 with avar bound: [0.007642177629708097]
Threshold 0.8 SUFFICIENT with avar bound: 0.007642177629708097
Evaluating threshold 0.9 with avar bound: [0.007642177629708097]
Threshold 0.9 SUFFICIENT with avar bound: 0.007642177629708097

Running BIRL with demonstration 5/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.17
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.12541574 -0.50952905  0.21919288 -0.26715449 -0.03639906  0.31655763
  0.70971852]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.003857
0.95-VaR bound for 5 demonstrations: 0.001310
0.99-VaR bound for 5 demonstrations: 0.005815
True expected value difference for MAP policy: -0.008766
Evaluating threshold 0.1 with avar bound: [0.0013095681894853724]
Threshold 0.1 SUFFICIENT with avar bound: 0.0013095681894853724
Evaluating threshold 0.2 with avar bound: [0.0013095681894853724]
Threshold 0.2 SUFFICIENT with avar bound: 0.0013095681894853724
Evaluating threshold 0.3 with avar bound: [0.0013095681894853724]
Threshold 0.3 SUFFICIENT with avar bound: 0.0013095681894853724
Evaluating threshold 0.4 with avar bound: [0.0013095681894853724]
Threshold 0.4 SUFFICIENT with avar bound: 0.0013095681894853724
Evaluating threshold 0.5 with avar bound: [0.0013095681894853724]
Threshold 0.5 SUFFICIENT with avar bound: 0.0013095681894853724
Evaluating threshold 0.6 with avar bound: [0.0013095681894853724]
Threshold 0.6 SUFFICIENT with avar bound: 0.0013095681894853724
Evaluating threshold 0.7 with avar bound: [0.0013095681894853724]
Threshold 0.7 SUFFICIENT with avar bound: 0.0013095681894853724
Evaluating threshold 0.8 with avar bound: [0.0013095681894853724]
Threshold 0.8 SUFFICIENT with avar bound: 0.0013095681894853724
Evaluating threshold 0.9 with avar bound: [0.0013095681894853724]
Threshold 0.9 SUFFICIENT with avar bound: 0.0013095681894853724

Running BIRL with demonstration 6/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.164
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.34683472 -0.64722503 -0.33983976  0.09656985 -0.23543299  0.22634943
  0.47887983]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.006221
0.95-VaR bound for 6 demonstrations: -0.004055
0.99-VaR bound for 6 demonstrations: 0.001982
True expected value difference for MAP policy: -0.008879
Evaluating threshold 0.1 with avar bound: [-0.004054612702255181]
Threshold 0.1 SUFFICIENT with avar bound: -0.004054612702255181
Evaluating threshold 0.2 with avar bound: [-0.004054612702255181]
Threshold 0.2 SUFFICIENT with avar bound: -0.004054612702255181
Evaluating threshold 0.3 with avar bound: [-0.004054612702255181]
Threshold 0.3 SUFFICIENT with avar bound: -0.004054612702255181
Evaluating threshold 0.4 with avar bound: [-0.004054612702255181]
Threshold 0.4 SUFFICIENT with avar bound: -0.004054612702255181
Evaluating threshold 0.5 with avar bound: [-0.004054612702255181]
Threshold 0.5 SUFFICIENT with avar bound: -0.004054612702255181
Evaluating threshold 0.6 with avar bound: [-0.004054612702255181]
Threshold 0.6 SUFFICIENT with avar bound: -0.004054612702255181
Evaluating threshold 0.7 with avar bound: [-0.004054612702255181]
Threshold 0.7 SUFFICIENT with avar bound: -0.004054612702255181
Evaluating threshold 0.8 with avar bound: [-0.004054612702255181]
Threshold 0.8 SUFFICIENT with avar bound: -0.004054612702255181
Evaluating threshold 0.9 with avar bound: [-0.004054612702255181]
Threshold 0.9 SUFFICIENT with avar bound: -0.004054612702255181

Running BIRL with demonstration 7/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.167
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.04295088 -0.48005044 -0.26000585  0.21780172 -0.07802057  0.35083138
  0.72353044]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.008233
0.95-VaR bound for 7 demonstrations: -0.007509
0.99-VaR bound for 7 demonstrations: -0.005615
True expected value difference for MAP policy: -0.008846
Evaluating threshold 0.1 with avar bound: [-0.0075093807939186005]
Threshold 0.1 SUFFICIENT with avar bound: -0.0075093807939186005
Evaluating threshold 0.2 with avar bound: [-0.0075093807939186005]
Threshold 0.2 SUFFICIENT with avar bound: -0.0075093807939186005
Evaluating threshold 0.3 with avar bound: [-0.0075093807939186005]
Threshold 0.3 SUFFICIENT with avar bound: -0.0075093807939186005
Evaluating threshold 0.4 with avar bound: [-0.0075093807939186005]
Threshold 0.4 SUFFICIENT with avar bound: -0.0075093807939186005
Evaluating threshold 0.5 with avar bound: [-0.0075093807939186005]
Threshold 0.5 SUFFICIENT with avar bound: -0.0075093807939186005
Evaluating threshold 0.6 with avar bound: [-0.0075093807939186005]
Threshold 0.6 SUFFICIENT with avar bound: -0.0075093807939186005
Evaluating threshold 0.7 with avar bound: [-0.0075093807939186005]
Threshold 0.7 SUFFICIENT with avar bound: -0.0075093807939186005
Evaluating threshold 0.8 with avar bound: [-0.0075093807939186005]
Threshold 0.8 SUFFICIENT with avar bound: -0.0075093807939186005
Evaluating threshold 0.9 with avar bound: [-0.0075093807939186005]
Threshold 0.9 SUFFICIENT with avar bound: -0.0075093807939186005

Running BIRL with demonstration 8/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.096
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.17460857 -0.84546414  0.08845491  0.03841444  0.00314645  0.0783441
  0.48913658]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.009138
0.95-VaR bound for 8 demonstrations: -0.008057
0.99-VaR bound for 8 demonstrations: -0.006482
True expected value difference for MAP policy: -0.008714
Evaluating threshold 0.1 with avar bound: [-0.008056664927065402]
Threshold 0.1 SUFFICIENT with avar bound: -0.008056664927065402
Evaluating threshold 0.2 with avar bound: [-0.008056664927065402]
Threshold 0.2 SUFFICIENT with avar bound: -0.008056664927065402
Evaluating threshold 0.3 with avar bound: [-0.008056664927065402]
Threshold 0.3 SUFFICIENT with avar bound: -0.008056664927065402
Evaluating threshold 0.4 with avar bound: [-0.008056664927065402]
Threshold 0.4 SUFFICIENT with avar bound: -0.008056664927065402
Evaluating threshold 0.5 with avar bound: [-0.008056664927065402]
Threshold 0.5 SUFFICIENT with avar bound: -0.008056664927065402
Evaluating threshold 0.6 with avar bound: [-0.008056664927065402]
Threshold 0.6 SUFFICIENT with avar bound: -0.008056664927065402
Evaluating threshold 0.7 with avar bound: [-0.008056664927065402]
Threshold 0.7 SUFFICIENT with avar bound: -0.008056664927065402
Evaluating threshold 0.8 with avar bound: [-0.008056664927065402]
Threshold 0.8 SUFFICIENT with avar bound: -0.008056664927065402
Evaluating threshold 0.9 with avar bound: [-0.008056664927065402]
Threshold 0.9 SUFFICIENT with avar bound: -0.008056664927065402

Running BIRL with demonstration 9/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.111
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62178994 -0.46684408 -0.23189843 -0.40125529  0.11803482  0.23207224
  0.33594857]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.008967
0.95-VaR bound for 9 demonstrations: -0.008239
0.99-VaR bound for 9 demonstrations: -0.004430
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.008239262654771207]
Threshold 0.1 SUFFICIENT with avar bound: -0.008239262654771207
Evaluating threshold 0.2 with avar bound: [-0.008239262654771207]
Threshold 0.2 SUFFICIENT with avar bound: -0.008239262654771207
Evaluating threshold 0.3 with avar bound: [-0.008239262654771207]
Threshold 0.3 SUFFICIENT with avar bound: -0.008239262654771207
Evaluating threshold 0.4 with avar bound: [-0.008239262654771207]
Threshold 0.4 SUFFICIENT with avar bound: -0.008239262654771207
Evaluating threshold 0.5 with avar bound: [-0.008239262654771207]
Threshold 0.5 SUFFICIENT with avar bound: -0.008239262654771207
Evaluating threshold 0.6 with avar bound: [-0.008239262654771207]
Threshold 0.6 SUFFICIENT with avar bound: -0.008239262654771207
Evaluating threshold 0.7 with avar bound: [-0.008239262654771207]
Threshold 0.7 SUFFICIENT with avar bound: -0.008239262654771207
Evaluating threshold 0.8 with avar bound: [-0.008239262654771207]
Threshold 0.8 SUFFICIENT with avar bound: -0.008239262654771207
Evaluating threshold 0.9 with avar bound: [-0.008239262654771207]
Threshold 0.9 SUFFICIENT with avar bound: -0.008239262654771207

Running BIRL with demonstration 10/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.12
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.26205215 -0.77410608 -0.08503932  0.09026555  0.11233573  0.17888847
  0.52162103]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.007408
0.95-VaR bound for 10 demonstrations: -0.006900
0.99-VaR bound for 10 demonstrations: -0.005873
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.006900322729577242]
Threshold 0.1 SUFFICIENT with avar bound: -0.006900322729577242
Evaluating threshold 0.2 with avar bound: [-0.006900322729577242]
Threshold 0.2 SUFFICIENT with avar bound: -0.006900322729577242
Evaluating threshold 0.3 with avar bound: [-0.006900322729577242]
Threshold 0.3 SUFFICIENT with avar bound: -0.006900322729577242
Evaluating threshold 0.4 with avar bound: [-0.006900322729577242]
Threshold 0.4 SUFFICIENT with avar bound: -0.006900322729577242
Evaluating threshold 0.5 with avar bound: [-0.006900322729577242]
Threshold 0.5 SUFFICIENT with avar bound: -0.006900322729577242
Evaluating threshold 0.6 with avar bound: [-0.006900322729577242]
Threshold 0.6 SUFFICIENT with avar bound: -0.006900322729577242
Evaluating threshold 0.7 with avar bound: [-0.006900322729577242]
Threshold 0.7 SUFFICIENT with avar bound: -0.006900322729577242
Evaluating threshold 0.8 with avar bound: [-0.006900322729577242]
Threshold 0.8 SUFFICIENT with avar bound: -0.006900322729577242
Evaluating threshold 0.9 with avar bound: [-0.006900322729577242]
Threshold 0.9 SUFFICIENT with avar bound: -0.006900322729577242

Running world 2/20

Running BIRL with demonstration 1/10 in world 2
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.438
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.5410345  -0.13009281 -0.01839987  0.24008086  0.56296872  0.18076872
  0.53176032]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.462808
0.95-VaR bound for 1 demonstrations: 3.781066
0.99-VaR bound for 1 demonstrations: 19.329327
True expected value difference for MAP policy: -0.002912
Evaluating threshold 0.1 with avar bound: [3.7810657213743517]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.7810657213743517]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.7810657213743517]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.7810657213743517]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.7810657213743517]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.7810657213743517]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.7810657213743517]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.7810657213743517]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.7810657213743517]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 2
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.222
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.36307201 -0.06482409 -0.4616115  -0.27166462 -0.29457897  0.27145639
  0.64546446]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: -0.001298
0.95-VaR bound for 2 demonstrations: -0.000463
0.99-VaR bound for 2 demonstrations: 0.272115
True expected value difference for MAP policy: -0.007540
Evaluating threshold 0.1 with avar bound: [-0.00046275708753736245]
Threshold 0.1 SUFFICIENT with avar bound: -0.00046275708753736245
Evaluating threshold 0.2 with avar bound: [-0.00046275708753736245]
Threshold 0.2 SUFFICIENT with avar bound: -0.00046275708753736245
Evaluating threshold 0.3 with avar bound: [-0.00046275708753736245]
Threshold 0.3 SUFFICIENT with avar bound: -0.00046275708753736245
Evaluating threshold 0.4 with avar bound: [-0.00046275708753736245]
Threshold 0.4 SUFFICIENT with avar bound: -0.00046275708753736245
Evaluating threshold 0.5 with avar bound: [-0.00046275708753736245]
Threshold 0.5 SUFFICIENT with avar bound: -0.00046275708753736245
Evaluating threshold 0.6 with avar bound: [-0.00046275708753736245]
Threshold 0.6 SUFFICIENT with avar bound: -0.00046275708753736245
Evaluating threshold 0.7 with avar bound: [-0.00046275708753736245]
Threshold 0.7 SUFFICIENT with avar bound: -0.00046275708753736245
Evaluating threshold 0.8 with avar bound: [-0.00046275708753736245]
Threshold 0.8 SUFFICIENT with avar bound: -0.00046275708753736245
Evaluating threshold 0.9 with avar bound: [-0.00046275708753736245]
Threshold 0.9 SUFFICIENT with avar bound: -0.00046275708753736245

Running BIRL with demonstration 3/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.201
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.10247401  0.06267202 -0.14039846 -0.3482563  -0.28114067  0.24099016
  0.84110688]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.017184
0.95-VaR bound for 3 demonstrations: 0.095641
0.99-VaR bound for 3 demonstrations: 0.106066
True expected value difference for MAP policy: -0.007540
Evaluating threshold 0.1 with avar bound: [0.09564085500650678]
Threshold 0.1 SUFFICIENT with avar bound: 0.09564085500650678
Evaluating threshold 0.2 with avar bound: [0.09564085500650678]
Threshold 0.2 SUFFICIENT with avar bound: 0.09564085500650678
Evaluating threshold 0.3 with avar bound: [0.09564085500650678]
Threshold 0.3 SUFFICIENT with avar bound: 0.09564085500650678
Evaluating threshold 0.4 with avar bound: [0.09564085500650678]
Threshold 0.4 SUFFICIENT with avar bound: 0.09564085500650678
Evaluating threshold 0.5 with avar bound: [0.09564085500650678]
Threshold 0.5 SUFFICIENT with avar bound: 0.09564085500650678
Evaluating threshold 0.6 with avar bound: [0.09564085500650678]
Threshold 0.6 SUFFICIENT with avar bound: 0.09564085500650678
Evaluating threshold 0.7 with avar bound: [0.09564085500650678]
Threshold 0.7 SUFFICIENT with avar bound: 0.09564085500650678
Evaluating threshold 0.8 with avar bound: [0.09564085500650678]
Threshold 0.8 SUFFICIENT with avar bound: 0.09564085500650678
Evaluating threshold 0.9 with avar bound: [0.09564085500650678]
Threshold 0.9 SUFFICIENT with avar bound: 0.09564085500650678

Running BIRL with demonstration 4/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.221
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.21562016  0.19683035 -0.34286547 -0.06684825 -0.54983534  0.14309458
  0.68552562]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: -0.002305
0.95-VaR bound for 4 demonstrations: -0.000407
0.99-VaR bound for 4 demonstrations: 0.019188
True expected value difference for MAP policy: -0.000387
Evaluating threshold 0.1 with avar bound: [-0.00040701009812304964]
Threshold 0.1 SUFFICIENT with avar bound: -0.00040701009812304964
Evaluating threshold 0.2 with avar bound: [-0.00040701009812304964]
Threshold 0.2 SUFFICIENT with avar bound: -0.00040701009812304964
Evaluating threshold 0.3 with avar bound: [-0.00040701009812304964]
Threshold 0.3 SUFFICIENT with avar bound: -0.00040701009812304964
Evaluating threshold 0.4 with avar bound: [-0.00040701009812304964]
Threshold 0.4 SUFFICIENT with avar bound: -0.00040701009812304964
Evaluating threshold 0.5 with avar bound: [-0.00040701009812304964]
Threshold 0.5 SUFFICIENT with avar bound: -0.00040701009812304964
Evaluating threshold 0.6 with avar bound: [-0.00040701009812304964]
Threshold 0.6 SUFFICIENT with avar bound: -0.00040701009812304964
Evaluating threshold 0.7 with avar bound: [-0.00040701009812304964]
Threshold 0.7 SUFFICIENT with avar bound: -0.00040701009812304964
Evaluating threshold 0.8 with avar bound: [-0.00040701009812304964]
Threshold 0.8 SUFFICIENT with avar bound: -0.00040701009812304964
Evaluating threshold 0.9 with avar bound: [-0.00040701009812304964]
Threshold 0.9 SUFFICIENT with avar bound: -0.00040701009812304964

Running BIRL with demonstration 5/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.143
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.45934194 -0.30627903  0.20917937 -0.34332582 -0.28479098  0.27041891
  0.61590357]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.002227
0.95-VaR bound for 5 demonstrations: -0.002227
0.99-VaR bound for 5 demonstrations: 0.012897
True expected value difference for MAP policy: -0.008531
Evaluating threshold 0.1 with avar bound: [-0.00222696993091531]
Threshold 0.1 SUFFICIENT with avar bound: -0.00222696993091531
Evaluating threshold 0.2 with avar bound: [-0.00222696993091531]
Threshold 0.2 SUFFICIENT with avar bound: -0.00222696993091531
Evaluating threshold 0.3 with avar bound: [-0.00222696993091531]
Threshold 0.3 SUFFICIENT with avar bound: -0.00222696993091531
Evaluating threshold 0.4 with avar bound: [-0.00222696993091531]
Threshold 0.4 SUFFICIENT with avar bound: -0.00222696993091531
Evaluating threshold 0.5 with avar bound: [-0.00222696993091531]
Threshold 0.5 SUFFICIENT with avar bound: -0.00222696993091531
Evaluating threshold 0.6 with avar bound: [-0.00222696993091531]
Threshold 0.6 SUFFICIENT with avar bound: -0.00222696993091531
Evaluating threshold 0.7 with avar bound: [-0.00222696993091531]
Threshold 0.7 SUFFICIENT with avar bound: -0.00222696993091531
Evaluating threshold 0.8 with avar bound: [-0.00222696993091531]
Threshold 0.8 SUFFICIENT with avar bound: -0.00222696993091531
Evaluating threshold 0.9 with avar bound: [-0.00222696993091531]
Threshold 0.9 SUFFICIENT with avar bound: -0.00222696993091531

Running BIRL with demonstration 6/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.159
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.25039586  0.11634814  0.6917968  -0.09084801 -0.20675634  0.20693678
  0.59275445]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: 0.573981
0.95-VaR bound for 6 demonstrations: 0.573981
0.99-VaR bound for 6 demonstrations: 0.573981
True expected value difference for MAP policy: 0.102719
Evaluating threshold 0.1 with avar bound: [0.573980949402576]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.573980949402576]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.573980949402576]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.573980949402576]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.573980949402576]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.573980949402576]
Threshold 0.6 SUFFICIENT with avar bound: 0.573980949402576
Evaluating threshold 0.7 with avar bound: [0.573980949402576]
Threshold 0.7 SUFFICIENT with avar bound: 0.573980949402576
Evaluating threshold 0.8 with avar bound: [0.573980949402576]
Threshold 0.8 SUFFICIENT with avar bound: 0.573980949402576
Evaluating threshold 0.9 with avar bound: [0.573980949402576]
Threshold 0.9 SUFFICIENT with avar bound: 0.573980949402576

Running BIRL with demonstration 7/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.148
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47766458 -0.28913694  0.39681084 -0.48395603  0.06652853  0.3136463
  0.44018638]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.002066
0.95-VaR bound for 7 demonstrations: 0.003578
0.99-VaR bound for 7 demonstrations: 0.030313
True expected value difference for MAP policy: -0.002017
Evaluating threshold 0.1 with avar bound: [0.0035777213944587155]
Threshold 0.1 SUFFICIENT with avar bound: 0.0035777213944587155
Evaluating threshold 0.2 with avar bound: [0.0035777213944587155]
Threshold 0.2 SUFFICIENT with avar bound: 0.0035777213944587155
Evaluating threshold 0.3 with avar bound: [0.0035777213944587155]
Threshold 0.3 SUFFICIENT with avar bound: 0.0035777213944587155
Evaluating threshold 0.4 with avar bound: [0.0035777213944587155]
Threshold 0.4 SUFFICIENT with avar bound: 0.0035777213944587155
Evaluating threshold 0.5 with avar bound: [0.0035777213944587155]
Threshold 0.5 SUFFICIENT with avar bound: 0.0035777213944587155
Evaluating threshold 0.6 with avar bound: [0.0035777213944587155]
Threshold 0.6 SUFFICIENT with avar bound: 0.0035777213944587155
Evaluating threshold 0.7 with avar bound: [0.0035777213944587155]
Threshold 0.7 SUFFICIENT with avar bound: 0.0035777213944587155
Evaluating threshold 0.8 with avar bound: [0.0035777213944587155]
Threshold 0.8 SUFFICIENT with avar bound: 0.0035777213944587155
Evaluating threshold 0.9 with avar bound: [0.0035777213944587155]
Threshold 0.9 SUFFICIENT with avar bound: 0.0035777213944587155

Running BIRL with demonstration 8/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.154
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.52239374 -0.32623679  0.26272345 -0.05777697 -0.05917764  0.37058864
  0.63833738]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.000268
0.95-VaR bound for 8 demonstrations: 0.001922
0.99-VaR bound for 8 demonstrations: 0.245522
True expected value difference for MAP policy: -0.006849
Evaluating threshold 0.1 with avar bound: [0.0019219323530431818]
Threshold 0.1 SUFFICIENT with avar bound: 0.0019219323530431818
Evaluating threshold 0.2 with avar bound: [0.0019219323530431818]
Threshold 0.2 SUFFICIENT with avar bound: 0.0019219323530431818
Evaluating threshold 0.3 with avar bound: [0.0019219323530431818]
Threshold 0.3 SUFFICIENT with avar bound: 0.0019219323530431818
Evaluating threshold 0.4 with avar bound: [0.0019219323530431818]
Threshold 0.4 SUFFICIENT with avar bound: 0.0019219323530431818
Evaluating threshold 0.5 with avar bound: [0.0019219323530431818]
Threshold 0.5 SUFFICIENT with avar bound: 0.0019219323530431818
Evaluating threshold 0.6 with avar bound: [0.0019219323530431818]
Threshold 0.6 SUFFICIENT with avar bound: 0.0019219323530431818
Evaluating threshold 0.7 with avar bound: [0.0019219323530431818]
Threshold 0.7 SUFFICIENT with avar bound: 0.0019219323530431818
Evaluating threshold 0.8 with avar bound: [0.0019219323530431818]
Threshold 0.8 SUFFICIENT with avar bound: 0.0019219323530431818
Evaluating threshold 0.9 with avar bound: [0.0019219323530431818]
Threshold 0.9 SUFFICIENT with avar bound: 0.0019219323530431818

Running BIRL with demonstration 9/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.148
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50330147 -0.14085834  0.24774209  0.18781106  0.09300432  0.43831367
  0.65530812]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.004045
0.95-VaR bound for 9 demonstrations: -0.003131
0.99-VaR bound for 9 demonstrations: -0.000507
True expected value difference for MAP policy: -0.006868
Evaluating threshold 0.1 with avar bound: [-0.0031312860204025334]
Threshold 0.1 SUFFICIENT with avar bound: -0.0031312860204025334
Evaluating threshold 0.2 with avar bound: [-0.0031312860204025334]
Threshold 0.2 SUFFICIENT with avar bound: -0.0031312860204025334
Evaluating threshold 0.3 with avar bound: [-0.0031312860204025334]
Threshold 0.3 SUFFICIENT with avar bound: -0.0031312860204025334
Evaluating threshold 0.4 with avar bound: [-0.0031312860204025334]
Threshold 0.4 SUFFICIENT with avar bound: -0.0031312860204025334
Evaluating threshold 0.5 with avar bound: [-0.0031312860204025334]
Threshold 0.5 SUFFICIENT with avar bound: -0.0031312860204025334
Evaluating threshold 0.6 with avar bound: [-0.0031312860204025334]
Threshold 0.6 SUFFICIENT with avar bound: -0.0031312860204025334
Evaluating threshold 0.7 with avar bound: [-0.0031312860204025334]
Threshold 0.7 SUFFICIENT with avar bound: -0.0031312860204025334
Evaluating threshold 0.8 with avar bound: [-0.0031312860204025334]
Threshold 0.8 SUFFICIENT with avar bound: -0.0031312860204025334
Evaluating threshold 0.9 with avar bound: [-0.0031312860204025334]
Threshold 0.9 SUFFICIENT with avar bound: -0.0031312860204025334

Running BIRL with demonstration 10/10 in world 2
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.153
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38034964 -0.41081827  0.26778174 -0.56517041  0.05270068  0.28842248
  0.45768216]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.003592
0.95-VaR bound for 10 demonstrations: -0.001857
0.99-VaR bound for 10 demonstrations: 0.004897
True expected value difference for MAP policy: -0.005858
Evaluating threshold 0.1 with avar bound: [-0.0018566577528818674]
Threshold 0.1 SUFFICIENT with avar bound: -0.0018566577528818674
Evaluating threshold 0.2 with avar bound: [-0.0018566577528818674]
Threshold 0.2 SUFFICIENT with avar bound: -0.0018566577528818674
Evaluating threshold 0.3 with avar bound: [-0.0018566577528818674]
Threshold 0.3 SUFFICIENT with avar bound: -0.0018566577528818674
Evaluating threshold 0.4 with avar bound: [-0.0018566577528818674]
Threshold 0.4 SUFFICIENT with avar bound: -0.0018566577528818674
Evaluating threshold 0.5 with avar bound: [-0.0018566577528818674]
Threshold 0.5 SUFFICIENT with avar bound: -0.0018566577528818674
Evaluating threshold 0.6 with avar bound: [-0.0018566577528818674]
Threshold 0.6 SUFFICIENT with avar bound: -0.0018566577528818674
Evaluating threshold 0.7 with avar bound: [-0.0018566577528818674]
Threshold 0.7 SUFFICIENT with avar bound: -0.0018566577528818674
Evaluating threshold 0.8 with avar bound: [-0.0018566577528818674]
Threshold 0.8 SUFFICIENT with avar bound: -0.0018566577528818674
Evaluating threshold 0.9 with avar bound: [-0.0018566577528818674]
Threshold 0.9 SUFFICIENT with avar bound: -0.0018566577528818674

Running world 3/20

Running BIRL with demonstration 1/10 in world 3
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.487
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.46153637  0.25846273 -0.38761326 -0.4001601  -0.19087206  0.40248863
 -0.4597606 ]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 1.827289
0.95-VaR bound for 1 demonstrations: 3.122445
0.99-VaR bound for 1 demonstrations: 24.075939
True expected value difference for MAP policy: 1.119714
Evaluating threshold 0.1 with avar bound: [3.122444652875379]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.122444652875379]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.122444652875379]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.122444652875379]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.122444652875379]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.122444652875379]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.122444652875379]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.122444652875379]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.122444652875379]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 3
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.264
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.83008414 -0.07145018 -0.32933134 -0.34680447 -0.225899    0.15825756
  0.03235586]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 1.914920
0.95-VaR bound for 2 demonstrations: 2.307875
0.99-VaR bound for 2 demonstrations: 4.818174
True expected value difference for MAP policy: 1.153661
Evaluating threshold 0.1 with avar bound: [2.307874705933213]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.307874705933213]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.307874705933213]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.307874705933213]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.307874705933213]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.307874705933213]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.307874705933213]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.307874705933213]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.307874705933213]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.255
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.78244491  0.05567466 -0.17196623 -0.21985076 -0.2082623   0.51138355
 -0.04344235]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 1.610743
0.95-VaR bound for 3 demonstrations: 3.112005
0.99-VaR bound for 3 demonstrations: 12.395056
True expected value difference for MAP policy: 1.127706
Evaluating threshold 0.1 with avar bound: [3.112005059682415]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.112005059682415]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.112005059682415]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.112005059682415]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.112005059682415]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.112005059682415]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.112005059682415]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.112005059682415]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.112005059682415]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.248
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.32132066 -0.4098349  -0.15867123 -0.55198984 -0.1240088  -0.07852942
  0.61430773]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.007013
0.95-VaR bound for 4 demonstrations: 0.010006
0.99-VaR bound for 4 demonstrations: 0.048720
True expected value difference for MAP policy: -0.001176
Evaluating threshold 0.1 with avar bound: [0.01000575934523958]
Threshold 0.1 SUFFICIENT with avar bound: 0.01000575934523958
Evaluating threshold 0.2 with avar bound: [0.01000575934523958]
Threshold 0.2 SUFFICIENT with avar bound: 0.01000575934523958
Evaluating threshold 0.3 with avar bound: [0.01000575934523958]
Threshold 0.3 SUFFICIENT with avar bound: 0.01000575934523958
Evaluating threshold 0.4 with avar bound: [0.01000575934523958]
Threshold 0.4 SUFFICIENT with avar bound: 0.01000575934523958
Evaluating threshold 0.5 with avar bound: [0.01000575934523958]
Threshold 0.5 SUFFICIENT with avar bound: 0.01000575934523958
Evaluating threshold 0.6 with avar bound: [0.01000575934523958]
Threshold 0.6 SUFFICIENT with avar bound: 0.01000575934523958
Evaluating threshold 0.7 with avar bound: [0.01000575934523958]
Threshold 0.7 SUFFICIENT with avar bound: 0.01000575934523958
Evaluating threshold 0.8 with avar bound: [0.01000575934523958]
Threshold 0.8 SUFFICIENT with avar bound: 0.01000575934523958
Evaluating threshold 0.9 with avar bound: [0.01000575934523958]
Threshold 0.9 SUFFICIENT with avar bound: 0.01000575934523958

Running BIRL with demonstration 5/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.206
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.32124224 -0.36231551 -0.21741073 -0.02882576 -0.23178756  0.57972498
  0.57238625]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: 0.005440
0.95-VaR bound for 5 demonstrations: 0.009202
0.99-VaR bound for 5 demonstrations: 0.078087
True expected value difference for MAP policy: -0.008299
Evaluating threshold 0.1 with avar bound: [0.009202007620141289]
Threshold 0.1 SUFFICIENT with avar bound: 0.009202007620141289
Evaluating threshold 0.2 with avar bound: [0.009202007620141289]
Threshold 0.2 SUFFICIENT with avar bound: 0.009202007620141289
Evaluating threshold 0.3 with avar bound: [0.009202007620141289]
Threshold 0.3 SUFFICIENT with avar bound: 0.009202007620141289
Evaluating threshold 0.4 with avar bound: [0.009202007620141289]
Threshold 0.4 SUFFICIENT with avar bound: 0.009202007620141289
Evaluating threshold 0.5 with avar bound: [0.009202007620141289]
Threshold 0.5 SUFFICIENT with avar bound: 0.009202007620141289
Evaluating threshold 0.6 with avar bound: [0.009202007620141289]
Threshold 0.6 SUFFICIENT with avar bound: 0.009202007620141289
Evaluating threshold 0.7 with avar bound: [0.009202007620141289]
Threshold 0.7 SUFFICIENT with avar bound: 0.009202007620141289
Evaluating threshold 0.8 with avar bound: [0.009202007620141289]
Threshold 0.8 SUFFICIENT with avar bound: 0.009202007620141289
Evaluating threshold 0.9 with avar bound: [0.009202007620141289]
Threshold 0.9 SUFFICIENT with avar bound: 0.009202007620141289

Running BIRL with demonstration 6/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.197
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.23893882 -0.6422709   0.21731093 -0.27732589 -0.0882279   0.24366
  0.58233004]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: 0.000826
0.95-VaR bound for 6 demonstrations: 0.002675
0.99-VaR bound for 6 demonstrations: 0.006775
True expected value difference for MAP policy: -0.008369
Evaluating threshold 0.1 with avar bound: [0.0026750697795047806]
Threshold 0.1 SUFFICIENT with avar bound: 0.0026750697795047806
Evaluating threshold 0.2 with avar bound: [0.0026750697795047806]
Threshold 0.2 SUFFICIENT with avar bound: 0.0026750697795047806
Evaluating threshold 0.3 with avar bound: [0.0026750697795047806]
Threshold 0.3 SUFFICIENT with avar bound: 0.0026750697795047806
Evaluating threshold 0.4 with avar bound: [0.0026750697795047806]
Threshold 0.4 SUFFICIENT with avar bound: 0.0026750697795047806
Evaluating threshold 0.5 with avar bound: [0.0026750697795047806]
Threshold 0.5 SUFFICIENT with avar bound: 0.0026750697795047806
Evaluating threshold 0.6 with avar bound: [0.0026750697795047806]
Threshold 0.6 SUFFICIENT with avar bound: 0.0026750697795047806
Evaluating threshold 0.7 with avar bound: [0.0026750697795047806]
Threshold 0.7 SUFFICIENT with avar bound: 0.0026750697795047806
Evaluating threshold 0.8 with avar bound: [0.0026750697795047806]
Threshold 0.8 SUFFICIENT with avar bound: 0.0026750697795047806
Evaluating threshold 0.9 with avar bound: [0.0026750697795047806]
Threshold 0.9 SUFFICIENT with avar bound: 0.0026750697795047806

Running BIRL with demonstration 7/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.171
Using 700 samples after burn-in
MAP Solution Reward Weights: [-4.29572991e-01 -4.28263030e-01 -1.95318902e-01 -7.06365779e-02
  3.84636754e-01  3.82133383e-04  6.64058163e-01]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: 0.001667
0.95-VaR bound for 7 demonstrations: 0.009511
0.99-VaR bound for 7 demonstrations: 0.014945
True expected value difference for MAP policy: -0.009502
Evaluating threshold 0.1 with avar bound: [0.009511246365349406]
Threshold 0.1 SUFFICIENT with avar bound: 0.009511246365349406
Evaluating threshold 0.2 with avar bound: [0.009511246365349406]
Threshold 0.2 SUFFICIENT with avar bound: 0.009511246365349406
Evaluating threshold 0.3 with avar bound: [0.009511246365349406]
Threshold 0.3 SUFFICIENT with avar bound: 0.009511246365349406
Evaluating threshold 0.4 with avar bound: [0.009511246365349406]
Threshold 0.4 SUFFICIENT with avar bound: 0.009511246365349406
Evaluating threshold 0.5 with avar bound: [0.009511246365349406]
Threshold 0.5 SUFFICIENT with avar bound: 0.009511246365349406
Evaluating threshold 0.6 with avar bound: [0.009511246365349406]
Threshold 0.6 SUFFICIENT with avar bound: 0.009511246365349406
Evaluating threshold 0.7 with avar bound: [0.009511246365349406]
Threshold 0.7 SUFFICIENT with avar bound: 0.009511246365349406
Evaluating threshold 0.8 with avar bound: [0.009511246365349406]
Threshold 0.8 SUFFICIENT with avar bound: 0.009511246365349406
Evaluating threshold 0.9 with avar bound: [0.009511246365349406]
Threshold 0.9 SUFFICIENT with avar bound: 0.009511246365349406

Running BIRL with demonstration 8/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.184
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.23844805 -0.228865   -0.12429764  0.00143825 -0.45613705  0.64991008
  0.49484064]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: 0.448985
0.95-VaR bound for 8 demonstrations: 0.502126
0.99-VaR bound for 8 demonstrations: 1.468787
True expected value difference for MAP policy: 0.035669
Evaluating threshold 0.1 with avar bound: [0.5021257442818953]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.5021257442818953]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.5021257442818953]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.5021257442818953]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.5021257442818953]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.5021257442818953]
Threshold 0.6 SUFFICIENT with avar bound: 0.5021257442818953
Evaluating threshold 0.7 with avar bound: [0.5021257442818953]
Threshold 0.7 SUFFICIENT with avar bound: 0.5021257442818953
Evaluating threshold 0.8 with avar bound: [0.5021257442818953]
Threshold 0.8 SUFFICIENT with avar bound: 0.5021257442818953
Evaluating threshold 0.9 with avar bound: [0.5021257442818953]
Threshold 0.9 SUFFICIENT with avar bound: 0.5021257442818953

Running BIRL with demonstration 9/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.177
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.30264269 -0.56182152 -0.05689305 -0.27840604 -0.55245533  0.26880787
  0.36681423]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: 0.005039
0.95-VaR bound for 9 demonstrations: 0.006623
0.99-VaR bound for 9 demonstrations: 0.032142
True expected value difference for MAP policy: 0.001235
Evaluating threshold 0.1 with avar bound: [0.006623467006647108]
Threshold 0.1 SUFFICIENT with avar bound: 0.006623467006647108
Evaluating threshold 0.2 with avar bound: [0.006623467006647108]
Threshold 0.2 SUFFICIENT with avar bound: 0.006623467006647108
Evaluating threshold 0.3 with avar bound: [0.006623467006647108]
Threshold 0.3 SUFFICIENT with avar bound: 0.006623467006647108
Evaluating threshold 0.4 with avar bound: [0.006623467006647108]
Threshold 0.4 SUFFICIENT with avar bound: 0.006623467006647108
Evaluating threshold 0.5 with avar bound: [0.006623467006647108]
Threshold 0.5 SUFFICIENT with avar bound: 0.006623467006647108
Evaluating threshold 0.6 with avar bound: [0.006623467006647108]
Threshold 0.6 SUFFICIENT with avar bound: 0.006623467006647108
Evaluating threshold 0.7 with avar bound: [0.006623467006647108]
Threshold 0.7 SUFFICIENT with avar bound: 0.006623467006647108
Evaluating threshold 0.8 with avar bound: [0.006623467006647108]
Threshold 0.8 SUFFICIENT with avar bound: 0.006623467006647108
Evaluating threshold 0.9 with avar bound: [0.006623467006647108]
Threshold 0.9 SUFFICIENT with avar bound: 0.006623467006647108

Running BIRL with demonstration 10/10 in world 3
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.166
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.53864249 -0.50627373 -0.28057592 -0.18252937  0.32133516 -0.08309749
  0.48098845]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: 0.000980
0.95-VaR bound for 10 demonstrations: 0.009506
0.99-VaR bound for 10 demonstrations: 0.016574
True expected value difference for MAP policy: -0.009502
Evaluating threshold 0.1 with avar bound: [0.009506435132232278]
Threshold 0.1 SUFFICIENT with avar bound: 0.009506435132232278
Evaluating threshold 0.2 with avar bound: [0.009506435132232278]
Threshold 0.2 SUFFICIENT with avar bound: 0.009506435132232278
Evaluating threshold 0.3 with avar bound: [0.009506435132232278]
Threshold 0.3 SUFFICIENT with avar bound: 0.009506435132232278
Evaluating threshold 0.4 with avar bound: [0.009506435132232278]
Threshold 0.4 SUFFICIENT with avar bound: 0.009506435132232278
Evaluating threshold 0.5 with avar bound: [0.009506435132232278]
Threshold 0.5 SUFFICIENT with avar bound: 0.009506435132232278
Evaluating threshold 0.6 with avar bound: [0.009506435132232278]
Threshold 0.6 SUFFICIENT with avar bound: 0.009506435132232278
Evaluating threshold 0.7 with avar bound: [0.009506435132232278]
Threshold 0.7 SUFFICIENT with avar bound: 0.009506435132232278
Evaluating threshold 0.8 with avar bound: [0.009506435132232278]
Threshold 0.8 SUFFICIENT with avar bound: 0.009506435132232278
Evaluating threshold 0.9 with avar bound: [0.009506435132232278]
Threshold 0.9 SUFFICIENT with avar bound: 0.009506435132232278

Running world 4/20

Running BIRL with demonstration 1/10 in world 4
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.318
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.46156034  0.29399794 -0.20061162 -0.28298509  0.44809052 -0.21219404
  0.57826487]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.015091
0.95-VaR bound for 1 demonstrations: 2.721904
0.99-VaR bound for 1 demonstrations: 6.494680
True expected value difference for MAP policy: 0.010258
Evaluating threshold 0.1 with avar bound: [2.7219035048595512]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.7219035048595512]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.7219035048595512]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.7219035048595512]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.7219035048595512]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.7219035048595512]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.7219035048595512]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.7219035048595512]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.7219035048595512]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 4
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.287
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.3895481  -0.22685638 -0.38286321 -0.30764958  0.45894687 -0.07248087
  0.58281236]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 2.427864
0.95-VaR bound for 2 demonstrations: 3.129459
0.99-VaR bound for 2 demonstrations: 7.835515
True expected value difference for MAP policy: -0.006584
Evaluating threshold 0.1 with avar bound: [3.1294587504254605]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.1294587504254605]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.1294587504254605]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.1294587504254605]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.1294587504254605]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.1294587504254605]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.1294587504254605]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.1294587504254605]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.1294587504254605]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 2)]
MCMC sampling complete.
Acceptance ratio: 0.148
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.25407712  0.0617118  -0.11586358 -0.5753032   0.13570875  0.49503248
  0.56900291]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 1.057724
0.95-VaR bound for 3 demonstrations: 1.367333
0.99-VaR bound for 3 demonstrations: 1.595143
True expected value difference for MAP policy: -0.009120
Evaluating threshold 0.1 with avar bound: [1.3673331800341575]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3673331800341575]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3673331800341575]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3673331800341575]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3673331800341575]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3673331800341575]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3673331800341575]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3673331800341575]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3673331800341575]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.141
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.58980513 -0.15436858 -0.08755503 -0.08296555  0.24876145  0.49362247
  0.55516276]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: -0.006757
0.95-VaR bound for 4 demonstrations: -0.006085
0.99-VaR bound for 4 demonstrations: -0.002375
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.006084628501885283]
Threshold 0.1 SUFFICIENT with avar bound: -0.006084628501885283
Evaluating threshold 0.2 with avar bound: [-0.006084628501885283]
Threshold 0.2 SUFFICIENT with avar bound: -0.006084628501885283
Evaluating threshold 0.3 with avar bound: [-0.006084628501885283]
Threshold 0.3 SUFFICIENT with avar bound: -0.006084628501885283
Evaluating threshold 0.4 with avar bound: [-0.006084628501885283]
Threshold 0.4 SUFFICIENT with avar bound: -0.006084628501885283
Evaluating threshold 0.5 with avar bound: [-0.006084628501885283]
Threshold 0.5 SUFFICIENT with avar bound: -0.006084628501885283
Evaluating threshold 0.6 with avar bound: [-0.006084628501885283]
Threshold 0.6 SUFFICIENT with avar bound: -0.006084628501885283
Evaluating threshold 0.7 with avar bound: [-0.006084628501885283]
Threshold 0.7 SUFFICIENT with avar bound: -0.006084628501885283
Evaluating threshold 0.8 with avar bound: [-0.006084628501885283]
Threshold 0.8 SUFFICIENT with avar bound: -0.006084628501885283
Evaluating threshold 0.9 with avar bound: [-0.006084628501885283]
Threshold 0.9 SUFFICIENT with avar bound: -0.006084628501885283

Running BIRL with demonstration 5/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.154
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.28621908  0.18536522 -0.10797391 -0.56025121  0.07298689  0.46004517
  0.58413179]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: 0.004110
0.95-VaR bound for 5 demonstrations: 0.071606
0.99-VaR bound for 5 demonstrations: 0.071606
True expected value difference for MAP policy: -0.009607
Evaluating threshold 0.1 with avar bound: [0.0716058489589618]
Threshold 0.1 SUFFICIENT with avar bound: 0.0716058489589618
Evaluating threshold 0.2 with avar bound: [0.0716058489589618]
Threshold 0.2 SUFFICIENT with avar bound: 0.0716058489589618
Evaluating threshold 0.3 with avar bound: [0.0716058489589618]
Threshold 0.3 SUFFICIENT with avar bound: 0.0716058489589618
Evaluating threshold 0.4 with avar bound: [0.0716058489589618]
Threshold 0.4 SUFFICIENT with avar bound: 0.0716058489589618
Evaluating threshold 0.5 with avar bound: [0.0716058489589618]
Threshold 0.5 SUFFICIENT with avar bound: 0.0716058489589618
Evaluating threshold 0.6 with avar bound: [0.0716058489589618]
Threshold 0.6 SUFFICIENT with avar bound: 0.0716058489589618
Evaluating threshold 0.7 with avar bound: [0.0716058489589618]
Threshold 0.7 SUFFICIENT with avar bound: 0.0716058489589618
Evaluating threshold 0.8 with avar bound: [0.0716058489589618]
Threshold 0.8 SUFFICIENT with avar bound: 0.0716058489589618
Evaluating threshold 0.9 with avar bound: [0.0716058489589618]
Threshold 0.9 SUFFICIENT with avar bound: 0.0716058489589618

Running BIRL with demonstration 6/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.155
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.22100177 -0.47595742  0.29214074 -0.09574617  0.36842497  0.39569065
  0.58120664]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.008937
0.95-VaR bound for 6 demonstrations: -0.008383
0.99-VaR bound for 6 demonstrations: -0.004874
True expected value difference for MAP policy: -0.009932
Evaluating threshold 0.1 with avar bound: [-0.008382849733613851]
Threshold 0.1 SUFFICIENT with avar bound: -0.008382849733613851
Evaluating threshold 0.2 with avar bound: [-0.008382849733613851]
Threshold 0.2 SUFFICIENT with avar bound: -0.008382849733613851
Evaluating threshold 0.3 with avar bound: [-0.008382849733613851]
Threshold 0.3 SUFFICIENT with avar bound: -0.008382849733613851
Evaluating threshold 0.4 with avar bound: [-0.008382849733613851]
Threshold 0.4 SUFFICIENT with avar bound: -0.008382849733613851
Evaluating threshold 0.5 with avar bound: [-0.008382849733613851]
Threshold 0.5 SUFFICIENT with avar bound: -0.008382849733613851
Evaluating threshold 0.6 with avar bound: [-0.008382849733613851]
Threshold 0.6 SUFFICIENT with avar bound: -0.008382849733613851
Evaluating threshold 0.7 with avar bound: [-0.008382849733613851]
Threshold 0.7 SUFFICIENT with avar bound: -0.008382849733613851
Evaluating threshold 0.8 with avar bound: [-0.008382849733613851]
Threshold 0.8 SUFFICIENT with avar bound: -0.008382849733613851
Evaluating threshold 0.9 with avar bound: [-0.008382849733613851]
Threshold 0.9 SUFFICIENT with avar bound: -0.008382849733613851

Running BIRL with demonstration 7/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.136
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.65046278 -0.42542501 -0.18747902 -0.28940042  0.11444642  0.29241539
  0.42238136]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.008890
0.95-VaR bound for 7 demonstrations: -0.006889
0.99-VaR bound for 7 demonstrations: -0.001888
True expected value difference for MAP policy: -0.010036
Evaluating threshold 0.1 with avar bound: [-0.006888538001868522]
Threshold 0.1 SUFFICIENT with avar bound: -0.006888538001868522
Evaluating threshold 0.2 with avar bound: [-0.006888538001868522]
Threshold 0.2 SUFFICIENT with avar bound: -0.006888538001868522
Evaluating threshold 0.3 with avar bound: [-0.006888538001868522]
Threshold 0.3 SUFFICIENT with avar bound: -0.006888538001868522
Evaluating threshold 0.4 with avar bound: [-0.006888538001868522]
Threshold 0.4 SUFFICIENT with avar bound: -0.006888538001868522
Evaluating threshold 0.5 with avar bound: [-0.006888538001868522]
Threshold 0.5 SUFFICIENT with avar bound: -0.006888538001868522
Evaluating threshold 0.6 with avar bound: [-0.006888538001868522]
Threshold 0.6 SUFFICIENT with avar bound: -0.006888538001868522
Evaluating threshold 0.7 with avar bound: [-0.006888538001868522]
Threshold 0.7 SUFFICIENT with avar bound: -0.006888538001868522
Evaluating threshold 0.8 with avar bound: [-0.006888538001868522]
Threshold 0.8 SUFFICIENT with avar bound: -0.006888538001868522
Evaluating threshold 0.9 with avar bound: [-0.006888538001868522]
Threshold 0.9 SUFFICIENT with avar bound: -0.006888538001868522

Running BIRL with demonstration 8/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.138
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.3292271  -0.28065616  0.24739121 -0.32089217  0.36518342  0.40624048
  0.5918422 ]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.008077
0.95-VaR bound for 8 demonstrations: -0.007750
0.99-VaR bound for 8 demonstrations: -0.006151
True expected value difference for MAP policy: -0.009932
Evaluating threshold 0.1 with avar bound: [-0.00775000975385396]
Threshold 0.1 SUFFICIENT with avar bound: -0.00775000975385396
Evaluating threshold 0.2 with avar bound: [-0.00775000975385396]
Threshold 0.2 SUFFICIENT with avar bound: -0.00775000975385396
Evaluating threshold 0.3 with avar bound: [-0.00775000975385396]
Threshold 0.3 SUFFICIENT with avar bound: -0.00775000975385396
Evaluating threshold 0.4 with avar bound: [-0.00775000975385396]
Threshold 0.4 SUFFICIENT with avar bound: -0.00775000975385396
Evaluating threshold 0.5 with avar bound: [-0.00775000975385396]
Threshold 0.5 SUFFICIENT with avar bound: -0.00775000975385396
Evaluating threshold 0.6 with avar bound: [-0.00775000975385396]
Threshold 0.6 SUFFICIENT with avar bound: -0.00775000975385396
Evaluating threshold 0.7 with avar bound: [-0.00775000975385396]
Threshold 0.7 SUFFICIENT with avar bound: -0.00775000975385396
Evaluating threshold 0.8 with avar bound: [-0.00775000975385396]
Threshold 0.8 SUFFICIENT with avar bound: -0.00775000975385396
Evaluating threshold 0.9 with avar bound: [-0.00775000975385396]
Threshold 0.9 SUFFICIENT with avar bound: -0.00775000975385396

Running BIRL with demonstration 9/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.138
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.59803601  0.02821707  0.20318203 -0.27154361  0.22294071  0.33965521
  0.60122345]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.006554
0.95-VaR bound for 9 demonstrations: 0.058169
0.99-VaR bound for 9 demonstrations: 0.058169
True expected value difference for MAP policy: -0.009932
Evaluating threshold 0.1 with avar bound: [0.05816918782325487]
Threshold 0.1 SUFFICIENT with avar bound: 0.05816918782325487
Evaluating threshold 0.2 with avar bound: [0.05816918782325487]
Threshold 0.2 SUFFICIENT with avar bound: 0.05816918782325487
Evaluating threshold 0.3 with avar bound: [0.05816918782325487]
Threshold 0.3 SUFFICIENT with avar bound: 0.05816918782325487
Evaluating threshold 0.4 with avar bound: [0.05816918782325487]
Threshold 0.4 SUFFICIENT with avar bound: 0.05816918782325487
Evaluating threshold 0.5 with avar bound: [0.05816918782325487]
Threshold 0.5 SUFFICIENT with avar bound: 0.05816918782325487
Evaluating threshold 0.6 with avar bound: [0.05816918782325487]
Threshold 0.6 SUFFICIENT with avar bound: 0.05816918782325487
Evaluating threshold 0.7 with avar bound: [0.05816918782325487]
Threshold 0.7 SUFFICIENT with avar bound: 0.05816918782325487
Evaluating threshold 0.8 with avar bound: [0.05816918782325487]
Threshold 0.8 SUFFICIENT with avar bound: 0.05816918782325487
Evaluating threshold 0.9 with avar bound: [0.05816918782325487]
Threshold 0.9 SUFFICIENT with avar bound: 0.05816918782325487

Running BIRL with demonstration 10/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 2), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.115
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.65471272 -0.18157432 -0.07222616 -0.20705181  0.23685178  0.33104448
  0.56974182]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.009155
0.95-VaR bound for 10 demonstrations: -0.008757
0.99-VaR bound for 10 demonstrations: -0.008218
True expected value difference for MAP policy: -0.009932
Evaluating threshold 0.1 with avar bound: [-0.008757015470054223]
Threshold 0.1 SUFFICIENT with avar bound: -0.008757015470054223
Evaluating threshold 0.2 with avar bound: [-0.008757015470054223]
Threshold 0.2 SUFFICIENT with avar bound: -0.008757015470054223
Evaluating threshold 0.3 with avar bound: [-0.008757015470054223]
Threshold 0.3 SUFFICIENT with avar bound: -0.008757015470054223
Evaluating threshold 0.4 with avar bound: [-0.008757015470054223]
Threshold 0.4 SUFFICIENT with avar bound: -0.008757015470054223
Evaluating threshold 0.5 with avar bound: [-0.008757015470054223]
Threshold 0.5 SUFFICIENT with avar bound: -0.008757015470054223
Evaluating threshold 0.6 with avar bound: [-0.008757015470054223]
Threshold 0.6 SUFFICIENT with avar bound: -0.008757015470054223
Evaluating threshold 0.7 with avar bound: [-0.008757015470054223]
Threshold 0.7 SUFFICIENT with avar bound: -0.008757015470054223
Evaluating threshold 0.8 with avar bound: [-0.008757015470054223]
Threshold 0.8 SUFFICIENT with avar bound: -0.008757015470054223
Evaluating threshold 0.9 with avar bound: [-0.008757015470054223]
Threshold 0.9 SUFFICIENT with avar bound: -0.008757015470054223

Saving results to files...
Results saved successfully.

Running world 5/20

Running BIRL with demonstration 1/10 in world 5
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.482
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.45781069 -0.37249205  0.51391107  0.33327292  0.36453835 -0.34594846
  0.15464497]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 1.295366
0.95-VaR bound for 1 demonstrations: 1.789013
0.99-VaR bound for 1 demonstrations: 2.680047
True expected value difference for MAP policy: 0.879015
Evaluating threshold 0.1 with avar bound: [1.7890126677456657]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.7890126677456657]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.7890126677456657]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.7890126677456657]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.7890126677456657]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.7890126677456657]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.7890126677456657]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.7890126677456657]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.7890126677456657]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 5
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.271
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.09986229 -0.1277857   0.87764275  0.08880388  0.00090557  0.44151015
  0.02496749]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 1.483096
0.95-VaR bound for 2 demonstrations: 2.209449
0.99-VaR bound for 2 demonstrations: 4.740237
True expected value difference for MAP policy: 0.856584
Evaluating threshold 0.1 with avar bound: [2.2094485461041713]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.2094485461041713]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.2094485461041713]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.2094485461041713]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.2094485461041713]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.2094485461041713]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.2094485461041713]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.2094485461041713]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.2094485461041713]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.217
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.47867075 -0.41242042  0.1451023  -0.50758482 -0.03948366  0.00738746
  0.56610348]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.011241
0.95-VaR bound for 3 demonstrations: 0.085956
0.99-VaR bound for 3 demonstrations: 4.260795
True expected value difference for MAP policy: -0.007764
Evaluating threshold 0.1 with avar bound: [0.08595599388346312]
Threshold 0.1 SUFFICIENT with avar bound: 0.08595599388346312
Evaluating threshold 0.2 with avar bound: [0.08595599388346312]
Threshold 0.2 SUFFICIENT with avar bound: 0.08595599388346312
Evaluating threshold 0.3 with avar bound: [0.08595599388346312]
Threshold 0.3 SUFFICIENT with avar bound: 0.08595599388346312
Evaluating threshold 0.4 with avar bound: [0.08595599388346312]
Threshold 0.4 SUFFICIENT with avar bound: 0.08595599388346312
Evaluating threshold 0.5 with avar bound: [0.08595599388346312]
Threshold 0.5 SUFFICIENT with avar bound: 0.08595599388346312
Evaluating threshold 0.6 with avar bound: [0.08595599388346312]
Threshold 0.6 SUFFICIENT with avar bound: 0.08595599388346312
Evaluating threshold 0.7 with avar bound: [0.08595599388346312]
Threshold 0.7 SUFFICIENT with avar bound: 0.08595599388346312
Evaluating threshold 0.8 with avar bound: [0.08595599388346312]
Threshold 0.8 SUFFICIENT with avar bound: 0.08595599388346312
Evaluating threshold 0.9 with avar bound: [0.08595599388346312]
Threshold 0.9 SUFFICIENT with avar bound: 0.08595599388346312

Running BIRL with demonstration 4/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.234
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.20912358 -0.2261391   0.32900648 -0.46735565 -0.46264942  0.03834818
  0.60245066]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: -0.000001
0.95-VaR bound for 4 demonstrations: 0.012897
0.99-VaR bound for 4 demonstrations: 0.025813
True expected value difference for MAP policy: -0.007320
Evaluating threshold 0.1 with avar bound: [0.012897447745944706]
Threshold 0.1 SUFFICIENT with avar bound: 0.012897447745944706
Evaluating threshold 0.2 with avar bound: [0.012897447745944706]
Threshold 0.2 SUFFICIENT with avar bound: 0.012897447745944706
Evaluating threshold 0.3 with avar bound: [0.012897447745944706]
Threshold 0.3 SUFFICIENT with avar bound: 0.012897447745944706
Evaluating threshold 0.4 with avar bound: [0.012897447745944706]
Threshold 0.4 SUFFICIENT with avar bound: 0.012897447745944706
Evaluating threshold 0.5 with avar bound: [0.012897447745944706]
Threshold 0.5 SUFFICIENT with avar bound: 0.012897447745944706
Evaluating threshold 0.6 with avar bound: [0.012897447745944706]
Threshold 0.6 SUFFICIENT with avar bound: 0.012897447745944706
Evaluating threshold 0.7 with avar bound: [0.012897447745944706]
Threshold 0.7 SUFFICIENT with avar bound: 0.012897447745944706
Evaluating threshold 0.8 with avar bound: [0.012897447745944706]
Threshold 0.8 SUFFICIENT with avar bound: 0.012897447745944706
Evaluating threshold 0.9 with avar bound: [0.012897447745944706]
Threshold 0.9 SUFFICIENT with avar bound: 0.012897447745944706

Running BIRL with demonstration 5/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.2
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.04485169 -0.29994932  0.42071563 -0.36925038  0.10400695 -0.15121037
  0.74899214]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: 0.001060
0.95-VaR bound for 5 demonstrations: 0.016138
0.99-VaR bound for 5 demonstrations: 0.065388
True expected value difference for MAP policy: -0.008372
Evaluating threshold 0.1 with avar bound: [0.016137686047338923]
Threshold 0.1 SUFFICIENT with avar bound: 0.016137686047338923
Evaluating threshold 0.2 with avar bound: [0.016137686047338923]
Threshold 0.2 SUFFICIENT with avar bound: 0.016137686047338923
Evaluating threshold 0.3 with avar bound: [0.016137686047338923]
Threshold 0.3 SUFFICIENT with avar bound: 0.016137686047338923
Evaluating threshold 0.4 with avar bound: [0.016137686047338923]
Threshold 0.4 SUFFICIENT with avar bound: 0.016137686047338923
Evaluating threshold 0.5 with avar bound: [0.016137686047338923]
Threshold 0.5 SUFFICIENT with avar bound: 0.016137686047338923
Evaluating threshold 0.6 with avar bound: [0.016137686047338923]
Threshold 0.6 SUFFICIENT with avar bound: 0.016137686047338923
Evaluating threshold 0.7 with avar bound: [0.016137686047338923]
Threshold 0.7 SUFFICIENT with avar bound: 0.016137686047338923
Evaluating threshold 0.8 with avar bound: [0.016137686047338923]
Threshold 0.8 SUFFICIENT with avar bound: 0.016137686047338923
Evaluating threshold 0.9 with avar bound: [0.016137686047338923]
Threshold 0.9 SUFFICIENT with avar bound: 0.016137686047338923

Running BIRL with demonstration 6/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.03430713  0.0772684   0.3658004  -0.46749483  0.11660652 -0.256514
  0.74906258]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.004644
0.95-VaR bound for 6 demonstrations: -0.003476
0.99-VaR bound for 6 demonstrations: -0.000778
True expected value difference for MAP policy: -0.007069
Evaluating threshold 0.1 with avar bound: [-0.003476486685271535]
Threshold 0.1 SUFFICIENT with avar bound: -0.003476486685271535
Evaluating threshold 0.2 with avar bound: [-0.003476486685271535]
Threshold 0.2 SUFFICIENT with avar bound: -0.003476486685271535
Evaluating threshold 0.3 with avar bound: [-0.003476486685271535]
Threshold 0.3 SUFFICIENT with avar bound: -0.003476486685271535
Evaluating threshold 0.4 with avar bound: [-0.003476486685271535]
Threshold 0.4 SUFFICIENT with avar bound: -0.003476486685271535
Evaluating threshold 0.5 with avar bound: [-0.003476486685271535]
Threshold 0.5 SUFFICIENT with avar bound: -0.003476486685271535
Evaluating threshold 0.6 with avar bound: [-0.003476486685271535]
Threshold 0.6 SUFFICIENT with avar bound: -0.003476486685271535
Evaluating threshold 0.7 with avar bound: [-0.003476486685271535]
Threshold 0.7 SUFFICIENT with avar bound: -0.003476486685271535
Evaluating threshold 0.8 with avar bound: [-0.003476486685271535]
Threshold 0.8 SUFFICIENT with avar bound: -0.003476486685271535
Evaluating threshold 0.9 with avar bound: [-0.003476486685271535]
Threshold 0.9 SUFFICIENT with avar bound: -0.003476486685271535

Running BIRL with demonstration 7/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.152
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.24582203 -0.15806777  0.03871267 -0.6767514  -0.02844837 -0.34137462
  0.58116181]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.006262
0.95-VaR bound for 7 demonstrations: -0.005043
0.99-VaR bound for 7 demonstrations: 0.002586
True expected value difference for MAP policy: -0.007322
Evaluating threshold 0.1 with avar bound: [-0.005042504727455936]
Threshold 0.1 SUFFICIENT with avar bound: -0.005042504727455936
Evaluating threshold 0.2 with avar bound: [-0.005042504727455936]
Threshold 0.2 SUFFICIENT with avar bound: -0.005042504727455936
Evaluating threshold 0.3 with avar bound: [-0.005042504727455936]
Threshold 0.3 SUFFICIENT with avar bound: -0.005042504727455936
Evaluating threshold 0.4 with avar bound: [-0.005042504727455936]
Threshold 0.4 SUFFICIENT with avar bound: -0.005042504727455936
Evaluating threshold 0.5 with avar bound: [-0.005042504727455936]
Threshold 0.5 SUFFICIENT with avar bound: -0.005042504727455936
Evaluating threshold 0.6 with avar bound: [-0.005042504727455936]
Threshold 0.6 SUFFICIENT with avar bound: -0.005042504727455936
Evaluating threshold 0.7 with avar bound: [-0.005042504727455936]
Threshold 0.7 SUFFICIENT with avar bound: -0.005042504727455936
Evaluating threshold 0.8 with avar bound: [-0.005042504727455936]
Threshold 0.8 SUFFICIENT with avar bound: -0.005042504727455936
Evaluating threshold 0.9 with avar bound: [-0.005042504727455936]
Threshold 0.9 SUFFICIENT with avar bound: -0.005042504727455936

Running BIRL with demonstration 8/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.152
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.08801747  0.03194549  0.32164098 -0.65899084 -0.05825032 -0.05095222
  0.66897036]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.005827
0.95-VaR bound for 8 demonstrations: -0.004295
0.99-VaR bound for 8 demonstrations: 0.001095
True expected value difference for MAP policy: -0.007322
Evaluating threshold 0.1 with avar bound: [-0.004295028510667732]
Threshold 0.1 SUFFICIENT with avar bound: -0.004295028510667732
Evaluating threshold 0.2 with avar bound: [-0.004295028510667732]
Threshold 0.2 SUFFICIENT with avar bound: -0.004295028510667732
Evaluating threshold 0.3 with avar bound: [-0.004295028510667732]
Threshold 0.3 SUFFICIENT with avar bound: -0.004295028510667732
Evaluating threshold 0.4 with avar bound: [-0.004295028510667732]
Threshold 0.4 SUFFICIENT with avar bound: -0.004295028510667732
Evaluating threshold 0.5 with avar bound: [-0.004295028510667732]
Threshold 0.5 SUFFICIENT with avar bound: -0.004295028510667732
Evaluating threshold 0.6 with avar bound: [-0.004295028510667732]
Threshold 0.6 SUFFICIENT with avar bound: -0.004295028510667732
Evaluating threshold 0.7 with avar bound: [-0.004295028510667732]
Threshold 0.7 SUFFICIENT with avar bound: -0.004295028510667732
Evaluating threshold 0.8 with avar bound: [-0.004295028510667732]
Threshold 0.8 SUFFICIENT with avar bound: -0.004295028510667732
Evaluating threshold 0.9 with avar bound: [-0.004295028510667732]
Threshold 0.9 SUFFICIENT with avar bound: -0.004295028510667732

Running BIRL with demonstration 9/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.168
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.27834615  0.09616127  0.23803218 -0.66891968 -0.14069611 -0.10848443
  0.6144911 ]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.008731
0.95-VaR bound for 9 demonstrations: -0.008168
0.99-VaR bound for 9 demonstrations: -0.007428
True expected value difference for MAP policy: -0.007322
Evaluating threshold 0.1 with avar bound: [-0.008167871336851798]
Threshold 0.1 SUFFICIENT with avar bound: -0.008167871336851798
Evaluating threshold 0.2 with avar bound: [-0.008167871336851798]
Threshold 0.2 SUFFICIENT with avar bound: -0.008167871336851798
Evaluating threshold 0.3 with avar bound: [-0.008167871336851798]
Threshold 0.3 SUFFICIENT with avar bound: -0.008167871336851798
Evaluating threshold 0.4 with avar bound: [-0.008167871336851798]
Threshold 0.4 SUFFICIENT with avar bound: -0.008167871336851798
Evaluating threshold 0.5 with avar bound: [-0.008167871336851798]
Threshold 0.5 SUFFICIENT with avar bound: -0.008167871336851798
Evaluating threshold 0.6 with avar bound: [-0.008167871336851798]
Threshold 0.6 SUFFICIENT with avar bound: -0.008167871336851798
Evaluating threshold 0.7 with avar bound: [-0.008167871336851798]
Threshold 0.7 SUFFICIENT with avar bound: -0.008167871336851798
Evaluating threshold 0.8 with avar bound: [-0.008167871336851798]
Threshold 0.8 SUFFICIENT with avar bound: -0.008167871336851798
Evaluating threshold 0.9 with avar bound: [-0.008167871336851798]
Threshold 0.9 SUFFICIENT with avar bound: -0.008167871336851798

Running BIRL with demonstration 10/10 in world 5
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 1), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.157
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.41927146 -0.03526086  0.48796885 -0.35569492 -0.08270599  0.0171207
  0.67171589]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.005765
0.95-VaR bound for 10 demonstrations: -0.004248
0.99-VaR bound for 10 demonstrations: -0.001816
True expected value difference for MAP policy: -0.008291
Evaluating threshold 0.1 with avar bound: [-0.004247578055458017]
Threshold 0.1 SUFFICIENT with avar bound: -0.004247578055458017
Evaluating threshold 0.2 with avar bound: [-0.004247578055458017]
Threshold 0.2 SUFFICIENT with avar bound: -0.004247578055458017
Evaluating threshold 0.3 with avar bound: [-0.004247578055458017]
Threshold 0.3 SUFFICIENT with avar bound: -0.004247578055458017
Evaluating threshold 0.4 with avar bound: [-0.004247578055458017]
Threshold 0.4 SUFFICIENT with avar bound: -0.004247578055458017
Evaluating threshold 0.5 with avar bound: [-0.004247578055458017]
Threshold 0.5 SUFFICIENT with avar bound: -0.004247578055458017
Evaluating threshold 0.6 with avar bound: [-0.004247578055458017]
Threshold 0.6 SUFFICIENT with avar bound: -0.004247578055458017
Evaluating threshold 0.7 with avar bound: [-0.004247578055458017]
Threshold 0.7 SUFFICIENT with avar bound: -0.004247578055458017
Evaluating threshold 0.8 with avar bound: [-0.004247578055458017]
Threshold 0.8 SUFFICIENT with avar bound: -0.004247578055458017
Evaluating threshold 0.9 with avar bound: [-0.004247578055458017]
Threshold 0.9 SUFFICIENT with avar bound: -0.004247578055458017

Running world 6/20

Running BIRL with demonstration 1/10 in world 6
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.472
Using 700 samples after burn-in
MAP Solution Reward Weights: [-5.73974908e-02 -5.22052357e-01  6.95389591e-04 -7.99675336e-01
  5.96544995e-02  2.48632450e-01  1.38956769e-01]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.692032
0.95-VaR bound for 1 demonstrations: 3.459325
0.99-VaR bound for 1 demonstrations: 15.597355
True expected value difference for MAP policy: 0.016828
Evaluating threshold 0.1 with avar bound: [3.4593250195814127]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.4593250195814127]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.4593250195814127]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.4593250195814127]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.4593250195814127]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.4593250195814127]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.4593250195814127]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.4593250195814127]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.4593250195814127]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 6
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.226
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.48187252 -0.1769517  -0.50874213  0.16997855  0.09050614  0.44393769
  0.49346092]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 2.518831
0.95-VaR bound for 2 demonstrations: 4.007171
0.99-VaR bound for 2 demonstrations: 8.021573
True expected value difference for MAP policy: -0.001008
Evaluating threshold 0.1 with avar bound: [4.007170828862696]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [4.007170828862696]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [4.007170828862696]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [4.007170828862696]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [4.007170828862696]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [4.007170828862696]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [4.007170828862696]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [4.007170828862696]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [4.007170828862696]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.263
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.3049978  -0.20306499 -0.88448923 -0.0767323  -0.03526755  0.11240671
  0.25229515]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.066577
0.95-VaR bound for 3 demonstrations: 0.490241
0.99-VaR bound for 3 demonstrations: 1.326473
True expected value difference for MAP policy: 0.017035
Evaluating threshold 0.1 with avar bound: [0.4902410439539947]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.4902410439539947]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.4902410439539947]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.4902410439539947]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.4902410439539947]
Threshold 0.5 SUFFICIENT with avar bound: 0.4902410439539947
Evaluating threshold 0.6 with avar bound: [0.4902410439539947]
Threshold 0.6 SUFFICIENT with avar bound: 0.4902410439539947
Evaluating threshold 0.7 with avar bound: [0.4902410439539947]
Threshold 0.7 SUFFICIENT with avar bound: 0.4902410439539947
Evaluating threshold 0.8 with avar bound: [0.4902410439539947]
Threshold 0.8 SUFFICIENT with avar bound: 0.4902410439539947
Evaluating threshold 0.9 with avar bound: [0.4902410439539947]
Threshold 0.9 SUFFICIENT with avar bound: 0.4902410439539947

Running BIRL with demonstration 4/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.262
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.17873418  0.09887113 -0.65493653 -0.19151912 -0.27616934  0.24026462
  0.59888277]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: -0.002413
0.95-VaR bound for 4 demonstrations: 0.002372
0.99-VaR bound for 4 demonstrations: 0.016625
True expected value difference for MAP policy: -0.001150
Evaluating threshold 0.1 with avar bound: [0.002371782988240884]
Threshold 0.1 SUFFICIENT with avar bound: 0.002371782988240884
Evaluating threshold 0.2 with avar bound: [0.002371782988240884]
Threshold 0.2 SUFFICIENT with avar bound: 0.002371782988240884
Evaluating threshold 0.3 with avar bound: [0.002371782988240884]
Threshold 0.3 SUFFICIENT with avar bound: 0.002371782988240884
Evaluating threshold 0.4 with avar bound: [0.002371782988240884]
Threshold 0.4 SUFFICIENT with avar bound: 0.002371782988240884
Evaluating threshold 0.5 with avar bound: [0.002371782988240884]
Threshold 0.5 SUFFICIENT with avar bound: 0.002371782988240884
Evaluating threshold 0.6 with avar bound: [0.002371782988240884]
Threshold 0.6 SUFFICIENT with avar bound: 0.002371782988240884
Evaluating threshold 0.7 with avar bound: [0.002371782988240884]
Threshold 0.7 SUFFICIENT with avar bound: 0.002371782988240884
Evaluating threshold 0.8 with avar bound: [0.002371782988240884]
Threshold 0.8 SUFFICIENT with avar bound: 0.002371782988240884
Evaluating threshold 0.9 with avar bound: [0.002371782988240884]
Threshold 0.9 SUFFICIENT with avar bound: 0.002371782988240884

Running BIRL with demonstration 5/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.246
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.15459212 -0.02604236 -0.72245998 -0.18966965 -0.3159202   0.42616561
  0.36888667]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: 0.002021
0.95-VaR bound for 5 demonstrations: 0.003735
0.99-VaR bound for 5 demonstrations: 0.617745
True expected value difference for MAP policy: -0.001617
Evaluating threshold 0.1 with avar bound: [0.003734638170872668]
Threshold 0.1 SUFFICIENT with avar bound: 0.003734638170872668
Evaluating threshold 0.2 with avar bound: [0.003734638170872668]
Threshold 0.2 SUFFICIENT with avar bound: 0.003734638170872668
Evaluating threshold 0.3 with avar bound: [0.003734638170872668]
Threshold 0.3 SUFFICIENT with avar bound: 0.003734638170872668
Evaluating threshold 0.4 with avar bound: [0.003734638170872668]
Threshold 0.4 SUFFICIENT with avar bound: 0.003734638170872668
Evaluating threshold 0.5 with avar bound: [0.003734638170872668]
Threshold 0.5 SUFFICIENT with avar bound: 0.003734638170872668
Evaluating threshold 0.6 with avar bound: [0.003734638170872668]
Threshold 0.6 SUFFICIENT with avar bound: 0.003734638170872668
Evaluating threshold 0.7 with avar bound: [0.003734638170872668]
Threshold 0.7 SUFFICIENT with avar bound: 0.003734638170872668
Evaluating threshold 0.8 with avar bound: [0.003734638170872668]
Threshold 0.8 SUFFICIENT with avar bound: 0.003734638170872668
Evaluating threshold 0.9 with avar bound: [0.003734638170872668]
Threshold 0.9 SUFFICIENT with avar bound: 0.003734638170872668

Running BIRL with demonstration 6/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.207
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.15936374 -0.09206076 -0.74833368 -0.1974291   0.10504565  0.36015832
  0.47581285]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.002424
0.95-VaR bound for 6 demonstrations: 0.007921
0.99-VaR bound for 6 demonstrations: 0.026324
True expected value difference for MAP policy: -0.002644
Evaluating threshold 0.1 with avar bound: [0.00792090305704977]
Threshold 0.1 SUFFICIENT with avar bound: 0.00792090305704977
Evaluating threshold 0.2 with avar bound: [0.00792090305704977]
Threshold 0.2 SUFFICIENT with avar bound: 0.00792090305704977
Evaluating threshold 0.3 with avar bound: [0.00792090305704977]
Threshold 0.3 SUFFICIENT with avar bound: 0.00792090305704977
Evaluating threshold 0.4 with avar bound: [0.00792090305704977]
Threshold 0.4 SUFFICIENT with avar bound: 0.00792090305704977
Evaluating threshold 0.5 with avar bound: [0.00792090305704977]
Threshold 0.5 SUFFICIENT with avar bound: 0.00792090305704977
Evaluating threshold 0.6 with avar bound: [0.00792090305704977]
Threshold 0.6 SUFFICIENT with avar bound: 0.00792090305704977
Evaluating threshold 0.7 with avar bound: [0.00792090305704977]
Threshold 0.7 SUFFICIENT with avar bound: 0.00792090305704977
Evaluating threshold 0.8 with avar bound: [0.00792090305704977]
Threshold 0.8 SUFFICIENT with avar bound: 0.00792090305704977
Evaluating threshold 0.9 with avar bound: [0.00792090305704977]
Threshold 0.9 SUFFICIENT with avar bound: 0.00792090305704977

Running BIRL with demonstration 7/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.194
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.36327546  0.02321    -0.59634113 -0.07589872  0.18838006  0.41242211
  0.54820601]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: 0.002430
0.95-VaR bound for 7 demonstrations: 0.011713
0.99-VaR bound for 7 demonstrations: 0.024473
True expected value difference for MAP policy: -0.002644
Evaluating threshold 0.1 with avar bound: [0.011712878011966597]
Threshold 0.1 SUFFICIENT with avar bound: 0.011712878011966597
Evaluating threshold 0.2 with avar bound: [0.011712878011966597]
Threshold 0.2 SUFFICIENT with avar bound: 0.011712878011966597
Evaluating threshold 0.3 with avar bound: [0.011712878011966597]
Threshold 0.3 SUFFICIENT with avar bound: 0.011712878011966597
Evaluating threshold 0.4 with avar bound: [0.011712878011966597]
Threshold 0.4 SUFFICIENT with avar bound: 0.011712878011966597
Evaluating threshold 0.5 with avar bound: [0.011712878011966597]
Threshold 0.5 SUFFICIENT with avar bound: 0.011712878011966597
Evaluating threshold 0.6 with avar bound: [0.011712878011966597]
Threshold 0.6 SUFFICIENT with avar bound: 0.011712878011966597
Evaluating threshold 0.7 with avar bound: [0.011712878011966597]
Threshold 0.7 SUFFICIENT with avar bound: 0.011712878011966597
Evaluating threshold 0.8 with avar bound: [0.011712878011966597]
Threshold 0.8 SUFFICIENT with avar bound: 0.011712878011966597
Evaluating threshold 0.9 with avar bound: [0.011712878011966597]
Threshold 0.9 SUFFICIENT with avar bound: 0.011712878011966597

Running BIRL with demonstration 8/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.161
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.11433606 -0.67865042 -0.45760373  0.22973426 -0.01135534  0.0243321
  0.5132844 ]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.004923
0.95-VaR bound for 8 demonstrations: -0.003403
0.99-VaR bound for 8 demonstrations: 0.001784
True expected value difference for MAP policy: -0.003206
Evaluating threshold 0.1 with avar bound: [-0.0034032241711615223]
Threshold 0.1 SUFFICIENT with avar bound: -0.0034032241711615223
Evaluating threshold 0.2 with avar bound: [-0.0034032241711615223]
Threshold 0.2 SUFFICIENT with avar bound: -0.0034032241711615223
Evaluating threshold 0.3 with avar bound: [-0.0034032241711615223]
Threshold 0.3 SUFFICIENT with avar bound: -0.0034032241711615223
Evaluating threshold 0.4 with avar bound: [-0.0034032241711615223]
Threshold 0.4 SUFFICIENT with avar bound: -0.0034032241711615223
Evaluating threshold 0.5 with avar bound: [-0.0034032241711615223]
Threshold 0.5 SUFFICIENT with avar bound: -0.0034032241711615223
Evaluating threshold 0.6 with avar bound: [-0.0034032241711615223]
Threshold 0.6 SUFFICIENT with avar bound: -0.0034032241711615223
Evaluating threshold 0.7 with avar bound: [-0.0034032241711615223]
Threshold 0.7 SUFFICIENT with avar bound: -0.0034032241711615223
Evaluating threshold 0.8 with avar bound: [-0.0034032241711615223]
Threshold 0.8 SUFFICIENT with avar bound: -0.0034032241711615223
Evaluating threshold 0.9 with avar bound: [-0.0034032241711615223]
Threshold 0.9 SUFFICIENT with avar bound: -0.0034032241711615223

Running BIRL with demonstration 9/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.167
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.19674752 -0.26047    -0.64428969  0.24177527  0.27193366 -0.04285491
  0.58659769]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.004946
0.95-VaR bound for 9 demonstrations: -0.004261
0.99-VaR bound for 9 demonstrations: -0.000139
True expected value difference for MAP policy: -0.004402
Evaluating threshold 0.1 with avar bound: [-0.004261152793722549]
Threshold 0.1 SUFFICIENT with avar bound: -0.004261152793722549
Evaluating threshold 0.2 with avar bound: [-0.004261152793722549]
Threshold 0.2 SUFFICIENT with avar bound: -0.004261152793722549
Evaluating threshold 0.3 with avar bound: [-0.004261152793722549]
Threshold 0.3 SUFFICIENT with avar bound: -0.004261152793722549
Evaluating threshold 0.4 with avar bound: [-0.004261152793722549]
Threshold 0.4 SUFFICIENT with avar bound: -0.004261152793722549
Evaluating threshold 0.5 with avar bound: [-0.004261152793722549]
Threshold 0.5 SUFFICIENT with avar bound: -0.004261152793722549
Evaluating threshold 0.6 with avar bound: [-0.004261152793722549]
Threshold 0.6 SUFFICIENT with avar bound: -0.004261152793722549
Evaluating threshold 0.7 with avar bound: [-0.004261152793722549]
Threshold 0.7 SUFFICIENT with avar bound: -0.004261152793722549
Evaluating threshold 0.8 with avar bound: [-0.004261152793722549]
Threshold 0.8 SUFFICIENT with avar bound: -0.004261152793722549
Evaluating threshold 0.9 with avar bound: [-0.004261152793722549]
Threshold 0.9 SUFFICIENT with avar bound: -0.004261152793722549

Running BIRL with demonstration 10/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.168
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.13695201 -0.23718879 -0.44416171  0.02037073  0.27483707  0.06625279
  0.80459069]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: 0.000084
0.95-VaR bound for 10 demonstrations: 0.002412
0.99-VaR bound for 10 demonstrations: 0.235653
True expected value difference for MAP policy: -0.004402
Evaluating threshold 0.1 with avar bound: [0.0024118593941544553]
Threshold 0.1 SUFFICIENT with avar bound: 0.0024118593941544553
Evaluating threshold 0.2 with avar bound: [0.0024118593941544553]
Threshold 0.2 SUFFICIENT with avar bound: 0.0024118593941544553
Evaluating threshold 0.3 with avar bound: [0.0024118593941544553]
Threshold 0.3 SUFFICIENT with avar bound: 0.0024118593941544553
Evaluating threshold 0.4 with avar bound: [0.0024118593941544553]
Threshold 0.4 SUFFICIENT with avar bound: 0.0024118593941544553
Evaluating threshold 0.5 with avar bound: [0.0024118593941544553]
Threshold 0.5 SUFFICIENT with avar bound: 0.0024118593941544553
Evaluating threshold 0.6 with avar bound: [0.0024118593941544553]
Threshold 0.6 SUFFICIENT with avar bound: 0.0024118593941544553
Evaluating threshold 0.7 with avar bound: [0.0024118593941544553]
Threshold 0.7 SUFFICIENT with avar bound: 0.0024118593941544553
Evaluating threshold 0.8 with avar bound: [0.0024118593941544553]
Threshold 0.8 SUFFICIENT with avar bound: 0.0024118593941544553
Evaluating threshold 0.9 with avar bound: [0.0024118593941544553]
Threshold 0.9 SUFFICIENT with avar bound: 0.0024118593941544553

Running world 7/20

Running BIRL with demonstration 1/10 in world 7
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.414
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.49633992  0.38215556 -0.42265005  0.34268339 -0.02894739  0.52628958
  0.18363051]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 0.978744
0.95-VaR bound for 1 demonstrations: 1.351469
0.99-VaR bound for 1 demonstrations: 8.833893
True expected value difference for MAP policy: 0.316556
Evaluating threshold 0.1 with avar bound: [1.3514685451597488]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3514685451597488]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3514685451597488]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3514685451597488]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3514685451597488]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3514685451597488]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3514685451597488]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3514685451597488]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3514685451597488]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 7
Current demos: [(16, 1), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.364
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.17198629 -0.34981567 -0.24689267 -0.45630427 -0.36498031  0.61561825
  0.25823182]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 1.163755
0.95-VaR bound for 2 demonstrations: 1.325176
0.99-VaR bound for 2 demonstrations: 2.758653
True expected value difference for MAP policy: 0.343199
Evaluating threshold 0.1 with avar bound: [1.325175692576146]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.325175692576146]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.325175692576146]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.325175692576146]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.325175692576146]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.325175692576146]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.325175692576146]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.325175692576146]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.325175692576146]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 7
Current demos: [(16, 1), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.273
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.40896861 -0.36585941 -0.50964152  0.33788028  0.14119212  0.41207516
  0.36776741]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 1.175543
0.95-VaR bound for 3 demonstrations: 1.331215
0.99-VaR bound for 3 demonstrations: 3.081174
True expected value difference for MAP policy: 0.297482
Evaluating threshold 0.1 with avar bound: [1.3312145649389984]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3312145649389984]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3312145649389984]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3312145649389984]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3312145649389984]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3312145649389984]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3312145649389984]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3312145649389984]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3312145649389984]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 7
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.226
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.54158315 -0.02038775 -0.38606673  0.56108289 -0.13974774  0.12658112
  0.45481676]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.187289
0.95-VaR bound for 4 demonstrations: 0.197991
0.99-VaR bound for 4 demonstrations: 0.255547
True expected value difference for MAP policy: 0.037515
Evaluating threshold 0.1 with avar bound: [0.19799125801251535]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.19799125801251535]
Threshold 0.2 SUFFICIENT with avar bound: 0.19799125801251535
Evaluating threshold 0.3 with avar bound: [0.19799125801251535]
Threshold 0.3 SUFFICIENT with avar bound: 0.19799125801251535
Evaluating threshold 0.4 with avar bound: [0.19799125801251535]
Threshold 0.4 SUFFICIENT with avar bound: 0.19799125801251535
Evaluating threshold 0.5 with avar bound: [0.19799125801251535]
Threshold 0.5 SUFFICIENT with avar bound: 0.19799125801251535
Evaluating threshold 0.6 with avar bound: [0.19799125801251535]
Threshold 0.6 SUFFICIENT with avar bound: 0.19799125801251535
Evaluating threshold 0.7 with avar bound: [0.19799125801251535]
Threshold 0.7 SUFFICIENT with avar bound: 0.19799125801251535
Evaluating threshold 0.8 with avar bound: [0.19799125801251535]
Threshold 0.8 SUFFICIENT with avar bound: 0.19799125801251535
Evaluating threshold 0.9 with avar bound: [0.19799125801251535]
Threshold 0.9 SUFFICIENT with avar bound: 0.19799125801251535

Running BIRL with demonstration 5/10 in world 7
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62564732 -0.05995627  0.11564039 -0.31577217  0.29312591  0.24047841
  0.59002818]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.001896
0.95-VaR bound for 5 demonstrations: 0.002233
0.99-VaR bound for 5 demonstrations: 0.011024
True expected value difference for MAP policy: -0.009517
Evaluating threshold 0.1 with avar bound: [0.002233161169372418]
Threshold 0.1 SUFFICIENT with avar bound: 0.002233161169372418
Evaluating threshold 0.2 with avar bound: [0.002233161169372418]
Threshold 0.2 SUFFICIENT with avar bound: 0.002233161169372418
Evaluating threshold 0.3 with avar bound: [0.002233161169372418]
Threshold 0.3 SUFFICIENT with avar bound: 0.002233161169372418
Evaluating threshold 0.4 with avar bound: [0.002233161169372418]
Threshold 0.4 SUFFICIENT with avar bound: 0.002233161169372418
Evaluating threshold 0.5 with avar bound: [0.002233161169372418]
Threshold 0.5 SUFFICIENT with avar bound: 0.002233161169372418
Evaluating threshold 0.6 with avar bound: [0.002233161169372418]
Threshold 0.6 SUFFICIENT with avar bound: 0.002233161169372418
Evaluating threshold 0.7 with avar bound: [0.002233161169372418]
Threshold 0.7 SUFFICIENT with avar bound: 0.002233161169372418
Evaluating threshold 0.8 with avar bound: [0.002233161169372418]
Threshold 0.8 SUFFICIENT with avar bound: 0.002233161169372418
Evaluating threshold 0.9 with avar bound: [0.002233161169372418]
Threshold 0.9 SUFFICIENT with avar bound: 0.002233161169372418

Running BIRL with demonstration 6/10 in world 7
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.213
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.69317162 -0.06546172 -0.2038317  -0.32784096 -0.00527368  0.24993439
  0.55109509]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.002979
0.95-VaR bound for 6 demonstrations: 0.000345
0.99-VaR bound for 6 demonstrations: 0.002690
True expected value difference for MAP policy: -0.009517
Evaluating threshold 0.1 with avar bound: [0.0003450328726369143]
Threshold 0.1 SUFFICIENT with avar bound: 0.0003450328726369143
Evaluating threshold 0.2 with avar bound: [0.0003450328726369143]
Threshold 0.2 SUFFICIENT with avar bound: 0.0003450328726369143
Evaluating threshold 0.3 with avar bound: [0.0003450328726369143]
Threshold 0.3 SUFFICIENT with avar bound: 0.0003450328726369143
Evaluating threshold 0.4 with avar bound: [0.0003450328726369143]
Threshold 0.4 SUFFICIENT with avar bound: 0.0003450328726369143
Evaluating threshold 0.5 with avar bound: [0.0003450328726369143]
Threshold 0.5 SUFFICIENT with avar bound: 0.0003450328726369143
Evaluating threshold 0.6 with avar bound: [0.0003450328726369143]
Threshold 0.6 SUFFICIENT with avar bound: 0.0003450328726369143
Evaluating threshold 0.7 with avar bound: [0.0003450328726369143]
Threshold 0.7 SUFFICIENT with avar bound: 0.0003450328726369143
Evaluating threshold 0.8 with avar bound: [0.0003450328726369143]
Threshold 0.8 SUFFICIENT with avar bound: 0.0003450328726369143
Evaluating threshold 0.9 with avar bound: [0.0003450328726369143]
Threshold 0.9 SUFFICIENT with avar bound: 0.0003450328726369143

Running BIRL with demonstration 7/10 in world 7
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.184
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.42839686 -0.14759234 -0.18501168 -0.14582838 -0.37414642  0.4537677
  0.62714171]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.005471
0.95-VaR bound for 7 demonstrations: -0.002949
0.99-VaR bound for 7 demonstrations: 0.014031
True expected value difference for MAP policy: -0.010006
Evaluating threshold 0.1 with avar bound: [-0.0029489578559553477]
Threshold 0.1 SUFFICIENT with avar bound: -0.0029489578559553477
Evaluating threshold 0.2 with avar bound: [-0.0029489578559553477]
Threshold 0.2 SUFFICIENT with avar bound: -0.0029489578559553477
Evaluating threshold 0.3 with avar bound: [-0.0029489578559553477]
Threshold 0.3 SUFFICIENT with avar bound: -0.0029489578559553477
Evaluating threshold 0.4 with avar bound: [-0.0029489578559553477]
Threshold 0.4 SUFFICIENT with avar bound: -0.0029489578559553477
Evaluating threshold 0.5 with avar bound: [-0.0029489578559553477]
Threshold 0.5 SUFFICIENT with avar bound: -0.0029489578559553477
Evaluating threshold 0.6 with avar bound: [-0.0029489578559553477]
Threshold 0.6 SUFFICIENT with avar bound: -0.0029489578559553477
Evaluating threshold 0.7 with avar bound: [-0.0029489578559553477]
Threshold 0.7 SUFFICIENT with avar bound: -0.0029489578559553477
Evaluating threshold 0.8 with avar bound: [-0.0029489578559553477]
Threshold 0.8 SUFFICIENT with avar bound: -0.0029489578559553477
Evaluating threshold 0.9 with avar bound: [-0.0029489578559553477]
Threshold 0.9 SUFFICIENT with avar bound: -0.0029489578559553477

Running BIRL with demonstration 8/10 in world 7
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.172
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.58464469 -0.33196536  0.01124948 -0.16124787 -0.37856458  0.19956977
  0.58199908]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.005880
0.95-VaR bound for 8 demonstrations: -0.004478
0.99-VaR bound for 8 demonstrations: 0.015598
True expected value difference for MAP policy: -0.010006
Evaluating threshold 0.1 with avar bound: [-0.004478130987138794]
Threshold 0.1 SUFFICIENT with avar bound: -0.004478130987138794
Evaluating threshold 0.2 with avar bound: [-0.004478130987138794]
Threshold 0.2 SUFFICIENT with avar bound: -0.004478130987138794
Evaluating threshold 0.3 with avar bound: [-0.004478130987138794]
Threshold 0.3 SUFFICIENT with avar bound: -0.004478130987138794
Evaluating threshold 0.4 with avar bound: [-0.004478130987138794]
Threshold 0.4 SUFFICIENT with avar bound: -0.004478130987138794
Evaluating threshold 0.5 with avar bound: [-0.004478130987138794]
Threshold 0.5 SUFFICIENT with avar bound: -0.004478130987138794
Evaluating threshold 0.6 with avar bound: [-0.004478130987138794]
Threshold 0.6 SUFFICIENT with avar bound: -0.004478130987138794
Evaluating threshold 0.7 with avar bound: [-0.004478130987138794]
Threshold 0.7 SUFFICIENT with avar bound: -0.004478130987138794
Evaluating threshold 0.8 with avar bound: [-0.004478130987138794]
Threshold 0.8 SUFFICIENT with avar bound: -0.004478130987138794
Evaluating threshold 0.9 with avar bound: [-0.004478130987138794]
Threshold 0.9 SUFFICIENT with avar bound: -0.004478130987138794

Running BIRL with demonstration 9/10 in world 7
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.157
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.49563457 -0.44400517  0.30139058 -0.09278572 -0.42755532  0.22781272
  0.4722903 ]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.008503
0.95-VaR bound for 9 demonstrations: -0.006382
0.99-VaR bound for 9 demonstrations: -0.000169
True expected value difference for MAP policy: -0.009008
Evaluating threshold 0.1 with avar bound: [-0.006381520769099268]
Threshold 0.1 SUFFICIENT with avar bound: -0.006381520769099268
Evaluating threshold 0.2 with avar bound: [-0.006381520769099268]
Threshold 0.2 SUFFICIENT with avar bound: -0.006381520769099268
Evaluating threshold 0.3 with avar bound: [-0.006381520769099268]
Threshold 0.3 SUFFICIENT with avar bound: -0.006381520769099268
Evaluating threshold 0.4 with avar bound: [-0.006381520769099268]
Threshold 0.4 SUFFICIENT with avar bound: -0.006381520769099268
Evaluating threshold 0.5 with avar bound: [-0.006381520769099268]
Threshold 0.5 SUFFICIENT with avar bound: -0.006381520769099268
Evaluating threshold 0.6 with avar bound: [-0.006381520769099268]
Threshold 0.6 SUFFICIENT with avar bound: -0.006381520769099268
Evaluating threshold 0.7 with avar bound: [-0.006381520769099268]
Threshold 0.7 SUFFICIENT with avar bound: -0.006381520769099268
Evaluating threshold 0.8 with avar bound: [-0.006381520769099268]
Threshold 0.8 SUFFICIENT with avar bound: -0.006381520769099268
Evaluating threshold 0.9 with avar bound: [-0.006381520769099268]
Threshold 0.9 SUFFICIENT with avar bound: -0.006381520769099268

Running BIRL with demonstration 10/10 in world 7
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.171
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.43240807 -0.51521202  0.23139354 -0.04486225 -0.16548662  0.39102133
  0.55833748]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.007825
0.95-VaR bound for 10 demonstrations: -0.006105
0.99-VaR bound for 10 demonstrations: -0.000844
True expected value difference for MAP policy: -0.010006
Evaluating threshold 0.1 with avar bound: [-0.006105410077741762]
Threshold 0.1 SUFFICIENT with avar bound: -0.006105410077741762
Evaluating threshold 0.2 with avar bound: [-0.006105410077741762]
Threshold 0.2 SUFFICIENT with avar bound: -0.006105410077741762
Evaluating threshold 0.3 with avar bound: [-0.006105410077741762]
Threshold 0.3 SUFFICIENT with avar bound: -0.006105410077741762
Evaluating threshold 0.4 with avar bound: [-0.006105410077741762]
Threshold 0.4 SUFFICIENT with avar bound: -0.006105410077741762
Evaluating threshold 0.5 with avar bound: [-0.006105410077741762]
Threshold 0.5 SUFFICIENT with avar bound: -0.006105410077741762
Evaluating threshold 0.6 with avar bound: [-0.006105410077741762]
Threshold 0.6 SUFFICIENT with avar bound: -0.006105410077741762
Evaluating threshold 0.7 with avar bound: [-0.006105410077741762]
Threshold 0.7 SUFFICIENT with avar bound: -0.006105410077741762
Evaluating threshold 0.8 with avar bound: [-0.006105410077741762]
Threshold 0.8 SUFFICIENT with avar bound: -0.006105410077741762
Evaluating threshold 0.9 with avar bound: [-0.006105410077741762]
Threshold 0.9 SUFFICIENT with avar bound: -0.006105410077741762

Running world 8/20

Running BIRL with demonstration 1/10 in world 8
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.455
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.02376735 -0.27439703  0.51856947 -0.63435408 -0.12926344 -0.05669193
 -0.48259608]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 1.694746
0.95-VaR bound for 1 demonstrations: 2.081888
0.99-VaR bound for 1 demonstrations: 13.313736
True expected value difference for MAP policy: 3.083995
Evaluating threshold 0.1 with avar bound: [2.081888357092023]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.081888357092023]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.081888357092023]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.081888357092023]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.081888357092023]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.081888357092023]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.081888357092023]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.081888357092023]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.081888357092023]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 8
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.389
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.11983422  0.02238202  0.31191783 -0.55676033 -0.04634998 -0.52570395
  0.54712982]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 2.426301
0.95-VaR bound for 2 demonstrations: 3.206006
0.99-VaR bound for 2 demonstrations: 36.770371
True expected value difference for MAP policy: 0.010539
Evaluating threshold 0.1 with avar bound: [3.2060064091601945]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.2060064091601945]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.2060064091601945]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.2060064091601945]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.2060064091601945]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.2060064091601945]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.2060064091601945]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.2060064091601945]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.2060064091601945]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.254
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38331494 -0.29717241  0.2762907  -0.653883   -0.04705544  0.2129895
  0.46182242]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 2.006486
0.95-VaR bound for 3 demonstrations: 2.425611
0.99-VaR bound for 3 demonstrations: 3.131439
True expected value difference for MAP policy: 0.009077
Evaluating threshold 0.1 with avar bound: [2.4256114095000925]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.4256114095000925]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.4256114095000925]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.4256114095000925]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.4256114095000925]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.4256114095000925]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.4256114095000925]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.4256114095000925]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.4256114095000925]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.241
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.55228925 -0.26648805  0.32059645 -0.52103689  0.06525433 -0.02340498
  0.49486691]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.016864
0.95-VaR bound for 4 demonstrations: 0.038510
0.99-VaR bound for 4 demonstrations: 0.198908
True expected value difference for MAP policy: 0.007159
Evaluating threshold 0.1 with avar bound: [0.03851025619257491]
Threshold 0.1 SUFFICIENT with avar bound: 0.03851025619257491
Evaluating threshold 0.2 with avar bound: [0.03851025619257491]
Threshold 0.2 SUFFICIENT with avar bound: 0.03851025619257491
Evaluating threshold 0.3 with avar bound: [0.03851025619257491]
Threshold 0.3 SUFFICIENT with avar bound: 0.03851025619257491
Evaluating threshold 0.4 with avar bound: [0.03851025619257491]
Threshold 0.4 SUFFICIENT with avar bound: 0.03851025619257491
Evaluating threshold 0.5 with avar bound: [0.03851025619257491]
Threshold 0.5 SUFFICIENT with avar bound: 0.03851025619257491
Evaluating threshold 0.6 with avar bound: [0.03851025619257491]
Threshold 0.6 SUFFICIENT with avar bound: 0.03851025619257491
Evaluating threshold 0.7 with avar bound: [0.03851025619257491]
Threshold 0.7 SUFFICIENT with avar bound: 0.03851025619257491
Evaluating threshold 0.8 with avar bound: [0.03851025619257491]
Threshold 0.8 SUFFICIENT with avar bound: 0.03851025619257491
Evaluating threshold 0.9 with avar bound: [0.03851025619257491]
Threshold 0.9 SUFFICIENT with avar bound: 0.03851025619257491

Running BIRL with demonstration 5/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.22
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.35875868 -0.24213873  0.39843954 -0.29656538  0.16698666 -0.07950011
  0.72921269]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.004721
0.95-VaR bound for 5 demonstrations: -0.001740
0.99-VaR bound for 5 demonstrations: 0.002251
True expected value difference for MAP policy: 0.007159
Evaluating threshold 0.1 with avar bound: [-0.001740334268358377]
Threshold 0.1 SUFFICIENT with avar bound: -0.001740334268358377
Evaluating threshold 0.2 with avar bound: [-0.001740334268358377]
Threshold 0.2 SUFFICIENT with avar bound: -0.001740334268358377
Evaluating threshold 0.3 with avar bound: [-0.001740334268358377]
Threshold 0.3 SUFFICIENT with avar bound: -0.001740334268358377
Evaluating threshold 0.4 with avar bound: [-0.001740334268358377]
Threshold 0.4 SUFFICIENT with avar bound: -0.001740334268358377
Evaluating threshold 0.5 with avar bound: [-0.001740334268358377]
Threshold 0.5 SUFFICIENT with avar bound: -0.001740334268358377
Evaluating threshold 0.6 with avar bound: [-0.001740334268358377]
Threshold 0.6 SUFFICIENT with avar bound: -0.001740334268358377
Evaluating threshold 0.7 with avar bound: [-0.001740334268358377]
Threshold 0.7 SUFFICIENT with avar bound: -0.001740334268358377
Evaluating threshold 0.8 with avar bound: [-0.001740334268358377]
Threshold 0.8 SUFFICIENT with avar bound: -0.001740334268358377
Evaluating threshold 0.9 with avar bound: [-0.001740334268358377]
Threshold 0.9 SUFFICIENT with avar bound: -0.001740334268358377

Running BIRL with demonstration 6/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.193
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.29516372 -0.15609846  0.36212676 -0.31322267 -0.10061096  0.43813813
  0.67615075]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: 0.011296
0.95-VaR bound for 6 demonstrations: 0.029955
0.99-VaR bound for 6 demonstrations: 0.029955
True expected value difference for MAP policy: 0.004278
Evaluating threshold 0.1 with avar bound: [0.029955087543598505]
Threshold 0.1 SUFFICIENT with avar bound: 0.029955087543598505
Evaluating threshold 0.2 with avar bound: [0.029955087543598505]
Threshold 0.2 SUFFICIENT with avar bound: 0.029955087543598505
Evaluating threshold 0.3 with avar bound: [0.029955087543598505]
Threshold 0.3 SUFFICIENT with avar bound: 0.029955087543598505
Evaluating threshold 0.4 with avar bound: [0.029955087543598505]
Threshold 0.4 SUFFICIENT with avar bound: 0.029955087543598505
Evaluating threshold 0.5 with avar bound: [0.029955087543598505]
Threshold 0.5 SUFFICIENT with avar bound: 0.029955087543598505
Evaluating threshold 0.6 with avar bound: [0.029955087543598505]
Threshold 0.6 SUFFICIENT with avar bound: 0.029955087543598505
Evaluating threshold 0.7 with avar bound: [0.029955087543598505]
Threshold 0.7 SUFFICIENT with avar bound: 0.029955087543598505
Evaluating threshold 0.8 with avar bound: [0.029955087543598505]
Threshold 0.8 SUFFICIENT with avar bound: 0.029955087543598505
Evaluating threshold 0.9 with avar bound: [0.029955087543598505]
Threshold 0.9 SUFFICIENT with avar bound: 0.029955087543598505

Running BIRL with demonstration 7/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.204
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.30019358 -0.17070895  0.26932783 -0.34486182 -0.56692067  0.12772152
  0.59292773]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.003972
0.95-VaR bound for 7 demonstrations: -0.002481
0.99-VaR bound for 7 demonstrations: 0.010675
True expected value difference for MAP policy: 0.005002
Evaluating threshold 0.1 with avar bound: [-0.002480858367840786]
Threshold 0.1 SUFFICIENT with avar bound: -0.002480858367840786
Evaluating threshold 0.2 with avar bound: [-0.002480858367840786]
Threshold 0.2 SUFFICIENT with avar bound: -0.002480858367840786
Evaluating threshold 0.3 with avar bound: [-0.002480858367840786]
Threshold 0.3 SUFFICIENT with avar bound: -0.002480858367840786
Evaluating threshold 0.4 with avar bound: [-0.002480858367840786]
Threshold 0.4 SUFFICIENT with avar bound: -0.002480858367840786
Evaluating threshold 0.5 with avar bound: [-0.002480858367840786]
Threshold 0.5 SUFFICIENT with avar bound: -0.002480858367840786
Evaluating threshold 0.6 with avar bound: [-0.002480858367840786]
Threshold 0.6 SUFFICIENT with avar bound: -0.002480858367840786
Evaluating threshold 0.7 with avar bound: [-0.002480858367840786]
Threshold 0.7 SUFFICIENT with avar bound: -0.002480858367840786
Evaluating threshold 0.8 with avar bound: [-0.002480858367840786]
Threshold 0.8 SUFFICIENT with avar bound: -0.002480858367840786
Evaluating threshold 0.9 with avar bound: [-0.002480858367840786]
Threshold 0.9 SUFFICIENT with avar bound: -0.002480858367840786

Running BIRL with demonstration 8/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.191
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.13008222 -0.35379824  0.52243795 -0.20579537 -0.12990825  0.19781094
  0.69757219]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.006681
0.95-VaR bound for 8 demonstrations: -0.000211
0.99-VaR bound for 8 demonstrations: 0.017016
True expected value difference for MAP policy: 0.006305
Evaluating threshold 0.1 with avar bound: [-0.00021103956375295997]
Threshold 0.1 SUFFICIENT with avar bound: -0.00021103956375295997
Evaluating threshold 0.2 with avar bound: [-0.00021103956375295997]
Threshold 0.2 SUFFICIENT with avar bound: -0.00021103956375295997
Evaluating threshold 0.3 with avar bound: [-0.00021103956375295997]
Threshold 0.3 SUFFICIENT with avar bound: -0.00021103956375295997
Evaluating threshold 0.4 with avar bound: [-0.00021103956375295997]
Threshold 0.4 SUFFICIENT with avar bound: -0.00021103956375295997
Evaluating threshold 0.5 with avar bound: [-0.00021103956375295997]
Threshold 0.5 SUFFICIENT with avar bound: -0.00021103956375295997
Evaluating threshold 0.6 with avar bound: [-0.00021103956375295997]
Threshold 0.6 SUFFICIENT with avar bound: -0.00021103956375295997
Evaluating threshold 0.7 with avar bound: [-0.00021103956375295997]
Threshold 0.7 SUFFICIENT with avar bound: -0.00021103956375295997
Evaluating threshold 0.8 with avar bound: [-0.00021103956375295997]
Threshold 0.8 SUFFICIENT with avar bound: -0.00021103956375295997
Evaluating threshold 0.9 with avar bound: [-0.00021103956375295997]
Threshold 0.9 SUFFICIENT with avar bound: -0.00021103956375295997

Running BIRL with demonstration 9/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.124
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.45804855 -0.25252889 -0.02860751 -0.0977523   0.12209212  0.44671603
  0.70822671]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.008115
0.95-VaR bound for 9 demonstrations: -0.008026
0.99-VaR bound for 9 demonstrations: -0.004656
True expected value difference for MAP policy: -0.010101
Evaluating threshold 0.1 with avar bound: [-0.008026005150932864]
Threshold 0.1 SUFFICIENT with avar bound: -0.008026005150932864
Evaluating threshold 0.2 with avar bound: [-0.008026005150932864]
Threshold 0.2 SUFFICIENT with avar bound: -0.008026005150932864
Evaluating threshold 0.3 with avar bound: [-0.008026005150932864]
Threshold 0.3 SUFFICIENT with avar bound: -0.008026005150932864
Evaluating threshold 0.4 with avar bound: [-0.008026005150932864]
Threshold 0.4 SUFFICIENT with avar bound: -0.008026005150932864
Evaluating threshold 0.5 with avar bound: [-0.008026005150932864]
Threshold 0.5 SUFFICIENT with avar bound: -0.008026005150932864
Evaluating threshold 0.6 with avar bound: [-0.008026005150932864]
Threshold 0.6 SUFFICIENT with avar bound: -0.008026005150932864
Evaluating threshold 0.7 with avar bound: [-0.008026005150932864]
Threshold 0.7 SUFFICIENT with avar bound: -0.008026005150932864
Evaluating threshold 0.8 with avar bound: [-0.008026005150932864]
Threshold 0.8 SUFFICIENT with avar bound: -0.008026005150932864
Evaluating threshold 0.9 with avar bound: [-0.008026005150932864]
Threshold 0.9 SUFFICIENT with avar bound: -0.008026005150932864

Running BIRL with demonstration 10/10 in world 8
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.138
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.6653504  -0.31661759 -0.1972581   0.01221756  0.22127975  0.18919788
  0.57727078]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.002664
0.95-VaR bound for 10 demonstrations: 0.002210
0.99-VaR bound for 10 demonstrations: 0.033585
True expected value difference for MAP policy: -0.009834
Evaluating threshold 0.1 with avar bound: [0.0022096297337085217]
Threshold 0.1 SUFFICIENT with avar bound: 0.0022096297337085217
Evaluating threshold 0.2 with avar bound: [0.0022096297337085217]
Threshold 0.2 SUFFICIENT with avar bound: 0.0022096297337085217
Evaluating threshold 0.3 with avar bound: [0.0022096297337085217]
Threshold 0.3 SUFFICIENT with avar bound: 0.0022096297337085217
Evaluating threshold 0.4 with avar bound: [0.0022096297337085217]
Threshold 0.4 SUFFICIENT with avar bound: 0.0022096297337085217
Evaluating threshold 0.5 with avar bound: [0.0022096297337085217]
Threshold 0.5 SUFFICIENT with avar bound: 0.0022096297337085217
Evaluating threshold 0.6 with avar bound: [0.0022096297337085217]
Threshold 0.6 SUFFICIENT with avar bound: 0.0022096297337085217
Evaluating threshold 0.7 with avar bound: [0.0022096297337085217]
Threshold 0.7 SUFFICIENT with avar bound: 0.0022096297337085217
Evaluating threshold 0.8 with avar bound: [0.0022096297337085217]
Threshold 0.8 SUFFICIENT with avar bound: 0.0022096297337085217
Evaluating threshold 0.9 with avar bound: [0.0022096297337085217]
Threshold 0.9 SUFFICIENT with avar bound: 0.0022096297337085217

Saving results to files...
Results saved successfully.

Running world 9/20

Running BIRL with demonstration 1/10 in world 9
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.359
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.03077    -0.4128519  -0.14467426 -0.74278919 -0.40232456  0.10983998
  0.28637428]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 2.061396
0.95-VaR bound for 1 demonstrations: 3.244738
0.99-VaR bound for 1 demonstrations: 7.824870
True expected value difference for MAP policy: -0.003550
Evaluating threshold 0.1 with avar bound: [3.244737852885447]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.244737852885447]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.244737852885447]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.244737852885447]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.244737852885447]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.244737852885447]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.244737852885447]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.244737852885447]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.244737852885447]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 9
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.291
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.04937374  0.7368929  -0.33775564 -0.1973316   0.06929998  0.54132088
  0.06084136]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 2.176641
0.95-VaR bound for 2 demonstrations: 3.003974
0.99-VaR bound for 2 demonstrations: 8.460313
True expected value difference for MAP policy: 1.728573
Evaluating threshold 0.1 with avar bound: [3.0039741964748385]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.0039741964748385]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.0039741964748385]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.0039741964748385]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.0039741964748385]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.0039741964748385]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.0039741964748385]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.0039741964748385]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.0039741964748385]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.29
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61080717  0.72317059  0.03180084 -0.27074088  0.06000734 -0.08290986
  0.13839096]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.999474
0.95-VaR bound for 3 demonstrations: 1.482898
0.99-VaR bound for 3 demonstrations: 2.559698
True expected value difference for MAP policy: 1.734018
Evaluating threshold 0.1 with avar bound: [1.4828982114703595]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4828982114703595]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4828982114703595]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4828982114703595]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4828982114703595]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4828982114703595]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4828982114703595]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4828982114703595]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4828982114703595]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.229
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.36651257  0.41063148 -0.45609081 -0.41676878 -0.44667576 -0.10986079
  0.32209728]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.206922
0.95-VaR bound for 4 demonstrations: 0.575902
0.99-VaR bound for 4 demonstrations: 0.830468
True expected value difference for MAP policy: 0.098152
Evaluating threshold 0.1 with avar bound: [0.5759022122554485]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.5759022122554485]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.5759022122554485]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.5759022122554485]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.5759022122554485]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.5759022122554485]
Threshold 0.6 SUFFICIENT with avar bound: 0.5759022122554485
Evaluating threshold 0.7 with avar bound: [0.5759022122554485]
Threshold 0.7 SUFFICIENT with avar bound: 0.5759022122554485
Evaluating threshold 0.8 with avar bound: [0.5759022122554485]
Threshold 0.8 SUFFICIENT with avar bound: 0.5759022122554485
Evaluating threshold 0.9 with avar bound: [0.5759022122554485]
Threshold 0.9 SUFFICIENT with avar bound: 0.5759022122554485

Running BIRL with demonstration 5/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.24030506  0.52849821 -0.66433296 -0.08805758 -0.14445633  0.00396215
  0.43928051]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: 0.081018
0.95-VaR bound for 5 demonstrations: 0.133910
0.99-VaR bound for 5 demonstrations: 0.171270
True expected value difference for MAP policy: 0.087857
Evaluating threshold 0.1 with avar bound: [0.1339103186774376]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.1339103186774376]
Threshold 0.2 SUFFICIENT with avar bound: 0.1339103186774376
Evaluating threshold 0.3 with avar bound: [0.1339103186774376]
Threshold 0.3 SUFFICIENT with avar bound: 0.1339103186774376
Evaluating threshold 0.4 with avar bound: [0.1339103186774376]
Threshold 0.4 SUFFICIENT with avar bound: 0.1339103186774376
Evaluating threshold 0.5 with avar bound: [0.1339103186774376]
Threshold 0.5 SUFFICIENT with avar bound: 0.1339103186774376
Evaluating threshold 0.6 with avar bound: [0.1339103186774376]
Threshold 0.6 SUFFICIENT with avar bound: 0.1339103186774376
Evaluating threshold 0.7 with avar bound: [0.1339103186774376]
Threshold 0.7 SUFFICIENT with avar bound: 0.1339103186774376
Evaluating threshold 0.8 with avar bound: [0.1339103186774376]
Threshold 0.8 SUFFICIENT with avar bound: 0.1339103186774376
Evaluating threshold 0.9 with avar bound: [0.1339103186774376]
Threshold 0.9 SUFFICIENT with avar bound: 0.1339103186774376

Running BIRL with demonstration 6/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.169
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.64544181 -0.1809167  -0.56743953 -0.08971559 -0.22943216  0.11862715
  0.39233402]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.005349
0.95-VaR bound for 6 demonstrations: -0.002052
0.99-VaR bound for 6 demonstrations: 0.005252
True expected value difference for MAP policy: -0.008907
Evaluating threshold 0.1 with avar bound: [-0.0020517961822381506]
Threshold 0.1 SUFFICIENT with avar bound: -0.0020517961822381506
Evaluating threshold 0.2 with avar bound: [-0.0020517961822381506]
Threshold 0.2 SUFFICIENT with avar bound: -0.0020517961822381506
Evaluating threshold 0.3 with avar bound: [-0.0020517961822381506]
Threshold 0.3 SUFFICIENT with avar bound: -0.0020517961822381506
Evaluating threshold 0.4 with avar bound: [-0.0020517961822381506]
Threshold 0.4 SUFFICIENT with avar bound: -0.0020517961822381506
Evaluating threshold 0.5 with avar bound: [-0.0020517961822381506]
Threshold 0.5 SUFFICIENT with avar bound: -0.0020517961822381506
Evaluating threshold 0.6 with avar bound: [-0.0020517961822381506]
Threshold 0.6 SUFFICIENT with avar bound: -0.0020517961822381506
Evaluating threshold 0.7 with avar bound: [-0.0020517961822381506]
Threshold 0.7 SUFFICIENT with avar bound: -0.0020517961822381506
Evaluating threshold 0.8 with avar bound: [-0.0020517961822381506]
Threshold 0.8 SUFFICIENT with avar bound: -0.0020517961822381506
Evaluating threshold 0.9 with avar bound: [-0.0020517961822381506]
Threshold 0.9 SUFFICIENT with avar bound: -0.0020517961822381506

Running BIRL with demonstration 7/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.159
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.52528326  0.38838616 -0.44353708 -0.02169917  0.01093764 -0.23206205
  0.56750794]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: 0.004116
0.95-VaR bound for 7 demonstrations: 0.014432
0.99-VaR bound for 7 demonstrations: 0.088090
True expected value difference for MAP policy: -0.004148
Evaluating threshold 0.1 with avar bound: [0.014432019911836324]
Threshold 0.1 SUFFICIENT with avar bound: 0.014432019911836324
Evaluating threshold 0.2 with avar bound: [0.014432019911836324]
Threshold 0.2 SUFFICIENT with avar bound: 0.014432019911836324
Evaluating threshold 0.3 with avar bound: [0.014432019911836324]
Threshold 0.3 SUFFICIENT with avar bound: 0.014432019911836324
Evaluating threshold 0.4 with avar bound: [0.014432019911836324]
Threshold 0.4 SUFFICIENT with avar bound: 0.014432019911836324
Evaluating threshold 0.5 with avar bound: [0.014432019911836324]
Threshold 0.5 SUFFICIENT with avar bound: 0.014432019911836324
Evaluating threshold 0.6 with avar bound: [0.014432019911836324]
Threshold 0.6 SUFFICIENT with avar bound: 0.014432019911836324
Evaluating threshold 0.7 with avar bound: [0.014432019911836324]
Threshold 0.7 SUFFICIENT with avar bound: 0.014432019911836324
Evaluating threshold 0.8 with avar bound: [0.014432019911836324]
Threshold 0.8 SUFFICIENT with avar bound: 0.014432019911836324
Evaluating threshold 0.9 with avar bound: [0.014432019911836324]
Threshold 0.9 SUFFICIENT with avar bound: 0.014432019911836324

Running BIRL with demonstration 8/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.134
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62081697  0.48081886 -0.16181975 -0.13860027  0.10031036 -0.08044357
  0.5669837 ]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: 0.003899
0.95-VaR bound for 8 demonstrations: 0.005431
0.99-VaR bound for 8 demonstrations: 0.026833
True expected value difference for MAP policy: -0.005868
Evaluating threshold 0.1 with avar bound: [0.005430588610785336]
Threshold 0.1 SUFFICIENT with avar bound: 0.005430588610785336
Evaluating threshold 0.2 with avar bound: [0.005430588610785336]
Threshold 0.2 SUFFICIENT with avar bound: 0.005430588610785336
Evaluating threshold 0.3 with avar bound: [0.005430588610785336]
Threshold 0.3 SUFFICIENT with avar bound: 0.005430588610785336
Evaluating threshold 0.4 with avar bound: [0.005430588610785336]
Threshold 0.4 SUFFICIENT with avar bound: 0.005430588610785336
Evaluating threshold 0.5 with avar bound: [0.005430588610785336]
Threshold 0.5 SUFFICIENT with avar bound: 0.005430588610785336
Evaluating threshold 0.6 with avar bound: [0.005430588610785336]
Threshold 0.6 SUFFICIENT with avar bound: 0.005430588610785336
Evaluating threshold 0.7 with avar bound: [0.005430588610785336]
Threshold 0.7 SUFFICIENT with avar bound: 0.005430588610785336
Evaluating threshold 0.8 with avar bound: [0.005430588610785336]
Threshold 0.8 SUFFICIENT with avar bound: 0.005430588610785336
Evaluating threshold 0.9 with avar bound: [0.005430588610785336]
Threshold 0.9 SUFFICIENT with avar bound: 0.005430588610785336

Running BIRL with demonstration 9/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.166
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61989533  0.20110184 -0.17848805 -0.22932072  0.11379414  0.26909505
  0.63677359]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.005466
0.95-VaR bound for 9 demonstrations: -0.004801
0.99-VaR bound for 9 demonstrations: 0.005376
True expected value difference for MAP policy: -0.009806
Evaluating threshold 0.1 with avar bound: [-0.004800940206831954]
Threshold 0.1 SUFFICIENT with avar bound: -0.004800940206831954
Evaluating threshold 0.2 with avar bound: [-0.004800940206831954]
Threshold 0.2 SUFFICIENT with avar bound: -0.004800940206831954
Evaluating threshold 0.3 with avar bound: [-0.004800940206831954]
Threshold 0.3 SUFFICIENT with avar bound: -0.004800940206831954
Evaluating threshold 0.4 with avar bound: [-0.004800940206831954]
Threshold 0.4 SUFFICIENT with avar bound: -0.004800940206831954
Evaluating threshold 0.5 with avar bound: [-0.004800940206831954]
Threshold 0.5 SUFFICIENT with avar bound: -0.004800940206831954
Evaluating threshold 0.6 with avar bound: [-0.004800940206831954]
Threshold 0.6 SUFFICIENT with avar bound: -0.004800940206831954
Evaluating threshold 0.7 with avar bound: [-0.004800940206831954]
Threshold 0.7 SUFFICIENT with avar bound: -0.004800940206831954
Evaluating threshold 0.8 with avar bound: [-0.004800940206831954]
Threshold 0.8 SUFFICIENT with avar bound: -0.004800940206831954
Evaluating threshold 0.9 with avar bound: [-0.004800940206831954]
Threshold 0.9 SUFFICIENT with avar bound: -0.004800940206831954

Running BIRL with demonstration 10/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.147
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.55042627  0.36657376 -0.17038398 -0.20847203  0.23973074  0.33771897
  0.56448063]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.005824
0.95-VaR bound for 10 demonstrations: -0.001543
0.99-VaR bound for 10 demonstrations: 0.001946
True expected value difference for MAP policy: -0.005542
Evaluating threshold 0.1 with avar bound: [-0.0015428628591368102]
Threshold 0.1 SUFFICIENT with avar bound: -0.0015428628591368102
Evaluating threshold 0.2 with avar bound: [-0.0015428628591368102]
Threshold 0.2 SUFFICIENT with avar bound: -0.0015428628591368102
Evaluating threshold 0.3 with avar bound: [-0.0015428628591368102]
Threshold 0.3 SUFFICIENT with avar bound: -0.0015428628591368102
Evaluating threshold 0.4 with avar bound: [-0.0015428628591368102]
Threshold 0.4 SUFFICIENT with avar bound: -0.0015428628591368102
Evaluating threshold 0.5 with avar bound: [-0.0015428628591368102]
Threshold 0.5 SUFFICIENT with avar bound: -0.0015428628591368102
Evaluating threshold 0.6 with avar bound: [-0.0015428628591368102]
Threshold 0.6 SUFFICIENT with avar bound: -0.0015428628591368102
Evaluating threshold 0.7 with avar bound: [-0.0015428628591368102]
Threshold 0.7 SUFFICIENT with avar bound: -0.0015428628591368102
Evaluating threshold 0.8 with avar bound: [-0.0015428628591368102]
Threshold 0.8 SUFFICIENT with avar bound: -0.0015428628591368102
Evaluating threshold 0.9 with avar bound: [-0.0015428628591368102]
Threshold 0.9 SUFFICIENT with avar bound: -0.0015428628591368102

Running world 10/20

Running BIRL with demonstration 1/10 in world 10
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.304
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.09768092 -0.11749022 -0.25662316 -0.57380829 -0.26792575 -0.39039308
  0.59778936]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 1.721658
0.95-VaR bound for 1 demonstrations: 2.641559
0.99-VaR bound for 1 demonstrations: 17.145492
True expected value difference for MAP policy: 0.008048
Evaluating threshold 0.1 with avar bound: [2.64155855226077]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.64155855226077]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.64155855226077]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.64155855226077]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.64155855226077]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.64155855226077]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.64155855226077]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.64155855226077]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.64155855226077]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 10
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.223
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.59705578 -0.0399899   0.06307643 -0.25858648  0.45627873  0.28265119
  0.53197521]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 2 demonstrations: 0.011769
0.95-VaR bound for 2 demonstrations: 0.021820
0.99-VaR bound for 2 demonstrations: 0.122950
True expected value difference for MAP policy: -0.007915
Evaluating threshold 0.1 with avar bound: [0.021820278816247547]
Threshold 0.1 SUFFICIENT with avar bound: 0.021820278816247547
Evaluating threshold 0.2 with avar bound: [0.021820278816247547]
Threshold 0.2 SUFFICIENT with avar bound: 0.021820278816247547
Evaluating threshold 0.3 with avar bound: [0.021820278816247547]
Threshold 0.3 SUFFICIENT with avar bound: 0.021820278816247547
Evaluating threshold 0.4 with avar bound: [0.021820278816247547]
Threshold 0.4 SUFFICIENT with avar bound: 0.021820278816247547
Evaluating threshold 0.5 with avar bound: [0.021820278816247547]
Threshold 0.5 SUFFICIENT with avar bound: 0.021820278816247547
Evaluating threshold 0.6 with avar bound: [0.021820278816247547]
Threshold 0.6 SUFFICIENT with avar bound: 0.021820278816247547
Evaluating threshold 0.7 with avar bound: [0.021820278816247547]
Threshold 0.7 SUFFICIENT with avar bound: 0.021820278816247547
Evaluating threshold 0.8 with avar bound: [0.021820278816247547]
Threshold 0.8 SUFFICIENT with avar bound: 0.021820278816247547
Evaluating threshold 0.9 with avar bound: [0.021820278816247547]
Threshold 0.9 SUFFICIENT with avar bound: 0.021820278816247547

Running BIRL with demonstration 3/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.22
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.66907     0.24553146  0.10048295 -0.30312506 -0.00567846 -0.2204412
  0.58433846]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 3 demonstrations: 0.008035
0.95-VaR bound for 3 demonstrations: 0.011960
0.99-VaR bound for 3 demonstrations: 0.039649
True expected value difference for MAP policy: -0.001433
Evaluating threshold 0.1 with avar bound: [0.011960085732877683]
Threshold 0.1 SUFFICIENT with avar bound: 0.011960085732877683
Evaluating threshold 0.2 with avar bound: [0.011960085732877683]
Threshold 0.2 SUFFICIENT with avar bound: 0.011960085732877683
Evaluating threshold 0.3 with avar bound: [0.011960085732877683]
Threshold 0.3 SUFFICIENT with avar bound: 0.011960085732877683
Evaluating threshold 0.4 with avar bound: [0.011960085732877683]
Threshold 0.4 SUFFICIENT with avar bound: 0.011960085732877683
Evaluating threshold 0.5 with avar bound: [0.011960085732877683]
Threshold 0.5 SUFFICIENT with avar bound: 0.011960085732877683
Evaluating threshold 0.6 with avar bound: [0.011960085732877683]
Threshold 0.6 SUFFICIENT with avar bound: 0.011960085732877683
Evaluating threshold 0.7 with avar bound: [0.011960085732877683]
Threshold 0.7 SUFFICIENT with avar bound: 0.011960085732877683
Evaluating threshold 0.8 with avar bound: [0.011960085732877683]
Threshold 0.8 SUFFICIENT with avar bound: 0.011960085732877683
Evaluating threshold 0.9 with avar bound: [0.011960085732877683]
Threshold 0.9 SUFFICIENT with avar bound: 0.011960085732877683

Running BIRL with demonstration 4/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.219
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.67957263 -0.25050057  0.22053282 -0.31312205 -0.01629998 -0.28734638
  0.49589992]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 4 demonstrations: 0.017444
0.95-VaR bound for 4 demonstrations: 0.034305
0.99-VaR bound for 4 demonstrations: 0.048905
True expected value difference for MAP policy: -0.000805
Evaluating threshold 0.1 with avar bound: [0.034304763579039235]
Threshold 0.1 SUFFICIENT with avar bound: 0.034304763579039235
Evaluating threshold 0.2 with avar bound: [0.034304763579039235]
Threshold 0.2 SUFFICIENT with avar bound: 0.034304763579039235
Evaluating threshold 0.3 with avar bound: [0.034304763579039235]
Threshold 0.3 SUFFICIENT with avar bound: 0.034304763579039235
Evaluating threshold 0.4 with avar bound: [0.034304763579039235]
Threshold 0.4 SUFFICIENT with avar bound: 0.034304763579039235
Evaluating threshold 0.5 with avar bound: [0.034304763579039235]
Threshold 0.5 SUFFICIENT with avar bound: 0.034304763579039235
Evaluating threshold 0.6 with avar bound: [0.034304763579039235]
Threshold 0.6 SUFFICIENT with avar bound: 0.034304763579039235
Evaluating threshold 0.7 with avar bound: [0.034304763579039235]
Threshold 0.7 SUFFICIENT with avar bound: 0.034304763579039235
Evaluating threshold 0.8 with avar bound: [0.034304763579039235]
Threshold 0.8 SUFFICIENT with avar bound: 0.034304763579039235
Evaluating threshold 0.9 with avar bound: [0.034304763579039235]
Threshold 0.9 SUFFICIENT with avar bound: 0.034304763579039235

Running BIRL with demonstration 5/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.191
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62583667 -0.09245973  0.4118841  -0.3485034   0.10411254 -0.03400652
  0.54468401]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 5 demonstrations: -0.002869
0.95-VaR bound for 5 demonstrations: 0.000410
0.99-VaR bound for 5 demonstrations: 0.007973
True expected value difference for MAP policy: 0.000564
Evaluating threshold 0.1 with avar bound: [0.0004099223134875366]
Threshold 0.1 SUFFICIENT with avar bound: 0.0004099223134875366
Evaluating threshold 0.2 with avar bound: [0.0004099223134875366]
Threshold 0.2 SUFFICIENT with avar bound: 0.0004099223134875366
Evaluating threshold 0.3 with avar bound: [0.0004099223134875366]
Threshold 0.3 SUFFICIENT with avar bound: 0.0004099223134875366
Evaluating threshold 0.4 with avar bound: [0.0004099223134875366]
Threshold 0.4 SUFFICIENT with avar bound: 0.0004099223134875366
Evaluating threshold 0.5 with avar bound: [0.0004099223134875366]
Threshold 0.5 SUFFICIENT with avar bound: 0.0004099223134875366
Evaluating threshold 0.6 with avar bound: [0.0004099223134875366]
Threshold 0.6 SUFFICIENT with avar bound: 0.0004099223134875366
Evaluating threshold 0.7 with avar bound: [0.0004099223134875366]
Threshold 0.7 SUFFICIENT with avar bound: 0.0004099223134875366
Evaluating threshold 0.8 with avar bound: [0.0004099223134875366]
Threshold 0.8 SUFFICIENT with avar bound: 0.0004099223134875366
Evaluating threshold 0.9 with avar bound: [0.0004099223134875366]
Threshold 0.9 SUFFICIENT with avar bound: 0.0004099223134875366

Running BIRL with demonstration 6/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.157
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.40323876 -0.52217091 -0.06025755 -0.27563133  0.0964335   0.25430498
  0.64121915]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 6 demonstrations: -0.000879
0.95-VaR bound for 6 demonstrations: 0.001204
0.99-VaR bound for 6 demonstrations: 0.007285
True expected value difference for MAP policy: -0.007717
Evaluating threshold 0.1 with avar bound: [0.001203911736089369]
Threshold 0.1 SUFFICIENT with avar bound: 0.001203911736089369
Evaluating threshold 0.2 with avar bound: [0.001203911736089369]
Threshold 0.2 SUFFICIENT with avar bound: 0.001203911736089369
Evaluating threshold 0.3 with avar bound: [0.001203911736089369]
Threshold 0.3 SUFFICIENT with avar bound: 0.001203911736089369
Evaluating threshold 0.4 with avar bound: [0.001203911736089369]
Threshold 0.4 SUFFICIENT with avar bound: 0.001203911736089369
Evaluating threshold 0.5 with avar bound: [0.001203911736089369]
Threshold 0.5 SUFFICIENT with avar bound: 0.001203911736089369
Evaluating threshold 0.6 with avar bound: [0.001203911736089369]
Threshold 0.6 SUFFICIENT with avar bound: 0.001203911736089369
Evaluating threshold 0.7 with avar bound: [0.001203911736089369]
Threshold 0.7 SUFFICIENT with avar bound: 0.001203911736089369
Evaluating threshold 0.8 with avar bound: [0.001203911736089369]
Threshold 0.8 SUFFICIENT with avar bound: 0.001203911736089369
Evaluating threshold 0.9 with avar bound: [0.001203911736089369]
Threshold 0.9 SUFFICIENT with avar bound: 0.001203911736089369

Running BIRL with demonstration 7/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.15
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.56997547 -0.53833932 -0.21640509 -0.25125261  0.10496     0.24503802
  0.45199498]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 7 demonstrations: -0.003873
0.95-VaR bound for 7 demonstrations: 0.007635
0.99-VaR bound for 7 demonstrations: 0.056765
True expected value difference for MAP policy: -0.008671
Evaluating threshold 0.1 with avar bound: [0.0076354958431832124]
Threshold 0.1 SUFFICIENT with avar bound: 0.0076354958431832124
Evaluating threshold 0.2 with avar bound: [0.0076354958431832124]
Threshold 0.2 SUFFICIENT with avar bound: 0.0076354958431832124
Evaluating threshold 0.3 with avar bound: [0.0076354958431832124]
Threshold 0.3 SUFFICIENT with avar bound: 0.0076354958431832124
Evaluating threshold 0.4 with avar bound: [0.0076354958431832124]
Threshold 0.4 SUFFICIENT with avar bound: 0.0076354958431832124
Evaluating threshold 0.5 with avar bound: [0.0076354958431832124]
Threshold 0.5 SUFFICIENT with avar bound: 0.0076354958431832124
Evaluating threshold 0.6 with avar bound: [0.0076354958431832124]
Threshold 0.6 SUFFICIENT with avar bound: 0.0076354958431832124
Evaluating threshold 0.7 with avar bound: [0.0076354958431832124]
Threshold 0.7 SUFFICIENT with avar bound: 0.0076354958431832124
Evaluating threshold 0.8 with avar bound: [0.0076354958431832124]
Threshold 0.8 SUFFICIENT with avar bound: 0.0076354958431832124
Evaluating threshold 0.9 with avar bound: [0.0076354958431832124]
Threshold 0.9 SUFFICIENT with avar bound: 0.0076354958431832124

Running BIRL with demonstration 8/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.135
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.23420958 -0.09347083  0.16420992 -0.0478256   0.46152031  0.46552356
  0.69097302]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 8 demonstrations: -0.006475
0.95-VaR bound for 8 demonstrations: 0.000283
0.99-VaR bound for 8 demonstrations: 0.000283
True expected value difference for MAP policy: -0.008671
Evaluating threshold 0.1 with avar bound: [0.00028290739566439355]
Threshold 0.1 SUFFICIENT with avar bound: 0.00028290739566439355
Evaluating threshold 0.2 with avar bound: [0.00028290739566439355]
Threshold 0.2 SUFFICIENT with avar bound: 0.00028290739566439355
Evaluating threshold 0.3 with avar bound: [0.00028290739566439355]
Threshold 0.3 SUFFICIENT with avar bound: 0.00028290739566439355
Evaluating threshold 0.4 with avar bound: [0.00028290739566439355]
Threshold 0.4 SUFFICIENT with avar bound: 0.00028290739566439355
Evaluating threshold 0.5 with avar bound: [0.00028290739566439355]
Threshold 0.5 SUFFICIENT with avar bound: 0.00028290739566439355
Evaluating threshold 0.6 with avar bound: [0.00028290739566439355]
Threshold 0.6 SUFFICIENT with avar bound: 0.00028290739566439355
Evaluating threshold 0.7 with avar bound: [0.00028290739566439355]
Threshold 0.7 SUFFICIENT with avar bound: 0.00028290739566439355
Evaluating threshold 0.8 with avar bound: [0.00028290739566439355]
Threshold 0.8 SUFFICIENT with avar bound: 0.00028290739566439355
Evaluating threshold 0.9 with avar bound: [0.00028290739566439355]
Threshold 0.9 SUFFICIENT with avar bound: 0.00028290739566439355

Running BIRL with demonstration 9/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.14
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.53400078 -0.28880014 -0.06352501 -0.11903164  0.33889579  0.30738732
  0.63552842]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 9 demonstrations: -0.007371
0.95-VaR bound for 9 demonstrations: -0.002609
0.99-VaR bound for 9 demonstrations: -0.002114
True expected value difference for MAP policy: -0.008671
Evaluating threshold 0.1 with avar bound: [-0.0026094938677318972]
Threshold 0.1 SUFFICIENT with avar bound: -0.0026094938677318972
Evaluating threshold 0.2 with avar bound: [-0.0026094938677318972]
Threshold 0.2 SUFFICIENT with avar bound: -0.0026094938677318972
Evaluating threshold 0.3 with avar bound: [-0.0026094938677318972]
Threshold 0.3 SUFFICIENT with avar bound: -0.0026094938677318972
Evaluating threshold 0.4 with avar bound: [-0.0026094938677318972]
Threshold 0.4 SUFFICIENT with avar bound: -0.0026094938677318972
Evaluating threshold 0.5 with avar bound: [-0.0026094938677318972]
Threshold 0.5 SUFFICIENT with avar bound: -0.0026094938677318972
Evaluating threshold 0.6 with avar bound: [-0.0026094938677318972]
Threshold 0.6 SUFFICIENT with avar bound: -0.0026094938677318972
Evaluating threshold 0.7 with avar bound: [-0.0026094938677318972]
Threshold 0.7 SUFFICIENT with avar bound: -0.0026094938677318972
Evaluating threshold 0.8 with avar bound: [-0.0026094938677318972]
Threshold 0.8 SUFFICIENT with avar bound: -0.0026094938677318972
Evaluating threshold 0.9 with avar bound: [-0.0026094938677318972]
Threshold 0.9 SUFFICIENT with avar bound: -0.0026094938677318972

Running BIRL with demonstration 10/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.154
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.3401515  -0.46457385 -0.14196055 -0.30828366  0.19948109  0.21814273
  0.68256687]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.9-VaR bound for 10 demonstrations: -0.007854
0.95-VaR bound for 10 demonstrations: -0.006482
0.99-VaR bound for 10 demonstrations: -0.003082
True expected value difference for MAP policy: -0.008671
Evaluating threshold 0.1 with avar bound: [-0.006482169345861347]
Threshold 0.1 SUFFICIENT with avar bound: -0.006482169345861347
Evaluating threshold 0.2 with avar bound: [-0.006482169345861347]
Threshold 0.2 SUFFICIENT with avar bound: -0.006482169345861347
Evaluating threshold 0.3 with avar bound: [-0.006482169345861347]
Threshold 0.3 SUFFICIENT with avar bound: -0.006482169345861347
Evaluating threshold 0.4 with avar bound: [-0.006482169345861347]
Threshold 0.4 SUFFICIENT with avar bound: -0.006482169345861347
Evaluating threshold 0.5 with avar bound: [-0.006482169345861347]
Threshold 0.5 SUFFICIENT with avar bound: -0.006482169345861347
Evaluating threshold 0.6 with avar bound: [-0.006482169345861347]
Threshold 0.6 SUFFICIENT with avar bound: -0.006482169345861347
Evaluating threshold 0.7 with avar bound: [-0.006482169345861347]
Threshold 0.7 SUFFICIENT with avar bound: -0.006482169345861347
Evaluating threshold 0.8 with avar bound: [-0.006482169345861347]
Threshold 0.8 SUFFICIENT with avar bound: -0.006482169345861347
Evaluating threshold 0.9 with avar bound: [-0.006482169345861347]
Threshold 0.9 SUFFICIENT with avar bound: -0.006482169345861347

Running world 11/20

Running BIRL with demonstration 1/10 in world 11
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.447
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.02352427 -0.18246331 -0.27544648 -0.88439759 -0.12902125  0.01106379
  0.3022499 ]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.9-VaR bound for 1 demonstrations: 3.902757
0.95-VaR bound for 1 demonstrations: 5.562054
0.99-VaR bound for 1 demonstrations: 26.034455
