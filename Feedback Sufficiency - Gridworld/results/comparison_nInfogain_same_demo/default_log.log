Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6168
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.86001218  0.16060023 -0.48434143]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000019

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6292
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9725995   0.07389434 -0.22043104]
True reward weights: [0.57471065 0.80125784 0.16641378]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000259

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6292
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.85503634  0.16617125 -0.49122294]
True reward weights: [0.57471065 0.80125784 0.16641378]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000131

Running experiment 2/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6244
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.44329479 -0.79962188  0.4050859 ]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000035

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.57075928 -0.25687343  0.77990376]
True reward weights: [0.73754506 0.26507697 0.621097  ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000583

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6076
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.86225324 -0.1628833   0.47957104]
True reward weights: [0.73754506 0.26507697 0.621097  ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000316

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6162
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.93650436  0.2343589   0.26083615]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000028

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6246
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.91170903  0.12997408 -0.38973501]
True reward weights: [ 0.2219584   0.39493405 -0.89149401]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000416

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6228
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.48742223  0.87196315 -0.04582393]
True reward weights: [ 0.2219584   0.39493405 -0.89149401]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000012

Running experiment 4/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99533981 -0.02989865  0.09167728]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000052

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6152
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.2387925  0.85391595 0.46239128]
True reward weights: [-0.91148564  0.36951193  0.18070655]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000561

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6200
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89124741 -0.14343298  0.43023836]
True reward weights: [-0.91148564  0.36951193  0.18070655]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000058

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6118
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.96553713 -0.0825304   0.24683351]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000023

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6214
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99865759  0.01902333 -0.0481782 ]
True reward weights: [-0.7890655  -0.59247019  0.16234132]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000390

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6066
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.10738537  0.31455867 -0.94314433]
True reward weights: [-0.7890655  -0.59247019  0.16234132]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000005

Running experiment 6/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6218
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.77905311 -0.19950194  0.59436961]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000029

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6170
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.6316918  -0.24615946  0.7350993 ]
True reward weights: [-0.10243464  0.01052702 -0.99468403]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000556

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6064
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.8298425   0.17801334 -0.52884088]
True reward weights: [-0.10243464  0.01052702 -0.99468403]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000295

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6142
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.92862368  0.1178341  -0.35181412]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000043

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6120
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.52403383  0.2715348  -0.807253  ]
True reward weights: [-0.81432967 -0.55249027 -0.17782492]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000725

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6310
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.43201674  0.286566   -0.85512658]
True reward weights: [-0.81432967 -0.55249027 -0.17782492]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000200

Running experiment 8/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6212
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.18422638  0.9738836  -0.13270783]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000022

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6328
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.46578726  0.28112495 -0.83905363]
True reward weights: [0.06946414 0.91235863 0.40345566]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000332

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6064
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.68786828  0.22980152 -0.68849727]
True reward weights: [0.06946414 0.91235863 0.40345566]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000098

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6166
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99969843 -0.00971092  0.02255522]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000049

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6170
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.42264333  0.28526043 -0.86023201]
True reward weights: [0.09999761 0.60000486 0.79372202]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000479

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6128
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.16298431  0.31317992 -0.93560379]
True reward weights: [0.09999761 0.60000486 0.79372202]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000136

Running experiment 10/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6198
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.88281408 -0.14843948  0.44565123]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000044

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6212
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.82954056 -0.1762819   0.52989352]
True reward weights: [-0.34150412  0.82626007  0.4479612 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000465

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.24889251  0.30375003 -0.91966757]
True reward weights: [-0.34150412  0.82626007  0.4479612 ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000278

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6340
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.17188866  0.31158521 -0.9345421 ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000029

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6284
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.69183783  0.2254532  -0.68595282]
True reward weights: [-0.81858824 -0.07125966  0.56994329]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000497

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.58265051  0.25931052 -0.7702444 ]
True reward weights: [-0.81858824 -0.07125966  0.56994329]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000153

Running experiment 12/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6250
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.38028113 -0.2909076   0.87792883]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000031

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6194
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.5959515  -0.25374119  0.76187743]
True reward weights: [-0.49531788  0.26337139  0.82782589]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000334

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6286
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.41944807 -0.28758703  0.86102092]
True reward weights: [-0.49531788  0.26337139  0.82782589]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000184

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6200
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.31984695  0.30083172 -0.8984421 ]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000020

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.83612645  0.17245743 -0.52072161]
True reward weights: [-0.17977627  0.98356276 -0.01687557]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000376

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6034
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.99406026 -0.03180348  0.1040804 ]
True reward weights: [-0.17977627  0.98356276 -0.01687557]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000301

Running experiment 14/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6246
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.06431527 -0.31737092  0.94611799]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000024

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6144
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.06041094 -0.31686193  0.94654584]
True reward weights: [-0.12539083 -0.99190159 -0.02020845]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000453

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6272
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.9014662  -0.13864477  0.4100443 ]
True reward weights: [-0.12539083 -0.99190159 -0.02020845]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000096

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6300
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.61468827  0.25161733 -0.74756073]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000019

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9878437   0.04845015 -0.14770716]
True reward weights: [-0.00531497  0.10471636 -0.99448793]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000117

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.82641735  0.17647615 -0.53468732]
True reward weights: [-0.00531497  0.10471636 -0.99448793]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000162

Running experiment 16/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.26175354 -0.30278104  0.91641079]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000011

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6192
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.91153775 -0.12867964  0.39056431]
True reward weights: [-0.02933416 -0.74570828  0.66562652]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000037

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6168
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.91057386 -0.13033045  0.39226168]
True reward weights: [-0.02933416 -0.74570828  0.66562652]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000254

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6186
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.80478481 -0.1849111   0.56402951]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000050

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6192
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.56615942 -0.80780261 -0.16406842]
True reward weights: [ 0.60401284 -0.78997518  0.1053931 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000607

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6138
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.26552874 -0.30253397  0.91540575]
True reward weights: [ 0.60401284 -0.78997518  0.1053931 ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000134

Running experiment 18/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6118
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.45845498  0.28105191 -0.84310667]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000030

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6204
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.76729318 -0.20538912  0.60751665]
True reward weights: [-0.76608099  0.57851588  0.28007015]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000142

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6148
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.74991475 -0.21189282  0.62668118]
True reward weights: [-0.76608099  0.57851588  0.28007015]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000595

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6348
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.9491623  -0.10153333  0.29796292]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000012

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6304
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.25782271 -0.30331635  0.91734761]
True reward weights: [0.28131493 0.64724134 0.70847764]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000069

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6116
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.37294436 -0.2914267   0.88089896]
True reward weights: [0.28131493 0.64724134 0.70847764]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000528

Running experiment 20/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6270
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.63418662  0.24265106 -0.73411702]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000028

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6212
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9272279  -0.12012797  0.35470791]
True reward weights: [-0.64706918 -0.2183744   0.73048895]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000301

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.70068829 -0.22734871  0.67627545]
True reward weights: [-0.64706918 -0.2183744   0.73048895]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000147

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6294
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.51665243 0.11151242 0.84890238]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000024

Running PBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6198
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.63876666 -0.24408656  0.72965671]
True reward weights: [-0.79148245 -0.57098557  0.21801607]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000335

Running PBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6272
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.08079266 -0.91102211 -0.40436526]
True reward weights: [-0.79148245 -0.57098557  0.21801607]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000079

Running experiment 22/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6216
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99768703  0.02172845 -0.06440861]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000014

Running PBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6176
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.61297858  0.24702547  0.75049029]
True reward weights: [ 0.27008998  0.41470334 -0.8689491 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000104

Running PBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.03510292 0.35936674 0.93253597]
True reward weights: [ 0.27008998  0.41470334 -0.8689491 ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000354

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6300
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.04827997 -0.31311072  0.94848865]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000016

Running PBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6312
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.13907005 -0.31491796  0.93887496]
True reward weights: [0.32780843 0.34579711 0.87918485]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000208

Running PBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6230
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.47032753 -0.87526684 -0.11269413]
True reward weights: [0.32780843 0.34579711 0.87918485]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000198

Running experiment 24/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6314
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.29949697 -0.30317058  0.90464864]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000021

Running PBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6130
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.58663422 -0.2576828   0.76776289]
True reward weights: [ 0.34659939 -0.22573991  0.91044514]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000293

Running PBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6182
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.42721218 -0.2870441   0.85737707]
True reward weights: [ 0.34659939 -0.22573991  0.91044514]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000070

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6406
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.90790336  0.13554877 -0.39665856]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000034

Running PBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6030
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.83476885 -0.17132973  0.52326579]
True reward weights: [ 0.5365396   0.74815537 -0.39037007]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000532

Running PBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6102
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.73554125  0.21570535 -0.64222292]
True reward weights: [ 0.5365396   0.74815537 -0.39037007]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000227

Running experiment 26/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6264
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99019919  0.04345292 -0.13273058]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000024

Running PBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6110
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99495467  0.03432119 -0.09427229]
True reward weights: [-0.9892876   0.12344044 -0.07792631]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000493

Running PBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6104
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.08652682  0.31302246 -0.94579599]
True reward weights: [-0.9892876   0.12344044 -0.07792631]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000183

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6206
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99954788 -0.00862402  0.02880388]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000041

Running PBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6144
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.67364525  0.23384549 -0.70108371]
True reward weights: [-0.82294413  0.55134275  0.13705522]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000395

Running PBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6290
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.61645391  0.17037301 -0.76873768]
True reward weights: [-0.82294413  0.55134275  0.13705522]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000393

Running experiment 28/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6226
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.8927652   0.43229421  0.12685431]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000009

Running PBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6374
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.69326237  0.2303139  -0.68289296]
True reward weights: [-0.67422256 -0.12395095 -0.72805226]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000236

Running PBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6212
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.73153577  0.21564413 -0.64680216]
True reward weights: [-0.67422256 -0.12395095 -0.72805226]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000257

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6284
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.65465413 -0.23605718  0.71812602]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000013

Running PBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6296
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9911566   0.03997815 -0.12653195]
True reward weights: [-0.70306395  0.06135671  0.70847472]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000095

Running PBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6406
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.54841376  0.26447995 -0.79327971]
True reward weights: [-0.70306395  0.06135671  0.70847472]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000360

Running experiment 30/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6306
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.67232854 -0.235656    0.70174111]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000025

Running PBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6276
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.93346579 -0.1291516   0.33460647]
True reward weights: [-0.36806907 -0.28152513  0.88615391]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000398

Running PBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6150
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.12865442 -0.32775395  0.93596228]
True reward weights: [-0.36806907 -0.28152513  0.88615391]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000134

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.32595807  0.30133487 -0.89607401]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000013

Running PBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6272
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.86890371  0.15649535 -0.46959082]
True reward weights: [0.43047222 0.66624222 0.60894579]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000114

Running PBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.7688958  -0.20099225  0.60696076]
True reward weights: [0.43047222 0.66624222 0.60894579]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000337

Running experiment 32/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6230
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.64523116  0.24106988 -0.72495659]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000010

Running PBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.7598332   0.46292381  0.45645926]
True reward weights: [-0.38370093  0.17133776  0.90742326]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000150

Running PBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6116
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.9140998  -0.30169815 -0.27092395]
True reward weights: [-0.38370093  0.17133776  0.90742326]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000177

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6264
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.93677486 -0.11279589  0.33125512]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000048

Running PBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6206
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.57089778 -0.25794343  0.77944911]
True reward weights: [ 0.69014693 -0.47852599  0.54287208]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000518

Running PBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6094
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.16349299 -0.31150155  0.93607522]
True reward weights: [ 0.69014693 -0.47852599  0.54287208]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000188

Running experiment 34/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6296
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99739008 -0.02312273  0.0683986 ]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000010

Running PBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6128
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.26791784  0.94754699 -0.1742835 ]
True reward weights: [-0.04062901  0.99674666  0.06960882]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000051

Running PBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6184
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.78675696  0.19565179 -0.58543477]
True reward weights: [-0.04062901  0.99674666  0.06960882]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000338

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.72795839 -0.21527824  0.6509469 ]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000033

Running PBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.72016077  0.21953597 -0.65815835]
True reward weights: [-0.6592344   0.30886526  0.6855744 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000293

Running PBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6054
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.38870085  0.29207389 -0.87384466]
True reward weights: [-0.6592344   0.30886526  0.6855744 ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000209

Running experiment 36/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6104
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.75649342  0.2630224   0.59877953]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000015

Running PBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.90701006  0.13531255 -0.39877722]
True reward weights: [-0.21889719  0.93357119  0.28377606]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000242

Running PBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6172
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.88900439  0.14371218 -0.434762  ]
True reward weights: [-0.21889719  0.93357119  0.28377606]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000024

Saving results to files...
Results saved successfully.

Running experiment 37/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.44720687  0.28319589 -0.84841388]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000024

Running PBIRL with 2 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6172
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.72826528 -0.21457154  0.65083695]
True reward weights: [-0.98200701 -0.00151646  0.18883837]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000414

Running PBIRL with 3 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6088
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.28748859  0.30092911 -0.90928102]
True reward weights: [-0.98200701 -0.00151646  0.18883837]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000078

Running experiment 38/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6178
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.42902755  0.28667793 -0.85659274]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000027

Running PBIRL with 2 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6040
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.96098461  0.08562498 -0.26301511]
True reward weights: [-0.96608579 -0.2546414  -0.04284851]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000420

Running PBIRL with 3 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6244
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.09861433  0.31453689 -0.94410898]
True reward weights: [-0.96608579 -0.2546414  -0.04284851]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000144

Saving results to files...
Results saved successfully.

Running experiment 39/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.86010367  0.16313769 -0.48332988]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000023

Running PBIRL with 2 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6078
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.53595722  0.26920789 -0.80017309]
True reward weights: [-0.29840501  0.30888567 -0.9030748 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000338

Running PBIRL with 3 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6182
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.88530675  0.1461994  -0.44142688]
True reward weights: [-0.29840501  0.30888567 -0.9030748 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000226

Running experiment 40/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6332
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.20347383  0.31213163 -0.92799367]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000021

Running PBIRL with 2 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6184
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99178553  0.03816398 -0.12208589]
True reward weights: [-0.71090958  0.48475588 -0.50952852]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000447

Running PBIRL with 3 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6200
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.2903653   0.30354113 -0.90749698]
True reward weights: [-0.71090958  0.48475588 -0.50952852]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000266

Saving results to files...
Results saved successfully.

Running experiment 41/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6158
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.45887688  0.28321689 -0.84215213]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000020

Running PBIRL with 2 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6292
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.72462233 -0.21949343  0.65325731]
True reward weights: [0.5831931  0.63258508 0.5096292 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000380

Running PBIRL with 3 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6356
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.99995403 -0.00292238  0.00913182]
True reward weights: [0.5831931  0.63258508 0.5096292 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000241

Running experiment 42/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6174
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.41730359 -0.28696556  0.86226938]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000024

Running PBIRL with 2 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6266
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.56891162 -0.25954555  0.78036894]
True reward weights: [-0.57421977 -0.78576673  0.22987452]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000273

Running PBIRL with 3 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6264
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.88353304 -0.14580549  0.44509563]
True reward weights: [-0.57421977 -0.78576673  0.22987452]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000397

Saving results to files...
Results saved successfully.

Running experiment 43/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.62420785  0.24506835 -0.74182617]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000017

Running PBIRL with 2 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6132
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.87881162  0.15129468 -0.4525484 ]
True reward weights: [-0.17549321  0.9657913  -0.19091697]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000423

Running PBIRL with 3 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.41493303  0.2872574  -0.86331556]
True reward weights: [-0.17549321  0.9657913  -0.19091697]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000466

Running experiment 44/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.90852707 -0.1299199   0.39711382]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000030

Running PBIRL with 2 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6204
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.25279967  0.30603087 -0.91784391]
True reward weights: [ 0.10320717  0.78185566 -0.61485772]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000361

Running PBIRL with 3 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6180
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.64884776 -0.23812655  0.72269796]
True reward weights: [ 0.10320717  0.78185566 -0.61485772]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000032

Saving results to files...
Results saved successfully.

Running experiment 45/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.2105092  -0.30621199  0.92839652]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000027

Running PBIRL with 2 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6168
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.92623566 -0.12075078  0.35708087]
True reward weights: [ 0.24981994 -0.73438522  0.63108506]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000158

Running PBIRL with 3 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6220
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.83857922 -0.17056734  0.51738928]
True reward weights: [ 0.24981994 -0.73438522  0.63108506]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000357

Running experiment 46/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.90195336 -0.13743724  0.40937898]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000028

Running PBIRL with 2 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6226
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.40877886 -0.28999844  0.86533274]
True reward weights: [-0.25645234 -0.88773287 -0.38231212]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000306

Running PBIRL with 3 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6358
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.84134965 -0.16801932  0.51371225]
True reward weights: [-0.25645234 -0.88773287 -0.38231212]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000308

Saving results to files...
Results saved successfully.

Running experiment 47/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6194
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.96544443 -0.08440912  0.24656065]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000025

Running PBIRL with 2 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9818624   0.06155866 -0.17932304]
True reward weights: [-0.6750473   0.02461946  0.73736356]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000278

Running PBIRL with 3 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6434
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.99871456 -0.01739375  0.04760963]
True reward weights: [-0.6750473   0.02461946  0.73736356]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000017

Running experiment 48/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6166
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.66351124 -0.23848969  0.70913715]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000048

Running PBIRL with 2 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6356
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.69170405 -0.22905107  0.68489496]
True reward weights: [-0.82637683 -0.56219458  0.032227  ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000512

Running PBIRL with 3 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.66840468 -0.23296499  0.70637278]
True reward weights: [-0.82637683 -0.56219458  0.032227  ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000034

Saving results to files...
Results saved successfully.

Running experiment 49/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6226
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.91191933 -0.12947398  0.38940932]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000056

Running PBIRL with 2 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6232
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.90020526  0.13583505 -0.41373823]
True reward weights: [-0.01496059  0.43753771  0.8990756 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000583

Running PBIRL with 3 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6090
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.40136037 0.90775137 0.12205452]
True reward weights: [-0.01496059  0.43753771  0.8990756 ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000051

Running experiment 50/50...
Same Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6280
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.18590789 -0.30966182  0.93249548]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000022

Running PBIRL with 2 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6148
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.46827345 -0.27981213  0.83810808]
True reward weights: [ 0.16343143 -0.21992973  0.96172817]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000000

Running PBIRL with 3 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.24990422 -0.30752132  0.91813861]
True reward weights: [ 0.16343143 -0.21992973  0.96172817]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.000536

Saving results to files...
Results saved successfully.
