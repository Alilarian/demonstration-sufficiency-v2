Config file loaded successfully.
Running experiment with 20 worlds and 10 demonstrations per world.
Feature weights for environment: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Feature weights for environment: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Feature weights for environment: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Feature weights for environment: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Feature weights for environment: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Feature weights for environment: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Feature weights for environment: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Feature weights for environment: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Feature weights for environment: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Feature weights for environment: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Feature weights for environment: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Feature weights for environment: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Feature weights for environment: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Feature weights for environment: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Feature weights for environment: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Feature weights for environment: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Feature weights for environment: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Feature weights for environment: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Feature weights for environment: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Feature weights for environment: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Initialized 20 GridWorld environments.
Generated optimal policies for all environments.
Shuffled demonstration order: [16, 12, 9, 19, 18, 6, 5, 10, 15, 21, 11, 17, 1, 14, 22, 13, 2, 23, 4, 24, 7, 8, 0, 3, 20]

Running world 1/20

Running BIRL with demonstration 1/10 in world 1
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.551
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.29729035 -0.5760732   0.5748641  -0.20956455  0.05205961 -0.11304805
  0.43575454]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.344327
0.9-VaR bound for 1 demonstrations: 1.384721
0.95-VaR bound for 1 demonstrations: 1.471749
0.99-VaR bound for 1 demonstrations: 1.620148
True expected value difference for MAP policy: -0.038680
Evaluating threshold 0.1 with avar bound: [1.4717489810063769]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4717489810063769]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4717489810063769]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4717489810063769]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4717489810063769]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4717489810063769]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4717489810063769]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4717489810063769]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4717489810063769]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 1
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.362
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.25108266 -0.03235188  0.64123635 -0.07905394  0.00931672  0.67116942
  0.26061865]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 2.179036
0.9-VaR bound for 2 demonstrations: 2.402733
0.95-VaR bound for 2 demonstrations: 2.946313
0.99-VaR bound for 2 demonstrations: 3.841554
True expected value difference for MAP policy: 0.904712
Evaluating threshold 0.1 with avar bound: [2.9463131295395777]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.9463131295395777]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.9463131295395777]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.9463131295395777]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.9463131295395777]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.9463131295395777]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.9463131295395777]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.9463131295395777]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.9463131295395777]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.298
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.23287472 -0.65095331  0.22178839 -0.10434079  0.31327456  0.36846396
  0.47754101]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.068834
0.9-VaR bound for 3 demonstrations: 1.236973
0.95-VaR bound for 3 demonstrations: 1.508131
0.99-VaR bound for 3 demonstrations: 1.526456
True expected value difference for MAP policy: -0.039442
Evaluating threshold 0.1 with avar bound: [1.5081307183376524]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.5081307183376524]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.5081307183376524]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.5081307183376524]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.5081307183376524]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.5081307183376524]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.5081307183376524]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.5081307183376524]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.5081307183376524]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.254
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.19576454 -0.39347737  0.06710992 -0.67078244 -0.00227743  0.29764849
  0.51361384]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.003046
0.9-VaR bound for 4 demonstrations: -0.000367
0.95-VaR bound for 4 demonstrations: 0.003010
0.99-VaR bound for 4 demonstrations: 0.016269
True expected value difference for MAP policy: -0.032554
Evaluating threshold 0.1 with avar bound: [0.003009826510280712]
Threshold 0.1 SUFFICIENT with avar bound: 0.003009826510280712
Evaluating threshold 0.2 with avar bound: [0.003009826510280712]
Threshold 0.2 SUFFICIENT with avar bound: 0.003009826510280712
Evaluating threshold 0.3 with avar bound: [0.003009826510280712]
Threshold 0.3 SUFFICIENT with avar bound: 0.003009826510280712
Evaluating threshold 0.4 with avar bound: [0.003009826510280712]
Threshold 0.4 SUFFICIENT with avar bound: 0.003009826510280712
Evaluating threshold 0.5 with avar bound: [0.003009826510280712]
Threshold 0.5 SUFFICIENT with avar bound: 0.003009826510280712
Evaluating threshold 0.6 with avar bound: [0.003009826510280712]
Threshold 0.6 SUFFICIENT with avar bound: 0.003009826510280712
Evaluating threshold 0.7 with avar bound: [0.003009826510280712]
Threshold 0.7 SUFFICIENT with avar bound: 0.003009826510280712
Evaluating threshold 0.8 with avar bound: [0.003009826510280712]
Threshold 0.8 SUFFICIENT with avar bound: 0.003009826510280712
Evaluating threshold 0.9 with avar bound: [0.003009826510280712]
Threshold 0.9 SUFFICIENT with avar bound: 0.003009826510280712

Running BIRL with demonstration 5/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.267
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.60620766 -0.03906005  0.37017804 -0.41616011 -0.06492678  0.25609222
  0.50096592]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.003070
0.9-VaR bound for 5 demonstrations: 0.000313
0.95-VaR bound for 5 demonstrations: 0.002285
0.99-VaR bound for 5 demonstrations: 0.009923
True expected value difference for MAP policy: -0.032361
Evaluating threshold 0.1 with avar bound: [0.002284723484561973]
Threshold 0.1 SUFFICIENT with avar bound: 0.002284723484561973
Evaluating threshold 0.2 with avar bound: [0.002284723484561973]
Threshold 0.2 SUFFICIENT with avar bound: 0.002284723484561973
Evaluating threshold 0.3 with avar bound: [0.002284723484561973]
Threshold 0.3 SUFFICIENT with avar bound: 0.002284723484561973
Evaluating threshold 0.4 with avar bound: [0.002284723484561973]
Threshold 0.4 SUFFICIENT with avar bound: 0.002284723484561973
Evaluating threshold 0.5 with avar bound: [0.002284723484561973]
Threshold 0.5 SUFFICIENT with avar bound: 0.002284723484561973
Evaluating threshold 0.6 with avar bound: [0.002284723484561973]
Threshold 0.6 SUFFICIENT with avar bound: 0.002284723484561973
Evaluating threshold 0.7 with avar bound: [0.002284723484561973]
Threshold 0.7 SUFFICIENT with avar bound: 0.002284723484561973
Evaluating threshold 0.8 with avar bound: [0.002284723484561973]
Threshold 0.8 SUFFICIENT with avar bound: 0.002284723484561973
Evaluating threshold 0.9 with avar bound: [0.002284723484561973]
Threshold 0.9 SUFFICIENT with avar bound: 0.002284723484561973

Running BIRL with demonstration 6/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.229
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.53188138 -0.26464838  0.25734669 -0.391698   -0.08716411  0.34627212
  0.5476375 ]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.006254
0.9-VaR bound for 6 demonstrations: -0.003553
0.95-VaR bound for 6 demonstrations: -0.000631
0.99-VaR bound for 6 demonstrations: 0.013605
True expected value difference for MAP policy: -0.032361
Evaluating threshold 0.1 with avar bound: [-0.0006308200385984176]
Threshold 0.1 SUFFICIENT with avar bound: -0.0006308200385984176
Evaluating threshold 0.2 with avar bound: [-0.0006308200385984176]
Threshold 0.2 SUFFICIENT with avar bound: -0.0006308200385984176
Evaluating threshold 0.3 with avar bound: [-0.0006308200385984176]
Threshold 0.3 SUFFICIENT with avar bound: -0.0006308200385984176
Evaluating threshold 0.4 with avar bound: [-0.0006308200385984176]
Threshold 0.4 SUFFICIENT with avar bound: -0.0006308200385984176
Evaluating threshold 0.5 with avar bound: [-0.0006308200385984176]
Threshold 0.5 SUFFICIENT with avar bound: -0.0006308200385984176
Evaluating threshold 0.6 with avar bound: [-0.0006308200385984176]
Threshold 0.6 SUFFICIENT with avar bound: -0.0006308200385984176
Evaluating threshold 0.7 with avar bound: [-0.0006308200385984176]
Threshold 0.7 SUFFICIENT with avar bound: -0.0006308200385984176
Evaluating threshold 0.8 with avar bound: [-0.0006308200385984176]
Threshold 0.8 SUFFICIENT with avar bound: -0.0006308200385984176
Evaluating threshold 0.9 with avar bound: [-0.0006308200385984176]
Threshold 0.9 SUFFICIENT with avar bound: -0.0006308200385984176

Running BIRL with demonstration 7/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.23
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.4096276  -0.50486062  0.21006438  0.04759983  0.09225976  0.33815228
  0.63880308]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: 0.001782
0.9-VaR bound for 7 demonstrations: 0.004596
0.95-VaR bound for 7 demonstrations: 0.009526
0.99-VaR bound for 7 demonstrations: 0.017397
True expected value difference for MAP policy: -0.041540
Evaluating threshold 0.1 with avar bound: [0.009525839313539142]
Threshold 0.1 SUFFICIENT with avar bound: 0.009525839313539142
Evaluating threshold 0.2 with avar bound: [0.009525839313539142]
Threshold 0.2 SUFFICIENT with avar bound: 0.009525839313539142
Evaluating threshold 0.3 with avar bound: [0.009525839313539142]
Threshold 0.3 SUFFICIENT with avar bound: 0.009525839313539142
Evaluating threshold 0.4 with avar bound: [0.009525839313539142]
Threshold 0.4 SUFFICIENT with avar bound: 0.009525839313539142
Evaluating threshold 0.5 with avar bound: [0.009525839313539142]
Threshold 0.5 SUFFICIENT with avar bound: 0.009525839313539142
Evaluating threshold 0.6 with avar bound: [0.009525839313539142]
Threshold 0.6 SUFFICIENT with avar bound: 0.009525839313539142
Evaluating threshold 0.7 with avar bound: [0.009525839313539142]
Threshold 0.7 SUFFICIENT with avar bound: 0.009525839313539142
Evaluating threshold 0.8 with avar bound: [0.009525839313539142]
Threshold 0.8 SUFFICIENT with avar bound: 0.009525839313539142
Evaluating threshold 0.9 with avar bound: [0.009525839313539142]
Threshold 0.9 SUFFICIENT with avar bound: 0.009525839313539142

Running BIRL with demonstration 8/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.217
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.48439436 -0.70798239 -0.13344073  0.00759143 -0.02539418  0.28183654
  0.40765462]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: 0.006041
0.9-VaR bound for 8 demonstrations: 0.007130
0.95-VaR bound for 8 demonstrations: 0.013179
0.99-VaR bound for 8 demonstrations: 0.021829
True expected value difference for MAP policy: -0.042170
Evaluating threshold 0.1 with avar bound: [0.013178859014337371]
Threshold 0.1 SUFFICIENT with avar bound: 0.013178859014337371
Evaluating threshold 0.2 with avar bound: [0.013178859014337371]
Threshold 0.2 SUFFICIENT with avar bound: 0.013178859014337371
Evaluating threshold 0.3 with avar bound: [0.013178859014337371]
Threshold 0.3 SUFFICIENT with avar bound: 0.013178859014337371
Evaluating threshold 0.4 with avar bound: [0.013178859014337371]
Threshold 0.4 SUFFICIENT with avar bound: 0.013178859014337371
Evaluating threshold 0.5 with avar bound: [0.013178859014337371]
Threshold 0.5 SUFFICIENT with avar bound: 0.013178859014337371
Evaluating threshold 0.6 with avar bound: [0.013178859014337371]
Threshold 0.6 SUFFICIENT with avar bound: 0.013178859014337371
Evaluating threshold 0.7 with avar bound: [0.013178859014337371]
Threshold 0.7 SUFFICIENT with avar bound: 0.013178859014337371
Evaluating threshold 0.8 with avar bound: [0.013178859014337371]
Threshold 0.8 SUFFICIENT with avar bound: 0.013178859014337371
Evaluating threshold 0.9 with avar bound: [0.013178859014337371]
Threshold 0.9 SUFFICIENT with avar bound: 0.013178859014337371

Running BIRL with demonstration 9/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.231
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.44183216 -0.55686622  0.04552698 -0.3782091   0.32357616  0.27119634
  0.41390885]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.011195
0.9-VaR bound for 9 demonstrations: -0.008370
0.95-VaR bound for 9 demonstrations: -0.004979
0.99-VaR bound for 9 demonstrations: 0.000508
True expected value difference for MAP policy: -0.038680
Evaluating threshold 0.1 with avar bound: [-0.004978843213355311]
Threshold 0.1 SUFFICIENT with avar bound: -0.004978843213355311
Evaluating threshold 0.2 with avar bound: [-0.004978843213355311]
Threshold 0.2 SUFFICIENT with avar bound: -0.004978843213355311
Evaluating threshold 0.3 with avar bound: [-0.004978843213355311]
Threshold 0.3 SUFFICIENT with avar bound: -0.004978843213355311
Evaluating threshold 0.4 with avar bound: [-0.004978843213355311]
Threshold 0.4 SUFFICIENT with avar bound: -0.004978843213355311
Evaluating threshold 0.5 with avar bound: [-0.004978843213355311]
Threshold 0.5 SUFFICIENT with avar bound: -0.004978843213355311
Evaluating threshold 0.6 with avar bound: [-0.004978843213355311]
Threshold 0.6 SUFFICIENT with avar bound: -0.004978843213355311
Evaluating threshold 0.7 with avar bound: [-0.004978843213355311]
Threshold 0.7 SUFFICIENT with avar bound: -0.004978843213355311
Evaluating threshold 0.8 with avar bound: [-0.004978843213355311]
Threshold 0.8 SUFFICIENT with avar bound: -0.004978843213355311
Evaluating threshold 0.9 with avar bound: [-0.004978843213355311]
Threshold 0.9 SUFFICIENT with avar bound: -0.004978843213355311

Running BIRL with demonstration 10/10 in world 1
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.08693784 -0.68411598  0.07044632 -0.08264614 -0.11247596  0.39892082
  0.58381967]
True Reward Weights: [-0.16151622 -0.13494881  0.16019508  0.31509737  0.42712587  0.49622327
  0.63409658]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.003366
0.9-VaR bound for 10 demonstrations: -0.000707
0.95-VaR bound for 10 demonstrations: 0.006364
0.99-VaR bound for 10 demonstrations: 0.016074
True expected value difference for MAP policy: -0.041540
Evaluating threshold 0.1 with avar bound: [0.00636358259493032]
Threshold 0.1 SUFFICIENT with avar bound: 0.00636358259493032
Evaluating threshold 0.2 with avar bound: [0.00636358259493032]
Threshold 0.2 SUFFICIENT with avar bound: 0.00636358259493032
Evaluating threshold 0.3 with avar bound: [0.00636358259493032]
Threshold 0.3 SUFFICIENT with avar bound: 0.00636358259493032
Evaluating threshold 0.4 with avar bound: [0.00636358259493032]
Threshold 0.4 SUFFICIENT with avar bound: 0.00636358259493032
Evaluating threshold 0.5 with avar bound: [0.00636358259493032]
Threshold 0.5 SUFFICIENT with avar bound: 0.00636358259493032
Evaluating threshold 0.6 with avar bound: [0.00636358259493032]
Threshold 0.6 SUFFICIENT with avar bound: 0.00636358259493032
Evaluating threshold 0.7 with avar bound: [0.00636358259493032]
Threshold 0.7 SUFFICIENT with avar bound: 0.00636358259493032
Evaluating threshold 0.8 with avar bound: [0.00636358259493032]
Threshold 0.8 SUFFICIENT with avar bound: 0.00636358259493032
Evaluating threshold 0.9 with avar bound: [0.00636358259493032]
Threshold 0.9 SUFFICIENT with avar bound: 0.00636358259493032

Running world 2/20

Running BIRL with demonstration 1/10 in world 2
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.4
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.05956082 -0.01605418 -0.69475899 -0.0810209   0.6686051  -0.13329068
 -0.20528308]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.277025
0.9-VaR bound for 1 demonstrations: 1.550078
0.95-VaR bound for 1 demonstrations: 1.847703
0.99-VaR bound for 1 demonstrations: 2.345364
True expected value difference for MAP policy: 2.313090
Evaluating threshold 0.1 with avar bound: [1.847702667686211]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.847702667686211]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.847702667686211]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.847702667686211]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.847702667686211]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.847702667686211]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.847702667686211]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.847702667686211]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.847702667686211]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 2
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.247
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.08279566  0.15796748 -0.65452265  0.07878447  0.39389177  0.14693494
  0.59736393]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.173455
0.9-VaR bound for 2 demonstrations: 1.231508
0.95-VaR bound for 2 demonstrations: 1.317938
0.99-VaR bound for 2 demonstrations: 1.524334
True expected value difference for MAP policy: -0.017497
Evaluating threshold 0.1 with avar bound: [1.317938249862827]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.317938249862827]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.317938249862827]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.317938249862827]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.317938249862827]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.317938249862827]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.317938249862827]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.317938249862827]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.317938249862827]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 2
Current demos: [(16, 1), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.205
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.10778571 -0.19391545 -0.7441971   0.22788525  0.31571466 -0.04365063
  0.49339326]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.202270
0.9-VaR bound for 3 demonstrations: 1.303589
0.95-VaR bound for 3 demonstrations: 1.512199
0.99-VaR bound for 3 demonstrations: 1.579707
True expected value difference for MAP policy: -0.017083
Evaluating threshold 0.1 with avar bound: [1.5121985410015166]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.5121985410015166]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.5121985410015166]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.5121985410015166]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.5121985410015166]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.5121985410015166]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.5121985410015166]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.5121985410015166]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.5121985410015166]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 2
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.236
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.09058002 -0.38031393 -0.51003128  0.08045015  0.24253166  0.25913801
  0.67422424]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.008547
0.9-VaR bound for 4 demonstrations: -0.005622
0.95-VaR bound for 4 demonstrations: 0.001754
0.99-VaR bound for 4 demonstrations: 0.028033
True expected value difference for MAP policy: -0.017852
Evaluating threshold 0.1 with avar bound: [0.001754064903602924]
Threshold 0.1 SUFFICIENT with avar bound: 0.001754064903602924
Evaluating threshold 0.2 with avar bound: [0.001754064903602924]
Threshold 0.2 SUFFICIENT with avar bound: 0.001754064903602924
Evaluating threshold 0.3 with avar bound: [0.001754064903602924]
Threshold 0.3 SUFFICIENT with avar bound: 0.001754064903602924
Evaluating threshold 0.4 with avar bound: [0.001754064903602924]
Threshold 0.4 SUFFICIENT with avar bound: 0.001754064903602924
Evaluating threshold 0.5 with avar bound: [0.001754064903602924]
Threshold 0.5 SUFFICIENT with avar bound: 0.001754064903602924
Evaluating threshold 0.6 with avar bound: [0.001754064903602924]
Threshold 0.6 SUFFICIENT with avar bound: 0.001754064903602924
Evaluating threshold 0.7 with avar bound: [0.001754064903602924]
Threshold 0.7 SUFFICIENT with avar bound: 0.001754064903602924
Evaluating threshold 0.8 with avar bound: [0.001754064903602924]
Threshold 0.8 SUFFICIENT with avar bound: 0.001754064903602924
Evaluating threshold 0.9 with avar bound: [0.001754064903602924]
Threshold 0.9 SUFFICIENT with avar bound: 0.001754064903602924

Running BIRL with demonstration 5/10 in world 2
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.207
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.26157523 -0.13752148 -0.67091761 -0.48067027  0.06300698  0.00086825
  0.47699189]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.008807
0.9-VaR bound for 5 demonstrations: -0.005364
0.95-VaR bound for 5 demonstrations: 0.011994
0.99-VaR bound for 5 demonstrations: 0.014825
True expected value difference for MAP policy: -0.017852
Evaluating threshold 0.1 with avar bound: [0.011994381554215278]
Threshold 0.1 SUFFICIENT with avar bound: 0.011994381554215278
Evaluating threshold 0.2 with avar bound: [0.011994381554215278]
Threshold 0.2 SUFFICIENT with avar bound: 0.011994381554215278
Evaluating threshold 0.3 with avar bound: [0.011994381554215278]
Threshold 0.3 SUFFICIENT with avar bound: 0.011994381554215278
Evaluating threshold 0.4 with avar bound: [0.011994381554215278]
Threshold 0.4 SUFFICIENT with avar bound: 0.011994381554215278
Evaluating threshold 0.5 with avar bound: [0.011994381554215278]
Threshold 0.5 SUFFICIENT with avar bound: 0.011994381554215278
Evaluating threshold 0.6 with avar bound: [0.011994381554215278]
Threshold 0.6 SUFFICIENT with avar bound: 0.011994381554215278
Evaluating threshold 0.7 with avar bound: [0.011994381554215278]
Threshold 0.7 SUFFICIENT with avar bound: 0.011994381554215278
Evaluating threshold 0.8 with avar bound: [0.011994381554215278]
Threshold 0.8 SUFFICIENT with avar bound: 0.011994381554215278
Evaluating threshold 0.9 with avar bound: [0.011994381554215278]
Threshold 0.9 SUFFICIENT with avar bound: 0.011994381554215278

Running BIRL with demonstration 6/10 in world 2
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.07324689  0.18628465 -0.53350118 -0.11626161  0.4265383   0.04768363
  0.69107453]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.009024
0.9-VaR bound for 6 demonstrations: -0.004312
0.95-VaR bound for 6 demonstrations: -0.004312
0.99-VaR bound for 6 demonstrations: -0.001437
True expected value difference for MAP policy: -0.017497
Evaluating threshold 0.1 with avar bound: [-0.0043116241209298824]
Threshold 0.1 SUFFICIENT with avar bound: -0.0043116241209298824
Evaluating threshold 0.2 with avar bound: [-0.0043116241209298824]
Threshold 0.2 SUFFICIENT with avar bound: -0.0043116241209298824
Evaluating threshold 0.3 with avar bound: [-0.0043116241209298824]
Threshold 0.3 SUFFICIENT with avar bound: -0.0043116241209298824
Evaluating threshold 0.4 with avar bound: [-0.0043116241209298824]
Threshold 0.4 SUFFICIENT with avar bound: -0.0043116241209298824
Evaluating threshold 0.5 with avar bound: [-0.0043116241209298824]
Threshold 0.5 SUFFICIENT with avar bound: -0.0043116241209298824
Evaluating threshold 0.6 with avar bound: [-0.0043116241209298824]
Threshold 0.6 SUFFICIENT with avar bound: -0.0043116241209298824
Evaluating threshold 0.7 with avar bound: [-0.0043116241209298824]
Threshold 0.7 SUFFICIENT with avar bound: -0.0043116241209298824
Evaluating threshold 0.8 with avar bound: [-0.0043116241209298824]
Threshold 0.8 SUFFICIENT with avar bound: -0.0043116241209298824
Evaluating threshold 0.9 with avar bound: [-0.0043116241209298824]
Threshold 0.9 SUFFICIENT with avar bound: -0.0043116241209298824

Running BIRL with demonstration 7/10 in world 2
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.188
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.03607486 -0.39797196 -0.39995106 -0.11515474  0.29315182  0.41404284
  0.64009843]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.009691
0.9-VaR bound for 7 demonstrations: -0.006743
0.95-VaR bound for 7 demonstrations: -0.003992
0.99-VaR bound for 7 demonstrations: 0.005710
True expected value difference for MAP policy: -0.019034
Evaluating threshold 0.1 with avar bound: [-0.0039923591102955375]
Threshold 0.1 SUFFICIENT with avar bound: -0.0039923591102955375
Evaluating threshold 0.2 with avar bound: [-0.0039923591102955375]
Threshold 0.2 SUFFICIENT with avar bound: -0.0039923591102955375
Evaluating threshold 0.3 with avar bound: [-0.0039923591102955375]
Threshold 0.3 SUFFICIENT with avar bound: -0.0039923591102955375
Evaluating threshold 0.4 with avar bound: [-0.0039923591102955375]
Threshold 0.4 SUFFICIENT with avar bound: -0.0039923591102955375
Evaluating threshold 0.5 with avar bound: [-0.0039923591102955375]
Threshold 0.5 SUFFICIENT with avar bound: -0.0039923591102955375
Evaluating threshold 0.6 with avar bound: [-0.0039923591102955375]
Threshold 0.6 SUFFICIENT with avar bound: -0.0039923591102955375
Evaluating threshold 0.7 with avar bound: [-0.0039923591102955375]
Threshold 0.7 SUFFICIENT with avar bound: -0.0039923591102955375
Evaluating threshold 0.8 with avar bound: [-0.0039923591102955375]
Threshold 0.8 SUFFICIENT with avar bound: -0.0039923591102955375
Evaluating threshold 0.9 with avar bound: [-0.0039923591102955375]
Threshold 0.9 SUFFICIENT with avar bound: -0.0039923591102955375

Running BIRL with demonstration 8/10 in world 2
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.168
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.08581933 -0.02694099 -0.37953662 -0.42872018  0.28342235  0.33905959
  0.68466821]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.011063
0.9-VaR bound for 8 demonstrations: -0.006818
0.95-VaR bound for 8 demonstrations: 0.000678
0.99-VaR bound for 8 demonstrations: 0.004781
True expected value difference for MAP policy: -0.019034
Evaluating threshold 0.1 with avar bound: [0.0006775943872612227]
Threshold 0.1 SUFFICIENT with avar bound: 0.0006775943872612227
Evaluating threshold 0.2 with avar bound: [0.0006775943872612227]
Threshold 0.2 SUFFICIENT with avar bound: 0.0006775943872612227
Evaluating threshold 0.3 with avar bound: [0.0006775943872612227]
Threshold 0.3 SUFFICIENT with avar bound: 0.0006775943872612227
Evaluating threshold 0.4 with avar bound: [0.0006775943872612227]
Threshold 0.4 SUFFICIENT with avar bound: 0.0006775943872612227
Evaluating threshold 0.5 with avar bound: [0.0006775943872612227]
Threshold 0.5 SUFFICIENT with avar bound: 0.0006775943872612227
Evaluating threshold 0.6 with avar bound: [0.0006775943872612227]
Threshold 0.6 SUFFICIENT with avar bound: 0.0006775943872612227
Evaluating threshold 0.7 with avar bound: [0.0006775943872612227]
Threshold 0.7 SUFFICIENT with avar bound: 0.0006775943872612227
Evaluating threshold 0.8 with avar bound: [0.0006775943872612227]
Threshold 0.8 SUFFICIENT with avar bound: 0.0006775943872612227
Evaluating threshold 0.9 with avar bound: [0.0006775943872612227]
Threshold 0.9 SUFFICIENT with avar bound: 0.0006775943872612227

Running BIRL with demonstration 9/10 in world 2
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.173
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.13916104 -0.00869936 -0.60757604 -0.32112128  0.12798103  0.29072845
  0.63827018]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.015556
0.9-VaR bound for 9 demonstrations: -0.011770
0.95-VaR bound for 9 demonstrations: -0.006590
0.99-VaR bound for 9 demonstrations: -0.003556
True expected value difference for MAP policy: -0.019034
Evaluating threshold 0.1 with avar bound: [-0.006590418419436229]
Threshold 0.1 SUFFICIENT with avar bound: -0.006590418419436229
Evaluating threshold 0.2 with avar bound: [-0.006590418419436229]
Threshold 0.2 SUFFICIENT with avar bound: -0.006590418419436229
Evaluating threshold 0.3 with avar bound: [-0.006590418419436229]
Threshold 0.3 SUFFICIENT with avar bound: -0.006590418419436229
Evaluating threshold 0.4 with avar bound: [-0.006590418419436229]
Threshold 0.4 SUFFICIENT with avar bound: -0.006590418419436229
Evaluating threshold 0.5 with avar bound: [-0.006590418419436229]
Threshold 0.5 SUFFICIENT with avar bound: -0.006590418419436229
Evaluating threshold 0.6 with avar bound: [-0.006590418419436229]
Threshold 0.6 SUFFICIENT with avar bound: -0.006590418419436229
Evaluating threshold 0.7 with avar bound: [-0.006590418419436229]
Threshold 0.7 SUFFICIENT with avar bound: -0.006590418419436229
Evaluating threshold 0.8 with avar bound: [-0.006590418419436229]
Threshold 0.8 SUFFICIENT with avar bound: -0.006590418419436229
Evaluating threshold 0.9 with avar bound: [-0.006590418419436229]
Threshold 0.9 SUFFICIENT with avar bound: -0.006590418419436229

Running BIRL with demonstration 10/10 in world 2
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.168
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.00557898 -0.29227944 -0.41225926 -0.20385433  0.16198721  0.42088627
  0.70685374]
True Reward Weights: [-0.62250303 -0.43759971 -0.24698236 -0.19363915 -0.10579465  0.34108085
  0.44155567]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.010682
0.9-VaR bound for 10 demonstrations: -0.006103
0.95-VaR bound for 10 demonstrations: -0.005149
0.99-VaR bound for 10 demonstrations: 0.004239
True expected value difference for MAP policy: -0.019034
Evaluating threshold 0.1 with avar bound: [-0.00514925212025427]
Threshold 0.1 SUFFICIENT with avar bound: -0.00514925212025427
Evaluating threshold 0.2 with avar bound: [-0.00514925212025427]
Threshold 0.2 SUFFICIENT with avar bound: -0.00514925212025427
Evaluating threshold 0.3 with avar bound: [-0.00514925212025427]
Threshold 0.3 SUFFICIENT with avar bound: -0.00514925212025427
Evaluating threshold 0.4 with avar bound: [-0.00514925212025427]
Threshold 0.4 SUFFICIENT with avar bound: -0.00514925212025427
Evaluating threshold 0.5 with avar bound: [-0.00514925212025427]
Threshold 0.5 SUFFICIENT with avar bound: -0.00514925212025427
Evaluating threshold 0.6 with avar bound: [-0.00514925212025427]
Threshold 0.6 SUFFICIENT with avar bound: -0.00514925212025427
Evaluating threshold 0.7 with avar bound: [-0.00514925212025427]
Threshold 0.7 SUFFICIENT with avar bound: -0.00514925212025427
Evaluating threshold 0.8 with avar bound: [-0.00514925212025427]
Threshold 0.8 SUFFICIENT with avar bound: -0.00514925212025427
Evaluating threshold 0.9 with avar bound: [-0.00514925212025427]
Threshold 0.9 SUFFICIENT with avar bound: -0.00514925212025427

Running world 3/20

Running BIRL with demonstration 1/10 in world 3
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.391
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.02713378 -0.27468425 -0.11727892 -0.03935331 -0.23317811  0.91651319
 -0.11891525]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.344660
0.9-VaR bound for 1 demonstrations: 2.154880
0.95-VaR bound for 1 demonstrations: 2.919181
0.99-VaR bound for 1 demonstrations: 3.712422
True expected value difference for MAP policy: 0.309685
Evaluating threshold 0.1 with avar bound: [2.919180791255351]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.919180791255351]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.919180791255351]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.919180791255351]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.919180791255351]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.919180791255351]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.919180791255351]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.919180791255351]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.919180791255351]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 3
Current demos: [(16, 1), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.373
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.07544794 -0.02411233 -0.11308973 -0.40845511 -0.1165503   0.89444255
 -0.0221337 ]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 0.076699
0.9-VaR bound for 2 demonstrations: 1.279577
0.95-VaR bound for 2 demonstrations: 2.501738
0.99-VaR bound for 2 demonstrations: 4.253109
True expected value difference for MAP policy: 0.308185
Evaluating threshold 0.1 with avar bound: [2.5017377744730034]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.5017377744730034]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.5017377744730034]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.5017377744730034]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.5017377744730034]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.5017377744730034]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.5017377744730034]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.5017377744730034]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.5017377744730034]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 3
Current demos: [(16, 1), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.232
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.12915131  0.03114179 -0.10662417 -0.01138457 -0.70954456  0.68190049
  0.04909215]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.797634
0.9-VaR bound for 3 demonstrations: 2.200261
0.95-VaR bound for 3 demonstrations: 2.565831
0.99-VaR bound for 3 demonstrations: 3.769238
True expected value difference for MAP policy: 0.313609
Evaluating threshold 0.1 with avar bound: [2.5658312134052133]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.5658312134052133]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.5658312134052133]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.5658312134052133]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.5658312134052133]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.5658312134052133]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.5658312134052133]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.5658312134052133]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.5658312134052133]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 3
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.216
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.12921593 -0.11985073  0.19263176 -0.21224039  0.11846793  0.65304977
  0.66803998]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.209285
0.9-VaR bound for 4 demonstrations: 0.232759
0.95-VaR bound for 4 demonstrations: 0.263949
0.99-VaR bound for 4 demonstrations: 0.296127
True expected value difference for MAP policy: -0.016287
Evaluating threshold 0.1 with avar bound: [0.2639490021260252]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.2639490021260252]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.2639490021260252]
Threshold 0.3 SUFFICIENT with avar bound: 0.2639490021260252
Evaluating threshold 0.4 with avar bound: [0.2639490021260252]
Threshold 0.4 SUFFICIENT with avar bound: 0.2639490021260252
Evaluating threshold 0.5 with avar bound: [0.2639490021260252]
Threshold 0.5 SUFFICIENT with avar bound: 0.2639490021260252
Evaluating threshold 0.6 with avar bound: [0.2639490021260252]
Threshold 0.6 SUFFICIENT with avar bound: 0.2639490021260252
Evaluating threshold 0.7 with avar bound: [0.2639490021260252]
Threshold 0.7 SUFFICIENT with avar bound: 0.2639490021260252
Evaluating threshold 0.8 with avar bound: [0.2639490021260252]
Threshold 0.8 SUFFICIENT with avar bound: 0.2639490021260252
Evaluating threshold 0.9 with avar bound: [0.2639490021260252]
Threshold 0.9 SUFFICIENT with avar bound: 0.2639490021260252

Running BIRL with demonstration 5/10 in world 3
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.182
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.3588537  -0.34631038  0.01236113 -0.3462244   0.2854822   0.51786393
  0.53064666]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.471790
0.9-VaR bound for 5 demonstrations: 0.514722
0.95-VaR bound for 5 demonstrations: 0.566860
0.99-VaR bound for 5 demonstrations: 0.690965
True expected value difference for MAP policy: 0.006728
Evaluating threshold 0.1 with avar bound: [0.5668603394035983]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.5668603394035983]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.5668603394035983]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.5668603394035983]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.5668603394035983]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.5668603394035983]
Threshold 0.6 SUFFICIENT with avar bound: 0.5668603394035983
Evaluating threshold 0.7 with avar bound: [0.5668603394035983]
Threshold 0.7 SUFFICIENT with avar bound: 0.5668603394035983
Evaluating threshold 0.8 with avar bound: [0.5668603394035983]
Threshold 0.8 SUFFICIENT with avar bound: 0.5668603394035983
Evaluating threshold 0.9 with avar bound: [0.5668603394035983]
Threshold 0.9 SUFFICIENT with avar bound: 0.5668603394035983

Running BIRL with demonstration 6/10 in world 3
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.205
Using 700 samples after burn-in
MAP Solution Reward Weights: [-4.40472198e-02 -2.20538588e-01  3.29796563e-01  5.82716895e-04
 -3.37030841e-01  6.03923830e-01  6.01949069e-01]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: 1.051016
0.9-VaR bound for 6 demonstrations: 1.140560
0.95-VaR bound for 6 demonstrations: 1.238909
0.99-VaR bound for 6 demonstrations: 1.448220
True expected value difference for MAP policy: 0.073293
Evaluating threshold 0.1 with avar bound: [1.238909088345779]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.238909088345779]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.238909088345779]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.238909088345779]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.238909088345779]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.238909088345779]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.238909088345779]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.238909088345779]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.238909088345779]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 7/10 in world 3
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.194
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.46568961 -0.28642659 -0.34995654  0.02616751 -0.15461777  0.52785028
  0.5247915 ]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: 1.029818
0.9-VaR bound for 7 demonstrations: 1.086556
0.95-VaR bound for 7 demonstrations: 1.254875
0.99-VaR bound for 7 demonstrations: 1.495608
True expected value difference for MAP policy: 0.085493
Evaluating threshold 0.1 with avar bound: [1.2548749674125865]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.2548749674125865]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.2548749674125865]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.2548749674125865]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.2548749674125865]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.2548749674125865]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.2548749674125865]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.2548749674125865]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.2548749674125865]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 8/10 in world 3
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.179
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.13309081 -0.33837825 -0.01323697 -0.42143322 -0.10840103  0.58480465
  0.57987805]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: 1.720295
0.9-VaR bound for 8 demonstrations: 1.994338
0.95-VaR bound for 8 demonstrations: 2.113855
0.99-VaR bound for 8 demonstrations: 2.319681
True expected value difference for MAP policy: 0.192549
Evaluating threshold 0.1 with avar bound: [2.113855413593517]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.113855413593517]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.113855413593517]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.113855413593517]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.113855413593517]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.113855413593517]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.113855413593517]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.113855413593517]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.113855413593517]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 9/10 in world 3
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.152
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.17965416 -0.66810366 -0.29436057 -0.42473599 -0.00633567  0.34994384
  0.36305956]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: 0.120358
0.9-VaR bound for 9 demonstrations: 0.134885
0.95-VaR bound for 9 demonstrations: 0.163081
0.99-VaR bound for 9 demonstrations: 0.192028
True expected value difference for MAP policy: -0.013411
Evaluating threshold 0.1 with avar bound: [0.16308130185298766]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.16308130185298766]
Threshold 0.2 SUFFICIENT with avar bound: 0.16308130185298766
Evaluating threshold 0.3 with avar bound: [0.16308130185298766]
Threshold 0.3 SUFFICIENT with avar bound: 0.16308130185298766
Evaluating threshold 0.4 with avar bound: [0.16308130185298766]
Threshold 0.4 SUFFICIENT with avar bound: 0.16308130185298766
Evaluating threshold 0.5 with avar bound: [0.16308130185298766]
Threshold 0.5 SUFFICIENT with avar bound: 0.16308130185298766
Evaluating threshold 0.6 with avar bound: [0.16308130185298766]
Threshold 0.6 SUFFICIENT with avar bound: 0.16308130185298766
Evaluating threshold 0.7 with avar bound: [0.16308130185298766]
Threshold 0.7 SUFFICIENT with avar bound: 0.16308130185298766
Evaluating threshold 0.8 with avar bound: [0.16308130185298766]
Threshold 0.8 SUFFICIENT with avar bound: 0.16308130185298766
Evaluating threshold 0.9 with avar bound: [0.16308130185298766]
Threshold 0.9 SUFFICIENT with avar bound: 0.16308130185298766

Running BIRL with demonstration 10/10 in world 3
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.165
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.23842571 -0.50985065 -0.24399938 -0.41822258 -0.19265188  0.26678397
  0.58349913]
True Reward Weights: [-0.24968265 -0.10726198 -0.08882802 -0.07140183  0.38820183  0.58386515
  0.64928086]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.011006
0.9-VaR bound for 10 demonstrations: -0.009623
0.95-VaR bound for 10 demonstrations: -0.008114
0.99-VaR bound for 10 demonstrations: -0.000681
True expected value difference for MAP policy: -0.037666
Evaluating threshold 0.1 with avar bound: [-0.008114031546219915]
Threshold 0.1 SUFFICIENT with avar bound: -0.008114031546219915
Evaluating threshold 0.2 with avar bound: [-0.008114031546219915]
Threshold 0.2 SUFFICIENT with avar bound: -0.008114031546219915
Evaluating threshold 0.3 with avar bound: [-0.008114031546219915]
Threshold 0.3 SUFFICIENT with avar bound: -0.008114031546219915
Evaluating threshold 0.4 with avar bound: [-0.008114031546219915]
Threshold 0.4 SUFFICIENT with avar bound: -0.008114031546219915
Evaluating threshold 0.5 with avar bound: [-0.008114031546219915]
Threshold 0.5 SUFFICIENT with avar bound: -0.008114031546219915
Evaluating threshold 0.6 with avar bound: [-0.008114031546219915]
Threshold 0.6 SUFFICIENT with avar bound: -0.008114031546219915
Evaluating threshold 0.7 with avar bound: [-0.008114031546219915]
Threshold 0.7 SUFFICIENT with avar bound: -0.008114031546219915
Evaluating threshold 0.8 with avar bound: [-0.008114031546219915]
Threshold 0.8 SUFFICIENT with avar bound: -0.008114031546219915
Evaluating threshold 0.9 with avar bound: [-0.008114031546219915]
Threshold 0.9 SUFFICIENT with avar bound: -0.008114031546219915

Running world 4/20

Running BIRL with demonstration 1/10 in world 4
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.543
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.45948945 -0.63250101 -0.00958613  0.11792338 -0.09004156  0.0957709
  0.59794193]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.346686
0.9-VaR bound for 1 demonstrations: 1.393043
0.95-VaR bound for 1 demonstrations: 1.440412
0.99-VaR bound for 1 demonstrations: 1.573540
True expected value difference for MAP policy: -0.011644
Evaluating threshold 0.1 with avar bound: [1.4404115390594172]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4404115390594172]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4404115390594172]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4404115390594172]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4404115390594172]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4404115390594172]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4404115390594172]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4404115390594172]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4404115390594172]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 4
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.32
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.20535587 -0.63052625 -0.25417617  0.1119729   0.15523995 -0.1855887
  0.65159769]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.216431
0.9-VaR bound for 2 demonstrations: 1.316444
0.95-VaR bound for 2 demonstrations: 1.444161
0.99-VaR bound for 2 demonstrations: 1.529909
True expected value difference for MAP policy: 0.000274
Evaluating threshold 0.1 with avar bound: [1.4441608186952661]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4441608186952661]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4441608186952661]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4441608186952661]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4441608186952661]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4441608186952661]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4441608186952661]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4441608186952661]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4441608186952661]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.272
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.01890793 -0.54992409 -0.43697869  0.16827906  0.01577625 -0.13302913
  0.67824194]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.019157
0.9-VaR bound for 3 demonstrations: 1.158429
0.95-VaR bound for 3 demonstrations: 1.294489
0.99-VaR bound for 3 demonstrations: 1.455551
True expected value difference for MAP policy: -0.001542
Evaluating threshold 0.1 with avar bound: [1.2944888082493073]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.2944888082493073]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.2944888082493073]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.2944888082493073]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.2944888082493073]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.2944888082493073]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.2944888082493073]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.2944888082493073]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.2944888082493073]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.241
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.01584326 -0.49492097 -0.33363114  0.2797418   0.16640189  0.06141966
  0.7305991 ]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.002936
0.9-VaR bound for 4 demonstrations: 0.000050
0.95-VaR bound for 4 demonstrations: 0.005091
0.99-VaR bound for 4 demonstrations: 0.017163
True expected value difference for MAP policy: -0.001542
Evaluating threshold 0.1 with avar bound: [0.0050914277189075515]
Threshold 0.1 SUFFICIENT with avar bound: 0.0050914277189075515
Evaluating threshold 0.2 with avar bound: [0.0050914277189075515]
Threshold 0.2 SUFFICIENT with avar bound: 0.0050914277189075515
Evaluating threshold 0.3 with avar bound: [0.0050914277189075515]
Threshold 0.3 SUFFICIENT with avar bound: 0.0050914277189075515
Evaluating threshold 0.4 with avar bound: [0.0050914277189075515]
Threshold 0.4 SUFFICIENT with avar bound: 0.0050914277189075515
Evaluating threshold 0.5 with avar bound: [0.0050914277189075515]
Threshold 0.5 SUFFICIENT with avar bound: 0.0050914277189075515
Evaluating threshold 0.6 with avar bound: [0.0050914277189075515]
Threshold 0.6 SUFFICIENT with avar bound: 0.0050914277189075515
Evaluating threshold 0.7 with avar bound: [0.0050914277189075515]
Threshold 0.7 SUFFICIENT with avar bound: 0.0050914277189075515
Evaluating threshold 0.8 with avar bound: [0.0050914277189075515]
Threshold 0.8 SUFFICIENT with avar bound: 0.0050914277189075515
Evaluating threshold 0.9 with avar bound: [0.0050914277189075515]
Threshold 0.9 SUFFICIENT with avar bound: 0.0050914277189075515

Running BIRL with demonstration 5/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.223
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.11792228 -0.33819466 -0.19139226  0.3613223   0.3590867  -0.09571534
  0.75261492]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.006959
0.9-VaR bound for 5 demonstrations: -0.003929
0.95-VaR bound for 5 demonstrations: -0.001610
0.99-VaR bound for 5 demonstrations: 0.024741
True expected value difference for MAP policy: -0.001542
Evaluating threshold 0.1 with avar bound: [-0.0016102074424852566]
Threshold 0.1 SUFFICIENT with avar bound: -0.0016102074424852566
Evaluating threshold 0.2 with avar bound: [-0.0016102074424852566]
Threshold 0.2 SUFFICIENT with avar bound: -0.0016102074424852566
Evaluating threshold 0.3 with avar bound: [-0.0016102074424852566]
Threshold 0.3 SUFFICIENT with avar bound: -0.0016102074424852566
Evaluating threshold 0.4 with avar bound: [-0.0016102074424852566]
Threshold 0.4 SUFFICIENT with avar bound: -0.0016102074424852566
Evaluating threshold 0.5 with avar bound: [-0.0016102074424852566]
Threshold 0.5 SUFFICIENT with avar bound: -0.0016102074424852566
Evaluating threshold 0.6 with avar bound: [-0.0016102074424852566]
Threshold 0.6 SUFFICIENT with avar bound: -0.0016102074424852566
Evaluating threshold 0.7 with avar bound: [-0.0016102074424852566]
Threshold 0.7 SUFFICIENT with avar bound: -0.0016102074424852566
Evaluating threshold 0.8 with avar bound: [-0.0016102074424852566]
Threshold 0.8 SUFFICIENT with avar bound: -0.0016102074424852566
Evaluating threshold 0.9 with avar bound: [-0.0016102074424852566]
Threshold 0.9 SUFFICIENT with avar bound: -0.0016102074424852566

Running BIRL with demonstration 6/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.1012311  -0.42475419 -0.41932768 -0.4430329   0.10089829  0.44772734
  0.47600637]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: 0.004513
0.9-VaR bound for 6 demonstrations: 0.010028
0.95-VaR bound for 6 demonstrations: 0.012737
0.99-VaR bound for 6 demonstrations: 0.023139
True expected value difference for MAP policy: -0.008034
Evaluating threshold 0.1 with avar bound: [0.012737257678010283]
Threshold 0.1 SUFFICIENT with avar bound: 0.012737257678010283
Evaluating threshold 0.2 with avar bound: [0.012737257678010283]
Threshold 0.2 SUFFICIENT with avar bound: 0.012737257678010283
Evaluating threshold 0.3 with avar bound: [0.012737257678010283]
Threshold 0.3 SUFFICIENT with avar bound: 0.012737257678010283
Evaluating threshold 0.4 with avar bound: [0.012737257678010283]
Threshold 0.4 SUFFICIENT with avar bound: 0.012737257678010283
Evaluating threshold 0.5 with avar bound: [0.012737257678010283]
Threshold 0.5 SUFFICIENT with avar bound: 0.012737257678010283
Evaluating threshold 0.6 with avar bound: [0.012737257678010283]
Threshold 0.6 SUFFICIENT with avar bound: 0.012737257678010283
Evaluating threshold 0.7 with avar bound: [0.012737257678010283]
Threshold 0.7 SUFFICIENT with avar bound: 0.012737257678010283
Evaluating threshold 0.8 with avar bound: [0.012737257678010283]
Threshold 0.8 SUFFICIENT with avar bound: 0.012737257678010283
Evaluating threshold 0.9 with avar bound: [0.012737257678010283]
Threshold 0.9 SUFFICIENT with avar bound: 0.012737257678010283

Running BIRL with demonstration 7/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.18
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.46960849  0.04474551 -0.22799891 -0.05203096  0.39812731 -0.20353051
  0.7230802 ]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.010517
0.9-VaR bound for 7 demonstrations: -0.008516
0.95-VaR bound for 7 demonstrations: -0.007391
0.99-VaR bound for 7 demonstrations: 0.007594
True expected value difference for MAP policy: -0.009113
Evaluating threshold 0.1 with avar bound: [-0.007391104594209499]
Threshold 0.1 SUFFICIENT with avar bound: -0.007391104594209499
Evaluating threshold 0.2 with avar bound: [-0.007391104594209499]
Threshold 0.2 SUFFICIENT with avar bound: -0.007391104594209499
Evaluating threshold 0.3 with avar bound: [-0.007391104594209499]
Threshold 0.3 SUFFICIENT with avar bound: -0.007391104594209499
Evaluating threshold 0.4 with avar bound: [-0.007391104594209499]
Threshold 0.4 SUFFICIENT with avar bound: -0.007391104594209499
Evaluating threshold 0.5 with avar bound: [-0.007391104594209499]
Threshold 0.5 SUFFICIENT with avar bound: -0.007391104594209499
Evaluating threshold 0.6 with avar bound: [-0.007391104594209499]
Threshold 0.6 SUFFICIENT with avar bound: -0.007391104594209499
Evaluating threshold 0.7 with avar bound: [-0.007391104594209499]
Threshold 0.7 SUFFICIENT with avar bound: -0.007391104594209499
Evaluating threshold 0.8 with avar bound: [-0.007391104594209499]
Threshold 0.8 SUFFICIENT with avar bound: -0.007391104594209499
Evaluating threshold 0.9 with avar bound: [-0.007391104594209499]
Threshold 0.9 SUFFICIENT with avar bound: -0.007391104594209499

Running BIRL with demonstration 8/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.171
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.5159121  -0.01969154 -0.53438529 -0.09740258  0.37027582 -0.17008251
  0.52188103]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.005903
0.9-VaR bound for 8 demonstrations: -0.004900
0.95-VaR bound for 8 demonstrations: 0.003322
0.99-VaR bound for 8 demonstrations: 0.010564
True expected value difference for MAP policy: -0.009113
Evaluating threshold 0.1 with avar bound: [0.0033220960490287976]
Threshold 0.1 SUFFICIENT with avar bound: 0.0033220960490287976
Evaluating threshold 0.2 with avar bound: [0.0033220960490287976]
Threshold 0.2 SUFFICIENT with avar bound: 0.0033220960490287976
Evaluating threshold 0.3 with avar bound: [0.0033220960490287976]
Threshold 0.3 SUFFICIENT with avar bound: 0.0033220960490287976
Evaluating threshold 0.4 with avar bound: [0.0033220960490287976]
Threshold 0.4 SUFFICIENT with avar bound: 0.0033220960490287976
Evaluating threshold 0.5 with avar bound: [0.0033220960490287976]
Threshold 0.5 SUFFICIENT with avar bound: 0.0033220960490287976
Evaluating threshold 0.6 with avar bound: [0.0033220960490287976]
Threshold 0.6 SUFFICIENT with avar bound: 0.0033220960490287976
Evaluating threshold 0.7 with avar bound: [0.0033220960490287976]
Threshold 0.7 SUFFICIENT with avar bound: 0.0033220960490287976
Evaluating threshold 0.8 with avar bound: [0.0033220960490287976]
Threshold 0.8 SUFFICIENT with avar bound: 0.0033220960490287976
Evaluating threshold 0.9 with avar bound: [0.0033220960490287976]
Threshold 0.9 SUFFICIENT with avar bound: 0.0033220960490287976

Running BIRL with demonstration 9/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.148
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.55118763  0.10774944 -0.27877328 -0.0699456   0.50932603  0.10287368
  0.57617647]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.000013
0.9-VaR bound for 9 demonstrations: 0.000736
0.95-VaR bound for 9 demonstrations: 0.003713
0.99-VaR bound for 9 demonstrations: 0.010918
True expected value difference for MAP policy: -0.009113
Evaluating threshold 0.1 with avar bound: [0.00371297524914457]
Threshold 0.1 SUFFICIENT with avar bound: 0.00371297524914457
Evaluating threshold 0.2 with avar bound: [0.00371297524914457]
Threshold 0.2 SUFFICIENT with avar bound: 0.00371297524914457
Evaluating threshold 0.3 with avar bound: [0.00371297524914457]
Threshold 0.3 SUFFICIENT with avar bound: 0.00371297524914457
Evaluating threshold 0.4 with avar bound: [0.00371297524914457]
Threshold 0.4 SUFFICIENT with avar bound: 0.00371297524914457
Evaluating threshold 0.5 with avar bound: [0.00371297524914457]
Threshold 0.5 SUFFICIENT with avar bound: 0.00371297524914457
Evaluating threshold 0.6 with avar bound: [0.00371297524914457]
Threshold 0.6 SUFFICIENT with avar bound: 0.00371297524914457
Evaluating threshold 0.7 with avar bound: [0.00371297524914457]
Threshold 0.7 SUFFICIENT with avar bound: 0.00371297524914457
Evaluating threshold 0.8 with avar bound: [0.00371297524914457]
Threshold 0.8 SUFFICIENT with avar bound: 0.00371297524914457
Evaluating threshold 0.9 with avar bound: [0.00371297524914457]
Threshold 0.9 SUFFICIENT with avar bound: 0.00371297524914457

Running BIRL with demonstration 10/10 in world 4
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.168
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.54546545  0.07698982 -0.38053675  0.0312255   0.40055224 -0.11222926
  0.61458869]
True Reward Weights: [-0.62327613 -0.41861306 -0.37373487 -0.2996539   0.1116593   0.26743665
  0.35047054]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.004448
0.9-VaR bound for 10 demonstrations: -0.002897
0.95-VaR bound for 10 demonstrations: 0.004750
0.99-VaR bound for 10 demonstrations: 0.012610
True expected value difference for MAP policy: -0.009113
Evaluating threshold 0.1 with avar bound: [0.004749871270203843]
Threshold 0.1 SUFFICIENT with avar bound: 0.004749871270203843
Evaluating threshold 0.2 with avar bound: [0.004749871270203843]
Threshold 0.2 SUFFICIENT with avar bound: 0.004749871270203843
Evaluating threshold 0.3 with avar bound: [0.004749871270203843]
Threshold 0.3 SUFFICIENT with avar bound: 0.004749871270203843
Evaluating threshold 0.4 with avar bound: [0.004749871270203843]
Threshold 0.4 SUFFICIENT with avar bound: 0.004749871270203843
Evaluating threshold 0.5 with avar bound: [0.004749871270203843]
Threshold 0.5 SUFFICIENT with avar bound: 0.004749871270203843
Evaluating threshold 0.6 with avar bound: [0.004749871270203843]
Threshold 0.6 SUFFICIENT with avar bound: 0.004749871270203843
Evaluating threshold 0.7 with avar bound: [0.004749871270203843]
Threshold 0.7 SUFFICIENT with avar bound: 0.004749871270203843
Evaluating threshold 0.8 with avar bound: [0.004749871270203843]
Threshold 0.8 SUFFICIENT with avar bound: 0.004749871270203843
Evaluating threshold 0.9 with avar bound: [0.004749871270203843]
Threshold 0.9 SUFFICIENT with avar bound: 0.004749871270203843

Saving results to files...
Results saved successfully.

Running world 5/20

Running BIRL with demonstration 1/10 in world 5
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.501
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.01949252 -0.07401468 -0.47475726  0.07006514  0.83431138 -0.15797173
 -0.20690031]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 2.000701
0.9-VaR bound for 1 demonstrations: 2.259497
0.95-VaR bound for 1 demonstrations: 2.666549
0.99-VaR bound for 1 demonstrations: 3.335929
True expected value difference for MAP policy: 1.915909
Evaluating threshold 0.1 with avar bound: [2.66654895032428]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.66654895032428]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.66654895032428]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.66654895032428]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.66654895032428]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.66654895032428]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.66654895032428]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.66654895032428]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.66654895032428]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 5
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.371
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.0242195   0.07489272 -0.44891261  0.00429152  0.82559767 -0.24278211
 -0.22739588]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 2.593465
0.9-VaR bound for 2 demonstrations: 2.868388
0.95-VaR bound for 2 demonstrations: 3.177353
0.99-VaR bound for 2 demonstrations: 3.727886
True expected value difference for MAP policy: 1.916377
Evaluating threshold 0.1 with avar bound: [3.177353048395026]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.177353048395026]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.177353048395026]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.177353048395026]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.177353048395026]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.177353048395026]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.177353048395026]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.177353048395026]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.177353048395026]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.26
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62190433 -0.36770621  0.01780298  0.44337595 -0.17705277  0.04457104
  0.49778881]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.012463
0.9-VaR bound for 3 demonstrations: 0.017056
0.95-VaR bound for 3 demonstrations: 0.113554
0.99-VaR bound for 3 demonstrations: 0.263263
True expected value difference for MAP policy: -0.023616
Evaluating threshold 0.1 with avar bound: [0.11355351522314203]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.11355351522314203]
Threshold 0.2 SUFFICIENT with avar bound: 0.11355351522314203
Evaluating threshold 0.3 with avar bound: [0.11355351522314203]
Threshold 0.3 SUFFICIENT with avar bound: 0.11355351522314203
Evaluating threshold 0.4 with avar bound: [0.11355351522314203]
Threshold 0.4 SUFFICIENT with avar bound: 0.11355351522314203
Evaluating threshold 0.5 with avar bound: [0.11355351522314203]
Threshold 0.5 SUFFICIENT with avar bound: 0.11355351522314203
Evaluating threshold 0.6 with avar bound: [0.11355351522314203]
Threshold 0.6 SUFFICIENT with avar bound: 0.11355351522314203
Evaluating threshold 0.7 with avar bound: [0.11355351522314203]
Threshold 0.7 SUFFICIENT with avar bound: 0.11355351522314203
Evaluating threshold 0.8 with avar bound: [0.11355351522314203]
Threshold 0.8 SUFFICIENT with avar bound: 0.11355351522314203
Evaluating threshold 0.9 with avar bound: [0.11355351522314203]
Threshold 0.9 SUFFICIENT with avar bound: 0.11355351522314203

Running BIRL with demonstration 4/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.242
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.36362257 -0.49786367 -0.27018655  0.34946303 -0.31584253  0.19172516
  0.53690797]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.010327
0.9-VaR bound for 4 demonstrations: 0.013630
0.95-VaR bound for 4 demonstrations: 0.023122
0.99-VaR bound for 4 demonstrations: 0.026978
True expected value difference for MAP policy: -0.024521
Evaluating threshold 0.1 with avar bound: [0.023122323646139052]
Threshold 0.1 SUFFICIENT with avar bound: 0.023122323646139052
Evaluating threshold 0.2 with avar bound: [0.023122323646139052]
Threshold 0.2 SUFFICIENT with avar bound: 0.023122323646139052
Evaluating threshold 0.3 with avar bound: [0.023122323646139052]
Threshold 0.3 SUFFICIENT with avar bound: 0.023122323646139052
Evaluating threshold 0.4 with avar bound: [0.023122323646139052]
Threshold 0.4 SUFFICIENT with avar bound: 0.023122323646139052
Evaluating threshold 0.5 with avar bound: [0.023122323646139052]
Threshold 0.5 SUFFICIENT with avar bound: 0.023122323646139052
Evaluating threshold 0.6 with avar bound: [0.023122323646139052]
Threshold 0.6 SUFFICIENT with avar bound: 0.023122323646139052
Evaluating threshold 0.7 with avar bound: [0.023122323646139052]
Threshold 0.7 SUFFICIENT with avar bound: 0.023122323646139052
Evaluating threshold 0.8 with avar bound: [0.023122323646139052]
Threshold 0.8 SUFFICIENT with avar bound: 0.023122323646139052
Evaluating threshold 0.9 with avar bound: [0.023122323646139052]
Threshold 0.9 SUFFICIENT with avar bound: 0.023122323646139052

Running BIRL with demonstration 5/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.216
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34940843 -0.36601164  0.20963633  0.43469755 -0.04539152 -0.2944604
  0.64982502]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.003083
0.9-VaR bound for 5 demonstrations: 0.004633
0.95-VaR bound for 5 demonstrations: 0.009758
0.99-VaR bound for 5 demonstrations: 0.023736
True expected value difference for MAP policy: -0.021458
Evaluating threshold 0.1 with avar bound: [0.009757664167171888]
Threshold 0.1 SUFFICIENT with avar bound: 0.009757664167171888
Evaluating threshold 0.2 with avar bound: [0.009757664167171888]
Threshold 0.2 SUFFICIENT with avar bound: 0.009757664167171888
Evaluating threshold 0.3 with avar bound: [0.009757664167171888]
Threshold 0.3 SUFFICIENT with avar bound: 0.009757664167171888
Evaluating threshold 0.4 with avar bound: [0.009757664167171888]
Threshold 0.4 SUFFICIENT with avar bound: 0.009757664167171888
Evaluating threshold 0.5 with avar bound: [0.009757664167171888]
Threshold 0.5 SUFFICIENT with avar bound: 0.009757664167171888
Evaluating threshold 0.6 with avar bound: [0.009757664167171888]
Threshold 0.6 SUFFICIENT with avar bound: 0.009757664167171888
Evaluating threshold 0.7 with avar bound: [0.009757664167171888]
Threshold 0.7 SUFFICIENT with avar bound: 0.009757664167171888
Evaluating threshold 0.8 with avar bound: [0.009757664167171888]
Threshold 0.8 SUFFICIENT with avar bound: 0.009757664167171888
Evaluating threshold 0.9 with avar bound: [0.009757664167171888]
Threshold 0.9 SUFFICIENT with avar bound: 0.009757664167171888

Running BIRL with demonstration 6/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.217
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.5663547  -0.51777787 -0.04397986  0.37604028 -0.03727829 -0.16426461
  0.48932134]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.000625
0.9-VaR bound for 6 demonstrations: 0.003290
0.95-VaR bound for 6 demonstrations: 0.010189
0.99-VaR bound for 6 demonstrations: 0.031123
True expected value difference for MAP policy: -0.025590
Evaluating threshold 0.1 with avar bound: [0.010189476307220642]
Threshold 0.1 SUFFICIENT with avar bound: 0.010189476307220642
Evaluating threshold 0.2 with avar bound: [0.010189476307220642]
Threshold 0.2 SUFFICIENT with avar bound: 0.010189476307220642
Evaluating threshold 0.3 with avar bound: [0.010189476307220642]
Threshold 0.3 SUFFICIENT with avar bound: 0.010189476307220642
Evaluating threshold 0.4 with avar bound: [0.010189476307220642]
Threshold 0.4 SUFFICIENT with avar bound: 0.010189476307220642
Evaluating threshold 0.5 with avar bound: [0.010189476307220642]
Threshold 0.5 SUFFICIENT with avar bound: 0.010189476307220642
Evaluating threshold 0.6 with avar bound: [0.010189476307220642]
Threshold 0.6 SUFFICIENT with avar bound: 0.010189476307220642
Evaluating threshold 0.7 with avar bound: [0.010189476307220642]
Threshold 0.7 SUFFICIENT with avar bound: 0.010189476307220642
Evaluating threshold 0.8 with avar bound: [0.010189476307220642]
Threshold 0.8 SUFFICIENT with avar bound: 0.010189476307220642
Evaluating threshold 0.9 with avar bound: [0.010189476307220642]
Threshold 0.9 SUFFICIENT with avar bound: 0.010189476307220642

Running BIRL with demonstration 7/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.195
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.51552673 -0.49895264 -0.15951342  0.32509971 -0.08931032  0.28068027
  0.51709414]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.010742
0.9-VaR bound for 7 demonstrations: -0.007280
0.95-VaR bound for 7 demonstrations: -0.002708
0.99-VaR bound for 7 demonstrations: 0.003197
True expected value difference for MAP policy: -0.026209
Evaluating threshold 0.1 with avar bound: [-0.00270797542062205]
Threshold 0.1 SUFFICIENT with avar bound: -0.00270797542062205
Evaluating threshold 0.2 with avar bound: [-0.00270797542062205]
Threshold 0.2 SUFFICIENT with avar bound: -0.00270797542062205
Evaluating threshold 0.3 with avar bound: [-0.00270797542062205]
Threshold 0.3 SUFFICIENT with avar bound: -0.00270797542062205
Evaluating threshold 0.4 with avar bound: [-0.00270797542062205]
Threshold 0.4 SUFFICIENT with avar bound: -0.00270797542062205
Evaluating threshold 0.5 with avar bound: [-0.00270797542062205]
Threshold 0.5 SUFFICIENT with avar bound: -0.00270797542062205
Evaluating threshold 0.6 with avar bound: [-0.00270797542062205]
Threshold 0.6 SUFFICIENT with avar bound: -0.00270797542062205
Evaluating threshold 0.7 with avar bound: [-0.00270797542062205]
Threshold 0.7 SUFFICIENT with avar bound: -0.00270797542062205
Evaluating threshold 0.8 with avar bound: [-0.00270797542062205]
Threshold 0.8 SUFFICIENT with avar bound: -0.00270797542062205
Evaluating threshold 0.9 with avar bound: [-0.00270797542062205]
Threshold 0.9 SUFFICIENT with avar bound: -0.00270797542062205

Running BIRL with demonstration 8/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.183
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.13224245 -0.44819536  0.10235285  0.3277081  -0.16420644  0.42329519
  0.67647733]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.000007
0.9-VaR bound for 8 demonstrations: 0.002448
0.95-VaR bound for 8 demonstrations: 0.004761
0.99-VaR bound for 8 demonstrations: 0.013242
True expected value difference for MAP policy: -0.023616
Evaluating threshold 0.1 with avar bound: [0.004761295440764031]
Threshold 0.1 SUFFICIENT with avar bound: 0.004761295440764031
Evaluating threshold 0.2 with avar bound: [0.004761295440764031]
Threshold 0.2 SUFFICIENT with avar bound: 0.004761295440764031
Evaluating threshold 0.3 with avar bound: [0.004761295440764031]
Threshold 0.3 SUFFICIENT with avar bound: 0.004761295440764031
Evaluating threshold 0.4 with avar bound: [0.004761295440764031]
Threshold 0.4 SUFFICIENT with avar bound: 0.004761295440764031
Evaluating threshold 0.5 with avar bound: [0.004761295440764031]
Threshold 0.5 SUFFICIENT with avar bound: 0.004761295440764031
Evaluating threshold 0.6 with avar bound: [0.004761295440764031]
Threshold 0.6 SUFFICIENT with avar bound: 0.004761295440764031
Evaluating threshold 0.7 with avar bound: [0.004761295440764031]
Threshold 0.7 SUFFICIENT with avar bound: 0.004761295440764031
Evaluating threshold 0.8 with avar bound: [0.004761295440764031]
Threshold 0.8 SUFFICIENT with avar bound: 0.004761295440764031
Evaluating threshold 0.9 with avar bound: [0.004761295440764031]
Threshold 0.9 SUFFICIENT with avar bound: 0.004761295440764031

Running BIRL with demonstration 9/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.175
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.51554472 -0.52228259  0.0467508   0.26500305  0.04083303  0.22793742
  0.57913685]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.010184
0.9-VaR bound for 9 demonstrations: -0.003342
0.95-VaR bound for 9 demonstrations: 0.007343
0.99-VaR bound for 9 demonstrations: 0.026363
True expected value difference for MAP policy: -0.026209
Evaluating threshold 0.1 with avar bound: [0.007342892232616271]
Threshold 0.1 SUFFICIENT with avar bound: 0.007342892232616271
Evaluating threshold 0.2 with avar bound: [0.007342892232616271]
Threshold 0.2 SUFFICIENT with avar bound: 0.007342892232616271
Evaluating threshold 0.3 with avar bound: [0.007342892232616271]
Threshold 0.3 SUFFICIENT with avar bound: 0.007342892232616271
Evaluating threshold 0.4 with avar bound: [0.007342892232616271]
Threshold 0.4 SUFFICIENT with avar bound: 0.007342892232616271
Evaluating threshold 0.5 with avar bound: [0.007342892232616271]
Threshold 0.5 SUFFICIENT with avar bound: 0.007342892232616271
Evaluating threshold 0.6 with avar bound: [0.007342892232616271]
Threshold 0.6 SUFFICIENT with avar bound: 0.007342892232616271
Evaluating threshold 0.7 with avar bound: [0.007342892232616271]
Threshold 0.7 SUFFICIENT with avar bound: 0.007342892232616271
Evaluating threshold 0.8 with avar bound: [0.007342892232616271]
Threshold 0.8 SUFFICIENT with avar bound: 0.007342892232616271
Evaluating threshold 0.9 with avar bound: [0.007342892232616271]
Threshold 0.9 SUFFICIENT with avar bound: 0.007342892232616271

Running BIRL with demonstration 10/10 in world 5
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.176
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.41017705 -0.03328298  0.16268059  0.32727413  0.06912342  0.37197402
  0.74426539]
True Reward Weights: [-0.511167   -0.28568156  0.08831603  0.12945673  0.21221609  0.28747743
  0.71053265]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.005517
0.9-VaR bound for 10 demonstrations: -0.002251
0.95-VaR bound for 10 demonstrations: 0.002052
0.99-VaR bound for 10 demonstrations: 0.010747
True expected value difference for MAP policy: -0.026209
Evaluating threshold 0.1 with avar bound: [0.002051770808092597]
Threshold 0.1 SUFFICIENT with avar bound: 0.002051770808092597
Evaluating threshold 0.2 with avar bound: [0.002051770808092597]
Threshold 0.2 SUFFICIENT with avar bound: 0.002051770808092597
Evaluating threshold 0.3 with avar bound: [0.002051770808092597]
Threshold 0.3 SUFFICIENT with avar bound: 0.002051770808092597
Evaluating threshold 0.4 with avar bound: [0.002051770808092597]
Threshold 0.4 SUFFICIENT with avar bound: 0.002051770808092597
Evaluating threshold 0.5 with avar bound: [0.002051770808092597]
Threshold 0.5 SUFFICIENT with avar bound: 0.002051770808092597
Evaluating threshold 0.6 with avar bound: [0.002051770808092597]
Threshold 0.6 SUFFICIENT with avar bound: 0.002051770808092597
Evaluating threshold 0.7 with avar bound: [0.002051770808092597]
Threshold 0.7 SUFFICIENT with avar bound: 0.002051770808092597
Evaluating threshold 0.8 with avar bound: [0.002051770808092597]
Threshold 0.8 SUFFICIENT with avar bound: 0.002051770808092597
Evaluating threshold 0.9 with avar bound: [0.002051770808092597]
Threshold 0.9 SUFFICIENT with avar bound: 0.002051770808092597

Running world 6/20

Running BIRL with demonstration 1/10 in world 6
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.447
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.09194315 -0.64617677 -0.10347887  0.19232014 -0.38344206 -0.22029346
  0.57510877]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.198392
0.9-VaR bound for 1 demonstrations: 1.270779
0.95-VaR bound for 1 demonstrations: 1.385290
0.99-VaR bound for 1 demonstrations: 1.471347
True expected value difference for MAP policy: 0.002656
Evaluating threshold 0.1 with avar bound: [1.3852901243400806]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3852901243400806]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3852901243400806]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3852901243400806]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3852901243400806]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3852901243400806]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3852901243400806]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3852901243400806]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3852901243400806]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 6
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.37
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.24132877 -0.16398844 -0.16717942  0.89996615  0.08975688 -0.22503823
 -0.1352098 ]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.880036
0.9-VaR bound for 2 demonstrations: 2.131051
0.95-VaR bound for 2 demonstrations: 2.398709
0.99-VaR bound for 2 demonstrations: 3.360342
True expected value difference for MAP policy: 2.009824
Evaluating threshold 0.1 with avar bound: [2.3987092758217106]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.3987092758217106]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.3987092758217106]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.3987092758217106]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.3987092758217106]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.3987092758217106]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.3987092758217106]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.3987092758217106]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.3987092758217106]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.321
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61759542 -0.40998183 -0.19654081  0.44746337 -0.15216736  0.02486292
  0.43343508]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.238037
0.9-VaR bound for 3 demonstrations: 1.289203
0.95-VaR bound for 3 demonstrations: 1.361402
0.99-VaR bound for 3 demonstrations: 1.483066
True expected value difference for MAP policy: -0.020292
Evaluating threshold 0.1 with avar bound: [1.361402367988106]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.361402367988106]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.361402367988106]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.361402367988106]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.361402367988106]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.361402367988106]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.361402367988106]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.361402367988106]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.361402367988106]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.259
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.06706341 -0.17700298 -0.32349522  0.60321425 -0.13922179  0.13549817
  0.67669299]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.002993
0.9-VaR bound for 4 demonstrations: 0.000484
0.95-VaR bound for 4 demonstrations: 0.002757
0.99-VaR bound for 4 demonstrations: 0.020320
True expected value difference for MAP policy: -0.001948
Evaluating threshold 0.1 with avar bound: [0.002757204292691321]
Threshold 0.1 SUFFICIENT with avar bound: 0.002757204292691321
Evaluating threshold 0.2 with avar bound: [0.002757204292691321]
Threshold 0.2 SUFFICIENT with avar bound: 0.002757204292691321
Evaluating threshold 0.3 with avar bound: [0.002757204292691321]
Threshold 0.3 SUFFICIENT with avar bound: 0.002757204292691321
Evaluating threshold 0.4 with avar bound: [0.002757204292691321]
Threshold 0.4 SUFFICIENT with avar bound: 0.002757204292691321
Evaluating threshold 0.5 with avar bound: [0.002757204292691321]
Threshold 0.5 SUFFICIENT with avar bound: 0.002757204292691321
Evaluating threshold 0.6 with avar bound: [0.002757204292691321]
Threshold 0.6 SUFFICIENT with avar bound: 0.002757204292691321
Evaluating threshold 0.7 with avar bound: [0.002757204292691321]
Threshold 0.7 SUFFICIENT with avar bound: 0.002757204292691321
Evaluating threshold 0.8 with avar bound: [0.002757204292691321]
Threshold 0.8 SUFFICIENT with avar bound: 0.002757204292691321
Evaluating threshold 0.9 with avar bound: [0.002757204292691321]
Threshold 0.9 SUFFICIENT with avar bound: 0.002757204292691321

Running BIRL with demonstration 5/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.244
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.30447319 -0.2760636  -0.33607448  0.68226153  0.13570271  0.02948707
  0.48308737]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.000874
0.9-VaR bound for 5 demonstrations: 0.003075
0.95-VaR bound for 5 demonstrations: 0.005748
0.99-VaR bound for 5 demonstrations: 0.012438
True expected value difference for MAP policy: -0.018772
Evaluating threshold 0.1 with avar bound: [0.005748365090162026]
Threshold 0.1 SUFFICIENT with avar bound: 0.005748365090162026
Evaluating threshold 0.2 with avar bound: [0.005748365090162026]
Threshold 0.2 SUFFICIENT with avar bound: 0.005748365090162026
Evaluating threshold 0.3 with avar bound: [0.005748365090162026]
Threshold 0.3 SUFFICIENT with avar bound: 0.005748365090162026
Evaluating threshold 0.4 with avar bound: [0.005748365090162026]
Threshold 0.4 SUFFICIENT with avar bound: 0.005748365090162026
Evaluating threshold 0.5 with avar bound: [0.005748365090162026]
Threshold 0.5 SUFFICIENT with avar bound: 0.005748365090162026
Evaluating threshold 0.6 with avar bound: [0.005748365090162026]
Threshold 0.6 SUFFICIENT with avar bound: 0.005748365090162026
Evaluating threshold 0.7 with avar bound: [0.005748365090162026]
Threshold 0.7 SUFFICIENT with avar bound: 0.005748365090162026
Evaluating threshold 0.8 with avar bound: [0.005748365090162026]
Threshold 0.8 SUFFICIENT with avar bound: 0.005748365090162026
Evaluating threshold 0.9 with avar bound: [0.005748365090162026]
Threshold 0.9 SUFFICIENT with avar bound: 0.005748365090162026

Running BIRL with demonstration 6/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.243
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.55151974 -0.11710038 -0.41463338  0.34419723 -0.10570426 -0.57900207
  0.21284763]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: 0.000581
0.9-VaR bound for 6 demonstrations: 0.002960
0.95-VaR bound for 6 demonstrations: 0.010328
0.99-VaR bound for 6 demonstrations: 0.013374
True expected value difference for MAP policy: -0.008987
Evaluating threshold 0.1 with avar bound: [0.010327983573500532]
Threshold 0.1 SUFFICIENT with avar bound: 0.010327983573500532
Evaluating threshold 0.2 with avar bound: [0.010327983573500532]
Threshold 0.2 SUFFICIENT with avar bound: 0.010327983573500532
Evaluating threshold 0.3 with avar bound: [0.010327983573500532]
Threshold 0.3 SUFFICIENT with avar bound: 0.010327983573500532
Evaluating threshold 0.4 with avar bound: [0.010327983573500532]
Threshold 0.4 SUFFICIENT with avar bound: 0.010327983573500532
Evaluating threshold 0.5 with avar bound: [0.010327983573500532]
Threshold 0.5 SUFFICIENT with avar bound: 0.010327983573500532
Evaluating threshold 0.6 with avar bound: [0.010327983573500532]
Threshold 0.6 SUFFICIENT with avar bound: 0.010327983573500532
Evaluating threshold 0.7 with avar bound: [0.010327983573500532]
Threshold 0.7 SUFFICIENT with avar bound: 0.010327983573500532
Evaluating threshold 0.8 with avar bound: [0.010327983573500532]
Threshold 0.8 SUFFICIENT with avar bound: 0.010327983573500532
Evaluating threshold 0.9 with avar bound: [0.010327983573500532]
Threshold 0.9 SUFFICIENT with avar bound: 0.010327983573500532

Running BIRL with demonstration 7/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.205
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.51480352 -0.66882832 -0.12380173  0.41399205 -0.15393895 -0.15926334
  0.22774484]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: 0.001064
0.9-VaR bound for 7 demonstrations: 0.003186
0.95-VaR bound for 7 demonstrations: 0.005095
0.99-VaR bound for 7 demonstrations: 0.007671
True expected value difference for MAP policy: -0.020295
Evaluating threshold 0.1 with avar bound: [0.005095468182200409]
Threshold 0.1 SUFFICIENT with avar bound: 0.005095468182200409
Evaluating threshold 0.2 with avar bound: [0.005095468182200409]
Threshold 0.2 SUFFICIENT with avar bound: 0.005095468182200409
Evaluating threshold 0.3 with avar bound: [0.005095468182200409]
Threshold 0.3 SUFFICIENT with avar bound: 0.005095468182200409
Evaluating threshold 0.4 with avar bound: [0.005095468182200409]
Threshold 0.4 SUFFICIENT with avar bound: 0.005095468182200409
Evaluating threshold 0.5 with avar bound: [0.005095468182200409]
Threshold 0.5 SUFFICIENT with avar bound: 0.005095468182200409
Evaluating threshold 0.6 with avar bound: [0.005095468182200409]
Threshold 0.6 SUFFICIENT with avar bound: 0.005095468182200409
Evaluating threshold 0.7 with avar bound: [0.005095468182200409]
Threshold 0.7 SUFFICIENT with avar bound: 0.005095468182200409
Evaluating threshold 0.8 with avar bound: [0.005095468182200409]
Threshold 0.8 SUFFICIENT with avar bound: 0.005095468182200409
Evaluating threshold 0.9 with avar bound: [0.005095468182200409]
Threshold 0.9 SUFFICIENT with avar bound: 0.005095468182200409

Running BIRL with demonstration 8/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.202
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.57666894 -0.39404995  0.02359748  0.6071655  -0.05810345  0.14580784
  0.34399833]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.005203
0.9-VaR bound for 8 demonstrations: 0.000039
0.95-VaR bound for 8 demonstrations: 0.004255
0.99-VaR bound for 8 demonstrations: 0.041386
True expected value difference for MAP policy: -0.020295
Evaluating threshold 0.1 with avar bound: [0.004255395904363456]
Threshold 0.1 SUFFICIENT with avar bound: 0.004255395904363456
Evaluating threshold 0.2 with avar bound: [0.004255395904363456]
Threshold 0.2 SUFFICIENT with avar bound: 0.004255395904363456
Evaluating threshold 0.3 with avar bound: [0.004255395904363456]
Threshold 0.3 SUFFICIENT with avar bound: 0.004255395904363456
Evaluating threshold 0.4 with avar bound: [0.004255395904363456]
Threshold 0.4 SUFFICIENT with avar bound: 0.004255395904363456
Evaluating threshold 0.5 with avar bound: [0.004255395904363456]
Threshold 0.5 SUFFICIENT with avar bound: 0.004255395904363456
Evaluating threshold 0.6 with avar bound: [0.004255395904363456]
Threshold 0.6 SUFFICIENT with avar bound: 0.004255395904363456
Evaluating threshold 0.7 with avar bound: [0.004255395904363456]
Threshold 0.7 SUFFICIENT with avar bound: 0.004255395904363456
Evaluating threshold 0.8 with avar bound: [0.004255395904363456]
Threshold 0.8 SUFFICIENT with avar bound: 0.004255395904363456
Evaluating threshold 0.9 with avar bound: [0.004255395904363456]
Threshold 0.9 SUFFICIENT with avar bound: 0.004255395904363456

Running BIRL with demonstration 9/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.189
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50931468 -0.53854216 -0.07460924  0.5155077   0.1826185  -0.08130455
  0.3732241 ]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.006119
0.9-VaR bound for 9 demonstrations: -0.005073
0.95-VaR bound for 9 demonstrations: -0.001197
0.99-VaR bound for 9 demonstrations: 0.011901
True expected value difference for MAP policy: -0.020295
Evaluating threshold 0.1 with avar bound: [-0.001196791342936608]
Threshold 0.1 SUFFICIENT with avar bound: -0.001196791342936608
Evaluating threshold 0.2 with avar bound: [-0.001196791342936608]
Threshold 0.2 SUFFICIENT with avar bound: -0.001196791342936608
Evaluating threshold 0.3 with avar bound: [-0.001196791342936608]
Threshold 0.3 SUFFICIENT with avar bound: -0.001196791342936608
Evaluating threshold 0.4 with avar bound: [-0.001196791342936608]
Threshold 0.4 SUFFICIENT with avar bound: -0.001196791342936608
Evaluating threshold 0.5 with avar bound: [-0.001196791342936608]
Threshold 0.5 SUFFICIENT with avar bound: -0.001196791342936608
Evaluating threshold 0.6 with avar bound: [-0.001196791342936608]
Threshold 0.6 SUFFICIENT with avar bound: -0.001196791342936608
Evaluating threshold 0.7 with avar bound: [-0.001196791342936608]
Threshold 0.7 SUFFICIENT with avar bound: -0.001196791342936608
Evaluating threshold 0.8 with avar bound: [-0.001196791342936608]
Threshold 0.8 SUFFICIENT with avar bound: -0.001196791342936608
Evaluating threshold 0.9 with avar bound: [-0.001196791342936608]
Threshold 0.9 SUFFICIENT with avar bound: -0.001196791342936608

Running BIRL with demonstration 10/10 in world 6
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.204
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.65386634 -0.45388608 -0.07349151  0.38523524 -0.04092334 -0.24909556
  0.385896  ]
True Reward Weights: [-0.59424118 -0.20951526 -0.12622464 -0.09121375  0.21871134  0.51083702
  0.5195566 ]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.008287
0.9-VaR bound for 10 demonstrations: -0.006484
0.95-VaR bound for 10 demonstrations: -0.002417
0.99-VaR bound for 10 demonstrations: 0.014961
True expected value difference for MAP policy: -0.020295
Evaluating threshold 0.1 with avar bound: [-0.002417242681872873]
Threshold 0.1 SUFFICIENT with avar bound: -0.002417242681872873
Evaluating threshold 0.2 with avar bound: [-0.002417242681872873]
Threshold 0.2 SUFFICIENT with avar bound: -0.002417242681872873
Evaluating threshold 0.3 with avar bound: [-0.002417242681872873]
Threshold 0.3 SUFFICIENT with avar bound: -0.002417242681872873
Evaluating threshold 0.4 with avar bound: [-0.002417242681872873]
Threshold 0.4 SUFFICIENT with avar bound: -0.002417242681872873
Evaluating threshold 0.5 with avar bound: [-0.002417242681872873]
Threshold 0.5 SUFFICIENT with avar bound: -0.002417242681872873
Evaluating threshold 0.6 with avar bound: [-0.002417242681872873]
Threshold 0.6 SUFFICIENT with avar bound: -0.002417242681872873
Evaluating threshold 0.7 with avar bound: [-0.002417242681872873]
Threshold 0.7 SUFFICIENT with avar bound: -0.002417242681872873
Evaluating threshold 0.8 with avar bound: [-0.002417242681872873]
Threshold 0.8 SUFFICIENT with avar bound: -0.002417242681872873
Evaluating threshold 0.9 with avar bound: [-0.002417242681872873]
Threshold 0.9 SUFFICIENT with avar bound: -0.002417242681872873

Running world 7/20

Running BIRL with demonstration 1/10 in world 7
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.518
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.20975898 -0.70402132  0.01049984 -0.33335824  0.34515098  0.06573184
  0.47504455]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.286057
0.9-VaR bound for 1 demonstrations: 1.341433
0.95-VaR bound for 1 demonstrations: 1.383411
0.99-VaR bound for 1 demonstrations: 1.546884
True expected value difference for MAP policy: -0.028722
Evaluating threshold 0.1 with avar bound: [1.3834108985140072]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3834108985140072]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3834108985140072]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3834108985140072]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3834108985140072]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3834108985140072]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3834108985140072]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3834108985140072]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3834108985140072]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 7
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.397
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.63425186 -0.51184003 -0.4481943  -0.29643795  0.0877632   0.0916296
 -0.17576235]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 2.099683
0.9-VaR bound for 2 demonstrations: 2.481893
0.95-VaR bound for 2 demonstrations: 2.987212
0.99-VaR bound for 2 demonstrations: 4.228180
True expected value difference for MAP policy: 3.071617
Evaluating threshold 0.1 with avar bound: [2.9872124967736022]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.9872124967736022]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.9872124967736022]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.9872124967736022]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.9872124967736022]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.9872124967736022]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.9872124967736022]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.9872124967736022]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.9872124967736022]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.349
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.04574946 -0.56394103  0.23379754 -0.4983987   0.04003078 -0.08553028
  0.60654517]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.192395
0.9-VaR bound for 3 demonstrations: 1.281010
0.95-VaR bound for 3 demonstrations: 1.318052
0.99-VaR bound for 3 demonstrations: 1.552081
True expected value difference for MAP policy: -0.024345
Evaluating threshold 0.1 with avar bound: [1.3180516883527527]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3180516883527527]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3180516883527527]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3180516883527527]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3180516883527527]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3180516883527527]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3180516883527527]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3180516883527527]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3180516883527527]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.233
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.29825566 -0.65148037  0.17135119 -0.21808577 -0.23420515 -0.18349041
  0.56672169]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.001566
0.9-VaR bound for 4 demonstrations: 0.008416
0.95-VaR bound for 4 demonstrations: 0.019919
0.99-VaR bound for 4 demonstrations: 0.027632
True expected value difference for MAP policy: -0.013567
Evaluating threshold 0.1 with avar bound: [0.019918981919621034]
Threshold 0.1 SUFFICIENT with avar bound: 0.019918981919621034
Evaluating threshold 0.2 with avar bound: [0.019918981919621034]
Threshold 0.2 SUFFICIENT with avar bound: 0.019918981919621034
Evaluating threshold 0.3 with avar bound: [0.019918981919621034]
Threshold 0.3 SUFFICIENT with avar bound: 0.019918981919621034
Evaluating threshold 0.4 with avar bound: [0.019918981919621034]
Threshold 0.4 SUFFICIENT with avar bound: 0.019918981919621034
Evaluating threshold 0.5 with avar bound: [0.019918981919621034]
Threshold 0.5 SUFFICIENT with avar bound: 0.019918981919621034
Evaluating threshold 0.6 with avar bound: [0.019918981919621034]
Threshold 0.6 SUFFICIENT with avar bound: 0.019918981919621034
Evaluating threshold 0.7 with avar bound: [0.019918981919621034]
Threshold 0.7 SUFFICIENT with avar bound: 0.019918981919621034
Evaluating threshold 0.8 with avar bound: [0.019918981919621034]
Threshold 0.8 SUFFICIENT with avar bound: 0.019918981919621034
Evaluating threshold 0.9 with avar bound: [0.019918981919621034]
Threshold 0.9 SUFFICIENT with avar bound: 0.019918981919621034

Running BIRL with demonstration 5/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.247
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.09242741 -0.64147124  0.04399147 -0.35092659  0.03283515 -0.3573022
  0.57109027]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.006349
0.9-VaR bound for 5 demonstrations: -0.003485
0.95-VaR bound for 5 demonstrations: -0.000011
0.99-VaR bound for 5 demonstrations: 0.029253
True expected value difference for MAP policy: -0.012363
Evaluating threshold 0.1 with avar bound: [-1.1328747631597341e-05]
Threshold 0.1 SUFFICIENT with avar bound: -1.1328747631597341e-05
Evaluating threshold 0.2 with avar bound: [-1.1328747631597341e-05]
Threshold 0.2 SUFFICIENT with avar bound: -1.1328747631597341e-05
Evaluating threshold 0.3 with avar bound: [-1.1328747631597341e-05]
Threshold 0.3 SUFFICIENT with avar bound: -1.1328747631597341e-05
Evaluating threshold 0.4 with avar bound: [-1.1328747631597341e-05]
Threshold 0.4 SUFFICIENT with avar bound: -1.1328747631597341e-05
Evaluating threshold 0.5 with avar bound: [-1.1328747631597341e-05]
Threshold 0.5 SUFFICIENT with avar bound: -1.1328747631597341e-05
Evaluating threshold 0.6 with avar bound: [-1.1328747631597341e-05]
Threshold 0.6 SUFFICIENT with avar bound: -1.1328747631597341e-05
Evaluating threshold 0.7 with avar bound: [-1.1328747631597341e-05]
Threshold 0.7 SUFFICIENT with avar bound: -1.1328747631597341e-05
Evaluating threshold 0.8 with avar bound: [-1.1328747631597341e-05]
Threshold 0.8 SUFFICIENT with avar bound: -1.1328747631597341e-05
Evaluating threshold 0.9 with avar bound: [-1.1328747631597341e-05]
Threshold 0.9 SUFFICIENT with avar bound: -1.1328747631597341e-05

Running BIRL with demonstration 6/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.226
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.21396343 -0.81969271  0.10296704 -0.05097135 -0.02830913 -0.13202243
  0.50089111]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.000248
0.9-VaR bound for 6 demonstrations: 0.001981
0.95-VaR bound for 6 demonstrations: 0.004840
0.99-VaR bound for 6 demonstrations: 0.028824
True expected value difference for MAP policy: -0.010012
Evaluating threshold 0.1 with avar bound: [0.00484041488630526]
Threshold 0.1 SUFFICIENT with avar bound: 0.00484041488630526
Evaluating threshold 0.2 with avar bound: [0.00484041488630526]
Threshold 0.2 SUFFICIENT with avar bound: 0.00484041488630526
Evaluating threshold 0.3 with avar bound: [0.00484041488630526]
Threshold 0.3 SUFFICIENT with avar bound: 0.00484041488630526
Evaluating threshold 0.4 with avar bound: [0.00484041488630526]
Threshold 0.4 SUFFICIENT with avar bound: 0.00484041488630526
Evaluating threshold 0.5 with avar bound: [0.00484041488630526]
Threshold 0.5 SUFFICIENT with avar bound: 0.00484041488630526
Evaluating threshold 0.6 with avar bound: [0.00484041488630526]
Threshold 0.6 SUFFICIENT with avar bound: 0.00484041488630526
Evaluating threshold 0.7 with avar bound: [0.00484041488630526]
Threshold 0.7 SUFFICIENT with avar bound: 0.00484041488630526
Evaluating threshold 0.8 with avar bound: [0.00484041488630526]
Threshold 0.8 SUFFICIENT with avar bound: 0.00484041488630526
Evaluating threshold 0.9 with avar bound: [0.00484041488630526]
Threshold 0.9 SUFFICIENT with avar bound: 0.00484041488630526

Running BIRL with demonstration 7/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.222
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.1967109  -0.53759144  0.26916249 -0.31274507 -0.01542838  0.14470466
  0.69344421]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.000688
0.9-VaR bound for 7 demonstrations: 0.007296
0.95-VaR bound for 7 demonstrations: 0.008864
0.99-VaR bound for 7 demonstrations: 0.017061
True expected value difference for MAP policy: -0.025554
Evaluating threshold 0.1 with avar bound: [0.008863777098457192]
Threshold 0.1 SUFFICIENT with avar bound: 0.008863777098457192
Evaluating threshold 0.2 with avar bound: [0.008863777098457192]
Threshold 0.2 SUFFICIENT with avar bound: 0.008863777098457192
Evaluating threshold 0.3 with avar bound: [0.008863777098457192]
Threshold 0.3 SUFFICIENT with avar bound: 0.008863777098457192
Evaluating threshold 0.4 with avar bound: [0.008863777098457192]
Threshold 0.4 SUFFICIENT with avar bound: 0.008863777098457192
Evaluating threshold 0.5 with avar bound: [0.008863777098457192]
Threshold 0.5 SUFFICIENT with avar bound: 0.008863777098457192
Evaluating threshold 0.6 with avar bound: [0.008863777098457192]
Threshold 0.6 SUFFICIENT with avar bound: 0.008863777098457192
Evaluating threshold 0.7 with avar bound: [0.008863777098457192]
Threshold 0.7 SUFFICIENT with avar bound: 0.008863777098457192
Evaluating threshold 0.8 with avar bound: [0.008863777098457192]
Threshold 0.8 SUFFICIENT with avar bound: 0.008863777098457192
Evaluating threshold 0.9 with avar bound: [0.008863777098457192]
Threshold 0.9 SUFFICIENT with avar bound: 0.008863777098457192

Running BIRL with demonstration 8/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.212
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.27096413 -0.59683446  0.23997121 -0.12974189  0.00683623 -0.41040847
  0.57224652]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.005005
0.9-VaR bound for 8 demonstrations: -0.002152
0.95-VaR bound for 8 demonstrations: -0.000907
0.99-VaR bound for 8 demonstrations: 0.003013
True expected value difference for MAP policy: -0.012363
Evaluating threshold 0.1 with avar bound: [-0.0009070724218616832]
Threshold 0.1 SUFFICIENT with avar bound: -0.0009070724218616832
Evaluating threshold 0.2 with avar bound: [-0.0009070724218616832]
Threshold 0.2 SUFFICIENT with avar bound: -0.0009070724218616832
Evaluating threshold 0.3 with avar bound: [-0.0009070724218616832]
Threshold 0.3 SUFFICIENT with avar bound: -0.0009070724218616832
Evaluating threshold 0.4 with avar bound: [-0.0009070724218616832]
Threshold 0.4 SUFFICIENT with avar bound: -0.0009070724218616832
Evaluating threshold 0.5 with avar bound: [-0.0009070724218616832]
Threshold 0.5 SUFFICIENT with avar bound: -0.0009070724218616832
Evaluating threshold 0.6 with avar bound: [-0.0009070724218616832]
Threshold 0.6 SUFFICIENT with avar bound: -0.0009070724218616832
Evaluating threshold 0.7 with avar bound: [-0.0009070724218616832]
Threshold 0.7 SUFFICIENT with avar bound: -0.0009070724218616832
Evaluating threshold 0.8 with avar bound: [-0.0009070724218616832]
Threshold 0.8 SUFFICIENT with avar bound: -0.0009070724218616832
Evaluating threshold 0.9 with avar bound: [-0.0009070724218616832]
Threshold 0.9 SUFFICIENT with avar bound: -0.0009070724218616832

Running BIRL with demonstration 9/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.215
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.00827406 -0.72811411  0.23567531 -0.32005335 -0.09168111 -0.2839061
  0.47201301]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.004441
0.9-VaR bound for 9 demonstrations: -0.001480
0.95-VaR bound for 9 demonstrations: 0.006142
0.99-VaR bound for 9 demonstrations: 0.016928
True expected value difference for MAP policy: -0.012363
Evaluating threshold 0.1 with avar bound: [0.006141693884860184]
Threshold 0.1 SUFFICIENT with avar bound: 0.006141693884860184
Evaluating threshold 0.2 with avar bound: [0.006141693884860184]
Threshold 0.2 SUFFICIENT with avar bound: 0.006141693884860184
Evaluating threshold 0.3 with avar bound: [0.006141693884860184]
Threshold 0.3 SUFFICIENT with avar bound: 0.006141693884860184
Evaluating threshold 0.4 with avar bound: [0.006141693884860184]
Threshold 0.4 SUFFICIENT with avar bound: 0.006141693884860184
Evaluating threshold 0.5 with avar bound: [0.006141693884860184]
Threshold 0.5 SUFFICIENT with avar bound: 0.006141693884860184
Evaluating threshold 0.6 with avar bound: [0.006141693884860184]
Threshold 0.6 SUFFICIENT with avar bound: 0.006141693884860184
Evaluating threshold 0.7 with avar bound: [0.006141693884860184]
Threshold 0.7 SUFFICIENT with avar bound: 0.006141693884860184
Evaluating threshold 0.8 with avar bound: [0.006141693884860184]
Threshold 0.8 SUFFICIENT with avar bound: 0.006141693884860184
Evaluating threshold 0.9 with avar bound: [0.006141693884860184]
Threshold 0.9 SUFFICIENT with avar bound: 0.006141693884860184

Running BIRL with demonstration 10/10 in world 7
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.208
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.07384567 -0.4297553   0.3841743  -0.29246753  0.21274316  0.12251122
  0.71865249]
True Reward Weights: [-0.13026953 -0.12866646  0.06484668  0.11035498  0.2978272   0.55249933
  0.74574455]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.003974
0.9-VaR bound for 10 demonstrations: 0.005128
0.95-VaR bound for 10 demonstrations: 0.019590
0.99-VaR bound for 10 demonstrations: 0.021801
True expected value difference for MAP policy: -0.024345
Evaluating threshold 0.1 with avar bound: [0.019589852758333474]
Threshold 0.1 SUFFICIENT with avar bound: 0.019589852758333474
Evaluating threshold 0.2 with avar bound: [0.019589852758333474]
Threshold 0.2 SUFFICIENT with avar bound: 0.019589852758333474
Evaluating threshold 0.3 with avar bound: [0.019589852758333474]
Threshold 0.3 SUFFICIENT with avar bound: 0.019589852758333474
Evaluating threshold 0.4 with avar bound: [0.019589852758333474]
Threshold 0.4 SUFFICIENT with avar bound: 0.019589852758333474
Evaluating threshold 0.5 with avar bound: [0.019589852758333474]
Threshold 0.5 SUFFICIENT with avar bound: 0.019589852758333474
Evaluating threshold 0.6 with avar bound: [0.019589852758333474]
Threshold 0.6 SUFFICIENT with avar bound: 0.019589852758333474
Evaluating threshold 0.7 with avar bound: [0.019589852758333474]
Threshold 0.7 SUFFICIENT with avar bound: 0.019589852758333474
Evaluating threshold 0.8 with avar bound: [0.019589852758333474]
Threshold 0.8 SUFFICIENT with avar bound: 0.019589852758333474
Evaluating threshold 0.9 with avar bound: [0.019589852758333474]
Threshold 0.9 SUFFICIENT with avar bound: 0.019589852758333474

Running world 8/20

Running BIRL with demonstration 1/10 in world 8
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.311
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.30820127  0.61075118 -0.08843269  0.28114748  0.51050901 -0.04983648
  0.42664693]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 2.445441
0.9-VaR bound for 1 demonstrations: 2.708158
0.95-VaR bound for 1 demonstrations: 3.293642
0.99-VaR bound for 1 demonstrations: 3.982748
True expected value difference for MAP policy: 2.869687
Evaluating threshold 0.1 with avar bound: [3.2936420674372227]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.2936420674372227]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.2936420674372227]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.2936420674372227]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.2936420674372227]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.2936420674372227]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.2936420674372227]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.2936420674372227]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.2936420674372227]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 8
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.211
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.88983747  0.02001263 -0.09445721 -0.03329662 -0.11559542 -0.02495808
  0.42868723]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: -0.002527
0.9-VaR bound for 2 demonstrations: 0.008092
0.95-VaR bound for 2 demonstrations: 0.645471
0.99-VaR bound for 2 demonstrations: 1.175636
True expected value difference for MAP policy: -0.005416
Evaluating threshold 0.1 with avar bound: [0.6454712702271715]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.6454712702271715]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.6454712702271715]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.6454712702271715]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.6454712702271715]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.6454712702271715]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [0.6454712702271715]
Threshold 0.7 SUFFICIENT with avar bound: 0.6454712702271715
Evaluating threshold 0.8 with avar bound: [0.6454712702271715]
Threshold 0.8 SUFFICIENT with avar bound: 0.6454712702271715
Evaluating threshold 0.9 with avar bound: [0.6454712702271715]
Threshold 0.9 SUFFICIENT with avar bound: 0.6454712702271715

Running BIRL with demonstration 3/10 in world 8
Current demos: [(16, 1), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.196
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.68499529  0.09156506 -0.02936289  0.22445365  0.31462224  0.22132308
  0.56849328]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.010407
0.9-VaR bound for 3 demonstrations: 0.314027
0.95-VaR bound for 3 demonstrations: 0.976163
0.99-VaR bound for 3 demonstrations: 1.352033
True expected value difference for MAP policy: -0.008655
Evaluating threshold 0.1 with avar bound: [0.9761626895080505]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.9761626895080505]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [0.9761626895080505]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [0.9761626895080505]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [0.9761626895080505]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [0.9761626895080505]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [0.9761626895080505]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [0.9761626895080505]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [0.9761626895080505]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 8
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.212
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.6798593  -0.05183211 -0.32768247 -0.19944548  0.17683611 -0.11520435
  0.58600974]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.001198
0.9-VaR bound for 4 demonstrations: 0.000478
0.95-VaR bound for 4 demonstrations: 0.006164
0.99-VaR bound for 4 demonstrations: 0.022521
True expected value difference for MAP policy: -0.008539
Evaluating threshold 0.1 with avar bound: [0.006164102385186212]
Threshold 0.1 SUFFICIENT with avar bound: 0.006164102385186212
Evaluating threshold 0.2 with avar bound: [0.006164102385186212]
Threshold 0.2 SUFFICIENT with avar bound: 0.006164102385186212
Evaluating threshold 0.3 with avar bound: [0.006164102385186212]
Threshold 0.3 SUFFICIENT with avar bound: 0.006164102385186212
Evaluating threshold 0.4 with avar bound: [0.006164102385186212]
Threshold 0.4 SUFFICIENT with avar bound: 0.006164102385186212
Evaluating threshold 0.5 with avar bound: [0.006164102385186212]
Threshold 0.5 SUFFICIENT with avar bound: 0.006164102385186212
Evaluating threshold 0.6 with avar bound: [0.006164102385186212]
Threshold 0.6 SUFFICIENT with avar bound: 0.006164102385186212
Evaluating threshold 0.7 with avar bound: [0.006164102385186212]
Threshold 0.7 SUFFICIENT with avar bound: 0.006164102385186212
Evaluating threshold 0.8 with avar bound: [0.006164102385186212]
Threshold 0.8 SUFFICIENT with avar bound: 0.006164102385186212
Evaluating threshold 0.9 with avar bound: [0.006164102385186212]
Threshold 0.9 SUFFICIENT with avar bound: 0.006164102385186212

Running BIRL with demonstration 5/10 in world 8
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.188
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.53452665  0.40159125  0.15340562 -0.22816757  0.24888406  0.07698312
  0.63995494]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.002943
0.9-VaR bound for 5 demonstrations: -0.000756
0.95-VaR bound for 5 demonstrations: 0.006448
0.99-VaR bound for 5 demonstrations: 0.016254
True expected value difference for MAP policy: -0.001515
Evaluating threshold 0.1 with avar bound: [0.006447975380224347]
Threshold 0.1 SUFFICIENT with avar bound: 0.006447975380224347
Evaluating threshold 0.2 with avar bound: [0.006447975380224347]
Threshold 0.2 SUFFICIENT with avar bound: 0.006447975380224347
Evaluating threshold 0.3 with avar bound: [0.006447975380224347]
Threshold 0.3 SUFFICIENT with avar bound: 0.006447975380224347
Evaluating threshold 0.4 with avar bound: [0.006447975380224347]
Threshold 0.4 SUFFICIENT with avar bound: 0.006447975380224347
Evaluating threshold 0.5 with avar bound: [0.006447975380224347]
Threshold 0.5 SUFFICIENT with avar bound: 0.006447975380224347
Evaluating threshold 0.6 with avar bound: [0.006447975380224347]
Threshold 0.6 SUFFICIENT with avar bound: 0.006447975380224347
Evaluating threshold 0.7 with avar bound: [0.006447975380224347]
Threshold 0.7 SUFFICIENT with avar bound: 0.006447975380224347
Evaluating threshold 0.8 with avar bound: [0.006447975380224347]
Threshold 0.8 SUFFICIENT with avar bound: 0.006447975380224347
Evaluating threshold 0.9 with avar bound: [0.006447975380224347]
Threshold 0.9 SUFFICIENT with avar bound: 0.006447975380224347

Running BIRL with demonstration 6/10 in world 8
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.174
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.58452232 -0.14779748 -0.04418567  0.00886805  0.33131179  0.0062985
  0.72432822]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.005533
0.9-VaR bound for 6 demonstrations: -0.001277
0.95-VaR bound for 6 demonstrations: 0.006983
0.99-VaR bound for 6 demonstrations: 0.007485
True expected value difference for MAP policy: -0.008655
Evaluating threshold 0.1 with avar bound: [0.00698318944079586]
Threshold 0.1 SUFFICIENT with avar bound: 0.00698318944079586
Evaluating threshold 0.2 with avar bound: [0.00698318944079586]
Threshold 0.2 SUFFICIENT with avar bound: 0.00698318944079586
Evaluating threshold 0.3 with avar bound: [0.00698318944079586]
Threshold 0.3 SUFFICIENT with avar bound: 0.00698318944079586
Evaluating threshold 0.4 with avar bound: [0.00698318944079586]
Threshold 0.4 SUFFICIENT with avar bound: 0.00698318944079586
Evaluating threshold 0.5 with avar bound: [0.00698318944079586]
Threshold 0.5 SUFFICIENT with avar bound: 0.00698318944079586
Evaluating threshold 0.6 with avar bound: [0.00698318944079586]
Threshold 0.6 SUFFICIENT with avar bound: 0.00698318944079586
Evaluating threshold 0.7 with avar bound: [0.00698318944079586]
Threshold 0.7 SUFFICIENT with avar bound: 0.00698318944079586
Evaluating threshold 0.8 with avar bound: [0.00698318944079586]
Threshold 0.8 SUFFICIENT with avar bound: 0.00698318944079586
Evaluating threshold 0.9 with avar bound: [0.00698318944079586]
Threshold 0.9 SUFFICIENT with avar bound: 0.00698318944079586

Running BIRL with demonstration 7/10 in world 8
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.182
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.49583218 -0.18731145 -0.44358984  0.03361071  0.34565638  0.1791495
  0.60793944]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.006788
0.9-VaR bound for 7 demonstrations: -0.005346
0.95-VaR bound for 7 demonstrations: -0.000963
0.99-VaR bound for 7 demonstrations: 0.004442
True expected value difference for MAP policy: -0.008714
Evaluating threshold 0.1 with avar bound: [-0.0009631186610218693]
Threshold 0.1 SUFFICIENT with avar bound: -0.0009631186610218693
Evaluating threshold 0.2 with avar bound: [-0.0009631186610218693]
Threshold 0.2 SUFFICIENT with avar bound: -0.0009631186610218693
Evaluating threshold 0.3 with avar bound: [-0.0009631186610218693]
Threshold 0.3 SUFFICIENT with avar bound: -0.0009631186610218693
Evaluating threshold 0.4 with avar bound: [-0.0009631186610218693]
Threshold 0.4 SUFFICIENT with avar bound: -0.0009631186610218693
Evaluating threshold 0.5 with avar bound: [-0.0009631186610218693]
Threshold 0.5 SUFFICIENT with avar bound: -0.0009631186610218693
Evaluating threshold 0.6 with avar bound: [-0.0009631186610218693]
Threshold 0.6 SUFFICIENT with avar bound: -0.0009631186610218693
Evaluating threshold 0.7 with avar bound: [-0.0009631186610218693]
Threshold 0.7 SUFFICIENT with avar bound: -0.0009631186610218693
Evaluating threshold 0.8 with avar bound: [-0.0009631186610218693]
Threshold 0.8 SUFFICIENT with avar bound: -0.0009631186610218693
Evaluating threshold 0.9 with avar bound: [-0.0009631186610218693]
Threshold 0.9 SUFFICIENT with avar bound: -0.0009631186610218693

Running BIRL with demonstration 8/10 in world 8
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.16
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.31476391 -0.16698255 -0.56266312  0.08952371  0.25516778  0.22214944
  0.65876799]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.007710
0.9-VaR bound for 8 demonstrations: -0.006399
0.95-VaR bound for 8 demonstrations: -0.001855
0.99-VaR bound for 8 demonstrations: 0.005326
True expected value difference for MAP policy: -0.006948
Evaluating threshold 0.1 with avar bound: [-0.001854560618959087]
Threshold 0.1 SUFFICIENT with avar bound: -0.001854560618959087
Evaluating threshold 0.2 with avar bound: [-0.001854560618959087]
Threshold 0.2 SUFFICIENT with avar bound: -0.001854560618959087
Evaluating threshold 0.3 with avar bound: [-0.001854560618959087]
Threshold 0.3 SUFFICIENT with avar bound: -0.001854560618959087
Evaluating threshold 0.4 with avar bound: [-0.001854560618959087]
Threshold 0.4 SUFFICIENT with avar bound: -0.001854560618959087
Evaluating threshold 0.5 with avar bound: [-0.001854560618959087]
Threshold 0.5 SUFFICIENT with avar bound: -0.001854560618959087
Evaluating threshold 0.6 with avar bound: [-0.001854560618959087]
Threshold 0.6 SUFFICIENT with avar bound: -0.001854560618959087
Evaluating threshold 0.7 with avar bound: [-0.001854560618959087]
Threshold 0.7 SUFFICIENT with avar bound: -0.001854560618959087
Evaluating threshold 0.8 with avar bound: [-0.001854560618959087]
Threshold 0.8 SUFFICIENT with avar bound: -0.001854560618959087
Evaluating threshold 0.9 with avar bound: [-0.001854560618959087]
Threshold 0.9 SUFFICIENT with avar bound: -0.001854560618959087

Running BIRL with demonstration 9/10 in world 8
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.171
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.17545914  0.01663263 -0.45629812 -0.19396046  0.46818824  0.02247869
  0.70950919]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.011662
0.9-VaR bound for 9 demonstrations: -0.009593
0.95-VaR bound for 9 demonstrations: -0.007855
0.99-VaR bound for 9 demonstrations: 0.003168
True expected value difference for MAP policy: -0.008675
Evaluating threshold 0.1 with avar bound: [-0.007855039632716427]
Threshold 0.1 SUFFICIENT with avar bound: -0.007855039632716427
Evaluating threshold 0.2 with avar bound: [-0.007855039632716427]
Threshold 0.2 SUFFICIENT with avar bound: -0.007855039632716427
Evaluating threshold 0.3 with avar bound: [-0.007855039632716427]
Threshold 0.3 SUFFICIENT with avar bound: -0.007855039632716427
Evaluating threshold 0.4 with avar bound: [-0.007855039632716427]
Threshold 0.4 SUFFICIENT with avar bound: -0.007855039632716427
Evaluating threshold 0.5 with avar bound: [-0.007855039632716427]
Threshold 0.5 SUFFICIENT with avar bound: -0.007855039632716427
Evaluating threshold 0.6 with avar bound: [-0.007855039632716427]
Threshold 0.6 SUFFICIENT with avar bound: -0.007855039632716427
Evaluating threshold 0.7 with avar bound: [-0.007855039632716427]
Threshold 0.7 SUFFICIENT with avar bound: -0.007855039632716427
Evaluating threshold 0.8 with avar bound: [-0.007855039632716427]
Threshold 0.8 SUFFICIENT with avar bound: -0.007855039632716427
Evaluating threshold 0.9 with avar bound: [-0.007855039632716427]
Threshold 0.9 SUFFICIENT with avar bound: -0.007855039632716427

Running BIRL with demonstration 10/10 in world 8
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.167
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.32089054 -0.27043365 -0.53740041  0.03750861  0.33423028  0.25432509
  0.59774382]
True Reward Weights: [-0.77636102 -0.45336175 -0.3490684  -0.16901698 -0.10460249 -0.00337706
  0.17423579]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.014616
0.9-VaR bound for 10 demonstrations: -0.013468
0.95-VaR bound for 10 demonstrations: -0.008407
0.99-VaR bound for 10 demonstrations: 0.008170
True expected value difference for MAP policy: -0.008018
Evaluating threshold 0.1 with avar bound: [-0.008406939794935288]
Threshold 0.1 SUFFICIENT with avar bound: -0.008406939794935288
Evaluating threshold 0.2 with avar bound: [-0.008406939794935288]
Threshold 0.2 SUFFICIENT with avar bound: -0.008406939794935288
Evaluating threshold 0.3 with avar bound: [-0.008406939794935288]
Threshold 0.3 SUFFICIENT with avar bound: -0.008406939794935288
Evaluating threshold 0.4 with avar bound: [-0.008406939794935288]
Threshold 0.4 SUFFICIENT with avar bound: -0.008406939794935288
Evaluating threshold 0.5 with avar bound: [-0.008406939794935288]
Threshold 0.5 SUFFICIENT with avar bound: -0.008406939794935288
Evaluating threshold 0.6 with avar bound: [-0.008406939794935288]
Threshold 0.6 SUFFICIENT with avar bound: -0.008406939794935288
Evaluating threshold 0.7 with avar bound: [-0.008406939794935288]
Threshold 0.7 SUFFICIENT with avar bound: -0.008406939794935288
Evaluating threshold 0.8 with avar bound: [-0.008406939794935288]
Threshold 0.8 SUFFICIENT with avar bound: -0.008406939794935288
Evaluating threshold 0.9 with avar bound: [-0.008406939794935288]
Threshold 0.9 SUFFICIENT with avar bound: -0.008406939794935288

Saving results to files...
Results saved successfully.

Running world 9/20

Running BIRL with demonstration 1/10 in world 9
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.457
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.35018027  0.04417597 -0.29775289 -0.11266237 -0.17620017  0.31572309
  0.80208796]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.307252
0.9-VaR bound for 1 demonstrations: 1.366688
0.95-VaR bound for 1 demonstrations: 1.422628
0.99-VaR bound for 1 demonstrations: 1.626128
True expected value difference for MAP policy: -0.012112
Evaluating threshold 0.1 with avar bound: [1.4226275923192757]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4226275923192757]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4226275923192757]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4226275923192757]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4226275923192757]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4226275923192757]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4226275923192757]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4226275923192757]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4226275923192757]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 9
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.32
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.05303043  0.28906799  0.12573807  0.00870036 -0.53194211  0.77879759
 -0.09084941]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.440015
0.9-VaR bound for 2 demonstrations: 1.741938
0.95-VaR bound for 2 demonstrations: 1.843446
0.99-VaR bound for 2 demonstrations: 2.450110
True expected value difference for MAP policy: 1.224608
Evaluating threshold 0.1 with avar bound: [1.8434458979899153]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.8434458979899153]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.8434458979899153]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.8434458979899153]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.8434458979899153]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.8434458979899153]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.8434458979899153]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.8434458979899153]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.8434458979899153]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.29
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.14221557  0.05761361 -0.37417417 -0.36068239 -0.19787672  0.28472259
  0.76559464]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.278774
0.9-VaR bound for 3 demonstrations: 1.352230
0.95-VaR bound for 3 demonstrations: 1.379767
0.99-VaR bound for 3 demonstrations: 1.505821
True expected value difference for MAP policy: -0.011416
Evaluating threshold 0.1 with avar bound: [1.3797674581244779]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3797674581244779]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3797674581244779]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3797674581244779]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3797674581244779]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3797674581244779]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3797674581244779]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3797674581244779]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3797674581244779]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.245
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.05258126 -0.16573627 -0.29614642  0.03697742 -0.30269062  0.32779333
  0.8256068 ]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.011069
0.9-VaR bound for 4 demonstrations: -0.006442
0.95-VaR bound for 4 demonstrations: -0.002324
0.99-VaR bound for 4 demonstrations: 0.018337
True expected value difference for MAP policy: -0.012112
Evaluating threshold 0.1 with avar bound: [-0.0023241191417914756]
Threshold 0.1 SUFFICIENT with avar bound: -0.0023241191417914756
Evaluating threshold 0.2 with avar bound: [-0.0023241191417914756]
Threshold 0.2 SUFFICIENT with avar bound: -0.0023241191417914756
Evaluating threshold 0.3 with avar bound: [-0.0023241191417914756]
Threshold 0.3 SUFFICIENT with avar bound: -0.0023241191417914756
Evaluating threshold 0.4 with avar bound: [-0.0023241191417914756]
Threshold 0.4 SUFFICIENT with avar bound: -0.0023241191417914756
Evaluating threshold 0.5 with avar bound: [-0.0023241191417914756]
Threshold 0.5 SUFFICIENT with avar bound: -0.0023241191417914756
Evaluating threshold 0.6 with avar bound: [-0.0023241191417914756]
Threshold 0.6 SUFFICIENT with avar bound: -0.0023241191417914756
Evaluating threshold 0.7 with avar bound: [-0.0023241191417914756]
Threshold 0.7 SUFFICIENT with avar bound: -0.0023241191417914756
Evaluating threshold 0.8 with avar bound: [-0.0023241191417914756]
Threshold 0.8 SUFFICIENT with avar bound: -0.0023241191417914756
Evaluating threshold 0.9 with avar bound: [-0.0023241191417914756]
Threshold 0.9 SUFFICIENT with avar bound: -0.0023241191417914756

Running BIRL with demonstration 5/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.222
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.16117352  0.01127392 -0.31171798 -0.17033405 -0.38116464  0.27938912
  0.79017052]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.008807
0.9-VaR bound for 5 demonstrations: -0.000648
0.95-VaR bound for 5 demonstrations: 0.002570
0.99-VaR bound for 5 demonstrations: 0.020859
True expected value difference for MAP policy: -0.011416
Evaluating threshold 0.1 with avar bound: [0.002570165085736887]
Threshold 0.1 SUFFICIENT with avar bound: 0.002570165085736887
Evaluating threshold 0.2 with avar bound: [0.002570165085736887]
Threshold 0.2 SUFFICIENT with avar bound: 0.002570165085736887
Evaluating threshold 0.3 with avar bound: [0.002570165085736887]
Threshold 0.3 SUFFICIENT with avar bound: 0.002570165085736887
Evaluating threshold 0.4 with avar bound: [0.002570165085736887]
Threshold 0.4 SUFFICIENT with avar bound: 0.002570165085736887
Evaluating threshold 0.5 with avar bound: [0.002570165085736887]
Threshold 0.5 SUFFICIENT with avar bound: 0.002570165085736887
Evaluating threshold 0.6 with avar bound: [0.002570165085736887]
Threshold 0.6 SUFFICIENT with avar bound: 0.002570165085736887
Evaluating threshold 0.7 with avar bound: [0.002570165085736887]
Threshold 0.7 SUFFICIENT with avar bound: 0.002570165085736887
Evaluating threshold 0.8 with avar bound: [0.002570165085736887]
Threshold 0.8 SUFFICIENT with avar bound: 0.002570165085736887
Evaluating threshold 0.9 with avar bound: [0.002570165085736887]
Threshold 0.9 SUFFICIENT with avar bound: 0.002570165085736887

Running BIRL with demonstration 6/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.195
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.48465514 -0.3680518  -0.20269618 -0.29442541  0.02656909  0.15167848
  0.69149326]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.009092
0.9-VaR bound for 6 demonstrations: -0.005810
0.95-VaR bound for 6 demonstrations: 0.004145
0.99-VaR bound for 6 demonstrations: 0.011027
True expected value difference for MAP policy: -0.013308
Evaluating threshold 0.1 with avar bound: [0.004144636796332872]
Threshold 0.1 SUFFICIENT with avar bound: 0.004144636796332872
Evaluating threshold 0.2 with avar bound: [0.004144636796332872]
Threshold 0.2 SUFFICIENT with avar bound: 0.004144636796332872
Evaluating threshold 0.3 with avar bound: [0.004144636796332872]
Threshold 0.3 SUFFICIENT with avar bound: 0.004144636796332872
Evaluating threshold 0.4 with avar bound: [0.004144636796332872]
Threshold 0.4 SUFFICIENT with avar bound: 0.004144636796332872
Evaluating threshold 0.5 with avar bound: [0.004144636796332872]
Threshold 0.5 SUFFICIENT with avar bound: 0.004144636796332872
Evaluating threshold 0.6 with avar bound: [0.004144636796332872]
Threshold 0.6 SUFFICIENT with avar bound: 0.004144636796332872
Evaluating threshold 0.7 with avar bound: [0.004144636796332872]
Threshold 0.7 SUFFICIENT with avar bound: 0.004144636796332872
Evaluating threshold 0.8 with avar bound: [0.004144636796332872]
Threshold 0.8 SUFFICIENT with avar bound: 0.004144636796332872
Evaluating threshold 0.9 with avar bound: [0.004144636796332872]
Threshold 0.9 SUFFICIENT with avar bound: 0.004144636796332872

Running BIRL with demonstration 7/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.192
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.39849942 -0.20620926  0.16342361 -0.49198639  0.03048007  0.26807059
  0.67611183]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.011653
0.9-VaR bound for 7 demonstrations: -0.008797
0.95-VaR bound for 7 demonstrations: -0.001871
0.99-VaR bound for 7 demonstrations: 0.020446
True expected value difference for MAP policy: -0.013308
Evaluating threshold 0.1 with avar bound: [-0.001870912507417982]
Threshold 0.1 SUFFICIENT with avar bound: -0.001870912507417982
Evaluating threshold 0.2 with avar bound: [-0.001870912507417982]
Threshold 0.2 SUFFICIENT with avar bound: -0.001870912507417982
Evaluating threshold 0.3 with avar bound: [-0.001870912507417982]
Threshold 0.3 SUFFICIENT with avar bound: -0.001870912507417982
Evaluating threshold 0.4 with avar bound: [-0.001870912507417982]
Threshold 0.4 SUFFICIENT with avar bound: -0.001870912507417982
Evaluating threshold 0.5 with avar bound: [-0.001870912507417982]
Threshold 0.5 SUFFICIENT with avar bound: -0.001870912507417982
Evaluating threshold 0.6 with avar bound: [-0.001870912507417982]
Threshold 0.6 SUFFICIENT with avar bound: -0.001870912507417982
Evaluating threshold 0.7 with avar bound: [-0.001870912507417982]
Threshold 0.7 SUFFICIENT with avar bound: -0.001870912507417982
Evaluating threshold 0.8 with avar bound: [-0.001870912507417982]
Threshold 0.8 SUFFICIENT with avar bound: -0.001870912507417982
Evaluating threshold 0.9 with avar bound: [-0.001870912507417982]
Threshold 0.9 SUFFICIENT with avar bound: -0.001870912507417982

Running BIRL with demonstration 8/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.184
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.68229892 -0.02229616 -0.22851748 -0.33713786 -0.2746406   0.15339369
  0.51877915]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.010892
0.9-VaR bound for 8 demonstrations: -0.008795
0.95-VaR bound for 8 demonstrations: -0.004576
0.99-VaR bound for 8 demonstrations: -0.000925
True expected value difference for MAP policy: -0.013093
Evaluating threshold 0.1 with avar bound: [-0.004576214381597026]
Threshold 0.1 SUFFICIENT with avar bound: -0.004576214381597026
Evaluating threshold 0.2 with avar bound: [-0.004576214381597026]
Threshold 0.2 SUFFICIENT with avar bound: -0.004576214381597026
Evaluating threshold 0.3 with avar bound: [-0.004576214381597026]
Threshold 0.3 SUFFICIENT with avar bound: -0.004576214381597026
Evaluating threshold 0.4 with avar bound: [-0.004576214381597026]
Threshold 0.4 SUFFICIENT with avar bound: -0.004576214381597026
Evaluating threshold 0.5 with avar bound: [-0.004576214381597026]
Threshold 0.5 SUFFICIENT with avar bound: -0.004576214381597026
Evaluating threshold 0.6 with avar bound: [-0.004576214381597026]
Threshold 0.6 SUFFICIENT with avar bound: -0.004576214381597026
Evaluating threshold 0.7 with avar bound: [-0.004576214381597026]
Threshold 0.7 SUFFICIENT with avar bound: -0.004576214381597026
Evaluating threshold 0.8 with avar bound: [-0.004576214381597026]
Threshold 0.8 SUFFICIENT with avar bound: -0.004576214381597026
Evaluating threshold 0.9 with avar bound: [-0.004576214381597026]
Threshold 0.9 SUFFICIENT with avar bound: -0.004576214381597026

Running BIRL with demonstration 9/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.197
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.70362952 -0.06705452 -0.17180329 -0.29493665 -0.03649486  0.14601654
  0.60104284]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.013078
0.9-VaR bound for 9 demonstrations: -0.011523
0.95-VaR bound for 9 demonstrations: -0.007734
0.99-VaR bound for 9 demonstrations: 0.006780
True expected value difference for MAP policy: -0.013345
Evaluating threshold 0.1 with avar bound: [-0.007733962215204749]
Threshold 0.1 SUFFICIENT with avar bound: -0.007733962215204749
Evaluating threshold 0.2 with avar bound: [-0.007733962215204749]
Threshold 0.2 SUFFICIENT with avar bound: -0.007733962215204749
Evaluating threshold 0.3 with avar bound: [-0.007733962215204749]
Threshold 0.3 SUFFICIENT with avar bound: -0.007733962215204749
Evaluating threshold 0.4 with avar bound: [-0.007733962215204749]
Threshold 0.4 SUFFICIENT with avar bound: -0.007733962215204749
Evaluating threshold 0.5 with avar bound: [-0.007733962215204749]
Threshold 0.5 SUFFICIENT with avar bound: -0.007733962215204749
Evaluating threshold 0.6 with avar bound: [-0.007733962215204749]
Threshold 0.6 SUFFICIENT with avar bound: -0.007733962215204749
Evaluating threshold 0.7 with avar bound: [-0.007733962215204749]
Threshold 0.7 SUFFICIENT with avar bound: -0.007733962215204749
Evaluating threshold 0.8 with avar bound: [-0.007733962215204749]
Threshold 0.8 SUFFICIENT with avar bound: -0.007733962215204749
Evaluating threshold 0.9 with avar bound: [-0.007733962215204749]
Threshold 0.9 SUFFICIENT with avar bound: -0.007733962215204749

Running BIRL with demonstration 10/10 in world 9
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 1), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.174
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.54855906  0.06231806 -0.32666244 -0.51220593 -0.09238209  0.16722693
  0.5381792 ]
True Reward Weights: [-0.62908197 -0.38460285 -0.36580859 -0.36024981 -0.13593839  0.04581559
  0.41492452]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.012172
0.9-VaR bound for 10 demonstrations: -0.010334
0.95-VaR bound for 10 demonstrations: -0.007790
0.99-VaR bound for 10 demonstrations: -0.004514
True expected value difference for MAP policy: -0.013308
Evaluating threshold 0.1 with avar bound: [-0.007790183136784501]
Threshold 0.1 SUFFICIENT with avar bound: -0.007790183136784501
Evaluating threshold 0.2 with avar bound: [-0.007790183136784501]
Threshold 0.2 SUFFICIENT with avar bound: -0.007790183136784501
Evaluating threshold 0.3 with avar bound: [-0.007790183136784501]
Threshold 0.3 SUFFICIENT with avar bound: -0.007790183136784501
Evaluating threshold 0.4 with avar bound: [-0.007790183136784501]
Threshold 0.4 SUFFICIENT with avar bound: -0.007790183136784501
Evaluating threshold 0.5 with avar bound: [-0.007790183136784501]
Threshold 0.5 SUFFICIENT with avar bound: -0.007790183136784501
Evaluating threshold 0.6 with avar bound: [-0.007790183136784501]
Threshold 0.6 SUFFICIENT with avar bound: -0.007790183136784501
Evaluating threshold 0.7 with avar bound: [-0.007790183136784501]
Threshold 0.7 SUFFICIENT with avar bound: -0.007790183136784501
Evaluating threshold 0.8 with avar bound: [-0.007790183136784501]
Threshold 0.8 SUFFICIENT with avar bound: -0.007790183136784501
Evaluating threshold 0.9 with avar bound: [-0.007790183136784501]
Threshold 0.9 SUFFICIENT with avar bound: -0.007790183136784501

Running world 10/20

Running BIRL with demonstration 1/10 in world 10
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.449
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.21879779 -0.01019666 -0.59143575 -0.17424139  0.18998616 -0.43529147
  0.58846737]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.273284
0.9-VaR bound for 1 demonstrations: 1.363926
0.95-VaR bound for 1 demonstrations: 1.486987
0.99-VaR bound for 1 demonstrations: 1.538543
True expected value difference for MAP policy: -0.023049
Evaluating threshold 0.1 with avar bound: [1.4869868595835192]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4869868595835192]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4869868595835192]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4869868595835192]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4869868595835192]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4869868595835192]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4869868595835192]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4869868595835192]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4869868595835192]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 10
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.356
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.10630867 -0.39643884 -0.22953731  0.02157464  0.52813384 -0.32922484
  0.62535391]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.274263
0.9-VaR bound for 2 demonstrations: 1.334580
0.95-VaR bound for 2 demonstrations: 1.390330
0.99-VaR bound for 2 demonstrations: 1.458820
True expected value difference for MAP policy: -0.027165
Evaluating threshold 0.1 with avar bound: [1.3903299688698978]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3903299688698978]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3903299688698978]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3903299688698978]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3903299688698978]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3903299688698978]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3903299688698978]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3903299688698978]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3903299688698978]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.264
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.21444452 -0.49807003 -0.5394007   0.0948884   0.15426256  0.03395122
  0.61727891]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.927880
0.9-VaR bound for 3 demonstrations: 1.250910
0.95-VaR bound for 3 demonstrations: 1.523153
0.99-VaR bound for 3 demonstrations: 1.554817
True expected value difference for MAP policy: -0.033046
Evaluating threshold 0.1 with avar bound: [1.5231529526981018]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.5231529526981018]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.5231529526981018]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.5231529526981018]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.5231529526981018]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.5231529526981018]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.5231529526981018]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.5231529526981018]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.5231529526981018]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.249
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.02398043 -0.46851003 -0.34642889  0.24964715  0.18053775  0.01269654
  0.75155275]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.004266
0.9-VaR bound for 4 demonstrations: -0.001364
0.95-VaR bound for 4 demonstrations: 0.007308
0.99-VaR bound for 4 demonstrations: 0.020342
True expected value difference for MAP policy: -0.025877
Evaluating threshold 0.1 with avar bound: [0.007308426509080079]
Threshold 0.1 SUFFICIENT with avar bound: 0.007308426509080079
Evaluating threshold 0.2 with avar bound: [0.007308426509080079]
Threshold 0.2 SUFFICIENT with avar bound: 0.007308426509080079
Evaluating threshold 0.3 with avar bound: [0.007308426509080079]
Threshold 0.3 SUFFICIENT with avar bound: 0.007308426509080079
Evaluating threshold 0.4 with avar bound: [0.007308426509080079]
Threshold 0.4 SUFFICIENT with avar bound: 0.007308426509080079
Evaluating threshold 0.5 with avar bound: [0.007308426509080079]
Threshold 0.5 SUFFICIENT with avar bound: 0.007308426509080079
Evaluating threshold 0.6 with avar bound: [0.007308426509080079]
Threshold 0.6 SUFFICIENT with avar bound: 0.007308426509080079
Evaluating threshold 0.7 with avar bound: [0.007308426509080079]
Threshold 0.7 SUFFICIENT with avar bound: 0.007308426509080079
Evaluating threshold 0.8 with avar bound: [0.007308426509080079]
Threshold 0.8 SUFFICIENT with avar bound: 0.007308426509080079
Evaluating threshold 0.9 with avar bound: [0.007308426509080079]
Threshold 0.9 SUFFICIENT with avar bound: 0.007308426509080079

Running BIRL with demonstration 5/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.235
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.12344541 -0.48853597 -0.54674549 -0.05478119  0.10185217 -0.26438158
  0.60323357]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.000803
0.9-VaR bound for 5 demonstrations: 0.011679
0.95-VaR bound for 5 demonstrations: 0.032653
0.99-VaR bound for 5 demonstrations: 0.038639
True expected value difference for MAP policy: -0.027165
Evaluating threshold 0.1 with avar bound: [0.03265253526390461]
Threshold 0.1 SUFFICIENT with avar bound: 0.03265253526390461
Evaluating threshold 0.2 with avar bound: [0.03265253526390461]
Threshold 0.2 SUFFICIENT with avar bound: 0.03265253526390461
Evaluating threshold 0.3 with avar bound: [0.03265253526390461]
Threshold 0.3 SUFFICIENT with avar bound: 0.03265253526390461
Evaluating threshold 0.4 with avar bound: [0.03265253526390461]
Threshold 0.4 SUFFICIENT with avar bound: 0.03265253526390461
Evaluating threshold 0.5 with avar bound: [0.03265253526390461]
Threshold 0.5 SUFFICIENT with avar bound: 0.03265253526390461
Evaluating threshold 0.6 with avar bound: [0.03265253526390461]
Threshold 0.6 SUFFICIENT with avar bound: 0.03265253526390461
Evaluating threshold 0.7 with avar bound: [0.03265253526390461]
Threshold 0.7 SUFFICIENT with avar bound: 0.03265253526390461
Evaluating threshold 0.8 with avar bound: [0.03265253526390461]
Threshold 0.8 SUFFICIENT with avar bound: 0.03265253526390461
Evaluating threshold 0.9 with avar bound: [0.03265253526390461]
Threshold 0.9 SUFFICIENT with avar bound: 0.03265253526390461

Running BIRL with demonstration 6/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.216
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.13485159 -0.52351155 -0.38127256  0.08418497  0.24346059 -0.15210185
  0.68766765]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.005084
0.9-VaR bound for 6 demonstrations: -0.000801
0.95-VaR bound for 6 demonstrations: 0.003762
0.99-VaR bound for 6 demonstrations: 0.023319
True expected value difference for MAP policy: -0.025877
Evaluating threshold 0.1 with avar bound: [0.0037615033817995284]
Threshold 0.1 SUFFICIENT with avar bound: 0.0037615033817995284
Evaluating threshold 0.2 with avar bound: [0.0037615033817995284]
Threshold 0.2 SUFFICIENT with avar bound: 0.0037615033817995284
Evaluating threshold 0.3 with avar bound: [0.0037615033817995284]
Threshold 0.3 SUFFICIENT with avar bound: 0.0037615033817995284
Evaluating threshold 0.4 with avar bound: [0.0037615033817995284]
Threshold 0.4 SUFFICIENT with avar bound: 0.0037615033817995284
Evaluating threshold 0.5 with avar bound: [0.0037615033817995284]
Threshold 0.5 SUFFICIENT with avar bound: 0.0037615033817995284
Evaluating threshold 0.6 with avar bound: [0.0037615033817995284]
Threshold 0.6 SUFFICIENT with avar bound: 0.0037615033817995284
Evaluating threshold 0.7 with avar bound: [0.0037615033817995284]
Threshold 0.7 SUFFICIENT with avar bound: 0.0037615033817995284
Evaluating threshold 0.8 with avar bound: [0.0037615033817995284]
Threshold 0.8 SUFFICIENT with avar bound: 0.0037615033817995284
Evaluating threshold 0.9 with avar bound: [0.0037615033817995284]
Threshold 0.9 SUFFICIENT with avar bound: 0.0037615033817995284

Running BIRL with demonstration 7/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.176
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.58478088 -0.29558178 -0.16247186  0.34877517  0.31923801 -0.08534419
  0.5598437 ]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.007890
0.9-VaR bound for 7 demonstrations: -0.006185
0.95-VaR bound for 7 demonstrations: -0.004896
0.99-VaR bound for 7 demonstrations: 0.001454
True expected value difference for MAP policy: -0.028025
Evaluating threshold 0.1 with avar bound: [-0.00489621751819412]
Threshold 0.1 SUFFICIENT with avar bound: -0.00489621751819412
Evaluating threshold 0.2 with avar bound: [-0.00489621751819412]
Threshold 0.2 SUFFICIENT with avar bound: -0.00489621751819412
Evaluating threshold 0.3 with avar bound: [-0.00489621751819412]
Threshold 0.3 SUFFICIENT with avar bound: -0.00489621751819412
Evaluating threshold 0.4 with avar bound: [-0.00489621751819412]
Threshold 0.4 SUFFICIENT with avar bound: -0.00489621751819412
Evaluating threshold 0.5 with avar bound: [-0.00489621751819412]
Threshold 0.5 SUFFICIENT with avar bound: -0.00489621751819412
Evaluating threshold 0.6 with avar bound: [-0.00489621751819412]
Threshold 0.6 SUFFICIENT with avar bound: -0.00489621751819412
Evaluating threshold 0.7 with avar bound: [-0.00489621751819412]
Threshold 0.7 SUFFICIENT with avar bound: -0.00489621751819412
Evaluating threshold 0.8 with avar bound: [-0.00489621751819412]
Threshold 0.8 SUFFICIENT with avar bound: -0.00489621751819412
Evaluating threshold 0.9 with avar bound: [-0.00489621751819412]
Threshold 0.9 SUFFICIENT with avar bound: -0.00489621751819412

Running BIRL with demonstration 8/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.178
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34017893 -0.40154611 -0.31977355  0.46100042  0.16815257 -0.07301324
  0.61209174]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.012844
0.9-VaR bound for 8 demonstrations: -0.011538
0.95-VaR bound for 8 demonstrations: -0.005241
0.99-VaR bound for 8 demonstrations: 0.006677
True expected value difference for MAP policy: -0.028025
Evaluating threshold 0.1 with avar bound: [-0.005241436764852244]
Threshold 0.1 SUFFICIENT with avar bound: -0.005241436764852244
Evaluating threshold 0.2 with avar bound: [-0.005241436764852244]
Threshold 0.2 SUFFICIENT with avar bound: -0.005241436764852244
Evaluating threshold 0.3 with avar bound: [-0.005241436764852244]
Threshold 0.3 SUFFICIENT with avar bound: -0.005241436764852244
Evaluating threshold 0.4 with avar bound: [-0.005241436764852244]
Threshold 0.4 SUFFICIENT with avar bound: -0.005241436764852244
Evaluating threshold 0.5 with avar bound: [-0.005241436764852244]
Threshold 0.5 SUFFICIENT with avar bound: -0.005241436764852244
Evaluating threshold 0.6 with avar bound: [-0.005241436764852244]
Threshold 0.6 SUFFICIENT with avar bound: -0.005241436764852244
Evaluating threshold 0.7 with avar bound: [-0.005241436764852244]
Threshold 0.7 SUFFICIENT with avar bound: -0.005241436764852244
Evaluating threshold 0.8 with avar bound: [-0.005241436764852244]
Threshold 0.8 SUFFICIENT with avar bound: -0.005241436764852244
Evaluating threshold 0.9 with avar bound: [-0.005241436764852244]
Threshold 0.9 SUFFICIENT with avar bound: -0.005241436764852244

Running BIRL with demonstration 9/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.168
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61301015 -0.34554703 -0.14185431  0.18802321  0.30843799  0.02711349
  0.59453453]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.011568
0.9-VaR bound for 9 demonstrations: -0.008656
0.95-VaR bound for 9 demonstrations: -0.001242
0.99-VaR bound for 9 demonstrations: 0.015037
True expected value difference for MAP policy: -0.028025
Evaluating threshold 0.1 with avar bound: [-0.0012418989579603744]
Threshold 0.1 SUFFICIENT with avar bound: -0.0012418989579603744
Evaluating threshold 0.2 with avar bound: [-0.0012418989579603744]
Threshold 0.2 SUFFICIENT with avar bound: -0.0012418989579603744
Evaluating threshold 0.3 with avar bound: [-0.0012418989579603744]
Threshold 0.3 SUFFICIENT with avar bound: -0.0012418989579603744
Evaluating threshold 0.4 with avar bound: [-0.0012418989579603744]
Threshold 0.4 SUFFICIENT with avar bound: -0.0012418989579603744
Evaluating threshold 0.5 with avar bound: [-0.0012418989579603744]
Threshold 0.5 SUFFICIENT with avar bound: -0.0012418989579603744
Evaluating threshold 0.6 with avar bound: [-0.0012418989579603744]
Threshold 0.6 SUFFICIENT with avar bound: -0.0012418989579603744
Evaluating threshold 0.7 with avar bound: [-0.0012418989579603744]
Threshold 0.7 SUFFICIENT with avar bound: -0.0012418989579603744
Evaluating threshold 0.8 with avar bound: [-0.0012418989579603744]
Threshold 0.8 SUFFICIENT with avar bound: -0.0012418989579603744
Evaluating threshold 0.9 with avar bound: [-0.0012418989579603744]
Threshold 0.9 SUFFICIENT with avar bound: -0.0012418989579603744

Running BIRL with demonstration 10/10 in world 10
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.177
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.58334198 -0.45914194 -0.47850404  0.21610201  0.14267443 -0.04072827
  0.38886994]
True Reward Weights: [-0.3940705  -0.05089806 -0.02628997  0.28978588  0.46070489  0.46504681
  0.57352705]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.011861
0.9-VaR bound for 10 demonstrations: -0.010548
0.95-VaR bound for 10 demonstrations: -0.008049
0.99-VaR bound for 10 demonstrations: 0.000332
True expected value difference for MAP policy: -0.028025
Evaluating threshold 0.1 with avar bound: [-0.008048545629572683]
Threshold 0.1 SUFFICIENT with avar bound: -0.008048545629572683
Evaluating threshold 0.2 with avar bound: [-0.008048545629572683]
Threshold 0.2 SUFFICIENT with avar bound: -0.008048545629572683
Evaluating threshold 0.3 with avar bound: [-0.008048545629572683]
Threshold 0.3 SUFFICIENT with avar bound: -0.008048545629572683
Evaluating threshold 0.4 with avar bound: [-0.008048545629572683]
Threshold 0.4 SUFFICIENT with avar bound: -0.008048545629572683
Evaluating threshold 0.5 with avar bound: [-0.008048545629572683]
Threshold 0.5 SUFFICIENT with avar bound: -0.008048545629572683
Evaluating threshold 0.6 with avar bound: [-0.008048545629572683]
Threshold 0.6 SUFFICIENT with avar bound: -0.008048545629572683
Evaluating threshold 0.7 with avar bound: [-0.008048545629572683]
Threshold 0.7 SUFFICIENT with avar bound: -0.008048545629572683
Evaluating threshold 0.8 with avar bound: [-0.008048545629572683]
Threshold 0.8 SUFFICIENT with avar bound: -0.008048545629572683
Evaluating threshold 0.9 with avar bound: [-0.008048545629572683]
Threshold 0.9 SUFFICIENT with avar bound: -0.008048545629572683

Running world 11/20

Running BIRL with demonstration 1/10 in world 11
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.455
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.08189796  0.01808348 -0.18659236  0.1433115  -0.49988775  0.82929017
  0.00093589]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.290526
0.9-VaR bound for 1 demonstrations: 1.639003
0.95-VaR bound for 1 demonstrations: 2.149213
0.99-VaR bound for 1 demonstrations: 2.723850
True expected value difference for MAP policy: 0.528833
Evaluating threshold 0.1 with avar bound: [2.149213396699117]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.149213396699117]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.149213396699117]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.149213396699117]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.149213396699117]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.149213396699117]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.149213396699117]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.149213396699117]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.149213396699117]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 11
Current demos: [(16, 1), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.382
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.15040514  0.31211792 -0.18871332 -0.09833723 -0.23784224  0.8810639
  0.04283973]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 0.647258
0.9-VaR bound for 2 demonstrations: 0.966967
0.95-VaR bound for 2 demonstrations: 1.459747
0.99-VaR bound for 2 demonstrations: 2.029665
True expected value difference for MAP policy: 0.528833
Evaluating threshold 0.1 with avar bound: [1.4597466185257595]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4597466185257595]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4597466185257595]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4597466185257595]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4597466185257595]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4597466185257595]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4597466185257595]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4597466185257595]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4597466185257595]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 11
Current demos: [(16, 1), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.289
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38740013 -0.0332963  -0.05524183  0.35697194 -0.37793589  0.54943444
  0.5230852 ]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.018924
0.9-VaR bound for 3 demonstrations: 1.068105
0.95-VaR bound for 3 demonstrations: 1.104175
0.99-VaR bound for 3 demonstrations: 1.239885
True expected value difference for MAP policy: 0.070844
Evaluating threshold 0.1 with avar bound: [1.1041749798000042]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.1041749798000042]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.1041749798000042]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.1041749798000042]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.1041749798000042]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.1041749798000042]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.1041749798000042]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.1041749798000042]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.1041749798000042]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 11
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.216
Using 700 samples after burn-in
MAP Solution Reward Weights: [-4.11437928e-01 -2.50259459e-04 -4.18588062e-02 -2.85968308e-01
 -4.54688291e-01  3.96912637e-01  6.18795324e-01]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.004391
0.9-VaR bound for 4 demonstrations: -0.002555
0.95-VaR bound for 4 demonstrations: 0.002223
0.99-VaR bound for 4 demonstrations: 0.027667
True expected value difference for MAP policy: -0.004638
Evaluating threshold 0.1 with avar bound: [0.0022233110689090303]
Threshold 0.1 SUFFICIENT with avar bound: 0.0022233110689090303
Evaluating threshold 0.2 with avar bound: [0.0022233110689090303]
Threshold 0.2 SUFFICIENT with avar bound: 0.0022233110689090303
Evaluating threshold 0.3 with avar bound: [0.0022233110689090303]
Threshold 0.3 SUFFICIENT with avar bound: 0.0022233110689090303
Evaluating threshold 0.4 with avar bound: [0.0022233110689090303]
Threshold 0.4 SUFFICIENT with avar bound: 0.0022233110689090303
Evaluating threshold 0.5 with avar bound: [0.0022233110689090303]
Threshold 0.5 SUFFICIENT with avar bound: 0.0022233110689090303
Evaluating threshold 0.6 with avar bound: [0.0022233110689090303]
Threshold 0.6 SUFFICIENT with avar bound: 0.0022233110689090303
Evaluating threshold 0.7 with avar bound: [0.0022233110689090303]
Threshold 0.7 SUFFICIENT with avar bound: 0.0022233110689090303
Evaluating threshold 0.8 with avar bound: [0.0022233110689090303]
Threshold 0.8 SUFFICIENT with avar bound: 0.0022233110689090303
Evaluating threshold 0.9 with avar bound: [0.0022233110689090303]
Threshold 0.9 SUFFICIENT with avar bound: 0.0022233110689090303

Running BIRL with demonstration 5/10 in world 11
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.207
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.45812191  0.12361242  0.27939678 -0.16829012 -0.24108015  0.54738892
  0.55740999]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.000158
0.9-VaR bound for 5 demonstrations: 0.002650
0.95-VaR bound for 5 demonstrations: 0.004361
0.99-VaR bound for 5 demonstrations: 0.023375
True expected value difference for MAP policy: -0.003528
Evaluating threshold 0.1 with avar bound: [0.004360906094854618]
Threshold 0.1 SUFFICIENT with avar bound: 0.004360906094854618
Evaluating threshold 0.2 with avar bound: [0.004360906094854618]
Threshold 0.2 SUFFICIENT with avar bound: 0.004360906094854618
Evaluating threshold 0.3 with avar bound: [0.004360906094854618]
Threshold 0.3 SUFFICIENT with avar bound: 0.004360906094854618
Evaluating threshold 0.4 with avar bound: [0.004360906094854618]
Threshold 0.4 SUFFICIENT with avar bound: 0.004360906094854618
Evaluating threshold 0.5 with avar bound: [0.004360906094854618]
Threshold 0.5 SUFFICIENT with avar bound: 0.004360906094854618
Evaluating threshold 0.6 with avar bound: [0.004360906094854618]
Threshold 0.6 SUFFICIENT with avar bound: 0.004360906094854618
Evaluating threshold 0.7 with avar bound: [0.004360906094854618]
Threshold 0.7 SUFFICIENT with avar bound: 0.004360906094854618
Evaluating threshold 0.8 with avar bound: [0.004360906094854618]
Threshold 0.8 SUFFICIENT with avar bound: 0.004360906094854618
Evaluating threshold 0.9 with avar bound: [0.004360906094854618]
Threshold 0.9 SUFFICIENT with avar bound: 0.004360906094854618

Running BIRL with demonstration 6/10 in world 11
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.201
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34444125  0.09194956 -0.01979703 -0.12520527 -0.17370275  0.62435704
  0.66094089]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.008364
0.9-VaR bound for 6 demonstrations: -0.006841
0.95-VaR bound for 6 demonstrations: -0.005552
0.99-VaR bound for 6 demonstrations: -0.002939
True expected value difference for MAP policy: -0.004638
Evaluating threshold 0.1 with avar bound: [-0.0055517193484867855]
Threshold 0.1 SUFFICIENT with avar bound: -0.0055517193484867855
Evaluating threshold 0.2 with avar bound: [-0.0055517193484867855]
Threshold 0.2 SUFFICIENT with avar bound: -0.0055517193484867855
Evaluating threshold 0.3 with avar bound: [-0.0055517193484867855]
Threshold 0.3 SUFFICIENT with avar bound: -0.0055517193484867855
Evaluating threshold 0.4 with avar bound: [-0.0055517193484867855]
Threshold 0.4 SUFFICIENT with avar bound: -0.0055517193484867855
Evaluating threshold 0.5 with avar bound: [-0.0055517193484867855]
Threshold 0.5 SUFFICIENT with avar bound: -0.0055517193484867855
Evaluating threshold 0.6 with avar bound: [-0.0055517193484867855]
Threshold 0.6 SUFFICIENT with avar bound: -0.0055517193484867855
Evaluating threshold 0.7 with avar bound: [-0.0055517193484867855]
Threshold 0.7 SUFFICIENT with avar bound: -0.0055517193484867855
Evaluating threshold 0.8 with avar bound: [-0.0055517193484867855]
Threshold 0.8 SUFFICIENT with avar bound: -0.0055517193484867855
Evaluating threshold 0.9 with avar bound: [-0.0055517193484867855]
Threshold 0.9 SUFFICIENT with avar bound: -0.0055517193484867855

Running BIRL with demonstration 7/10 in world 11
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.2
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62943459 -0.00579992 -0.18940845 -0.035884   -0.26541047  0.46391413
  0.53005302]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.007149
0.9-VaR bound for 7 demonstrations: -0.004413
0.95-VaR bound for 7 demonstrations: 0.002293
0.99-VaR bound for 7 demonstrations: 0.011768
True expected value difference for MAP policy: -0.004638
Evaluating threshold 0.1 with avar bound: [0.0022928158471613026]
Threshold 0.1 SUFFICIENT with avar bound: 0.0022928158471613026
Evaluating threshold 0.2 with avar bound: [0.0022928158471613026]
Threshold 0.2 SUFFICIENT with avar bound: 0.0022928158471613026
Evaluating threshold 0.3 with avar bound: [0.0022928158471613026]
Threshold 0.3 SUFFICIENT with avar bound: 0.0022928158471613026
Evaluating threshold 0.4 with avar bound: [0.0022928158471613026]
Threshold 0.4 SUFFICIENT with avar bound: 0.0022928158471613026
Evaluating threshold 0.5 with avar bound: [0.0022928158471613026]
Threshold 0.5 SUFFICIENT with avar bound: 0.0022928158471613026
Evaluating threshold 0.6 with avar bound: [0.0022928158471613026]
Threshold 0.6 SUFFICIENT with avar bound: 0.0022928158471613026
Evaluating threshold 0.7 with avar bound: [0.0022928158471613026]
Threshold 0.7 SUFFICIENT with avar bound: 0.0022928158471613026
Evaluating threshold 0.8 with avar bound: [0.0022928158471613026]
Threshold 0.8 SUFFICIENT with avar bound: 0.0022928158471613026
Evaluating threshold 0.9 with avar bound: [0.0022928158471613026]
Threshold 0.9 SUFFICIENT with avar bound: 0.0022928158471613026

Running BIRL with demonstration 8/10 in world 11
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.186
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.64140293  0.12147809  0.059845    0.09831736 -0.02749837  0.17963838
  0.72634119]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: 0.000982
0.9-VaR bound for 8 demonstrations: 0.002578
0.95-VaR bound for 8 demonstrations: 0.021462
0.99-VaR bound for 8 demonstrations: 0.035579
True expected value difference for MAP policy: -0.014862
Evaluating threshold 0.1 with avar bound: [0.021462469584399207]
Threshold 0.1 SUFFICIENT with avar bound: 0.021462469584399207
Evaluating threshold 0.2 with avar bound: [0.021462469584399207]
Threshold 0.2 SUFFICIENT with avar bound: 0.021462469584399207
Evaluating threshold 0.3 with avar bound: [0.021462469584399207]
Threshold 0.3 SUFFICIENT with avar bound: 0.021462469584399207
Evaluating threshold 0.4 with avar bound: [0.021462469584399207]
Threshold 0.4 SUFFICIENT with avar bound: 0.021462469584399207
Evaluating threshold 0.5 with avar bound: [0.021462469584399207]
Threshold 0.5 SUFFICIENT with avar bound: 0.021462469584399207
Evaluating threshold 0.6 with avar bound: [0.021462469584399207]
Threshold 0.6 SUFFICIENT with avar bound: 0.021462469584399207
Evaluating threshold 0.7 with avar bound: [0.021462469584399207]
Threshold 0.7 SUFFICIENT with avar bound: 0.021462469584399207
Evaluating threshold 0.8 with avar bound: [0.021462469584399207]
Threshold 0.8 SUFFICIENT with avar bound: 0.021462469584399207
Evaluating threshold 0.9 with avar bound: [0.021462469584399207]
Threshold 0.9 SUFFICIENT with avar bound: 0.021462469584399207

Running BIRL with demonstration 9/10 in world 11
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.181
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.74407363  0.32068743  0.02295522  0.04904853  0.12048895  0.33538626
  0.46214693]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.002751
0.9-VaR bound for 9 demonstrations: 0.001678
0.95-VaR bound for 9 demonstrations: 0.015029
0.99-VaR bound for 9 demonstrations: 0.028442
True expected value difference for MAP policy: -0.016254
Evaluating threshold 0.1 with avar bound: [0.015028834811337849]
Threshold 0.1 SUFFICIENT with avar bound: 0.015028834811337849
Evaluating threshold 0.2 with avar bound: [0.015028834811337849]
Threshold 0.2 SUFFICIENT with avar bound: 0.015028834811337849
Evaluating threshold 0.3 with avar bound: [0.015028834811337849]
Threshold 0.3 SUFFICIENT with avar bound: 0.015028834811337849
Evaluating threshold 0.4 with avar bound: [0.015028834811337849]
Threshold 0.4 SUFFICIENT with avar bound: 0.015028834811337849
Evaluating threshold 0.5 with avar bound: [0.015028834811337849]
Threshold 0.5 SUFFICIENT with avar bound: 0.015028834811337849
Evaluating threshold 0.6 with avar bound: [0.015028834811337849]
Threshold 0.6 SUFFICIENT with avar bound: 0.015028834811337849
Evaluating threshold 0.7 with avar bound: [0.015028834811337849]
Threshold 0.7 SUFFICIENT with avar bound: 0.015028834811337849
Evaluating threshold 0.8 with avar bound: [0.015028834811337849]
Threshold 0.8 SUFFICIENT with avar bound: 0.015028834811337849
Evaluating threshold 0.9 with avar bound: [0.015028834811337849]
Threshold 0.9 SUFFICIENT with avar bound: 0.015028834811337849

Running BIRL with demonstration 10/10 in world 11
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.187
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.76457393  0.06718378 -0.09969633  0.1619952  -0.12791322  0.22520848
  0.55466259]
True Reward Weights: [-0.65469197 -0.58613388 -0.10226558  0.05348018  0.19732369  0.24911293
  0.33691726]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: 0.000597
0.9-VaR bound for 10 demonstrations: 0.007695
0.95-VaR bound for 10 demonstrations: 0.012696
0.99-VaR bound for 10 demonstrations: 0.023020
True expected value difference for MAP policy: -0.014862
Evaluating threshold 0.1 with avar bound: [0.0126959904912803]
Threshold 0.1 SUFFICIENT with avar bound: 0.0126959904912803
Evaluating threshold 0.2 with avar bound: [0.0126959904912803]
Threshold 0.2 SUFFICIENT with avar bound: 0.0126959904912803
Evaluating threshold 0.3 with avar bound: [0.0126959904912803]
Threshold 0.3 SUFFICIENT with avar bound: 0.0126959904912803
Evaluating threshold 0.4 with avar bound: [0.0126959904912803]
Threshold 0.4 SUFFICIENT with avar bound: 0.0126959904912803
Evaluating threshold 0.5 with avar bound: [0.0126959904912803]
Threshold 0.5 SUFFICIENT with avar bound: 0.0126959904912803
Evaluating threshold 0.6 with avar bound: [0.0126959904912803]
Threshold 0.6 SUFFICIENT with avar bound: 0.0126959904912803
Evaluating threshold 0.7 with avar bound: [0.0126959904912803]
Threshold 0.7 SUFFICIENT with avar bound: 0.0126959904912803
Evaluating threshold 0.8 with avar bound: [0.0126959904912803]
Threshold 0.8 SUFFICIENT with avar bound: 0.0126959904912803
Evaluating threshold 0.9 with avar bound: [0.0126959904912803]
Threshold 0.9 SUFFICIENT with avar bound: 0.0126959904912803

Running world 12/20

Running BIRL with demonstration 1/10 in world 12
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.526
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.13292836  0.18433239  0.11478578 -0.59610361  0.27973313 -0.35080007
  0.61524387]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.338053
0.9-VaR bound for 1 demonstrations: 1.370842
0.95-VaR bound for 1 demonstrations: 1.434336
0.99-VaR bound for 1 demonstrations: 1.571021
True expected value difference for MAP policy: 0.022727
Evaluating threshold 0.1 with avar bound: [1.4343360628832482]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4343360628832482]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4343360628832482]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4343360628832482]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4343360628832482]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4343360628832482]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4343360628832482]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4343360628832482]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4343360628832482]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 12
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.274
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.30079241  0.01944282 -0.66578789  0.15611417  0.36916935 -0.22391646
  0.50505065]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.199454
0.9-VaR bound for 2 demonstrations: 1.380089
0.95-VaR bound for 2 demonstrations: 1.484121
0.99-VaR bound for 2 demonstrations: 1.571009
True expected value difference for MAP policy: -0.017536
Evaluating threshold 0.1 with avar bound: [1.4841214478048779]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4841214478048779]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4841214478048779]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4841214478048779]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4841214478048779]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4841214478048779]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4841214478048779]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4841214478048779]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4841214478048779]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.265
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.23266899 -0.01296376 -0.04316122 -0.03290428  0.429098   -0.58080498
  0.64907009]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.063579
0.9-VaR bound for 3 demonstrations: 1.219074
0.95-VaR bound for 3 demonstrations: 1.356909
0.99-VaR bound for 3 demonstrations: 1.447036
True expected value difference for MAP policy: 0.013991
Evaluating threshold 0.1 with avar bound: [1.3569092869239023]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3569092869239023]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3569092869239023]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3569092869239023]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3569092869239023]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3569092869239023]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3569092869239023]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3569092869239023]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3569092869239023]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.261
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.22187888 -0.17811974 -0.75339105 -0.0914461   0.10796778 -0.13578528
  0.55945328]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.028589
0.9-VaR bound for 4 demonstrations: 0.033048
0.95-VaR bound for 4 demonstrations: 0.050780
0.99-VaR bound for 4 demonstrations: 0.057966
True expected value difference for MAP policy: -0.019359
Evaluating threshold 0.1 with avar bound: [0.05078003101770369]
Threshold 0.1 SUFFICIENT with avar bound: 0.05078003101770369
Evaluating threshold 0.2 with avar bound: [0.05078003101770369]
Threshold 0.2 SUFFICIENT with avar bound: 0.05078003101770369
Evaluating threshold 0.3 with avar bound: [0.05078003101770369]
Threshold 0.3 SUFFICIENT with avar bound: 0.05078003101770369
Evaluating threshold 0.4 with avar bound: [0.05078003101770369]
Threshold 0.4 SUFFICIENT with avar bound: 0.05078003101770369
Evaluating threshold 0.5 with avar bound: [0.05078003101770369]
Threshold 0.5 SUFFICIENT with avar bound: 0.05078003101770369
Evaluating threshold 0.6 with avar bound: [0.05078003101770369]
Threshold 0.6 SUFFICIENT with avar bound: 0.05078003101770369
Evaluating threshold 0.7 with avar bound: [0.05078003101770369]
Threshold 0.7 SUFFICIENT with avar bound: 0.05078003101770369
Evaluating threshold 0.8 with avar bound: [0.05078003101770369]
Threshold 0.8 SUFFICIENT with avar bound: 0.05078003101770369
Evaluating threshold 0.9 with avar bound: [0.05078003101770369]
Threshold 0.9 SUFFICIENT with avar bound: 0.05078003101770369

Running BIRL with demonstration 5/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.227
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.00645694 -0.04593396 -0.62905104 -0.02202161  0.31072324  0.02817635
  0.71015166]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.002781
0.9-VaR bound for 5 demonstrations: 0.003251
0.95-VaR bound for 5 demonstrations: 0.005663
0.99-VaR bound for 5 demonstrations: 0.040538
True expected value difference for MAP policy: -0.019359
Evaluating threshold 0.1 with avar bound: [0.005663449534719646]
Threshold 0.1 SUFFICIENT with avar bound: 0.005663449534719646
Evaluating threshold 0.2 with avar bound: [0.005663449534719646]
Threshold 0.2 SUFFICIENT with avar bound: 0.005663449534719646
Evaluating threshold 0.3 with avar bound: [0.005663449534719646]
Threshold 0.3 SUFFICIENT with avar bound: 0.005663449534719646
Evaluating threshold 0.4 with avar bound: [0.005663449534719646]
Threshold 0.4 SUFFICIENT with avar bound: 0.005663449534719646
Evaluating threshold 0.5 with avar bound: [0.005663449534719646]
Threshold 0.5 SUFFICIENT with avar bound: 0.005663449534719646
Evaluating threshold 0.6 with avar bound: [0.005663449534719646]
Threshold 0.6 SUFFICIENT with avar bound: 0.005663449534719646
Evaluating threshold 0.7 with avar bound: [0.005663449534719646]
Threshold 0.7 SUFFICIENT with avar bound: 0.005663449534719646
Evaluating threshold 0.8 with avar bound: [0.005663449534719646]
Threshold 0.8 SUFFICIENT with avar bound: 0.005663449534719646
Evaluating threshold 0.9 with avar bound: [0.005663449534719646]
Threshold 0.9 SUFFICIENT with avar bound: 0.005663449534719646

Running BIRL with demonstration 6/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.218
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.4553752   0.26021861 -0.65040217  0.02418248  0.0538067  -0.03441072
  0.54519049]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.007121
0.9-VaR bound for 6 demonstrations: -0.001958
0.95-VaR bound for 6 demonstrations: 0.000543
0.99-VaR bound for 6 demonstrations: 0.011781
True expected value difference for MAP policy: -0.014521
Evaluating threshold 0.1 with avar bound: [0.0005429311869890341]
Threshold 0.1 SUFFICIENT with avar bound: 0.0005429311869890341
Evaluating threshold 0.2 with avar bound: [0.0005429311869890341]
Threshold 0.2 SUFFICIENT with avar bound: 0.0005429311869890341
Evaluating threshold 0.3 with avar bound: [0.0005429311869890341]
Threshold 0.3 SUFFICIENT with avar bound: 0.0005429311869890341
Evaluating threshold 0.4 with avar bound: [0.0005429311869890341]
Threshold 0.4 SUFFICIENT with avar bound: 0.0005429311869890341
Evaluating threshold 0.5 with avar bound: [0.0005429311869890341]
Threshold 0.5 SUFFICIENT with avar bound: 0.0005429311869890341
Evaluating threshold 0.6 with avar bound: [0.0005429311869890341]
Threshold 0.6 SUFFICIENT with avar bound: 0.0005429311869890341
Evaluating threshold 0.7 with avar bound: [0.0005429311869890341]
Threshold 0.7 SUFFICIENT with avar bound: 0.0005429311869890341
Evaluating threshold 0.8 with avar bound: [0.0005429311869890341]
Threshold 0.8 SUFFICIENT with avar bound: 0.0005429311869890341
Evaluating threshold 0.9 with avar bound: [0.0005429311869890341]
Threshold 0.9 SUFFICIENT with avar bound: 0.0005429311869890341

Running BIRL with demonstration 7/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.218
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.11347114  0.08577257 -0.7772734  -0.03138525  0.00368216  0.09491437
  0.60465371]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.008191
0.9-VaR bound for 7 demonstrations: -0.006491
0.95-VaR bound for 7 demonstrations: -0.003605
0.99-VaR bound for 7 demonstrations: 0.016836
True expected value difference for MAP policy: -0.019806
Evaluating threshold 0.1 with avar bound: [-0.0036047062454744507]
Threshold 0.1 SUFFICIENT with avar bound: -0.0036047062454744507
Evaluating threshold 0.2 with avar bound: [-0.0036047062454744507]
Threshold 0.2 SUFFICIENT with avar bound: -0.0036047062454744507
Evaluating threshold 0.3 with avar bound: [-0.0036047062454744507]
Threshold 0.3 SUFFICIENT with avar bound: -0.0036047062454744507
Evaluating threshold 0.4 with avar bound: [-0.0036047062454744507]
Threshold 0.4 SUFFICIENT with avar bound: -0.0036047062454744507
Evaluating threshold 0.5 with avar bound: [-0.0036047062454744507]
Threshold 0.5 SUFFICIENT with avar bound: -0.0036047062454744507
Evaluating threshold 0.6 with avar bound: [-0.0036047062454744507]
Threshold 0.6 SUFFICIENT with avar bound: -0.0036047062454744507
Evaluating threshold 0.7 with avar bound: [-0.0036047062454744507]
Threshold 0.7 SUFFICIENT with avar bound: -0.0036047062454744507
Evaluating threshold 0.8 with avar bound: [-0.0036047062454744507]
Threshold 0.8 SUFFICIENT with avar bound: -0.0036047062454744507
Evaluating threshold 0.9 with avar bound: [-0.0036047062454744507]
Threshold 0.9 SUFFICIENT with avar bound: -0.0036047062454744507

Running BIRL with demonstration 8/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.195
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.10660743  0.05188433 -0.65917582  0.48607888 -0.01338185 -0.24775317
  0.50358388]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.010452
0.9-VaR bound for 8 demonstrations: -0.008315
0.95-VaR bound for 8 demonstrations: -0.004623
0.99-VaR bound for 8 demonstrations: 0.002970
True expected value difference for MAP policy: -0.019850
Evaluating threshold 0.1 with avar bound: [-0.004622771861030156]
Threshold 0.1 SUFFICIENT with avar bound: -0.004622771861030156
Evaluating threshold 0.2 with avar bound: [-0.004622771861030156]
Threshold 0.2 SUFFICIENT with avar bound: -0.004622771861030156
Evaluating threshold 0.3 with avar bound: [-0.004622771861030156]
Threshold 0.3 SUFFICIENT with avar bound: -0.004622771861030156
Evaluating threshold 0.4 with avar bound: [-0.004622771861030156]
Threshold 0.4 SUFFICIENT with avar bound: -0.004622771861030156
Evaluating threshold 0.5 with avar bound: [-0.004622771861030156]
Threshold 0.5 SUFFICIENT with avar bound: -0.004622771861030156
Evaluating threshold 0.6 with avar bound: [-0.004622771861030156]
Threshold 0.6 SUFFICIENT with avar bound: -0.004622771861030156
Evaluating threshold 0.7 with avar bound: [-0.004622771861030156]
Threshold 0.7 SUFFICIENT with avar bound: -0.004622771861030156
Evaluating threshold 0.8 with avar bound: [-0.004622771861030156]
Threshold 0.8 SUFFICIENT with avar bound: -0.004622771861030156
Evaluating threshold 0.9 with avar bound: [-0.004622771861030156]
Threshold 0.9 SUFFICIENT with avar bound: -0.004622771861030156

Running BIRL with demonstration 9/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.185
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.34195298  0.04819696 -0.58192845  0.19739028  0.05548811  0.07733753
  0.70290935]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.009115
0.9-VaR bound for 9 demonstrations: -0.008694
0.95-VaR bound for 9 demonstrations: -0.008089
0.99-VaR bound for 9 demonstrations: -0.002799
True expected value difference for MAP policy: -0.019806
Evaluating threshold 0.1 with avar bound: [-0.008089066462353457]
Threshold 0.1 SUFFICIENT with avar bound: -0.008089066462353457
Evaluating threshold 0.2 with avar bound: [-0.008089066462353457]
Threshold 0.2 SUFFICIENT with avar bound: -0.008089066462353457
Evaluating threshold 0.3 with avar bound: [-0.008089066462353457]
Threshold 0.3 SUFFICIENT with avar bound: -0.008089066462353457
Evaluating threshold 0.4 with avar bound: [-0.008089066462353457]
Threshold 0.4 SUFFICIENT with avar bound: -0.008089066462353457
Evaluating threshold 0.5 with avar bound: [-0.008089066462353457]
Threshold 0.5 SUFFICIENT with avar bound: -0.008089066462353457
Evaluating threshold 0.6 with avar bound: [-0.008089066462353457]
Threshold 0.6 SUFFICIENT with avar bound: -0.008089066462353457
Evaluating threshold 0.7 with avar bound: [-0.008089066462353457]
Threshold 0.7 SUFFICIENT with avar bound: -0.008089066462353457
Evaluating threshold 0.8 with avar bound: [-0.008089066462353457]
Threshold 0.8 SUFFICIENT with avar bound: -0.008089066462353457
Evaluating threshold 0.9 with avar bound: [-0.008089066462353457]
Threshold 0.9 SUFFICIENT with avar bound: -0.008089066462353457

Running BIRL with demonstration 10/10 in world 12
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.188
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.2077782  -0.12819017 -0.69626831  0.21119441 -0.18601381  0.17723018
  0.58735951]
True Reward Weights: [-0.69922942 -0.35796412 -0.29355928  0.06135005  0.09428214  0.33369285
  0.41564286]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.006267
0.9-VaR bound for 10 demonstrations: -0.004587
0.95-VaR bound for 10 demonstrations: -0.000282
0.99-VaR bound for 10 demonstrations: 0.020823
True expected value difference for MAP policy: -0.019850
Evaluating threshold 0.1 with avar bound: [-0.0002820765704572597]
Threshold 0.1 SUFFICIENT with avar bound: -0.0002820765704572597
Evaluating threshold 0.2 with avar bound: [-0.0002820765704572597]
Threshold 0.2 SUFFICIENT with avar bound: -0.0002820765704572597
Evaluating threshold 0.3 with avar bound: [-0.0002820765704572597]
Threshold 0.3 SUFFICIENT with avar bound: -0.0002820765704572597
Evaluating threshold 0.4 with avar bound: [-0.0002820765704572597]
Threshold 0.4 SUFFICIENT with avar bound: -0.0002820765704572597
Evaluating threshold 0.5 with avar bound: [-0.0002820765704572597]
Threshold 0.5 SUFFICIENT with avar bound: -0.0002820765704572597
Evaluating threshold 0.6 with avar bound: [-0.0002820765704572597]
Threshold 0.6 SUFFICIENT with avar bound: -0.0002820765704572597
Evaluating threshold 0.7 with avar bound: [-0.0002820765704572597]
Threshold 0.7 SUFFICIENT with avar bound: -0.0002820765704572597
Evaluating threshold 0.8 with avar bound: [-0.0002820765704572597]
Threshold 0.8 SUFFICIENT with avar bound: -0.0002820765704572597
Evaluating threshold 0.9 with avar bound: [-0.0002820765704572597]
Threshold 0.9 SUFFICIENT with avar bound: -0.0002820765704572597

Saving results to files...
Results saved successfully.

Running world 13/20

Running BIRL with demonstration 1/10 in world 13
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.438
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.12467883 -0.57038913  0.7135766   0.0444988   0.24319066  0.26105847
 -0.14368889]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.708803
0.9-VaR bound for 1 demonstrations: 2.111854
0.95-VaR bound for 1 demonstrations: 2.667883
0.99-VaR bound for 1 demonstrations: 3.727721
True expected value difference for MAP policy: 1.610503
Evaluating threshold 0.1 with avar bound: [2.667882841897153]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.667882841897153]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.667882841897153]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.667882841897153]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.667882841897153]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.667882841897153]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.667882841897153]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.667882841897153]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.667882841897153]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 13
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.184
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.92794354 -0.03843619 -0.02565258  0.03835283  0.08937224 -0.20411151
  0.29268676]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.218629
0.9-VaR bound for 2 demonstrations: 1.292685
0.95-VaR bound for 2 demonstrations: 1.427183
0.99-VaR bound for 2 demonstrations: 1.514391
True expected value difference for MAP policy: -0.007787
Evaluating threshold 0.1 with avar bound: [1.4271832611308088]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4271832611308088]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4271832611308088]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4271832611308088]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4271832611308088]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4271832611308088]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4271832611308088]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4271832611308088]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4271832611308088]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 13
Current demos: [(16, 1), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.221
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61690711  0.01904433  0.37443224 -0.43810926  0.03559902  0.23192786
  0.48152455]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.545888
0.9-VaR bound for 3 demonstrations: 1.024274
0.95-VaR bound for 3 demonstrations: 1.154229
0.99-VaR bound for 3 demonstrations: 1.240115
True expected value difference for MAP policy: 0.000575
Evaluating threshold 0.1 with avar bound: [1.1542286761338199]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.1542286761338199]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.1542286761338199]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.1542286761338199]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.1542286761338199]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.1542286761338199]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.1542286761338199]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.1542286761338199]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.1542286761338199]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 13
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.218
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.66085461  0.0174985   0.28594858 -0.08443962  0.13978279  0.11034618
  0.66509611]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.001232
0.9-VaR bound for 4 demonstrations: 0.003627
0.95-VaR bound for 4 demonstrations: 0.008169
0.99-VaR bound for 4 demonstrations: 0.030393
True expected value difference for MAP policy: -0.006388
Evaluating threshold 0.1 with avar bound: [0.008168794460777751]
Threshold 0.1 SUFFICIENT with avar bound: 0.008168794460777751
Evaluating threshold 0.2 with avar bound: [0.008168794460777751]
Threshold 0.2 SUFFICIENT with avar bound: 0.008168794460777751
Evaluating threshold 0.3 with avar bound: [0.008168794460777751]
Threshold 0.3 SUFFICIENT with avar bound: 0.008168794460777751
Evaluating threshold 0.4 with avar bound: [0.008168794460777751]
Threshold 0.4 SUFFICIENT with avar bound: 0.008168794460777751
Evaluating threshold 0.5 with avar bound: [0.008168794460777751]
Threshold 0.5 SUFFICIENT with avar bound: 0.008168794460777751
Evaluating threshold 0.6 with avar bound: [0.008168794460777751]
Threshold 0.6 SUFFICIENT with avar bound: 0.008168794460777751
Evaluating threshold 0.7 with avar bound: [0.008168794460777751]
Threshold 0.7 SUFFICIENT with avar bound: 0.008168794460777751
Evaluating threshold 0.8 with avar bound: [0.008168794460777751]
Threshold 0.8 SUFFICIENT with avar bound: 0.008168794460777751
Evaluating threshold 0.9 with avar bound: [0.008168794460777751]
Threshold 0.9 SUFFICIENT with avar bound: 0.008168794460777751

Running BIRL with demonstration 5/10 in world 13
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.177
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.72531299 -0.46467105  0.17081339  0.04478462  0.16503505 -0.01711315
  0.44641862]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.002872
0.9-VaR bound for 5 demonstrations: 0.000546
0.95-VaR bound for 5 demonstrations: 0.011864
0.99-VaR bound for 5 demonstrations: 0.019173
True expected value difference for MAP policy: -0.011863
Evaluating threshold 0.1 with avar bound: [0.011864420845503012]
Threshold 0.1 SUFFICIENT with avar bound: 0.011864420845503012
Evaluating threshold 0.2 with avar bound: [0.011864420845503012]
Threshold 0.2 SUFFICIENT with avar bound: 0.011864420845503012
Evaluating threshold 0.3 with avar bound: [0.011864420845503012]
Threshold 0.3 SUFFICIENT with avar bound: 0.011864420845503012
Evaluating threshold 0.4 with avar bound: [0.011864420845503012]
Threshold 0.4 SUFFICIENT with avar bound: 0.011864420845503012
Evaluating threshold 0.5 with avar bound: [0.011864420845503012]
Threshold 0.5 SUFFICIENT with avar bound: 0.011864420845503012
Evaluating threshold 0.6 with avar bound: [0.011864420845503012]
Threshold 0.6 SUFFICIENT with avar bound: 0.011864420845503012
Evaluating threshold 0.7 with avar bound: [0.011864420845503012]
Threshold 0.7 SUFFICIENT with avar bound: 0.011864420845503012
Evaluating threshold 0.8 with avar bound: [0.011864420845503012]
Threshold 0.8 SUFFICIENT with avar bound: 0.011864420845503012
Evaluating threshold 0.9 with avar bound: [0.011864420845503012]
Threshold 0.9 SUFFICIENT with avar bound: 0.011864420845503012

Running BIRL with demonstration 6/10 in world 13
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.186
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.65764692 -0.40595716  0.13695211  0.14845918  0.14581729 -0.02598827
  0.58306537]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.010153
0.9-VaR bound for 6 demonstrations: -0.007364
0.95-VaR bound for 6 demonstrations: -0.005853
0.99-VaR bound for 6 demonstrations: 0.003899
True expected value difference for MAP policy: -0.013192
Evaluating threshold 0.1 with avar bound: [-0.005852550917234773]
Threshold 0.1 SUFFICIENT with avar bound: -0.005852550917234773
Evaluating threshold 0.2 with avar bound: [-0.005852550917234773]
Threshold 0.2 SUFFICIENT with avar bound: -0.005852550917234773
Evaluating threshold 0.3 with avar bound: [-0.005852550917234773]
Threshold 0.3 SUFFICIENT with avar bound: -0.005852550917234773
Evaluating threshold 0.4 with avar bound: [-0.005852550917234773]
Threshold 0.4 SUFFICIENT with avar bound: -0.005852550917234773
Evaluating threshold 0.5 with avar bound: [-0.005852550917234773]
Threshold 0.5 SUFFICIENT with avar bound: -0.005852550917234773
Evaluating threshold 0.6 with avar bound: [-0.005852550917234773]
Threshold 0.6 SUFFICIENT with avar bound: -0.005852550917234773
Evaluating threshold 0.7 with avar bound: [-0.005852550917234773]
Threshold 0.7 SUFFICIENT with avar bound: -0.005852550917234773
Evaluating threshold 0.8 with avar bound: [-0.005852550917234773]
Threshold 0.8 SUFFICIENT with avar bound: -0.005852550917234773
Evaluating threshold 0.9 with avar bound: [-0.005852550917234773]
Threshold 0.9 SUFFICIENT with avar bound: -0.005852550917234773

Running BIRL with demonstration 7/10 in world 13
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.172
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47899289 -0.39367586  0.33024     0.19898522  0.31277758 -0.16845744
  0.58371554]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.002621
0.9-VaR bound for 7 demonstrations: 0.003065
0.95-VaR bound for 7 demonstrations: 0.008338
0.99-VaR bound for 7 demonstrations: 0.019895
True expected value difference for MAP policy: -0.009572
Evaluating threshold 0.1 with avar bound: [0.008337764326619828]
Threshold 0.1 SUFFICIENT with avar bound: 0.008337764326619828
Evaluating threshold 0.2 with avar bound: [0.008337764326619828]
Threshold 0.2 SUFFICIENT with avar bound: 0.008337764326619828
Evaluating threshold 0.3 with avar bound: [0.008337764326619828]
Threshold 0.3 SUFFICIENT with avar bound: 0.008337764326619828
Evaluating threshold 0.4 with avar bound: [0.008337764326619828]
Threshold 0.4 SUFFICIENT with avar bound: 0.008337764326619828
Evaluating threshold 0.5 with avar bound: [0.008337764326619828]
Threshold 0.5 SUFFICIENT with avar bound: 0.008337764326619828
Evaluating threshold 0.6 with avar bound: [0.008337764326619828]
Threshold 0.6 SUFFICIENT with avar bound: 0.008337764326619828
Evaluating threshold 0.7 with avar bound: [0.008337764326619828]
Threshold 0.7 SUFFICIENT with avar bound: 0.008337764326619828
Evaluating threshold 0.8 with avar bound: [0.008337764326619828]
Threshold 0.8 SUFFICIENT with avar bound: 0.008337764326619828
Evaluating threshold 0.9 with avar bound: [0.008337764326619828]
Threshold 0.9 SUFFICIENT with avar bound: 0.008337764326619828

Running BIRL with demonstration 8/10 in world 13
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.18
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.60974857 -0.19943536  0.05390786  0.33879966  0.007117   -0.0369093
  0.68507518]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.008615
0.9-VaR bound for 8 demonstrations: -0.004567
0.95-VaR bound for 8 demonstrations: -0.002046
0.99-VaR bound for 8 demonstrations: 0.003866
True expected value difference for MAP policy: -0.013192
Evaluating threshold 0.1 with avar bound: [-0.002045912453945391]
Threshold 0.1 SUFFICIENT with avar bound: -0.002045912453945391
Evaluating threshold 0.2 with avar bound: [-0.002045912453945391]
Threshold 0.2 SUFFICIENT with avar bound: -0.002045912453945391
Evaluating threshold 0.3 with avar bound: [-0.002045912453945391]
Threshold 0.3 SUFFICIENT with avar bound: -0.002045912453945391
Evaluating threshold 0.4 with avar bound: [-0.002045912453945391]
Threshold 0.4 SUFFICIENT with avar bound: -0.002045912453945391
Evaluating threshold 0.5 with avar bound: [-0.002045912453945391]
Threshold 0.5 SUFFICIENT with avar bound: -0.002045912453945391
Evaluating threshold 0.6 with avar bound: [-0.002045912453945391]
Threshold 0.6 SUFFICIENT with avar bound: -0.002045912453945391
Evaluating threshold 0.7 with avar bound: [-0.002045912453945391]
Threshold 0.7 SUFFICIENT with avar bound: -0.002045912453945391
Evaluating threshold 0.8 with avar bound: [-0.002045912453945391]
Threshold 0.8 SUFFICIENT with avar bound: -0.002045912453945391
Evaluating threshold 0.9 with avar bound: [-0.002045912453945391]
Threshold 0.9 SUFFICIENT with avar bound: -0.002045912453945391

Running BIRL with demonstration 9/10 in world 13
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 1), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.157
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.5901324  -0.20053293 -0.16696322  0.24982473  0.31441386  0.36656672
  0.53666931]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.005725
0.9-VaR bound for 9 demonstrations: -0.002080
0.95-VaR bound for 9 demonstrations: 0.009802
0.99-VaR bound for 9 demonstrations: 0.009802
True expected value difference for MAP policy: -0.015872
Evaluating threshold 0.1 with avar bound: [0.009801901915302518]
Threshold 0.1 SUFFICIENT with avar bound: 0.009801901915302518
Evaluating threshold 0.2 with avar bound: [0.009801901915302518]
Threshold 0.2 SUFFICIENT with avar bound: 0.009801901915302518
Evaluating threshold 0.3 with avar bound: [0.009801901915302518]
Threshold 0.3 SUFFICIENT with avar bound: 0.009801901915302518
Evaluating threshold 0.4 with avar bound: [0.009801901915302518]
Threshold 0.4 SUFFICIENT with avar bound: 0.009801901915302518
Evaluating threshold 0.5 with avar bound: [0.009801901915302518]
Threshold 0.5 SUFFICIENT with avar bound: 0.009801901915302518
Evaluating threshold 0.6 with avar bound: [0.009801901915302518]
Threshold 0.6 SUFFICIENT with avar bound: 0.009801901915302518
Evaluating threshold 0.7 with avar bound: [0.009801901915302518]
Threshold 0.7 SUFFICIENT with avar bound: 0.009801901915302518
Evaluating threshold 0.8 with avar bound: [0.009801901915302518]
Threshold 0.8 SUFFICIENT with avar bound: 0.009801901915302518
Evaluating threshold 0.9 with avar bound: [0.009801901915302518]
Threshold 0.9 SUFFICIENT with avar bound: 0.009801901915302518

Running BIRL with demonstration 10/10 in world 13
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 1), (6, 3), (5, 3), (10, 1), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.158
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.7510496  -0.27394787 -0.26511815  0.20547602 -0.01332686  0.07881965
  0.4919135 ]
True Reward Weights: [-0.81650133 -0.24318445 -0.01898216  0.10950969  0.15853281  0.34335478
  0.34468687]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.006400
0.9-VaR bound for 10 demonstrations: -0.002654
0.95-VaR bound for 10 demonstrations: 0.021592
0.99-VaR bound for 10 demonstrations: 0.025946
True expected value difference for MAP policy: -0.015872
Evaluating threshold 0.1 with avar bound: [0.02159229654420147]
Threshold 0.1 SUFFICIENT with avar bound: 0.02159229654420147
Evaluating threshold 0.2 with avar bound: [0.02159229654420147]
Threshold 0.2 SUFFICIENT with avar bound: 0.02159229654420147
Evaluating threshold 0.3 with avar bound: [0.02159229654420147]
Threshold 0.3 SUFFICIENT with avar bound: 0.02159229654420147
Evaluating threshold 0.4 with avar bound: [0.02159229654420147]
Threshold 0.4 SUFFICIENT with avar bound: 0.02159229654420147
Evaluating threshold 0.5 with avar bound: [0.02159229654420147]
Threshold 0.5 SUFFICIENT with avar bound: 0.02159229654420147
Evaluating threshold 0.6 with avar bound: [0.02159229654420147]
Threshold 0.6 SUFFICIENT with avar bound: 0.02159229654420147
Evaluating threshold 0.7 with avar bound: [0.02159229654420147]
Threshold 0.7 SUFFICIENT with avar bound: 0.02159229654420147
Evaluating threshold 0.8 with avar bound: [0.02159229654420147]
Threshold 0.8 SUFFICIENT with avar bound: 0.02159229654420147
Evaluating threshold 0.9 with avar bound: [0.02159229654420147]
Threshold 0.9 SUFFICIENT with avar bound: 0.02159229654420147

Running world 14/20

Running BIRL with demonstration 1/10 in world 14
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.42
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.00270793 -0.18136449  0.09601801 -0.66419588 -0.42318782  0.03780372
  0.57983352]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.289770
0.9-VaR bound for 1 demonstrations: 1.356956
0.95-VaR bound for 1 demonstrations: 1.429767
0.99-VaR bound for 1 demonstrations: 1.517329
True expected value difference for MAP policy: -0.012157
Evaluating threshold 0.1 with avar bound: [1.4297674630810353]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4297674630810353]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4297674630810353]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4297674630810353]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4297674630810353]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4297674630810353]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4297674630810353]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4297674630810353]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4297674630810353]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 14
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.342
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.32538815 -0.27266399 -0.13568373 -0.30129663 -0.1657385   0.81320306
 -0.14771151]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.833362
0.9-VaR bound for 2 demonstrations: 2.092637
0.95-VaR bound for 2 demonstrations: 2.398682
0.99-VaR bound for 2 demonstrations: 2.954975
True expected value difference for MAP policy: 0.527738
Evaluating threshold 0.1 with avar bound: [2.3986823531348107]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.3986823531348107]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.3986823531348107]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.3986823531348107]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.3986823531348107]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.3986823531348107]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.3986823531348107]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.3986823531348107]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.3986823531348107]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 14
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.257
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.33513454 -0.13163622 -0.42523681 -0.36241196 -0.24473945  0.37272579
  0.59947148]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.030290
0.9-VaR bound for 3 demonstrations: 0.460016
0.95-VaR bound for 3 demonstrations: 1.108848
0.99-VaR bound for 3 demonstrations: 1.273761
True expected value difference for MAP policy: -0.011373
Evaluating threshold 0.1 with avar bound: [1.1088484455460152]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.1088484455460152]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.1088484455460152]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.1088484455460152]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.1088484455460152]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.1088484455460152]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.1088484455460152]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.1088484455460152]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.1088484455460152]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 14
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.251
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.3676594   0.09549851 -0.49078082 -0.09042331 -0.23468336  0.3192506
  0.67057228]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.007315
0.9-VaR bound for 4 demonstrations: -0.003977
0.95-VaR bound for 4 demonstrations: 0.003571
0.99-VaR bound for 4 demonstrations: 0.006665
True expected value difference for MAP policy: -0.017699
Evaluating threshold 0.1 with avar bound: [0.003571180376027918]
Threshold 0.1 SUFFICIENT with avar bound: 0.003571180376027918
Evaluating threshold 0.2 with avar bound: [0.003571180376027918]
Threshold 0.2 SUFFICIENT with avar bound: 0.003571180376027918
Evaluating threshold 0.3 with avar bound: [0.003571180376027918]
Threshold 0.3 SUFFICIENT with avar bound: 0.003571180376027918
Evaluating threshold 0.4 with avar bound: [0.003571180376027918]
Threshold 0.4 SUFFICIENT with avar bound: 0.003571180376027918
Evaluating threshold 0.5 with avar bound: [0.003571180376027918]
Threshold 0.5 SUFFICIENT with avar bound: 0.003571180376027918
Evaluating threshold 0.6 with avar bound: [0.003571180376027918]
Threshold 0.6 SUFFICIENT with avar bound: 0.003571180376027918
Evaluating threshold 0.7 with avar bound: [0.003571180376027918]
Threshold 0.7 SUFFICIENT with avar bound: 0.003571180376027918
Evaluating threshold 0.8 with avar bound: [0.003571180376027918]
Threshold 0.8 SUFFICIENT with avar bound: 0.003571180376027918
Evaluating threshold 0.9 with avar bound: [0.003571180376027918]
Threshold 0.9 SUFFICIENT with avar bound: 0.003571180376027918

Running BIRL with demonstration 5/10 in world 14
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.236
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.01879033 -0.16829438 -0.5883632  -0.07865742 -0.3543226   0.3269404
  0.62171629]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.008569
0.9-VaR bound for 5 demonstrations: -0.007087
0.95-VaR bound for 5 demonstrations: -0.003133
0.99-VaR bound for 5 demonstrations: 0.016999
True expected value difference for MAP policy: -0.016499
Evaluating threshold 0.1 with avar bound: [-0.0031328428127322967]
Threshold 0.1 SUFFICIENT with avar bound: -0.0031328428127322967
Evaluating threshold 0.2 with avar bound: [-0.0031328428127322967]
Threshold 0.2 SUFFICIENT with avar bound: -0.0031328428127322967
Evaluating threshold 0.3 with avar bound: [-0.0031328428127322967]
Threshold 0.3 SUFFICIENT with avar bound: -0.0031328428127322967
Evaluating threshold 0.4 with avar bound: [-0.0031328428127322967]
Threshold 0.4 SUFFICIENT with avar bound: -0.0031328428127322967
Evaluating threshold 0.5 with avar bound: [-0.0031328428127322967]
Threshold 0.5 SUFFICIENT with avar bound: -0.0031328428127322967
Evaluating threshold 0.6 with avar bound: [-0.0031328428127322967]
Threshold 0.6 SUFFICIENT with avar bound: -0.0031328428127322967
Evaluating threshold 0.7 with avar bound: [-0.0031328428127322967]
Threshold 0.7 SUFFICIENT with avar bound: -0.0031328428127322967
Evaluating threshold 0.8 with avar bound: [-0.0031328428127322967]
Threshold 0.8 SUFFICIENT with avar bound: -0.0031328428127322967
Evaluating threshold 0.9 with avar bound: [-0.0031328428127322967]
Threshold 0.9 SUFFICIENT with avar bound: -0.0031328428127322967

Running BIRL with demonstration 6/10 in world 14
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.214
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.46207811  0.17965331 -0.38661317 -0.1802248  -0.40547947  0.2895463
  0.56921624]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.006640
0.9-VaR bound for 6 demonstrations: -0.005224
0.95-VaR bound for 6 demonstrations: 0.004278
0.99-VaR bound for 6 demonstrations: 0.015726
True expected value difference for MAP policy: -0.014635
Evaluating threshold 0.1 with avar bound: [0.004277528331835594]
Threshold 0.1 SUFFICIENT with avar bound: 0.004277528331835594
Evaluating threshold 0.2 with avar bound: [0.004277528331835594]
Threshold 0.2 SUFFICIENT with avar bound: 0.004277528331835594
Evaluating threshold 0.3 with avar bound: [0.004277528331835594]
Threshold 0.3 SUFFICIENT with avar bound: 0.004277528331835594
Evaluating threshold 0.4 with avar bound: [0.004277528331835594]
Threshold 0.4 SUFFICIENT with avar bound: 0.004277528331835594
Evaluating threshold 0.5 with avar bound: [0.004277528331835594]
Threshold 0.5 SUFFICIENT with avar bound: 0.004277528331835594
Evaluating threshold 0.6 with avar bound: [0.004277528331835594]
Threshold 0.6 SUFFICIENT with avar bound: 0.004277528331835594
Evaluating threshold 0.7 with avar bound: [0.004277528331835594]
Threshold 0.7 SUFFICIENT with avar bound: 0.004277528331835594
Evaluating threshold 0.8 with avar bound: [0.004277528331835594]
Threshold 0.8 SUFFICIENT with avar bound: 0.004277528331835594
Evaluating threshold 0.9 with avar bound: [0.004277528331835594]
Threshold 0.9 SUFFICIENT with avar bound: 0.004277528331835594

Running BIRL with demonstration 7/10 in world 14
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.179
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.62627412  0.0576328   0.01529947  0.08118691 -0.13652394  0.4612866
  0.60515262]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.003952
0.9-VaR bound for 7 demonstrations: 0.001022
0.95-VaR bound for 7 demonstrations: 0.009154
0.99-VaR bound for 7 demonstrations: 0.067405
True expected value difference for MAP policy: -0.018498
Evaluating threshold 0.1 with avar bound: [0.009154308325878442]
Threshold 0.1 SUFFICIENT with avar bound: 0.009154308325878442
Evaluating threshold 0.2 with avar bound: [0.009154308325878442]
Threshold 0.2 SUFFICIENT with avar bound: 0.009154308325878442
Evaluating threshold 0.3 with avar bound: [0.009154308325878442]
Threshold 0.3 SUFFICIENT with avar bound: 0.009154308325878442
Evaluating threshold 0.4 with avar bound: [0.009154308325878442]
Threshold 0.4 SUFFICIENT with avar bound: 0.009154308325878442
Evaluating threshold 0.5 with avar bound: [0.009154308325878442]
Threshold 0.5 SUFFICIENT with avar bound: 0.009154308325878442
Evaluating threshold 0.6 with avar bound: [0.009154308325878442]
Threshold 0.6 SUFFICIENT with avar bound: 0.009154308325878442
Evaluating threshold 0.7 with avar bound: [0.009154308325878442]
Threshold 0.7 SUFFICIENT with avar bound: 0.009154308325878442
Evaluating threshold 0.8 with avar bound: [0.009154308325878442]
Threshold 0.8 SUFFICIENT with avar bound: 0.009154308325878442
Evaluating threshold 0.9 with avar bound: [0.009154308325878442]
Threshold 0.9 SUFFICIENT with avar bound: 0.009154308325878442

Running BIRL with demonstration 8/10 in world 14
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.192
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38668815 -0.2633775   0.23571232  0.00574888  0.078515    0.49615112
  0.6878813 ]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.007367
0.9-VaR bound for 8 demonstrations: -0.003571
0.95-VaR bound for 8 demonstrations: 0.000348
0.99-VaR bound for 8 demonstrations: 0.009018
True expected value difference for MAP policy: -0.018080
Evaluating threshold 0.1 with avar bound: [0.0003479554762273965]
Threshold 0.1 SUFFICIENT with avar bound: 0.0003479554762273965
Evaluating threshold 0.2 with avar bound: [0.0003479554762273965]
Threshold 0.2 SUFFICIENT with avar bound: 0.0003479554762273965
Evaluating threshold 0.3 with avar bound: [0.0003479554762273965]
Threshold 0.3 SUFFICIENT with avar bound: 0.0003479554762273965
Evaluating threshold 0.4 with avar bound: [0.0003479554762273965]
Threshold 0.4 SUFFICIENT with avar bound: 0.0003479554762273965
Evaluating threshold 0.5 with avar bound: [0.0003479554762273965]
Threshold 0.5 SUFFICIENT with avar bound: 0.0003479554762273965
Evaluating threshold 0.6 with avar bound: [0.0003479554762273965]
Threshold 0.6 SUFFICIENT with avar bound: 0.0003479554762273965
Evaluating threshold 0.7 with avar bound: [0.0003479554762273965]
Threshold 0.7 SUFFICIENT with avar bound: 0.0003479554762273965
Evaluating threshold 0.8 with avar bound: [0.0003479554762273965]
Threshold 0.8 SUFFICIENT with avar bound: 0.0003479554762273965
Evaluating threshold 0.9 with avar bound: [0.0003479554762273965]
Threshold 0.9 SUFFICIENT with avar bound: 0.0003479554762273965

Running BIRL with demonstration 9/10 in world 14
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.194
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.33038876 -0.22092438  0.09582079 -0.120833   -0.17633493  0.55778396
  0.68995398]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.012720
0.9-VaR bound for 9 demonstrations: -0.011224
0.95-VaR bound for 9 demonstrations: -0.008903
0.99-VaR bound for 9 demonstrations: -0.005875
True expected value difference for MAP policy: -0.017550
Evaluating threshold 0.1 with avar bound: [-0.008903399343406275]
Threshold 0.1 SUFFICIENT with avar bound: -0.008903399343406275
Evaluating threshold 0.2 with avar bound: [-0.008903399343406275]
Threshold 0.2 SUFFICIENT with avar bound: -0.008903399343406275
Evaluating threshold 0.3 with avar bound: [-0.008903399343406275]
Threshold 0.3 SUFFICIENT with avar bound: -0.008903399343406275
Evaluating threshold 0.4 with avar bound: [-0.008903399343406275]
Threshold 0.4 SUFFICIENT with avar bound: -0.008903399343406275
Evaluating threshold 0.5 with avar bound: [-0.008903399343406275]
Threshold 0.5 SUFFICIENT with avar bound: -0.008903399343406275
Evaluating threshold 0.6 with avar bound: [-0.008903399343406275]
Threshold 0.6 SUFFICIENT with avar bound: -0.008903399343406275
Evaluating threshold 0.7 with avar bound: [-0.008903399343406275]
Threshold 0.7 SUFFICIENT with avar bound: -0.008903399343406275
Evaluating threshold 0.8 with avar bound: [-0.008903399343406275]
Threshold 0.8 SUFFICIENT with avar bound: -0.008903399343406275
Evaluating threshold 0.9 with avar bound: [-0.008903399343406275]
Threshold 0.9 SUFFICIENT with avar bound: -0.008903399343406275

Running BIRL with demonstration 10/10 in world 14
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.195
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.4908166  -0.30822872 -0.09417839  0.19357337 -0.25587152  0.37713455
  0.64035397]
True Reward Weights: [-0.56220806 -0.40187548 -0.17990573 -0.0174719   0.39426353  0.40033813
  0.41717203]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.011128
0.9-VaR bound for 10 demonstrations: -0.010146
0.95-VaR bound for 10 demonstrations: -0.008926
0.99-VaR bound for 10 demonstrations: -0.005223
True expected value difference for MAP policy: -0.018498
Evaluating threshold 0.1 with avar bound: [-0.00892632090814834]
Threshold 0.1 SUFFICIENT with avar bound: -0.00892632090814834
Evaluating threshold 0.2 with avar bound: [-0.00892632090814834]
Threshold 0.2 SUFFICIENT with avar bound: -0.00892632090814834
Evaluating threshold 0.3 with avar bound: [-0.00892632090814834]
Threshold 0.3 SUFFICIENT with avar bound: -0.00892632090814834
Evaluating threshold 0.4 with avar bound: [-0.00892632090814834]
Threshold 0.4 SUFFICIENT with avar bound: -0.00892632090814834
Evaluating threshold 0.5 with avar bound: [-0.00892632090814834]
Threshold 0.5 SUFFICIENT with avar bound: -0.00892632090814834
Evaluating threshold 0.6 with avar bound: [-0.00892632090814834]
Threshold 0.6 SUFFICIENT with avar bound: -0.00892632090814834
Evaluating threshold 0.7 with avar bound: [-0.00892632090814834]
Threshold 0.7 SUFFICIENT with avar bound: -0.00892632090814834
Evaluating threshold 0.8 with avar bound: [-0.00892632090814834]
Threshold 0.8 SUFFICIENT with avar bound: -0.00892632090814834
Evaluating threshold 0.9 with avar bound: [-0.00892632090814834]
Threshold 0.9 SUFFICIENT with avar bound: -0.00892632090814834

Running world 15/20

Running BIRL with demonstration 1/10 in world 15
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.406
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.19196825  0.00862977  0.00430903  0.08622937 -0.08288222  0.97389021
  0.01697202]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.229344
0.9-VaR bound for 1 demonstrations: 1.662466
0.95-VaR bound for 1 demonstrations: 1.988644
0.99-VaR bound for 1 demonstrations: 3.353693
True expected value difference for MAP policy: 0.905230
Evaluating threshold 0.1 with avar bound: [1.988644187366409]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.988644187366409]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.988644187366409]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.988644187366409]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.988644187366409]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.988644187366409]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.988644187366409]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.988644187366409]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.988644187366409]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 15
Current demos: [(16, 1), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.374
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.05380581  0.13899064 -0.27838621 -0.17115467 -0.3359263   0.86889938
 -0.05622382]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 0.972857
0.9-VaR bound for 2 demonstrations: 1.418593
0.95-VaR bound for 2 demonstrations: 1.589424
0.99-VaR bound for 2 demonstrations: 2.334580
True expected value difference for MAP policy: 0.921485
Evaluating threshold 0.1 with avar bound: [1.5894242465483683]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.5894242465483683]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.5894242465483683]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.5894242465483683]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.5894242465483683]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.5894242465483683]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.5894242465483683]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.5894242465483683]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.5894242465483683]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 15
Current demos: [(16, 1), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.274
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.58688182 -0.31476936 -0.45657824 -0.0190271  -0.301572    0.36682557
  0.34951049]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.192239
0.9-VaR bound for 3 demonstrations: 1.207548
0.95-VaR bound for 3 demonstrations: 1.270509
0.99-VaR bound for 3 demonstrations: 1.345112
True expected value difference for MAP policy: 0.008878
Evaluating threshold 0.1 with avar bound: [1.2705091951867886]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.2705091951867886]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.2705091951867886]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.2705091951867886]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.2705091951867886]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.2705091951867886]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.2705091951867886]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.2705091951867886]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.2705091951867886]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 15
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.215
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.33867831 -0.3948648  -0.30736091  0.01633666 -0.12650399  0.55774999
  0.55457449]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.077667
0.9-VaR bound for 4 demonstrations: 0.082997
0.95-VaR bound for 4 demonstrations: 0.100593
0.99-VaR bound for 4 demonstrations: 0.135217
True expected value difference for MAP policy: 0.008143
Evaluating threshold 0.1 with avar bound: [0.10059309707663498]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.10059309707663498]
Threshold 0.2 SUFFICIENT with avar bound: 0.10059309707663498
Evaluating threshold 0.3 with avar bound: [0.10059309707663498]
Threshold 0.3 SUFFICIENT with avar bound: 0.10059309707663498
Evaluating threshold 0.4 with avar bound: [0.10059309707663498]
Threshold 0.4 SUFFICIENT with avar bound: 0.10059309707663498
Evaluating threshold 0.5 with avar bound: [0.10059309707663498]
Threshold 0.5 SUFFICIENT with avar bound: 0.10059309707663498
Evaluating threshold 0.6 with avar bound: [0.10059309707663498]
Threshold 0.6 SUFFICIENT with avar bound: 0.10059309707663498
Evaluating threshold 0.7 with avar bound: [0.10059309707663498]
Threshold 0.7 SUFFICIENT with avar bound: 0.10059309707663498
Evaluating threshold 0.8 with avar bound: [0.10059309707663498]
Threshold 0.8 SUFFICIENT with avar bound: 0.10059309707663498
Evaluating threshold 0.9 with avar bound: [0.10059309707663498]
Threshold 0.9 SUFFICIENT with avar bound: 0.10059309707663498

Running BIRL with demonstration 5/10 in world 15
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.216
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.34744017 -0.40402151  0.0456222  -0.10532256 -0.14496573  0.52389657
  0.63827506]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.004668
0.9-VaR bound for 5 demonstrations: -0.002385
0.95-VaR bound for 5 demonstrations: 0.001612
0.99-VaR bound for 5 demonstrations: 0.025548
True expected value difference for MAP policy: -0.029220
Evaluating threshold 0.1 with avar bound: [0.0016119999890069868]
Threshold 0.1 SUFFICIENT with avar bound: 0.0016119999890069868
Evaluating threshold 0.2 with avar bound: [0.0016119999890069868]
Threshold 0.2 SUFFICIENT with avar bound: 0.0016119999890069868
Evaluating threshold 0.3 with avar bound: [0.0016119999890069868]
Threshold 0.3 SUFFICIENT with avar bound: 0.0016119999890069868
Evaluating threshold 0.4 with avar bound: [0.0016119999890069868]
Threshold 0.4 SUFFICIENT with avar bound: 0.0016119999890069868
Evaluating threshold 0.5 with avar bound: [0.0016119999890069868]
Threshold 0.5 SUFFICIENT with avar bound: 0.0016119999890069868
Evaluating threshold 0.6 with avar bound: [0.0016119999890069868]
Threshold 0.6 SUFFICIENT with avar bound: 0.0016119999890069868
Evaluating threshold 0.7 with avar bound: [0.0016119999890069868]
Threshold 0.7 SUFFICIENT with avar bound: 0.0016119999890069868
Evaluating threshold 0.8 with avar bound: [0.0016119999890069868]
Threshold 0.8 SUFFICIENT with avar bound: 0.0016119999890069868
Evaluating threshold 0.9 with avar bound: [0.0016119999890069868]
Threshold 0.9 SUFFICIENT with avar bound: 0.0016119999890069868

Running BIRL with demonstration 6/10 in world 15
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.187
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.45160888  0.00739311  0.01482489  0.23407689 -0.32358967  0.57276635
  0.55516793]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: 0.067050
0.9-VaR bound for 6 demonstrations: 0.078804
0.95-VaR bound for 6 demonstrations: 0.097016
0.99-VaR bound for 6 demonstrations: 0.118801
True expected value difference for MAP policy: 0.008878
Evaluating threshold 0.1 with avar bound: [0.09701551811523902]
Threshold 0.1 SUFFICIENT with avar bound: 0.09701551811523902
Evaluating threshold 0.2 with avar bound: [0.09701551811523902]
Threshold 0.2 SUFFICIENT with avar bound: 0.09701551811523902
Evaluating threshold 0.3 with avar bound: [0.09701551811523902]
Threshold 0.3 SUFFICIENT with avar bound: 0.09701551811523902
Evaluating threshold 0.4 with avar bound: [0.09701551811523902]
Threshold 0.4 SUFFICIENT with avar bound: 0.09701551811523902
Evaluating threshold 0.5 with avar bound: [0.09701551811523902]
Threshold 0.5 SUFFICIENT with avar bound: 0.09701551811523902
Evaluating threshold 0.6 with avar bound: [0.09701551811523902]
Threshold 0.6 SUFFICIENT with avar bound: 0.09701551811523902
Evaluating threshold 0.7 with avar bound: [0.09701551811523902]
Threshold 0.7 SUFFICIENT with avar bound: 0.09701551811523902
Evaluating threshold 0.8 with avar bound: [0.09701551811523902]
Threshold 0.8 SUFFICIENT with avar bound: 0.09701551811523902
Evaluating threshold 0.9 with avar bound: [0.09701551811523902]
Threshold 0.9 SUFFICIENT with avar bound: 0.09701551811523902

Running BIRL with demonstration 7/10 in world 15
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.19
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.3325526  -0.08070421  0.00633002 -0.62684834 -0.2085759   0.46340499
  0.48131963]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.003856
0.9-VaR bound for 7 demonstrations: -0.003131
0.95-VaR bound for 7 demonstrations: 0.004798
0.99-VaR bound for 7 demonstrations: 0.013210
True expected value difference for MAP policy: -0.026526
Evaluating threshold 0.1 with avar bound: [0.004798224376272483]
Threshold 0.1 SUFFICIENT with avar bound: 0.004798224376272483
Evaluating threshold 0.2 with avar bound: [0.004798224376272483]
Threshold 0.2 SUFFICIENT with avar bound: 0.004798224376272483
Evaluating threshold 0.3 with avar bound: [0.004798224376272483]
Threshold 0.3 SUFFICIENT with avar bound: 0.004798224376272483
Evaluating threshold 0.4 with avar bound: [0.004798224376272483]
Threshold 0.4 SUFFICIENT with avar bound: 0.004798224376272483
Evaluating threshold 0.5 with avar bound: [0.004798224376272483]
Threshold 0.5 SUFFICIENT with avar bound: 0.004798224376272483
Evaluating threshold 0.6 with avar bound: [0.004798224376272483]
Threshold 0.6 SUFFICIENT with avar bound: 0.004798224376272483
Evaluating threshold 0.7 with avar bound: [0.004798224376272483]
Threshold 0.7 SUFFICIENT with avar bound: 0.004798224376272483
Evaluating threshold 0.8 with avar bound: [0.004798224376272483]
Threshold 0.8 SUFFICIENT with avar bound: 0.004798224376272483
Evaluating threshold 0.9 with avar bound: [0.004798224376272483]
Threshold 0.9 SUFFICIENT with avar bound: 0.004798224376272483

Running BIRL with demonstration 8/10 in world 15
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.179
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.31484179  0.09758169  0.01184541 -0.37051644 -0.53234742  0.4066527
  0.55242151]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.004796
0.9-VaR bound for 8 demonstrations: -0.001342
0.95-VaR bound for 8 demonstrations: 0.002678
0.99-VaR bound for 8 demonstrations: 0.037490
True expected value difference for MAP policy: -0.026992
Evaluating threshold 0.1 with avar bound: [0.002678487168871306]
Threshold 0.1 SUFFICIENT with avar bound: 0.002678487168871306
Evaluating threshold 0.2 with avar bound: [0.002678487168871306]
Threshold 0.2 SUFFICIENT with avar bound: 0.002678487168871306
Evaluating threshold 0.3 with avar bound: [0.002678487168871306]
Threshold 0.3 SUFFICIENT with avar bound: 0.002678487168871306
Evaluating threshold 0.4 with avar bound: [0.002678487168871306]
Threshold 0.4 SUFFICIENT with avar bound: 0.002678487168871306
Evaluating threshold 0.5 with avar bound: [0.002678487168871306]
Threshold 0.5 SUFFICIENT with avar bound: 0.002678487168871306
Evaluating threshold 0.6 with avar bound: [0.002678487168871306]
Threshold 0.6 SUFFICIENT with avar bound: 0.002678487168871306
Evaluating threshold 0.7 with avar bound: [0.002678487168871306]
Threshold 0.7 SUFFICIENT with avar bound: 0.002678487168871306
Evaluating threshold 0.8 with avar bound: [0.002678487168871306]
Threshold 0.8 SUFFICIENT with avar bound: 0.002678487168871306
Evaluating threshold 0.9 with avar bound: [0.002678487168871306]
Threshold 0.9 SUFFICIENT with avar bound: 0.002678487168871306

Running BIRL with demonstration 9/10 in world 15
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.169
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.53486664 -0.04765293 -0.18882099  0.14568992 -0.15812884  0.48666166
  0.62683623]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.009395
0.9-VaR bound for 9 demonstrations: -0.005174
0.95-VaR bound for 9 demonstrations: 0.004281
0.99-VaR bound for 9 demonstrations: 0.057132
True expected value difference for MAP policy: -0.029744
Evaluating threshold 0.1 with avar bound: [0.004281438361066]
Threshold 0.1 SUFFICIENT with avar bound: 0.004281438361066
Evaluating threshold 0.2 with avar bound: [0.004281438361066]
Threshold 0.2 SUFFICIENT with avar bound: 0.004281438361066
Evaluating threshold 0.3 with avar bound: [0.004281438361066]
Threshold 0.3 SUFFICIENT with avar bound: 0.004281438361066
Evaluating threshold 0.4 with avar bound: [0.004281438361066]
Threshold 0.4 SUFFICIENT with avar bound: 0.004281438361066
Evaluating threshold 0.5 with avar bound: [0.004281438361066]
Threshold 0.5 SUFFICIENT with avar bound: 0.004281438361066
Evaluating threshold 0.6 with avar bound: [0.004281438361066]
Threshold 0.6 SUFFICIENT with avar bound: 0.004281438361066
Evaluating threshold 0.7 with avar bound: [0.004281438361066]
Threshold 0.7 SUFFICIENT with avar bound: 0.004281438361066
Evaluating threshold 0.8 with avar bound: [0.004281438361066]
Threshold 0.8 SUFFICIENT with avar bound: 0.004281438361066
Evaluating threshold 0.9 with avar bound: [0.004281438361066]
Threshold 0.9 SUFFICIENT with avar bound: 0.004281438361066

Running BIRL with demonstration 10/10 in world 15
Current demos: [(16, 1), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.187
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.63179153  0.02292287 -0.30831891  0.11356697 -0.23018326  0.33710363
  0.57073007]
True Reward Weights: [-0.50282913 -0.00510785  0.12939193  0.18205449  0.26893846  0.47111772
  0.63479986]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.012833
0.9-VaR bound for 10 demonstrations: -0.012041
0.95-VaR bound for 10 demonstrations: -0.009003
0.99-VaR bound for 10 demonstrations: 0.003591
True expected value difference for MAP policy: -0.028658
Evaluating threshold 0.1 with avar bound: [-0.009003410689380159]
Threshold 0.1 SUFFICIENT with avar bound: -0.009003410689380159
Evaluating threshold 0.2 with avar bound: [-0.009003410689380159]
Threshold 0.2 SUFFICIENT with avar bound: -0.009003410689380159
Evaluating threshold 0.3 with avar bound: [-0.009003410689380159]
Threshold 0.3 SUFFICIENT with avar bound: -0.009003410689380159
Evaluating threshold 0.4 with avar bound: [-0.009003410689380159]
Threshold 0.4 SUFFICIENT with avar bound: -0.009003410689380159
Evaluating threshold 0.5 with avar bound: [-0.009003410689380159]
Threshold 0.5 SUFFICIENT with avar bound: -0.009003410689380159
Evaluating threshold 0.6 with avar bound: [-0.009003410689380159]
Threshold 0.6 SUFFICIENT with avar bound: -0.009003410689380159
Evaluating threshold 0.7 with avar bound: [-0.009003410689380159]
Threshold 0.7 SUFFICIENT with avar bound: -0.009003410689380159
Evaluating threshold 0.8 with avar bound: [-0.009003410689380159]
Threshold 0.8 SUFFICIENT with avar bound: -0.009003410689380159
Evaluating threshold 0.9 with avar bound: [-0.009003410689380159]
Threshold 0.9 SUFFICIENT with avar bound: -0.009003410689380159

Running world 16/20

Running BIRL with demonstration 1/10 in world 16
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.392
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.16842041 -0.2413393  -0.24853604 -0.00496336  0.80176971 -0.45119007
 -0.07202753]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.278448
0.9-VaR bound for 1 demonstrations: 1.502089
0.95-VaR bound for 1 demonstrations: 1.732335
0.99-VaR bound for 1 demonstrations: 2.592978
True expected value difference for MAP policy: 0.998166
Evaluating threshold 0.1 with avar bound: [1.7323354368803552]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.7323354368803552]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.7323354368803552]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.7323354368803552]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.7323354368803552]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.7323354368803552]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.7323354368803552]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.7323354368803552]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.7323354368803552]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 16
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.229
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.6924972  -0.13828576  0.2856025  -0.37954787 -0.04612414 -0.48782148
  0.18868511]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 0.989020
0.9-VaR bound for 2 demonstrations: 1.157786
0.95-VaR bound for 2 demonstrations: 1.432823
0.99-VaR bound for 2 demonstrations: 1.449181
True expected value difference for MAP policy: -0.006840
Evaluating threshold 0.1 with avar bound: [1.4328230489033362]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4328230489033362]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4328230489033362]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4328230489033362]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4328230489033362]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4328230489033362]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4328230489033362]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4328230489033362]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4328230489033362]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2)]
MCMC sampling complete.
Acceptance ratio: 0.196
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.54554508  0.04867516  0.47114771  0.12441249  0.25217733 -0.62947593
  0.0521469 ]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.593612
0.9-VaR bound for 3 demonstrations: 1.078815
0.95-VaR bound for 3 demonstrations: 1.305654
0.99-VaR bound for 3 demonstrations: 1.627916
True expected value difference for MAP policy: 1.014646
Evaluating threshold 0.1 with avar bound: [1.3056540942396206]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3056540942396206]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3056540942396206]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3056540942396206]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3056540942396206]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3056540942396206]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3056540942396206]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3056540942396206]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3056540942396206]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.158
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.6140329   0.04765379  0.51971667 -0.11033267  0.1582     -0.48478244
  0.27995132]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.005029
0.9-VaR bound for 4 demonstrations: 0.008686
0.95-VaR bound for 4 demonstrations: 0.022784
0.99-VaR bound for 4 demonstrations: 0.022784
True expected value difference for MAP policy: -0.001823
Evaluating threshold 0.1 with avar bound: [0.02278392121690047]
Threshold 0.1 SUFFICIENT with avar bound: 0.02278392121690047
Evaluating threshold 0.2 with avar bound: [0.02278392121690047]
Threshold 0.2 SUFFICIENT with avar bound: 0.02278392121690047
Evaluating threshold 0.3 with avar bound: [0.02278392121690047]
Threshold 0.3 SUFFICIENT with avar bound: 0.02278392121690047
Evaluating threshold 0.4 with avar bound: [0.02278392121690047]
Threshold 0.4 SUFFICIENT with avar bound: 0.02278392121690047
Evaluating threshold 0.5 with avar bound: [0.02278392121690047]
Threshold 0.5 SUFFICIENT with avar bound: 0.02278392121690047
Evaluating threshold 0.6 with avar bound: [0.02278392121690047]
Threshold 0.6 SUFFICIENT with avar bound: 0.02278392121690047
Evaluating threshold 0.7 with avar bound: [0.02278392121690047]
Threshold 0.7 SUFFICIENT with avar bound: 0.02278392121690047
Evaluating threshold 0.8 with avar bound: [0.02278392121690047]
Threshold 0.8 SUFFICIENT with avar bound: 0.02278392121690047
Evaluating threshold 0.9 with avar bound: [0.02278392121690047]
Threshold 0.9 SUFFICIENT with avar bound: 0.02278392121690047

Running BIRL with demonstration 5/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.139
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50798225 -0.03653753  0.54270199  0.16220522  0.40901452  0.15532358
  0.47787526]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.004652
0.9-VaR bound for 5 demonstrations: 0.014117
0.95-VaR bound for 5 demonstrations: 0.029766
0.99-VaR bound for 5 demonstrations: 0.034992
True expected value difference for MAP policy: -0.017981
Evaluating threshold 0.1 with avar bound: [0.029766268712971902]
Threshold 0.1 SUFFICIENT with avar bound: 0.029766268712971902
Evaluating threshold 0.2 with avar bound: [0.029766268712971902]
Threshold 0.2 SUFFICIENT with avar bound: 0.029766268712971902
Evaluating threshold 0.3 with avar bound: [0.029766268712971902]
Threshold 0.3 SUFFICIENT with avar bound: 0.029766268712971902
Evaluating threshold 0.4 with avar bound: [0.029766268712971902]
Threshold 0.4 SUFFICIENT with avar bound: 0.029766268712971902
Evaluating threshold 0.5 with avar bound: [0.029766268712971902]
Threshold 0.5 SUFFICIENT with avar bound: 0.029766268712971902
Evaluating threshold 0.6 with avar bound: [0.029766268712971902]
Threshold 0.6 SUFFICIENT with avar bound: 0.029766268712971902
Evaluating threshold 0.7 with avar bound: [0.029766268712971902]
Threshold 0.7 SUFFICIENT with avar bound: 0.029766268712971902
Evaluating threshold 0.8 with avar bound: [0.029766268712971902]
Threshold 0.8 SUFFICIENT with avar bound: 0.029766268712971902
Evaluating threshold 0.9 with avar bound: [0.029766268712971902]
Threshold 0.9 SUFFICIENT with avar bound: 0.029766268712971902

Running BIRL with demonstration 6/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 3), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.136
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.42465428 -0.40451476  0.46348801  0.20040666  0.41496647 -0.04938807
  0.47583215]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: 0.005739
0.9-VaR bound for 6 demonstrations: 0.005818
0.95-VaR bound for 6 demonstrations: 0.008903
0.99-VaR bound for 6 demonstrations: 0.021653
True expected value difference for MAP policy: -0.015433
Evaluating threshold 0.1 with avar bound: [0.008903287595446787]
Threshold 0.1 SUFFICIENT with avar bound: 0.008903287595446787
Evaluating threshold 0.2 with avar bound: [0.008903287595446787]
Threshold 0.2 SUFFICIENT with avar bound: 0.008903287595446787
Evaluating threshold 0.3 with avar bound: [0.008903287595446787]
Threshold 0.3 SUFFICIENT with avar bound: 0.008903287595446787
Evaluating threshold 0.4 with avar bound: [0.008903287595446787]
Threshold 0.4 SUFFICIENT with avar bound: 0.008903287595446787
Evaluating threshold 0.5 with avar bound: [0.008903287595446787]
Threshold 0.5 SUFFICIENT with avar bound: 0.008903287595446787
Evaluating threshold 0.6 with avar bound: [0.008903287595446787]
Threshold 0.6 SUFFICIENT with avar bound: 0.008903287595446787
Evaluating threshold 0.7 with avar bound: [0.008903287595446787]
Threshold 0.7 SUFFICIENT with avar bound: 0.008903287595446787
Evaluating threshold 0.8 with avar bound: [0.008903287595446787]
Threshold 0.8 SUFFICIENT with avar bound: 0.008903287595446787
Evaluating threshold 0.9 with avar bound: [0.008903287595446787]
Threshold 0.9 SUFFICIENT with avar bound: 0.008903287595446787

Running BIRL with demonstration 7/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 3), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.144
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.61261463 -0.24946031  0.37831519  0.09696518  0.37277534 -0.2373752
  0.46329235]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.010973
0.9-VaR bound for 7 demonstrations: -0.003010
0.95-VaR bound for 7 demonstrations: 0.002233
0.99-VaR bound for 7 demonstrations: 0.002233
True expected value difference for MAP policy: -0.017120
Evaluating threshold 0.1 with avar bound: [0.002232613941524346]
Threshold 0.1 SUFFICIENT with avar bound: 0.002232613941524346
Evaluating threshold 0.2 with avar bound: [0.002232613941524346]
Threshold 0.2 SUFFICIENT with avar bound: 0.002232613941524346
Evaluating threshold 0.3 with avar bound: [0.002232613941524346]
Threshold 0.3 SUFFICIENT with avar bound: 0.002232613941524346
Evaluating threshold 0.4 with avar bound: [0.002232613941524346]
Threshold 0.4 SUFFICIENT with avar bound: 0.002232613941524346
Evaluating threshold 0.5 with avar bound: [0.002232613941524346]
Threshold 0.5 SUFFICIENT with avar bound: 0.002232613941524346
Evaluating threshold 0.6 with avar bound: [0.002232613941524346]
Threshold 0.6 SUFFICIENT with avar bound: 0.002232613941524346
Evaluating threshold 0.7 with avar bound: [0.002232613941524346]
Threshold 0.7 SUFFICIENT with avar bound: 0.002232613941524346
Evaluating threshold 0.8 with avar bound: [0.002232613941524346]
Threshold 0.8 SUFFICIENT with avar bound: 0.002232613941524346
Evaluating threshold 0.9 with avar bound: [0.002232613941524346]
Threshold 0.9 SUFFICIENT with avar bound: 0.002232613941524346

Running BIRL with demonstration 8/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.147
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.4480971  -0.16908069  0.51473136  0.11655065  0.45410149 -0.06008869
  0.53129038]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.006858
0.9-VaR bound for 8 demonstrations: -0.006858
0.95-VaR bound for 8 demonstrations: -0.003988
0.99-VaR bound for 8 demonstrations: 0.002995
True expected value difference for MAP policy: -0.017120
Evaluating threshold 0.1 with avar bound: [-0.003988300264025222]
Threshold 0.1 SUFFICIENT with avar bound: -0.003988300264025222
Evaluating threshold 0.2 with avar bound: [-0.003988300264025222]
Threshold 0.2 SUFFICIENT with avar bound: -0.003988300264025222
Evaluating threshold 0.3 with avar bound: [-0.003988300264025222]
Threshold 0.3 SUFFICIENT with avar bound: -0.003988300264025222
Evaluating threshold 0.4 with avar bound: [-0.003988300264025222]
Threshold 0.4 SUFFICIENT with avar bound: -0.003988300264025222
Evaluating threshold 0.5 with avar bound: [-0.003988300264025222]
Threshold 0.5 SUFFICIENT with avar bound: -0.003988300264025222
Evaluating threshold 0.6 with avar bound: [-0.003988300264025222]
Threshold 0.6 SUFFICIENT with avar bound: -0.003988300264025222
Evaluating threshold 0.7 with avar bound: [-0.003988300264025222]
Threshold 0.7 SUFFICIENT with avar bound: -0.003988300264025222
Evaluating threshold 0.8 with avar bound: [-0.003988300264025222]
Threshold 0.8 SUFFICIENT with avar bound: -0.003988300264025222
Evaluating threshold 0.9 with avar bound: [-0.003988300264025222]
Threshold 0.9 SUFFICIENT with avar bound: -0.003988300264025222

Running BIRL with demonstration 9/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.14
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.73920251 -0.25467509  0.29033854 -0.06275667  0.34851187 -0.22918814
  0.35566508]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: 0.138913
0.9-VaR bound for 9 demonstrations: 0.154641
0.95-VaR bound for 9 demonstrations: 0.186681
0.99-VaR bound for 9 demonstrations: 0.221362
True expected value difference for MAP policy: 0.139221
Evaluating threshold 0.1 with avar bound: [0.1866809071264808]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [0.1866809071264808]
Threshold 0.2 SUFFICIENT with avar bound: 0.1866809071264808
Evaluating threshold 0.3 with avar bound: [0.1866809071264808]
Threshold 0.3 SUFFICIENT with avar bound: 0.1866809071264808
Evaluating threshold 0.4 with avar bound: [0.1866809071264808]
Threshold 0.4 SUFFICIENT with avar bound: 0.1866809071264808
Evaluating threshold 0.5 with avar bound: [0.1866809071264808]
Threshold 0.5 SUFFICIENT with avar bound: 0.1866809071264808
Evaluating threshold 0.6 with avar bound: [0.1866809071264808]
Threshold 0.6 SUFFICIENT with avar bound: 0.1866809071264808
Evaluating threshold 0.7 with avar bound: [0.1866809071264808]
Threshold 0.7 SUFFICIENT with avar bound: 0.1866809071264808
Evaluating threshold 0.8 with avar bound: [0.1866809071264808]
Threshold 0.8 SUFFICIENT with avar bound: 0.1866809071264808
Evaluating threshold 0.9 with avar bound: [0.1866809071264808]
Threshold 0.9 SUFFICIENT with avar bound: 0.1866809071264808

Running BIRL with demonstration 10/10 in world 16
Current demos: [(16, 1), (12, 3), (9, 2), (19, 1), (18, 3), (6, 1), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.14
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.70039298 -0.14774271  0.37356179  0.0607724   0.36643381 -0.03833822
  0.45676747]
True Reward Weights: [-0.90887862  0.02218579  0.06840918  0.08344137  0.14489815  0.16463882
  0.33719986]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.006123
0.9-VaR bound for 10 demonstrations: 0.002296
0.95-VaR bound for 10 demonstrations: 0.020621
0.99-VaR bound for 10 demonstrations: 0.020621
True expected value difference for MAP policy: -0.017120
Evaluating threshold 0.1 with avar bound: [0.020621410615770858]
Threshold 0.1 SUFFICIENT with avar bound: 0.020621410615770858
Evaluating threshold 0.2 with avar bound: [0.020621410615770858]
Threshold 0.2 SUFFICIENT with avar bound: 0.020621410615770858
Evaluating threshold 0.3 with avar bound: [0.020621410615770858]
Threshold 0.3 SUFFICIENT with avar bound: 0.020621410615770858
Evaluating threshold 0.4 with avar bound: [0.020621410615770858]
Threshold 0.4 SUFFICIENT with avar bound: 0.020621410615770858
Evaluating threshold 0.5 with avar bound: [0.020621410615770858]
Threshold 0.5 SUFFICIENT with avar bound: 0.020621410615770858
Evaluating threshold 0.6 with avar bound: [0.020621410615770858]
Threshold 0.6 SUFFICIENT with avar bound: 0.020621410615770858
Evaluating threshold 0.7 with avar bound: [0.020621410615770858]
Threshold 0.7 SUFFICIENT with avar bound: 0.020621410615770858
Evaluating threshold 0.8 with avar bound: [0.020621410615770858]
Threshold 0.8 SUFFICIENT with avar bound: 0.020621410615770858
Evaluating threshold 0.9 with avar bound: [0.020621410615770858]
Threshold 0.9 SUFFICIENT with avar bound: 0.020621410615770858

Saving results to files...
Results saved successfully.

Running world 17/20

Running BIRL with demonstration 1/10 in world 17
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.432
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.56775576 -0.23796946  0.08827261  0.60899019 -0.35277458 -0.29960405
 -0.16778061]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 3.845910
0.9-VaR bound for 1 demonstrations: 4.482099
0.95-VaR bound for 1 demonstrations: 5.134946
0.99-VaR bound for 1 demonstrations: 7.766856
True expected value difference for MAP policy: 1.063491
Evaluating threshold 0.1 with avar bound: [5.1349457024350755]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [5.1349457024350755]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [5.1349457024350755]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [5.1349457024350755]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [5.1349457024350755]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [5.1349457024350755]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [5.1349457024350755]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [5.1349457024350755]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [5.1349457024350755]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 17
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.319
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.4941339  -0.07328744 -0.14076875 -0.18246313  0.48836978 -0.11103546
  0.66822009]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.168574
0.9-VaR bound for 2 demonstrations: 1.247942
0.95-VaR bound for 2 demonstrations: 1.343358
0.99-VaR bound for 2 demonstrations: 1.390064
True expected value difference for MAP policy: 0.000787
Evaluating threshold 0.1 with avar bound: [1.3433582215395468]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.3433582215395468]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.3433582215395468]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.3433582215395468]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.3433582215395468]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.3433582215395468]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.3433582215395468]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.3433582215395468]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.3433582215395468]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.279
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.40182756  0.1394873  -0.03341891 -0.09561543  0.39009042 -0.35005112
  0.73082997]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: -0.000526
0.9-VaR bound for 3 demonstrations: 0.004065
0.95-VaR bound for 3 demonstrations: 0.011266
0.99-VaR bound for 3 demonstrations: 0.022363
True expected value difference for MAP policy: 0.003666
Evaluating threshold 0.1 with avar bound: [0.011266439631743246]
Threshold 0.1 SUFFICIENT with avar bound: 0.011266439631743246
Evaluating threshold 0.2 with avar bound: [0.011266439631743246]
Threshold 0.2 SUFFICIENT with avar bound: 0.011266439631743246
Evaluating threshold 0.3 with avar bound: [0.011266439631743246]
Threshold 0.3 SUFFICIENT with avar bound: 0.011266439631743246
Evaluating threshold 0.4 with avar bound: [0.011266439631743246]
Threshold 0.4 SUFFICIENT with avar bound: 0.011266439631743246
Evaluating threshold 0.5 with avar bound: [0.011266439631743246]
Threshold 0.5 SUFFICIENT with avar bound: 0.011266439631743246
Evaluating threshold 0.6 with avar bound: [0.011266439631743246]
Threshold 0.6 SUFFICIENT with avar bound: 0.011266439631743246
Evaluating threshold 0.7 with avar bound: [0.011266439631743246]
Threshold 0.7 SUFFICIENT with avar bound: 0.011266439631743246
Evaluating threshold 0.8 with avar bound: [0.011266439631743246]
Threshold 0.8 SUFFICIENT with avar bound: 0.011266439631743246
Evaluating threshold 0.9 with avar bound: [0.011266439631743246]
Threshold 0.9 SUFFICIENT with avar bound: 0.011266439631743246

Running BIRL with demonstration 4/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.287
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.46558902 -0.09886458 -0.12729986 -0.38218575  0.28020031 -0.1042163
  0.72236293]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.002313
0.9-VaR bound for 4 demonstrations: 0.006701
0.95-VaR bound for 4 demonstrations: 0.010926
0.99-VaR bound for 4 demonstrations: 0.020896
True expected value difference for MAP policy: 0.000787
Evaluating threshold 0.1 with avar bound: [0.010926270032564288]
Threshold 0.1 SUFFICIENT with avar bound: 0.010926270032564288
Evaluating threshold 0.2 with avar bound: [0.010926270032564288]
Threshold 0.2 SUFFICIENT with avar bound: 0.010926270032564288
Evaluating threshold 0.3 with avar bound: [0.010926270032564288]
Threshold 0.3 SUFFICIENT with avar bound: 0.010926270032564288
Evaluating threshold 0.4 with avar bound: [0.010926270032564288]
Threshold 0.4 SUFFICIENT with avar bound: 0.010926270032564288
Evaluating threshold 0.5 with avar bound: [0.010926270032564288]
Threshold 0.5 SUFFICIENT with avar bound: 0.010926270032564288
Evaluating threshold 0.6 with avar bound: [0.010926270032564288]
Threshold 0.6 SUFFICIENT with avar bound: 0.010926270032564288
Evaluating threshold 0.7 with avar bound: [0.010926270032564288]
Threshold 0.7 SUFFICIENT with avar bound: 0.010926270032564288
Evaluating threshold 0.8 with avar bound: [0.010926270032564288]
Threshold 0.8 SUFFICIENT with avar bound: 0.010926270032564288
Evaluating threshold 0.9 with avar bound: [0.010926270032564288]
Threshold 0.9 SUFFICIENT with avar bound: 0.010926270032564288

Running BIRL with demonstration 5/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.248
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.38691143  0.11737706  0.06375542 -0.29895403  0.37938652  0.18621543
  0.75131457]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.001323
0.9-VaR bound for 5 demonstrations: 0.003266
0.95-VaR bound for 5 demonstrations: 0.011922
0.99-VaR bound for 5 demonstrations: 0.016591
True expected value difference for MAP policy: 0.000787
Evaluating threshold 0.1 with avar bound: [0.01192206012234459]
Threshold 0.1 SUFFICIENT with avar bound: 0.01192206012234459
Evaluating threshold 0.2 with avar bound: [0.01192206012234459]
Threshold 0.2 SUFFICIENT with avar bound: 0.01192206012234459
Evaluating threshold 0.3 with avar bound: [0.01192206012234459]
Threshold 0.3 SUFFICIENT with avar bound: 0.01192206012234459
Evaluating threshold 0.4 with avar bound: [0.01192206012234459]
Threshold 0.4 SUFFICIENT with avar bound: 0.01192206012234459
Evaluating threshold 0.5 with avar bound: [0.01192206012234459]
Threshold 0.5 SUFFICIENT with avar bound: 0.01192206012234459
Evaluating threshold 0.6 with avar bound: [0.01192206012234459]
Threshold 0.6 SUFFICIENT with avar bound: 0.01192206012234459
Evaluating threshold 0.7 with avar bound: [0.01192206012234459]
Threshold 0.7 SUFFICIENT with avar bound: 0.01192206012234459
Evaluating threshold 0.8 with avar bound: [0.01192206012234459]
Threshold 0.8 SUFFICIENT with avar bound: 0.01192206012234459
Evaluating threshold 0.9 with avar bound: [0.01192206012234459]
Threshold 0.9 SUFFICIENT with avar bound: 0.01192206012234459

Running BIRL with demonstration 6/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.187
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.47274091 -0.17794905 -0.17133332 -0.45486886  0.04228153  0.28140952
  0.65391921]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.005085
0.9-VaR bound for 6 demonstrations: -0.001816
0.95-VaR bound for 6 demonstrations: 0.002303
0.99-VaR bound for 6 demonstrations: 0.010838
True expected value difference for MAP policy: -0.000045
Evaluating threshold 0.1 with avar bound: [0.002302920571686791]
Threshold 0.1 SUFFICIENT with avar bound: 0.002302920571686791
Evaluating threshold 0.2 with avar bound: [0.002302920571686791]
Threshold 0.2 SUFFICIENT with avar bound: 0.002302920571686791
Evaluating threshold 0.3 with avar bound: [0.002302920571686791]
Threshold 0.3 SUFFICIENT with avar bound: 0.002302920571686791
Evaluating threshold 0.4 with avar bound: [0.002302920571686791]
Threshold 0.4 SUFFICIENT with avar bound: 0.002302920571686791
Evaluating threshold 0.5 with avar bound: [0.002302920571686791]
Threshold 0.5 SUFFICIENT with avar bound: 0.002302920571686791
Evaluating threshold 0.6 with avar bound: [0.002302920571686791]
Threshold 0.6 SUFFICIENT with avar bound: 0.002302920571686791
Evaluating threshold 0.7 with avar bound: [0.002302920571686791]
Threshold 0.7 SUFFICIENT with avar bound: 0.002302920571686791
Evaluating threshold 0.8 with avar bound: [0.002302920571686791]
Threshold 0.8 SUFFICIENT with avar bound: 0.002302920571686791
Evaluating threshold 0.9 with avar bound: [0.002302920571686791]
Threshold 0.9 SUFFICIENT with avar bound: 0.002302920571686791

Running BIRL with demonstration 7/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.221
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.4471841  -0.43961265 -0.26887714 -0.25649891  0.09759718  0.32913248
  0.59230658]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.005979
0.9-VaR bound for 7 demonstrations: -0.002909
0.95-VaR bound for 7 demonstrations: 0.002498
0.99-VaR bound for 7 demonstrations: 0.012734
True expected value difference for MAP policy: -0.000362
Evaluating threshold 0.1 with avar bound: [0.002498105159647588]
Threshold 0.1 SUFFICIENT with avar bound: 0.002498105159647588
Evaluating threshold 0.2 with avar bound: [0.002498105159647588]
Threshold 0.2 SUFFICIENT with avar bound: 0.002498105159647588
Evaluating threshold 0.3 with avar bound: [0.002498105159647588]
Threshold 0.3 SUFFICIENT with avar bound: 0.002498105159647588
Evaluating threshold 0.4 with avar bound: [0.002498105159647588]
Threshold 0.4 SUFFICIENT with avar bound: 0.002498105159647588
Evaluating threshold 0.5 with avar bound: [0.002498105159647588]
Threshold 0.5 SUFFICIENT with avar bound: 0.002498105159647588
Evaluating threshold 0.6 with avar bound: [0.002498105159647588]
Threshold 0.6 SUFFICIENT with avar bound: 0.002498105159647588
Evaluating threshold 0.7 with avar bound: [0.002498105159647588]
Threshold 0.7 SUFFICIENT with avar bound: 0.002498105159647588
Evaluating threshold 0.8 with avar bound: [0.002498105159647588]
Threshold 0.8 SUFFICIENT with avar bound: 0.002498105159647588
Evaluating threshold 0.9 with avar bound: [0.002498105159647588]
Threshold 0.9 SUFFICIENT with avar bound: 0.002498105159647588

Running BIRL with demonstration 8/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 0)]
MCMC sampling complete.
Acceptance ratio: 0.146
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.76747033 -0.09713578  0.26270389  0.28000498  0.15501266  0.23042548
  0.4207291 ]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: 0.042812
0.9-VaR bound for 8 demonstrations: 0.056165
0.95-VaR bound for 8 demonstrations: 0.064965
0.99-VaR bound for 8 demonstrations: 0.084639
True expected value difference for MAP policy: -0.008316
Evaluating threshold 0.1 with avar bound: [0.0649652559225163]
Threshold 0.1 SUFFICIENT with avar bound: 0.0649652559225163
Evaluating threshold 0.2 with avar bound: [0.0649652559225163]
Threshold 0.2 SUFFICIENT with avar bound: 0.0649652559225163
Evaluating threshold 0.3 with avar bound: [0.0649652559225163]
Threshold 0.3 SUFFICIENT with avar bound: 0.0649652559225163
Evaluating threshold 0.4 with avar bound: [0.0649652559225163]
Threshold 0.4 SUFFICIENT with avar bound: 0.0649652559225163
Evaluating threshold 0.5 with avar bound: [0.0649652559225163]
Threshold 0.5 SUFFICIENT with avar bound: 0.0649652559225163
Evaluating threshold 0.6 with avar bound: [0.0649652559225163]
Threshold 0.6 SUFFICIENT with avar bound: 0.0649652559225163
Evaluating threshold 0.7 with avar bound: [0.0649652559225163]
Threshold 0.7 SUFFICIENT with avar bound: 0.0649652559225163
Evaluating threshold 0.8 with avar bound: [0.0649652559225163]
Threshold 0.8 SUFFICIENT with avar bound: 0.0649652559225163
Evaluating threshold 0.9 with avar bound: [0.0649652559225163]
Threshold 0.9 SUFFICIENT with avar bound: 0.0649652559225163

Running BIRL with demonstration 9/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 0), (15, 0)]
MCMC sampling complete.
Acceptance ratio: 0.124
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.5736221  -0.42882319 -0.43259857  0.15236954  0.21536791  0.30033172
  0.37433657]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: 0.020584
0.9-VaR bound for 9 demonstrations: 0.022796
0.95-VaR bound for 9 demonstrations: 0.029007
0.99-VaR bound for 9 demonstrations: 0.043407
True expected value difference for MAP policy: -0.012697
Evaluating threshold 0.1 with avar bound: [0.02900748737021288]
Threshold 0.1 SUFFICIENT with avar bound: 0.02900748737021288
Evaluating threshold 0.2 with avar bound: [0.02900748737021288]
Threshold 0.2 SUFFICIENT with avar bound: 0.02900748737021288
Evaluating threshold 0.3 with avar bound: [0.02900748737021288]
Threshold 0.3 SUFFICIENT with avar bound: 0.02900748737021288
Evaluating threshold 0.4 with avar bound: [0.02900748737021288]
Threshold 0.4 SUFFICIENT with avar bound: 0.02900748737021288
Evaluating threshold 0.5 with avar bound: [0.02900748737021288]
Threshold 0.5 SUFFICIENT with avar bound: 0.02900748737021288
Evaluating threshold 0.6 with avar bound: [0.02900748737021288]
Threshold 0.6 SUFFICIENT with avar bound: 0.02900748737021288
Evaluating threshold 0.7 with avar bound: [0.02900748737021288]
Threshold 0.7 SUFFICIENT with avar bound: 0.02900748737021288
Evaluating threshold 0.8 with avar bound: [0.02900748737021288]
Threshold 0.8 SUFFICIENT with avar bound: 0.02900748737021288
Evaluating threshold 0.9 with avar bound: [0.02900748737021288]
Threshold 0.9 SUFFICIENT with avar bound: 0.02900748737021288

Running BIRL with demonstration 10/10 in world 17
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 0), (15, 0), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.14
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.60393283 -0.67786353 -0.22178527  0.12497189  0.16199353  0.15313425
  0.24752271]
True Reward Weights: [-0.87861704 -0.30578721 -0.00595068  0.07130837  0.12407258  0.21667214
  0.25896943]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: 0.023810
0.9-VaR bound for 10 demonstrations: 0.030051
0.95-VaR bound for 10 demonstrations: 0.040184
0.99-VaR bound for 10 demonstrations: 0.052612
True expected value difference for MAP policy: -0.013576
Evaluating threshold 0.1 with avar bound: [0.040183869693507505]
Threshold 0.1 SUFFICIENT with avar bound: 0.040183869693507505
Evaluating threshold 0.2 with avar bound: [0.040183869693507505]
Threshold 0.2 SUFFICIENT with avar bound: 0.040183869693507505
Evaluating threshold 0.3 with avar bound: [0.040183869693507505]
Threshold 0.3 SUFFICIENT with avar bound: 0.040183869693507505
Evaluating threshold 0.4 with avar bound: [0.040183869693507505]
Threshold 0.4 SUFFICIENT with avar bound: 0.040183869693507505
Evaluating threshold 0.5 with avar bound: [0.040183869693507505]
Threshold 0.5 SUFFICIENT with avar bound: 0.040183869693507505
Evaluating threshold 0.6 with avar bound: [0.040183869693507505]
Threshold 0.6 SUFFICIENT with avar bound: 0.040183869693507505
Evaluating threshold 0.7 with avar bound: [0.040183869693507505]
Threshold 0.7 SUFFICIENT with avar bound: 0.040183869693507505
Evaluating threshold 0.8 with avar bound: [0.040183869693507505]
Threshold 0.8 SUFFICIENT with avar bound: 0.040183869693507505
Evaluating threshold 0.9 with avar bound: [0.040183869693507505]
Threshold 0.9 SUFFICIENT with avar bound: 0.040183869693507505

Running world 18/20

Running BIRL with demonstration 1/10 in world 18
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.407
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.00580135  0.03669589 -0.27309736 -0.05561451 -0.69183848  0.17194122
  0.64244871]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.263935
0.9-VaR bound for 1 demonstrations: 1.358639
0.95-VaR bound for 1 demonstrations: 1.451351
0.99-VaR bound for 1 demonstrations: 1.535008
True expected value difference for MAP policy: 0.025928
Evaluating threshold 0.1 with avar bound: [1.4513506279444124]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4513506279444124]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4513506279444124]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4513506279444124]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4513506279444124]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4513506279444124]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4513506279444124]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4513506279444124]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4513506279444124]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 18
Current demos: [(16, 3), (12, 1)]
MCMC sampling complete.
Acceptance ratio: 0.301
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.50701981  0.39040119 -0.2707231   0.08883925 -0.1736253   0.39503995
  0.5684471 ]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.371003
0.9-VaR bound for 2 demonstrations: 1.430898
0.95-VaR bound for 2 demonstrations: 1.482228
0.99-VaR bound for 2 demonstrations: 1.593406
True expected value difference for MAP policy: -0.006967
Evaluating threshold 0.1 with avar bound: [1.4822282130290698]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4822282130290698]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4822282130290698]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4822282130290698]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4822282130290698]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4822282130290698]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4822282130290698]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4822282130290698]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4822282130290698]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 18
Current demos: [(16, 3), (12, 1), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.252
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.44549924 -0.09946631  0.07020604 -0.18607587 -0.173597    0.49891573
  0.68777245]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.229002
0.9-VaR bound for 3 demonstrations: 1.359688
0.95-VaR bound for 3 demonstrations: 1.430844
0.99-VaR bound for 3 demonstrations: 1.577314
True expected value difference for MAP policy: -0.006198
Evaluating threshold 0.1 with avar bound: [1.4308435437991855]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4308435437991855]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4308435437991855]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4308435437991855]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4308435437991855]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4308435437991855]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4308435437991855]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4308435437991855]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4308435437991855]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 18
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.232
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.55783574 -0.25271649 -0.13908823 -0.38224757 -0.29407464  0.30766891
  0.52759347]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.011484
0.9-VaR bound for 4 demonstrations: -0.009495
0.95-VaR bound for 4 demonstrations: -0.001750
0.99-VaR bound for 4 demonstrations: 0.049284
True expected value difference for MAP policy: -0.008008
Evaluating threshold 0.1 with avar bound: [-0.0017495189888737937]
Threshold 0.1 SUFFICIENT with avar bound: -0.0017495189888737937
Evaluating threshold 0.2 with avar bound: [-0.0017495189888737937]
Threshold 0.2 SUFFICIENT with avar bound: -0.0017495189888737937
Evaluating threshold 0.3 with avar bound: [-0.0017495189888737937]
Threshold 0.3 SUFFICIENT with avar bound: -0.0017495189888737937
Evaluating threshold 0.4 with avar bound: [-0.0017495189888737937]
Threshold 0.4 SUFFICIENT with avar bound: -0.0017495189888737937
Evaluating threshold 0.5 with avar bound: [-0.0017495189888737937]
Threshold 0.5 SUFFICIENT with avar bound: -0.0017495189888737937
Evaluating threshold 0.6 with avar bound: [-0.0017495189888737937]
Threshold 0.6 SUFFICIENT with avar bound: -0.0017495189888737937
Evaluating threshold 0.7 with avar bound: [-0.0017495189888737937]
Threshold 0.7 SUFFICIENT with avar bound: -0.0017495189888737937
Evaluating threshold 0.8 with avar bound: [-0.0017495189888737937]
Threshold 0.8 SUFFICIENT with avar bound: -0.0017495189888737937
Evaluating threshold 0.9 with avar bound: [-0.0017495189888737937]
Threshold 0.9 SUFFICIENT with avar bound: -0.0017495189888737937

Running BIRL with demonstration 5/10 in world 18
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1)]
MCMC sampling complete.
Acceptance ratio: 0.205
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.39351356  0.25793868 -0.27472491 -0.04171828  0.03735912  0.50437049
  0.66754418]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.006279
0.9-VaR bound for 5 demonstrations: -0.003137
0.95-VaR bound for 5 demonstrations: 0.002874
0.99-VaR bound for 5 demonstrations: 0.012349
True expected value difference for MAP policy: -0.012056
Evaluating threshold 0.1 with avar bound: [0.0028744337669660766]
Threshold 0.1 SUFFICIENT with avar bound: 0.0028744337669660766
Evaluating threshold 0.2 with avar bound: [0.0028744337669660766]
Threshold 0.2 SUFFICIENT with avar bound: 0.0028744337669660766
Evaluating threshold 0.3 with avar bound: [0.0028744337669660766]
Threshold 0.3 SUFFICIENT with avar bound: 0.0028744337669660766
Evaluating threshold 0.4 with avar bound: [0.0028744337669660766]
Threshold 0.4 SUFFICIENT with avar bound: 0.0028744337669660766
Evaluating threshold 0.5 with avar bound: [0.0028744337669660766]
Threshold 0.5 SUFFICIENT with avar bound: 0.0028744337669660766
Evaluating threshold 0.6 with avar bound: [0.0028744337669660766]
Threshold 0.6 SUFFICIENT with avar bound: 0.0028744337669660766
Evaluating threshold 0.7 with avar bound: [0.0028744337669660766]
Threshold 0.7 SUFFICIENT with avar bound: 0.0028744337669660766
Evaluating threshold 0.8 with avar bound: [0.0028744337669660766]
Threshold 0.8 SUFFICIENT with avar bound: 0.0028744337669660766
Evaluating threshold 0.9 with avar bound: [0.0028744337669660766]
Threshold 0.9 SUFFICIENT with avar bound: 0.0028744337669660766

Running BIRL with demonstration 6/10 in world 18
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1)]
MCMC sampling complete.
Acceptance ratio: 0.202
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.6856992  -0.27762691  0.07966167 -0.20638238 -0.36330851  0.04875836
  0.51906626]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.007434
0.9-VaR bound for 6 demonstrations: -0.004206
0.95-VaR bound for 6 demonstrations: 0.003700
0.99-VaR bound for 6 demonstrations: 0.012952
True expected value difference for MAP policy: -0.006967
Evaluating threshold 0.1 with avar bound: [0.0036998924937095765]
Threshold 0.1 SUFFICIENT with avar bound: 0.0036998924937095765
Evaluating threshold 0.2 with avar bound: [0.0036998924937095765]
Threshold 0.2 SUFFICIENT with avar bound: 0.0036998924937095765
Evaluating threshold 0.3 with avar bound: [0.0036998924937095765]
Threshold 0.3 SUFFICIENT with avar bound: 0.0036998924937095765
Evaluating threshold 0.4 with avar bound: [0.0036998924937095765]
Threshold 0.4 SUFFICIENT with avar bound: 0.0036998924937095765
Evaluating threshold 0.5 with avar bound: [0.0036998924937095765]
Threshold 0.5 SUFFICIENT with avar bound: 0.0036998924937095765
Evaluating threshold 0.6 with avar bound: [0.0036998924937095765]
Threshold 0.6 SUFFICIENT with avar bound: 0.0036998924937095765
Evaluating threshold 0.7 with avar bound: [0.0036998924937095765]
Threshold 0.7 SUFFICIENT with avar bound: 0.0036998924937095765
Evaluating threshold 0.8 with avar bound: [0.0036998924937095765]
Threshold 0.8 SUFFICIENT with avar bound: 0.0036998924937095765
Evaluating threshold 0.9 with avar bound: [0.0036998924937095765]
Threshold 0.9 SUFFICIENT with avar bound: 0.0036998924937095765

Running BIRL with demonstration 7/10 in world 18
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.189
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.6389118   0.15218788 -0.20034398  0.11726317 -0.14866541  0.3748587
  0.59339847]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.009624
0.9-VaR bound for 7 demonstrations: -0.008683
0.95-VaR bound for 7 demonstrations: -0.005552
0.99-VaR bound for 7 demonstrations: 0.007523
True expected value difference for MAP policy: -0.009148
Evaluating threshold 0.1 with avar bound: [-0.005552189763300749]
Threshold 0.1 SUFFICIENT with avar bound: -0.005552189763300749
Evaluating threshold 0.2 with avar bound: [-0.005552189763300749]
Threshold 0.2 SUFFICIENT with avar bound: -0.005552189763300749
Evaluating threshold 0.3 with avar bound: [-0.005552189763300749]
Threshold 0.3 SUFFICIENT with avar bound: -0.005552189763300749
Evaluating threshold 0.4 with avar bound: [-0.005552189763300749]
Threshold 0.4 SUFFICIENT with avar bound: -0.005552189763300749
Evaluating threshold 0.5 with avar bound: [-0.005552189763300749]
Threshold 0.5 SUFFICIENT with avar bound: -0.005552189763300749
Evaluating threshold 0.6 with avar bound: [-0.005552189763300749]
Threshold 0.6 SUFFICIENT with avar bound: -0.005552189763300749
Evaluating threshold 0.7 with avar bound: [-0.005552189763300749]
Threshold 0.7 SUFFICIENT with avar bound: -0.005552189763300749
Evaluating threshold 0.8 with avar bound: [-0.005552189763300749]
Threshold 0.8 SUFFICIENT with avar bound: -0.005552189763300749
Evaluating threshold 0.9 with avar bound: [-0.005552189763300749]
Threshold 0.9 SUFFICIENT with avar bound: -0.005552189763300749

Running BIRL with demonstration 8/10 in world 18
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.19
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.64238006 -0.02192527 -0.08238267  0.21103473 -0.12935126  0.25133428
  0.67501401]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.009902
0.9-VaR bound for 8 demonstrations: -0.008029
0.95-VaR bound for 8 demonstrations: -0.006919
0.99-VaR bound for 8 demonstrations: 0.007927
True expected value difference for MAP policy: -0.010677
Evaluating threshold 0.1 with avar bound: [-0.006918531173511063]
Threshold 0.1 SUFFICIENT with avar bound: -0.006918531173511063
Evaluating threshold 0.2 with avar bound: [-0.006918531173511063]
Threshold 0.2 SUFFICIENT with avar bound: -0.006918531173511063
Evaluating threshold 0.3 with avar bound: [-0.006918531173511063]
Threshold 0.3 SUFFICIENT with avar bound: -0.006918531173511063
Evaluating threshold 0.4 with avar bound: [-0.006918531173511063]
Threshold 0.4 SUFFICIENT with avar bound: -0.006918531173511063
Evaluating threshold 0.5 with avar bound: [-0.006918531173511063]
Threshold 0.5 SUFFICIENT with avar bound: -0.006918531173511063
Evaluating threshold 0.6 with avar bound: [-0.006918531173511063]
Threshold 0.6 SUFFICIENT with avar bound: -0.006918531173511063
Evaluating threshold 0.7 with avar bound: [-0.006918531173511063]
Threshold 0.7 SUFFICIENT with avar bound: -0.006918531173511063
Evaluating threshold 0.8 with avar bound: [-0.006918531173511063]
Threshold 0.8 SUFFICIENT with avar bound: -0.006918531173511063
Evaluating threshold 0.9 with avar bound: [-0.006918531173511063]
Threshold 0.9 SUFFICIENT with avar bound: -0.006918531173511063

Running BIRL with demonstration 9/10 in world 18
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.183
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.79092579 -0.12829635 -0.38478409 -0.07945099 -0.04171662  0.01515938
  0.44903798]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.013258
0.9-VaR bound for 9 demonstrations: -0.011383
0.95-VaR bound for 9 demonstrations: -0.007504
0.99-VaR bound for 9 demonstrations: 0.008275
True expected value difference for MAP policy: -0.013474
Evaluating threshold 0.1 with avar bound: [-0.007503968995754282]
Threshold 0.1 SUFFICIENT with avar bound: -0.007503968995754282
Evaluating threshold 0.2 with avar bound: [-0.007503968995754282]
Threshold 0.2 SUFFICIENT with avar bound: -0.007503968995754282
Evaluating threshold 0.3 with avar bound: [-0.007503968995754282]
Threshold 0.3 SUFFICIENT with avar bound: -0.007503968995754282
Evaluating threshold 0.4 with avar bound: [-0.007503968995754282]
Threshold 0.4 SUFFICIENT with avar bound: -0.007503968995754282
Evaluating threshold 0.5 with avar bound: [-0.007503968995754282]
Threshold 0.5 SUFFICIENT with avar bound: -0.007503968995754282
Evaluating threshold 0.6 with avar bound: [-0.007503968995754282]
Threshold 0.6 SUFFICIENT with avar bound: -0.007503968995754282
Evaluating threshold 0.7 with avar bound: [-0.007503968995754282]
Threshold 0.7 SUFFICIENT with avar bound: -0.007503968995754282
Evaluating threshold 0.8 with avar bound: [-0.007503968995754282]
Threshold 0.8 SUFFICIENT with avar bound: -0.007503968995754282
Evaluating threshold 0.9 with avar bound: [-0.007503968995754282]
Threshold 0.9 SUFFICIENT with avar bound: -0.007503968995754282

Running BIRL with demonstration 10/10 in world 18
Current demos: [(16, 3), (12, 1), (9, 1), (19, 1), (18, 1), (6, 1), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.182
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.74732945 -0.093265   -0.39287898 -0.05268751 -0.01778857  0.1009116
  0.51494745]
True Reward Weights: [-0.71486988 -0.49248258 -0.35634852 -0.04533014 -0.04516447 -0.01445882
  0.33931398]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.003652
0.9-VaR bound for 10 demonstrations: 0.000876
0.95-VaR bound for 10 demonstrations: 0.000876
0.99-VaR bound for 10 demonstrations: 0.000876
True expected value difference for MAP policy: -0.013474
Evaluating threshold 0.1 with avar bound: [0.0008760349882446654]
Threshold 0.1 SUFFICIENT with avar bound: 0.0008760349882446654
Evaluating threshold 0.2 with avar bound: [0.0008760349882446654]
Threshold 0.2 SUFFICIENT with avar bound: 0.0008760349882446654
Evaluating threshold 0.3 with avar bound: [0.0008760349882446654]
Threshold 0.3 SUFFICIENT with avar bound: 0.0008760349882446654
Evaluating threshold 0.4 with avar bound: [0.0008760349882446654]
Threshold 0.4 SUFFICIENT with avar bound: 0.0008760349882446654
Evaluating threshold 0.5 with avar bound: [0.0008760349882446654]
Threshold 0.5 SUFFICIENT with avar bound: 0.0008760349882446654
Evaluating threshold 0.6 with avar bound: [0.0008760349882446654]
Threshold 0.6 SUFFICIENT with avar bound: 0.0008760349882446654
Evaluating threshold 0.7 with avar bound: [0.0008760349882446654]
Threshold 0.7 SUFFICIENT with avar bound: 0.0008760349882446654
Evaluating threshold 0.8 with avar bound: [0.0008760349882446654]
Threshold 0.8 SUFFICIENT with avar bound: 0.0008760349882446654
Evaluating threshold 0.9 with avar bound: [0.0008760349882446654]
Threshold 0.9 SUFFICIENT with avar bound: 0.0008760349882446654

Running world 19/20

Running BIRL with demonstration 1/10 in world 19
Current demos: [(16, 1)]
MCMC sampling complete.
Acceptance ratio: 0.379
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.68580191  0.05689844 -0.16622544 -0.13196002  0.30676745 -0.25584933
  0.56729958]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 1.374569
0.9-VaR bound for 1 demonstrations: 1.415341
0.95-VaR bound for 1 demonstrations: 1.455923
0.99-VaR bound for 1 demonstrations: 1.581650
True expected value difference for MAP policy: -0.019060
Evaluating threshold 0.1 with avar bound: [1.4559225456344502]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.4559225456344502]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.4559225456344502]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.4559225456344502]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.4559225456344502]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.4559225456344502]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.4559225456344502]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.4559225456344502]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.4559225456344502]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 19
Current demos: [(16, 1), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.227
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.67198394  0.09942891  0.24418268 -0.1212445   0.37200776 -0.19423985
  0.53675616]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 1.185705
0.9-VaR bound for 2 demonstrations: 1.263001
0.95-VaR bound for 2 demonstrations: 1.385479
0.99-VaR bound for 2 demonstrations: 1.540584
True expected value difference for MAP policy: -0.020491
Evaluating threshold 0.1 with avar bound: [1.385479444646688]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.385479444646688]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.385479444646688]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.385479444646688]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.385479444646688]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.385479444646688]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.385479444646688]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.385479444646688]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.385479444646688]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 19
Current demos: [(16, 1), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.202
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.56587898 -0.15724035 -0.14363414 -0.11720226  0.56077892 -0.17595872
  0.52464735]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 0.989211
0.9-VaR bound for 3 demonstrations: 1.243606
0.95-VaR bound for 3 demonstrations: 1.269715
0.99-VaR bound for 3 demonstrations: 1.404563
True expected value difference for MAP policy: -0.021371
Evaluating threshold 0.1 with avar bound: [1.2697147083890834]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [1.2697147083890834]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [1.2697147083890834]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [1.2697147083890834]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [1.2697147083890834]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [1.2697147083890834]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [1.2697147083890834]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [1.2697147083890834]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [1.2697147083890834]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 19
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.212
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.68245038  0.10182496  0.12118643 -0.31275285  0.1514873  -0.28494444
  0.55430219]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: 0.002698
0.9-VaR bound for 4 demonstrations: 0.003428
0.95-VaR bound for 4 demonstrations: 0.008728
0.99-VaR bound for 4 demonstrations: 0.037502
True expected value difference for MAP policy: -0.019778
Evaluating threshold 0.1 with avar bound: [0.008728499647385618]
Threshold 0.1 SUFFICIENT with avar bound: 0.008728499647385618
Evaluating threshold 0.2 with avar bound: [0.008728499647385618]
Threshold 0.2 SUFFICIENT with avar bound: 0.008728499647385618
Evaluating threshold 0.3 with avar bound: [0.008728499647385618]
Threshold 0.3 SUFFICIENT with avar bound: 0.008728499647385618
Evaluating threshold 0.4 with avar bound: [0.008728499647385618]
Threshold 0.4 SUFFICIENT with avar bound: 0.008728499647385618
Evaluating threshold 0.5 with avar bound: [0.008728499647385618]
Threshold 0.5 SUFFICIENT with avar bound: 0.008728499647385618
Evaluating threshold 0.6 with avar bound: [0.008728499647385618]
Threshold 0.6 SUFFICIENT with avar bound: 0.008728499647385618
Evaluating threshold 0.7 with avar bound: [0.008728499647385618]
Threshold 0.7 SUFFICIENT with avar bound: 0.008728499647385618
Evaluating threshold 0.8 with avar bound: [0.008728499647385618]
Threshold 0.8 SUFFICIENT with avar bound: 0.008728499647385618
Evaluating threshold 0.9 with avar bound: [0.008728499647385618]
Threshold 0.9 SUFFICIENT with avar bound: 0.008728499647385618

Running BIRL with demonstration 5/10 in world 19
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.212
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.6302498   0.04765726  0.33160206 -0.27308094  0.23867623  0.15659886
  0.57835223]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: -0.006605
0.9-VaR bound for 5 demonstrations: -0.002872
0.95-VaR bound for 5 demonstrations: -0.000669
0.99-VaR bound for 5 demonstrations: 0.003901
True expected value difference for MAP policy: -0.021047
Evaluating threshold 0.1 with avar bound: [-0.0006694475850902787]
Threshold 0.1 SUFFICIENT with avar bound: -0.0006694475850902787
Evaluating threshold 0.2 with avar bound: [-0.0006694475850902787]
Threshold 0.2 SUFFICIENT with avar bound: -0.0006694475850902787
Evaluating threshold 0.3 with avar bound: [-0.0006694475850902787]
Threshold 0.3 SUFFICIENT with avar bound: -0.0006694475850902787
Evaluating threshold 0.4 with avar bound: [-0.0006694475850902787]
Threshold 0.4 SUFFICIENT with avar bound: -0.0006694475850902787
Evaluating threshold 0.5 with avar bound: [-0.0006694475850902787]
Threshold 0.5 SUFFICIENT with avar bound: -0.0006694475850902787
Evaluating threshold 0.6 with avar bound: [-0.0006694475850902787]
Threshold 0.6 SUFFICIENT with avar bound: -0.0006694475850902787
Evaluating threshold 0.7 with avar bound: [-0.0006694475850902787]
Threshold 0.7 SUFFICIENT with avar bound: -0.0006694475850902787
Evaluating threshold 0.8 with avar bound: [-0.0006694475850902787]
Threshold 0.8 SUFFICIENT with avar bound: -0.0006694475850902787
Evaluating threshold 0.9 with avar bound: [-0.0006694475850902787]
Threshold 0.9 SUFFICIENT with avar bound: -0.0006694475850902787

Running BIRL with demonstration 6/10 in world 19
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.213
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.68218084 -0.18814152  0.19086257 -0.29961599  0.4111287  -0.22740027
  0.39025136]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.012921
0.9-VaR bound for 6 demonstrations: -0.010597
0.95-VaR bound for 6 demonstrations: -0.007160
0.99-VaR bound for 6 demonstrations: 0.000638
True expected value difference for MAP policy: -0.021586
Evaluating threshold 0.1 with avar bound: [-0.007160382142654432]
Threshold 0.1 SUFFICIENT with avar bound: -0.007160382142654432
Evaluating threshold 0.2 with avar bound: [-0.007160382142654432]
Threshold 0.2 SUFFICIENT with avar bound: -0.007160382142654432
Evaluating threshold 0.3 with avar bound: [-0.007160382142654432]
Threshold 0.3 SUFFICIENT with avar bound: -0.007160382142654432
Evaluating threshold 0.4 with avar bound: [-0.007160382142654432]
Threshold 0.4 SUFFICIENT with avar bound: -0.007160382142654432
Evaluating threshold 0.5 with avar bound: [-0.007160382142654432]
Threshold 0.5 SUFFICIENT with avar bound: -0.007160382142654432
Evaluating threshold 0.6 with avar bound: [-0.007160382142654432]
Threshold 0.6 SUFFICIENT with avar bound: -0.007160382142654432
Evaluating threshold 0.7 with avar bound: [-0.007160382142654432]
Threshold 0.7 SUFFICIENT with avar bound: -0.007160382142654432
Evaluating threshold 0.8 with avar bound: [-0.007160382142654432]
Threshold 0.8 SUFFICIENT with avar bound: -0.007160382142654432
Evaluating threshold 0.9 with avar bound: [-0.007160382142654432]
Threshold 0.9 SUFFICIENT with avar bound: -0.007160382142654432

Running BIRL with demonstration 7/10 in world 19
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1)]
MCMC sampling complete.
Acceptance ratio: 0.195
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.73420032  0.19988334  0.19989535 -0.16749794  0.28442131 -0.23369194
  0.46634261]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: -0.007002
0.9-VaR bound for 7 demonstrations: -0.005265
0.95-VaR bound for 7 demonstrations: 0.002980
0.99-VaR bound for 7 demonstrations: 0.013711
True expected value difference for MAP policy: -0.019289
Evaluating threshold 0.1 with avar bound: [0.002979559042902571]
Threshold 0.1 SUFFICIENT with avar bound: 0.002979559042902571
Evaluating threshold 0.2 with avar bound: [0.002979559042902571]
Threshold 0.2 SUFFICIENT with avar bound: 0.002979559042902571
Evaluating threshold 0.3 with avar bound: [0.002979559042902571]
Threshold 0.3 SUFFICIENT with avar bound: 0.002979559042902571
Evaluating threshold 0.4 with avar bound: [0.002979559042902571]
Threshold 0.4 SUFFICIENT with avar bound: 0.002979559042902571
Evaluating threshold 0.5 with avar bound: [0.002979559042902571]
Threshold 0.5 SUFFICIENT with avar bound: 0.002979559042902571
Evaluating threshold 0.6 with avar bound: [0.002979559042902571]
Threshold 0.6 SUFFICIENT with avar bound: 0.002979559042902571
Evaluating threshold 0.7 with avar bound: [0.002979559042902571]
Threshold 0.7 SUFFICIENT with avar bound: 0.002979559042902571
Evaluating threshold 0.8 with avar bound: [0.002979559042902571]
Threshold 0.8 SUFFICIENT with avar bound: 0.002979559042902571
Evaluating threshold 0.9 with avar bound: [0.002979559042902571]
Threshold 0.9 SUFFICIENT with avar bound: 0.002979559042902571

Running BIRL with demonstration 8/10 in world 19
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 1)]
MCMC sampling complete.
Acceptance ratio: 0.191
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.58811707  0.20417575 -0.0099184  -0.27569344  0.51746699  0.05308142
  0.5154955 ]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: -0.005842
0.9-VaR bound for 8 demonstrations: -0.004111
0.95-VaR bound for 8 demonstrations: -0.001940
0.99-VaR bound for 8 demonstrations: 0.001235
True expected value difference for MAP policy: -0.020008
Evaluating threshold 0.1 with avar bound: [-0.0019401275401261643]
Threshold 0.1 SUFFICIENT with avar bound: -0.0019401275401261643
Evaluating threshold 0.2 with avar bound: [-0.0019401275401261643]
Threshold 0.2 SUFFICIENT with avar bound: -0.0019401275401261643
Evaluating threshold 0.3 with avar bound: [-0.0019401275401261643]
Threshold 0.3 SUFFICIENT with avar bound: -0.0019401275401261643
Evaluating threshold 0.4 with avar bound: [-0.0019401275401261643]
Threshold 0.4 SUFFICIENT with avar bound: -0.0019401275401261643
Evaluating threshold 0.5 with avar bound: [-0.0019401275401261643]
Threshold 0.5 SUFFICIENT with avar bound: -0.0019401275401261643
Evaluating threshold 0.6 with avar bound: [-0.0019401275401261643]
Threshold 0.6 SUFFICIENT with avar bound: -0.0019401275401261643
Evaluating threshold 0.7 with avar bound: [-0.0019401275401261643]
Threshold 0.7 SUFFICIENT with avar bound: -0.0019401275401261643
Evaluating threshold 0.8 with avar bound: [-0.0019401275401261643]
Threshold 0.8 SUFFICIENT with avar bound: -0.0019401275401261643
Evaluating threshold 0.9 with avar bound: [-0.0019401275401261643]
Threshold 0.9 SUFFICIENT with avar bound: -0.0019401275401261643

Running BIRL with demonstration 9/10 in world 19
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 1), (15, 1)]
MCMC sampling complete.
Acceptance ratio: 0.162
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.52761394 -0.39883857 -0.37734882 -0.40024257  0.1472942   0.03655322
  0.48675801]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.007311
0.9-VaR bound for 9 demonstrations: -0.006566
0.95-VaR bound for 9 demonstrations: -0.000943
0.99-VaR bound for 9 demonstrations: 0.005515
True expected value difference for MAP policy: -0.022727
Evaluating threshold 0.1 with avar bound: [-0.000942577393107414]
Threshold 0.1 SUFFICIENT with avar bound: -0.000942577393107414
Evaluating threshold 0.2 with avar bound: [-0.000942577393107414]
Threshold 0.2 SUFFICIENT with avar bound: -0.000942577393107414
Evaluating threshold 0.3 with avar bound: [-0.000942577393107414]
Threshold 0.3 SUFFICIENT with avar bound: -0.000942577393107414
Evaluating threshold 0.4 with avar bound: [-0.000942577393107414]
Threshold 0.4 SUFFICIENT with avar bound: -0.000942577393107414
Evaluating threshold 0.5 with avar bound: [-0.000942577393107414]
Threshold 0.5 SUFFICIENT with avar bound: -0.000942577393107414
Evaluating threshold 0.6 with avar bound: [-0.000942577393107414]
Threshold 0.6 SUFFICIENT with avar bound: -0.000942577393107414
Evaluating threshold 0.7 with avar bound: [-0.000942577393107414]
Threshold 0.7 SUFFICIENT with avar bound: -0.000942577393107414
Evaluating threshold 0.8 with avar bound: [-0.000942577393107414]
Threshold 0.8 SUFFICIENT with avar bound: -0.000942577393107414
Evaluating threshold 0.9 with avar bound: [-0.000942577393107414]
Threshold 0.9 SUFFICIENT with avar bound: -0.000942577393107414

Running BIRL with demonstration 10/10 in world 19
Current demos: [(16, 1), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 1), (10, 1), (15, 1), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.172
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.5940219   0.02167336 -0.05388012 -0.07054829  0.30017095  0.25095858
  0.69692561]
True Reward Weights: [-0.7117918  -0.03139834  0.02610432  0.05028028  0.11909836  0.18948209
  0.66262293]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.010825
0.9-VaR bound for 10 demonstrations: -0.009452
0.95-VaR bound for 10 demonstrations: -0.006204
0.99-VaR bound for 10 demonstrations: -0.004824
True expected value difference for MAP policy: -0.022330
Evaluating threshold 0.1 with avar bound: [-0.006204088749435524]
Threshold 0.1 SUFFICIENT with avar bound: -0.006204088749435524
Evaluating threshold 0.2 with avar bound: [-0.006204088749435524]
Threshold 0.2 SUFFICIENT with avar bound: -0.006204088749435524
Evaluating threshold 0.3 with avar bound: [-0.006204088749435524]
Threshold 0.3 SUFFICIENT with avar bound: -0.006204088749435524
Evaluating threshold 0.4 with avar bound: [-0.006204088749435524]
Threshold 0.4 SUFFICIENT with avar bound: -0.006204088749435524
Evaluating threshold 0.5 with avar bound: [-0.006204088749435524]
Threshold 0.5 SUFFICIENT with avar bound: -0.006204088749435524
Evaluating threshold 0.6 with avar bound: [-0.006204088749435524]
Threshold 0.6 SUFFICIENT with avar bound: -0.006204088749435524
Evaluating threshold 0.7 with avar bound: [-0.006204088749435524]
Threshold 0.7 SUFFICIENT with avar bound: -0.006204088749435524
Evaluating threshold 0.8 with avar bound: [-0.006204088749435524]
Threshold 0.8 SUFFICIENT with avar bound: -0.006204088749435524
Evaluating threshold 0.9 with avar bound: [-0.006204088749435524]
Threshold 0.9 SUFFICIENT with avar bound: -0.006204088749435524

Running world 20/20

Running BIRL with demonstration 1/10 in world 20
Current demos: [(16, 3)]
MCMC sampling complete.
Acceptance ratio: 0.523
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.40089131 -0.45257712 -0.47245766  0.61896542  0.11217514  0.04469763
  0.11638101]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 1 demonstrations: 2.701144
0.9-VaR bound for 1 demonstrations: 2.936606
0.95-VaR bound for 1 demonstrations: 4.371381
0.99-VaR bound for 1 demonstrations: 5.247918
True expected value difference for MAP policy: 2.079213
Evaluating threshold 0.1 with avar bound: [4.371381226201124]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [4.371381226201124]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [4.371381226201124]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [4.371381226201124]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [4.371381226201124]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [4.371381226201124]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [4.371381226201124]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [4.371381226201124]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [4.371381226201124]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 2/10 in world 20
Current demos: [(16, 3), (12, 3)]
MCMC sampling complete.
Acceptance ratio: 0.344
Using 700 samples after burn-in
MAP Solution Reward Weights: [ 0.10696869 -0.088607   -0.35456986  0.82486463  0.25742385 -0.10451848
 -0.31207996]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 2 demonstrations: 2.422555
0.9-VaR bound for 2 demonstrations: 2.776435
0.95-VaR bound for 2 demonstrations: 3.483916
0.99-VaR bound for 2 demonstrations: 5.636079
True expected value difference for MAP policy: 2.082685
Evaluating threshold 0.1 with avar bound: [3.4839157933189906]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [3.4839157933189906]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [3.4839157933189906]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [3.4839157933189906]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [3.4839157933189906]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [3.4839157933189906]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [3.4839157933189906]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [3.4839157933189906]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [3.4839157933189906]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 3/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1)]
MCMC sampling complete.
Acceptance ratio: 0.291
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.01772335 -0.06818005 -0.32809366  0.80535019 -0.47207761  0.12618013
 -0.00492732]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 3 demonstrations: 1.614470
0.9-VaR bound for 3 demonstrations: 1.852398
0.95-VaR bound for 3 demonstrations: 2.234375
0.99-VaR bound for 3 demonstrations: 3.910693
True expected value difference for MAP policy: 2.284785
Evaluating threshold 0.1 with avar bound: [2.234374643424305]
Threshold 0.1 INSUFFICIENT
Evaluating threshold 0.2 with avar bound: [2.234374643424305]
Threshold 0.2 INSUFFICIENT
Evaluating threshold 0.3 with avar bound: [2.234374643424305]
Threshold 0.3 INSUFFICIENT
Evaluating threshold 0.4 with avar bound: [2.234374643424305]
Threshold 0.4 INSUFFICIENT
Evaluating threshold 0.5 with avar bound: [2.234374643424305]
Threshold 0.5 INSUFFICIENT
Evaluating threshold 0.6 with avar bound: [2.234374643424305]
Threshold 0.6 INSUFFICIENT
Evaluating threshold 0.7 with avar bound: [2.234374643424305]
Threshold 0.7 INSUFFICIENT
Evaluating threshold 0.8 with avar bound: [2.234374643424305]
Threshold 0.8 INSUFFICIENT
Evaluating threshold 0.9 with avar bound: [2.234374643424305]
Threshold 0.9 INSUFFICIENT

Running BIRL with demonstration 4/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1)]
MCMC sampling complete.
Acceptance ratio: 0.221
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.2892811   0.14225743 -0.64101356  0.03632313 -0.24423581  0.09187968
  0.64480114]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 4 demonstrations: -0.004911
0.9-VaR bound for 4 demonstrations: -0.000391
0.95-VaR bound for 4 demonstrations: 0.007765
0.99-VaR bound for 4 demonstrations: 0.026205
True expected value difference for MAP policy: 0.006081
Evaluating threshold 0.1 with avar bound: [0.007765406391288203]
Threshold 0.1 SUFFICIENT with avar bound: 0.007765406391288203
Evaluating threshold 0.2 with avar bound: [0.007765406391288203]
Threshold 0.2 SUFFICIENT with avar bound: 0.007765406391288203
Evaluating threshold 0.3 with avar bound: [0.007765406391288203]
Threshold 0.3 SUFFICIENT with avar bound: 0.007765406391288203
Evaluating threshold 0.4 with avar bound: [0.007765406391288203]
Threshold 0.4 SUFFICIENT with avar bound: 0.007765406391288203
Evaluating threshold 0.5 with avar bound: [0.007765406391288203]
Threshold 0.5 SUFFICIENT with avar bound: 0.007765406391288203
Evaluating threshold 0.6 with avar bound: [0.007765406391288203]
Threshold 0.6 SUFFICIENT with avar bound: 0.007765406391288203
Evaluating threshold 0.7 with avar bound: [0.007765406391288203]
Threshold 0.7 SUFFICIENT with avar bound: 0.007765406391288203
Evaluating threshold 0.8 with avar bound: [0.007765406391288203]
Threshold 0.8 SUFFICIENT with avar bound: 0.007765406391288203
Evaluating threshold 0.9 with avar bound: [0.007765406391288203]
Threshold 0.9 SUFFICIENT with avar bound: 0.007765406391288203

Running BIRL with demonstration 5/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3)]
MCMC sampling complete.
Acceptance ratio: 0.231
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.41671007 -0.1162036  -0.59290536  0.04862398 -0.04450599  0.17489274
  0.65297789]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 5 demonstrations: 0.004793
0.9-VaR bound for 5 demonstrations: 0.010925
0.95-VaR bound for 5 demonstrations: 0.021193
0.99-VaR bound for 5 demonstrations: 0.030005
True expected value difference for MAP policy: -0.010267
Evaluating threshold 0.1 with avar bound: [0.021192891656748036]
Threshold 0.1 SUFFICIENT with avar bound: 0.021192891656748036
Evaluating threshold 0.2 with avar bound: [0.021192891656748036]
Threshold 0.2 SUFFICIENT with avar bound: 0.021192891656748036
Evaluating threshold 0.3 with avar bound: [0.021192891656748036]
Threshold 0.3 SUFFICIENT with avar bound: 0.021192891656748036
Evaluating threshold 0.4 with avar bound: [0.021192891656748036]
Threshold 0.4 SUFFICIENT with avar bound: 0.021192891656748036
Evaluating threshold 0.5 with avar bound: [0.021192891656748036]
Threshold 0.5 SUFFICIENT with avar bound: 0.021192891656748036
Evaluating threshold 0.6 with avar bound: [0.021192891656748036]
Threshold 0.6 SUFFICIENT with avar bound: 0.021192891656748036
Evaluating threshold 0.7 with avar bound: [0.021192891656748036]
Threshold 0.7 SUFFICIENT with avar bound: 0.021192891656748036
Evaluating threshold 0.8 with avar bound: [0.021192891656748036]
Threshold 0.8 SUFFICIENT with avar bound: 0.021192891656748036
Evaluating threshold 0.9 with avar bound: [0.021192891656748036]
Threshold 0.9 SUFFICIENT with avar bound: 0.021192891656748036

Running BIRL with demonstration 6/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3)]
MCMC sampling complete.
Acceptance ratio: 0.218
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.14572581  0.21852431 -0.69631194  0.07479261 -0.06786995  0.36710698
  0.54881053]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 6 demonstrations: -0.001697
0.9-VaR bound for 6 demonstrations: 0.001064
0.95-VaR bound for 6 demonstrations: 0.003263
0.99-VaR bound for 6 demonstrations: 0.012097
True expected value difference for MAP policy: 0.006081
Evaluating threshold 0.1 with avar bound: [0.003263373647249742]
Threshold 0.1 SUFFICIENT with avar bound: 0.003263373647249742
Evaluating threshold 0.2 with avar bound: [0.003263373647249742]
Threshold 0.2 SUFFICIENT with avar bound: 0.003263373647249742
Evaluating threshold 0.3 with avar bound: [0.003263373647249742]
Threshold 0.3 SUFFICIENT with avar bound: 0.003263373647249742
Evaluating threshold 0.4 with avar bound: [0.003263373647249742]
Threshold 0.4 SUFFICIENT with avar bound: 0.003263373647249742
Evaluating threshold 0.5 with avar bound: [0.003263373647249742]
Threshold 0.5 SUFFICIENT with avar bound: 0.003263373647249742
Evaluating threshold 0.6 with avar bound: [0.003263373647249742]
Threshold 0.6 SUFFICIENT with avar bound: 0.003263373647249742
Evaluating threshold 0.7 with avar bound: [0.003263373647249742]
Threshold 0.7 SUFFICIENT with avar bound: 0.003263373647249742
Evaluating threshold 0.8 with avar bound: [0.003263373647249742]
Threshold 0.8 SUFFICIENT with avar bound: 0.003263373647249742
Evaluating threshold 0.9 with avar bound: [0.003263373647249742]
Threshold 0.9 SUFFICIENT with avar bound: 0.003263373647249742

Running BIRL with demonstration 7/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.22426598  0.00420119 -0.52357526  0.2815993   0.20229921 -0.0868267
  0.74013111]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 7 demonstrations: 0.008212
0.9-VaR bound for 7 demonstrations: 0.019094
0.95-VaR bound for 7 demonstrations: 0.027927
0.99-VaR bound for 7 demonstrations: 0.046698
True expected value difference for MAP policy: -0.009142
Evaluating threshold 0.1 with avar bound: [0.027926731549216495]
Threshold 0.1 SUFFICIENT with avar bound: 0.027926731549216495
Evaluating threshold 0.2 with avar bound: [0.027926731549216495]
Threshold 0.2 SUFFICIENT with avar bound: 0.027926731549216495
Evaluating threshold 0.3 with avar bound: [0.027926731549216495]
Threshold 0.3 SUFFICIENT with avar bound: 0.027926731549216495
Evaluating threshold 0.4 with avar bound: [0.027926731549216495]
Threshold 0.4 SUFFICIENT with avar bound: 0.027926731549216495
Evaluating threshold 0.5 with avar bound: [0.027926731549216495]
Threshold 0.5 SUFFICIENT with avar bound: 0.027926731549216495
Evaluating threshold 0.6 with avar bound: [0.027926731549216495]
Threshold 0.6 SUFFICIENT with avar bound: 0.027926731549216495
Evaluating threshold 0.7 with avar bound: [0.027926731549216495]
Threshold 0.7 SUFFICIENT with avar bound: 0.027926731549216495
Evaluating threshold 0.8 with avar bound: [0.027926731549216495]
Threshold 0.8 SUFFICIENT with avar bound: 0.027926731549216495
Evaluating threshold 0.9 with avar bound: [0.027926731549216495]
Threshold 0.9 SUFFICIENT with avar bound: 0.027926731549216495

Running BIRL with demonstration 8/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3)]
MCMC sampling complete.
Acceptance ratio: 0.199
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.23602223 -0.0553805  -0.49497132  0.15031677  0.26376377 -0.06966142
  0.77408703]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 8 demonstrations: 0.003037
0.9-VaR bound for 8 demonstrations: 0.006563
0.95-VaR bound for 8 demonstrations: 0.013447
0.99-VaR bound for 8 demonstrations: 0.029656
True expected value difference for MAP policy: -0.010267
Evaluating threshold 0.1 with avar bound: [0.01344689878166908]
Threshold 0.1 SUFFICIENT with avar bound: 0.01344689878166908
Evaluating threshold 0.2 with avar bound: [0.01344689878166908]
Threshold 0.2 SUFFICIENT with avar bound: 0.01344689878166908
Evaluating threshold 0.3 with avar bound: [0.01344689878166908]
Threshold 0.3 SUFFICIENT with avar bound: 0.01344689878166908
Evaluating threshold 0.4 with avar bound: [0.01344689878166908]
Threshold 0.4 SUFFICIENT with avar bound: 0.01344689878166908
Evaluating threshold 0.5 with avar bound: [0.01344689878166908]
Threshold 0.5 SUFFICIENT with avar bound: 0.01344689878166908
Evaluating threshold 0.6 with avar bound: [0.01344689878166908]
Threshold 0.6 SUFFICIENT with avar bound: 0.01344689878166908
Evaluating threshold 0.7 with avar bound: [0.01344689878166908]
Threshold 0.7 SUFFICIENT with avar bound: 0.01344689878166908
Evaluating threshold 0.8 with avar bound: [0.01344689878166908]
Threshold 0.8 SUFFICIENT with avar bound: 0.01344689878166908
Evaluating threshold 0.9 with avar bound: [0.01344689878166908]
Threshold 0.9 SUFFICIENT with avar bound: 0.01344689878166908

Running BIRL with demonstration 9/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3)]
MCMC sampling complete.
Acceptance ratio: 0.196
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.33767353  0.02286887 -0.35297786  0.26867172  0.19072643  0.06023169
  0.80540134]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 9 demonstrations: -0.008207
0.9-VaR bound for 9 demonstrations: -0.004595
0.95-VaR bound for 9 demonstrations: 0.000736
0.99-VaR bound for 9 demonstrations: 0.022868
True expected value difference for MAP policy: -0.009142
Evaluating threshold 0.1 with avar bound: [0.0007357668199707468]
Threshold 0.1 SUFFICIENT with avar bound: 0.0007357668199707468
Evaluating threshold 0.2 with avar bound: [0.0007357668199707468]
Threshold 0.2 SUFFICIENT with avar bound: 0.0007357668199707468
Evaluating threshold 0.3 with avar bound: [0.0007357668199707468]
Threshold 0.3 SUFFICIENT with avar bound: 0.0007357668199707468
Evaluating threshold 0.4 with avar bound: [0.0007357668199707468]
Threshold 0.4 SUFFICIENT with avar bound: 0.0007357668199707468
Evaluating threshold 0.5 with avar bound: [0.0007357668199707468]
Threshold 0.5 SUFFICIENT with avar bound: 0.0007357668199707468
Evaluating threshold 0.6 with avar bound: [0.0007357668199707468]
Threshold 0.6 SUFFICIENT with avar bound: 0.0007357668199707468
Evaluating threshold 0.7 with avar bound: [0.0007357668199707468]
Threshold 0.7 SUFFICIENT with avar bound: 0.0007357668199707468
Evaluating threshold 0.8 with avar bound: [0.0007357668199707468]
Threshold 0.8 SUFFICIENT with avar bound: 0.0007357668199707468
Evaluating threshold 0.9 with avar bound: [0.0007357668199707468]
Threshold 0.9 SUFFICIENT with avar bound: 0.0007357668199707468

Running BIRL with demonstration 10/10 in world 20
Current demos: [(16, 3), (12, 3), (9, 1), (19, 1), (18, 3), (6, 3), (5, 3), (10, 3), (15, 3), (21, 3)]
MCMC sampling complete.
Acceptance ratio: 0.193
Using 700 samples after burn-in
MAP Solution Reward Weights: [-0.3086302  -0.11862544 -0.41266711  0.32540683  0.18717754 -0.29961954
  0.69977451]
True Reward Weights: [-0.6159758  -0.47893476 -0.4336164  -0.31858011 -0.04655113  0.11845331
  0.29237074]
Visualizing the learned policy:
0.85-VaR bound for 10 demonstrations: -0.006318
0.9-VaR bound for 10 demonstrations: -0.001502
0.95-VaR bound for 10 demonstrations: 0.009385
0.99-VaR bound for 10 demonstrations: 0.015876
True expected value difference for MAP policy: -0.009142
Evaluating threshold 0.1 with avar bound: [0.009384904353468075]
Threshold 0.1 SUFFICIENT with avar bound: 0.009384904353468075
Evaluating threshold 0.2 with avar bound: [0.009384904353468075]
Threshold 0.2 SUFFICIENT with avar bound: 0.009384904353468075
Evaluating threshold 0.3 with avar bound: [0.009384904353468075]
Threshold 0.3 SUFFICIENT with avar bound: 0.009384904353468075
Evaluating threshold 0.4 with avar bound: [0.009384904353468075]
Threshold 0.4 SUFFICIENT with avar bound: 0.009384904353468075
Evaluating threshold 0.5 with avar bound: [0.009384904353468075]
Threshold 0.5 SUFFICIENT with avar bound: 0.009384904353468075
Evaluating threshold 0.6 with avar bound: [0.009384904353468075]
Threshold 0.6 SUFFICIENT with avar bound: 0.009384904353468075
Evaluating threshold 0.7 with avar bound: [0.009384904353468075]
Threshold 0.7 SUFFICIENT with avar bound: 0.009384904353468075
Evaluating threshold 0.8 with avar bound: [0.009384904353468075]
Threshold 0.8 SUFFICIENT with avar bound: 0.009384904353468075
Evaluating threshold 0.9 with avar bound: [0.009384904353468075]
Threshold 0.9 SUFFICIENT with avar bound: 0.009384904353468075

Saving results to files...
Results saved successfully.
