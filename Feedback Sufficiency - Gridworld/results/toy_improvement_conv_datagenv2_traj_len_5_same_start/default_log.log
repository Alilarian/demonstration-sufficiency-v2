Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 2), (0, 0), (0, 2)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 3), (0, 1), (3, 2), (3, 2), (3, 1)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (2, 0), (2, 0), (2, 0)]), ([(0, 1), (0, 1), (3, 3), (3, 3), (0, 1)], [(0, 2), (0, 3), (1, 2), (0, 2), (0, 1)]), ([(0, 3), (1, 3), (2, 2), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 2), (1, 0), (1, 0)]), ([(0, 1), (3, 3), (4, 1), (4, 3), (5, None)], [(0, 1), (3, 3), (4, 1), (4, 1), (4, 2)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6420
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.44885362 -0.89291393  0.03514455]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.45269653 -0.87414577 -0.17588355]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5882
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.87907016 -0.45810682  0.13180968]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.1836
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.64524433 -0.30126124  0.70206939]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.1868
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.77984984 -0.26820007  0.56559963]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.1812
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.88536798 -0.30293076  0.35264216]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 3), (0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 1), (3, 1), (3, 3), (4, 0)]), ([(0, 2), (0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 1), (3, 2), (3, 1)]), ([(0, 0), (0, 1), (3, 3), (0, 1), (1, 1)], [(0, 0), (0, 2), (0, 3), (3, 2), (3, 1)]), ([(0, 0), (0, 2), (0, 1), (3, 3), (4, 3)], [(0, 0), (0, 2), (0, 2), (0, 2), (0, 3)]), ([], [(0, 1), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 1), (4, 3), (1, 1)], [(0, 1), (3, 3), (4, 1), (4, 0), (1, 1)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6572
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.1150909  0.58583074 0.80221969]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6594
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.24156243  0.90532232  0.34934093]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.4446
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.03223784 -0.75799703  0.65146084]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.4450
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.51374384 0.1278492  0.84836422]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2648
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.06530467 -0.80370377  0.59143516]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2726
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.45844896 -0.70614647  0.53961256]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 1), (1, 2), (4, 2)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 1), (3, 3), (4, 3), (4, 0), (5, None)]), ([(0, 3), (3, 2), (3, 2), (0, 1), (3, 3)], [(0, 3), (3, 2), (3, 2), (0, 0), (0, 2)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 3), (1, 0), (0, 1)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (0, 1)], [(0, 3), (3, 1), (3, 3), (4, 2), (3, 1)]), ([(0, 3), (0, 1), (1, 1), (0, 1), (3, 3)], [(0, 3), (0, 1), (1, 2), (0, 0), (0, 3)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6574
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98374921 -0.16883412 -0.06109451]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6664
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.45567457 0.09866134 0.88466187]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6724
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.50259827  0.45574705  0.7346357 ]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6042
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.37063677  0.51146138  0.77526488]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.41527577  0.51072289  0.75280022]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5784
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.57202338  0.51157501  0.64115542]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running experiment 4/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (1, 1), (4, 3), (5, None)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 2), (0, 3), (1, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 0), (0, 3), (3, 0)]), ([(0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 0), (0, 3), (1, 3)]), ([(0, 1), (3, 1), (3, 0), (0, 1), (3, 3)], [(0, 1), (3, 1), (3, 0), (0, 3), (0, 3)]), ([(0, 2), (3, 3), (4, 3), (1, 1), (4, 3)], [(0, 2), (3, 0), (0, 1), (3, 3), (4, 3)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6684
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.5114317   0.71777273 -0.47248273]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5264
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.65620825  0.71950948 -0.2273694 ]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2892
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.50904643  0.02729526  0.86030617]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2742
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.78838417 -0.2862788   0.54451341]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2732
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.68124069  0.12690085  0.72097663]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.0170
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.22348683 0.22370512 0.94868839]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 0), (3, 0), (0, 2)]), ([(0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 0), (0, 3), (1, 1)]), ([(0, 1), (3, 3), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 1), (3, 3), (0, 0), (0, 0), (0, 1)]), ([(0, 1), (3, 0), (0, 0), (0, 1), (3, 3)], [(0, 1), (3, 0), (0, 0), (0, 3), (1, 1)]), ([(0, 2), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 2), (0, 2), (0, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 0), (0, 2), (0, 2)])]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6544
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.4841405  -0.87461855  0.02550219]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5336
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.4856682   0.07251796  0.87113004]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.4394
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.31087071 -0.08947071  0.94623168]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2046
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.12255247  0.43605748  0.89153506]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2048
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.06276529 0.52060403 0.85148809]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2054
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.26889932  0.30917948  0.91219582]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running experiment 6/50...
Shuffled Demos: [([(0, 0), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 1), (4, 0), (1, 3)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 1), (0, 0), (0, 2)]), ([(0, 2), (3, 1), (3, 1), (3, 3), (3, 3)], [(0, 2), (3, 1), (3, 1), (3, 0), (0, 0)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 2), (0, 0), (0, 0)]), ([(0, 0), (0, 3), (1, 2), (0, 1), (0, 1)], [(0, 0), (0, 3), (1, 2), (0, 2), (0, 1)]), ([(0, 0), (0, 3), (1, 2), (0, 1), (3, 3)], [(0, 0), (0, 3), (1, 2), (0, 2), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6654
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98293201 -0.18364233  0.0109616 ]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.4294
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.41466039 -0.60633035  0.67854275]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.4496
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.0032824   0.12675532  0.99192858]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.4496
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.46172572 -0.05111529  0.88554875]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.4458
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.01570478 0.03955833 0.99909384]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.4468
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.04709484 -0.03778619  0.99817548]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [([(0, 1), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 0), (0, 0), (0, 3), (1, 0), (0, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 3), (1, 0), (1, 2)]), ([(0, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 2), (0, 2), (3, 2)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 3), (1, 1), (4, 1)]), ([(0, 0), (0, 0), (0, 2), (0, 1), (3, 3)], [(0, 0), (0, 0), (0, 2), (0, 2), (0, 1)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (4, 0), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.35550036 0.92518771 0.13284272]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6566
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.70261024 -0.59251147  0.3940419 ]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.0622143  0.68857731 0.72248922]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5218
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.14991364 -0.71692352  0.68084254]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5210
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.05442011 0.80871778 0.58567398]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.10595925 -0.69127079  0.71478482]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running experiment 8/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 0), (0, 0), (0, 0), (0, 2), (0, 3)]), ([(0, 2), (0, 3), (1, 0), (1, 1), (4, 3)], [(0, 2), (0, 3), (1, 0), (1, 3), (4, 1)]), ([(0, 0), (0, 2), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 3), (1, 0), (1, 1)]), ([(0, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 2), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 3), (2, 2), (1, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 1), (3, 2), (0, 2)])]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6576
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.55982628 -0.75599071 -0.33922351]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6542
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.95039506 -0.20772782  0.23151325]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.37608821 -0.03819164  0.92579644]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2076
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.27682543 -0.10897882  0.95472053]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.1248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.2278931  -0.08977148  0.96953897]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.1146
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.21258092 -0.10777896  0.97118127]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 0), (0, 3), (1, 0)]), ([(0, 3), (1, 2), (1, 0), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 2), (1, 0), (1, 2), (0, 0)]), ([(0, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 1), (3, 0), (0, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 1), (3, 2), (3, 1)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 0), (0, 1), (3, 1)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (0, 1), (3, 0), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6668
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.71327915 -0.69882359  0.05365114]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5774
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.87100215  0.31704636  0.37528237]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5582
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.50994552 -0.39327704  0.76504166]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.4624
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.02228631 -0.73207761  0.68085658]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.4450
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.27899528 -0.44291354  0.85205002]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.4390
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.03045201 -0.17480492  0.98413206]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running experiment 10/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 3), (1, 1), (4, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 3), (2, 3), (2, 3)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (3, 3)], [(0, 2), (0, 2), (0, 0), (0, 3), (1, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (3, 3), (4, 2), (3, 3), (4, 3)]), ([(0, 2), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 3), (2, 2), (2, 2)]), ([(0, 0), (0, 1), (1, 1), (0, 1), (3, 3)], [(0, 0), (0, 1), (1, 0), (1, 1), (0, 2)])]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6612
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.685573   -0.70984877 -0.16156848]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6168
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.65795536 -0.41962876  0.62530509]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5342
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.48026576  0.62165981  0.61877611]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2844
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.85300904 -0.03549114  0.52068797]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.89716117 -0.35520298  0.26255034]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2700
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.94885308 -0.19506198  0.24825119]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 0), (2, 1), (5, None)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (0, 1), (3, 1), (3, 3), (0, 3)]), ([(0, 3), (1, 1), (2, 1), (2, 1), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 0), (0, 2), (0, 0)]), ([(0, 0), (0, 0), (0, 1), (3, 3), (3, 3)], [(0, 0), (0, 0), (0, 1), (3, 1), (3, 2)]), ([(0, 1), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (0, 2), (0, 0), (0, 0), (0, 2)])]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6540
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.84447259  0.46679868  0.26261196]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.3258
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.80933298 -0.01114464  0.58724434]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2148
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.05990935 0.49189415 0.8685914 ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.1244
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.06077759  0.31426163  0.94738889]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.1282
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.10553759  0.30803949  0.94550171]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.1286
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.00833718  0.30893234  0.95104748]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running experiment 12/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 0), (0, 3), (1, 1)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 0), (0, 1), (3, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 0), (0, 1), (3, 2)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 1), (4, 0), (5, None)]), ([(0, 1), (3, 3), (4, 2), (3, 3), (3, 3)], [(0, 1), (3, 3), (4, 2), (3, 1), (4, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 3), (2, 0), (2, 2)])]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6532
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.34776287 -0.12180549  0.92963671]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.09835557 -0.92792962 -0.35954528]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5508
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.30893356 -0.92398237 -0.22542544]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.1494
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.03706759 0.31386614 0.9487434 ]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.1496
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.00610154  0.31391694  0.94943084]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.1470
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.16117732 0.30861078 0.93743333]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [([(0, 3), (1, 3), (2, 1), (5, None)], [(0, 3), (1, 3), (2, 0), (1, 3), (2, 1)]), ([(0, 3), (3, 3), (4, 3), (5, None)], [(0, 3), (3, 2), (0, 3), (1, 0), (1, 0)]), ([(0, 2), (0, 2), (0, 1), (3, 3), (3, 3)], [(0, 2), (0, 2), (0, 0), (1, 0), (1, 0)]), ([(0, 2), (0, 2), (0, 1), (3, 3), (0, 1)], [(0, 2), (0, 2), (0, 3), (1, 2), (1, 2)]), ([(0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 2), (0, 2), (0, 0)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 0), (0, 3), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6532
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94075996  0.2888432   0.1775959 ]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5782
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.94484531 -0.31380176  0.09378592]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.4536
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.46208537  0.46957747  0.75231251]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.4482
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.95332694 -0.29550709 -0.06199432]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3598
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.43243468  0.40681051  0.80467724]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3112
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.09495315 0.3481286  0.93262553]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running experiment 14/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 2), (3, 3), (4, 1)]), ([(0, 3), (0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 3), (0, 1), (3, 0), (4, 0), (3, 3)]), ([(0, 0), (0, 1), (0, 1), (3, 3), (3, 3)], [(0, 0), (0, 1), (0, 3), (1, 1), (4, 2)]), ([(0, 3), (1, 1), (4, 3), (1, 1)], [(0, 3), (1, 3), (2, 3), (5, None)]), ([(0, 1), (1, 1), (4, 0), (1, 1), (4, 3), (5, None)], [(0, 1), (1, 1), (4, 0), (1, 2), (0, 3)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 3), (4, 2), (1, 1)])]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6548
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.15812645 -0.91785563  0.36405642]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5592
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.09870225 -0.08258673  0.99168407]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.3192
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.84070478 -0.23378716  0.48842506]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.0014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.58693941 0.57372007 0.57126824]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.0020
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.59058266 0.57432357 0.56689026]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.0034
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.56684541 0.58089801 0.58416075]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 1), (1, 0), (1, 1)]), ([(0, 2), (0, 2), (0, 0), (0, 1), (3, 3)], [(0, 2), (0, 2), (0, 0), (0, 2), (3, 0)]), ([(0, 0), (0, 0), (1, 2), (4, 3), (5, None)], [(0, 0), (0, 0), (1, 2), (4, 1), (4, 3)]), ([(0, 3), (1, 1), (0, 0), (0, 1), (3, 3)], [(0, 3), (1, 1), (0, 0), (0, 3), (1, 3)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 1), (4, 2), (3, 1)]), ([(0, 2), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (3, 3), (4, 0), (1, 2), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6456
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.63226471  0.77473674 -0.00493084]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6506
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.52236743  0.51164528 -0.68216667]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.4416
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.05009472 0.25517414 0.96559654]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.3304
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.52151459  0.12741791  0.84367482]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.3108
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.04801095  0.51160187  0.85788022]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.3176
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.42238143  0.12791745  0.89734667]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running experiment 16/50...
Shuffled Demos: [([(0, 0), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 1), (4, 0), (1, 2)]), ([(0, 1), (3, 3), (4, 3), (4, 3)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 2), (0, 1), (3, 1)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 1), (3, 0), (4, 0), (1, 3)]), ([(0, 2), (0, 1), (0, 1), (3, 3), (4, 3)], [(0, 2), (0, 2), (0, 0), (0, 3), (1, 2)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 3), (3, 1), (3, 1), (3, 1), (3, 3)])]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6578
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.27738928 -0.94412943  0.17797415]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.4350
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.64116678  0.72139288  0.26172023]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.1532
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93839003 -0.12190271  0.32336338]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.1362
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.92570385 -0.35936173 -0.11803186]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.1344
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.94829138 -0.08690996  0.30527055]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.0350
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.90481523 -0.40852155 -0.12008138]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (1, 1)], [(0, 1), (3, 3), (4, 1), (5, None)]), ([(0, 1), (0, 2), (0, 2), (0, 1), (1, 1)], [(0, 1), (0, 2), (0, 2), (0, 0), (0, 0)]), ([(0, 1), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 2), (0, 1), (3, 2)]), ([(0, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 0), (0, 2), (0, 1)]), ([(0, 1), (3, 2), (3, 2), (0, 1), (3, 3)], [(0, 1), (3, 2), (3, 2), (0, 0), (0, 3)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 2), (1, 3), (2, 0)])]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6642
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.84844938 -0.48203547 -0.21857596]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5334
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.95818971  0.14578127 -0.24621192]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.0572
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.72364784 0.49461545 0.48134121]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.0590
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.73529807 0.47123368 0.4871094 ]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.0514
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.73284566 0.46064014 0.50074734]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.0250
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.68352512 0.52671223 0.50533913]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running experiment 18/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 0), (0, 3), (1, 1)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 0), (0, 0), (0, 0)]), ([(0, 1), (3, 2), (3, 1), (3, 3), (3, 3)], [(0, 1), (3, 2), (3, 1), (3, 0), (0, 0)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 2), (4, 2), (3, 2), (3, 1)]), ([(0, 1), (3, 3), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 3), (3, 1), (3, 3), (4, 3)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 0), (0, 3), (1, 2)])]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6582
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.22587749 -0.6357307   0.73812319]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5340
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.78676283 -0.00584826  0.61722771]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5344
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.75134567  0.04018734  0.65868404]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.4842
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.44946443 0.0549667  0.89160551]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.4584
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.03203867  0.25566657  0.96623399]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.4534
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.29547514  0.05497555  0.95376733]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [([(0, 3), (3, 3), (4, 3), (5, None)], [(0, 3), (3, 0), (0, 3), (1, 0), (0, 1)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (1, 2), (0, 2), (0, 0)]), ([(0, 3), (1, 1), (2, 1), (5, None)], [(0, 3), (1, 2), (4, 3), (5, None)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 1), (3, 3), (4, 2)]), ([(0, 0), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 2), (0, 2), (0, 0)]), ([(0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 1), (3, 2), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6546
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.25916422 -0.95956778 -0.10983431]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5766
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.62419868 -0.68836098  0.36950665]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5746
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.07215557 -0.20519928  0.97605678]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5232
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.34032947 -0.00155726  0.94030496]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.18662965 0.05508264 0.98088494]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5174
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.35924662  0.3959698   0.84507383]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running experiment 20/50...
Shuffled Demos: [([(0, 2), (0, 2), (0, 0), (1, 1), (2, 1), (5, None)], [(0, 2), (0, 2), (0, 0), (1, 3), (2, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (3, 3), (4, 2), (3, 2), (3, 2)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 0), (2, 0), (2, 2)]), ([(0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 2), (3, 1), (3, 3), (3, 0), (0, 0)]), ([(0, 1), (3, 3), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 1), (3, 3), (4, 2)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 0), (0, 3), (1, 2), (0, 3), (1, 2)])]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6626
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.57919497 -0.63346987  0.51307807]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5230
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.73537645 -0.36617824  0.57020608]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.3778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.17440334 -0.54564831  0.81966542]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.3856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.8667979  -0.10448113  0.48759111]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.3222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.24767465 0.1517118  0.95689121]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.1680
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.25851693  0.10418953  0.96037156]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 1), (3, 2), (3, 2)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 1), (4, 2)]), ([(0, 1), (1, 1), (4, 3), (4, 3), (5, None)], [(0, 1), (1, 3), (2, 0), (2, 0)]), ([(0, 1), (1, 1), (0, 1), (3, 3)], [(0, 2), (0, 3), (1, 2), (0, 2)]), ([(0, 0), (0, 1), (0, 1), (3, 3)], [(0, 0), (0, 0), (0, 3), (1, 3)]), ([(0, 2), (0, 1), (3, 3), (3, 3)], [(0, 2), (0, 0), (0, 0), (0, 1)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6440
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.20083681 -0.96721412  0.15543944]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6692
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.52309072 -0.8191452   0.23532368]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5678
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.90613584 -0.20860192  0.36797158]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5680
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.31444782 -0.8136788   0.48892675]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.3022
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.85721113 -0.29122156  0.42471059]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.3144
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.79697003 -0.45445881  0.39787682]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (3, 3), (0, 1)], [(0, 1), (3, 0), (0, 1), (1, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 0), (0, 0)]), ([(0, 2), (0, 1), (0, 1), (3, 3)], [(0, 2), (0, 3), (3, 0), (0, 0)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 1), (3, 2)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 1), (3, 1)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6664
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.92653844  0.37240154  0.0533255 ]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.3256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.52133959 -0.17347575  0.83553049]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.3268
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.88250014  0.04840269  0.4678148 ]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2652
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.52655767  0.15939778  0.8350625 ]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2692
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.55572582  0.31836408  0.76799292]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2738
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.57075062  0.31874407  0.75673374]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 1), (4, 1)]), ([(0, 1), (3, 3), (3, 3), (4, 3)], [(0, 1), (3, 3), (3, 1), (3, 0)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 2), (3, 3), (4, 3), (5, None)], [(0, 2), (3, 2), (3, 3), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 0), (4, 3)]), ([(0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 3), (1, 3)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6600
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94272706  0.29589535  0.15398583]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6664
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.74869913  0.63840834  0.17856206]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6602
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.87707936  0.31828759  0.3597566 ]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5378
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.71114047  0.15834125  0.68498706]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.33348374  0.01510341  0.94263486]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.4426
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.13081621  0.31896761  0.93869419]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running experiment 4/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 1), (0, 1)], [(0, 0), (0, 0), (0, 3), (1, 1)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 1), (3, 3), (4, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 3), (4, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 3), (4, 1)]), ([(0, 3), (0, 1), (0, 1), (3, 3)], [(0, 3), (0, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 2), (0, 3)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6588
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.90192405 -0.40348842 -0.1540458 ]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4412
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.63380851 -0.26747458  0.7257714 ]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.3014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.80081632  0.05977898  0.5959192 ]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.3258
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.80306917  0.12128129  0.58341303]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.3190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.90101727  0.06205023  0.42932232]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.3046
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.59167485  0.31970955  0.74007207]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 2), (3, 1)]), ([(0, 3), (1, 2), (0, 1), (3, 3)], [(0, 3), (1, 2), (0, 3), (0, 3)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 0), (0, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (4, 0)]), ([(0, 3), (0, 1), (3, 3), (4, 3)], [(0, 3), (0, 2), (0, 0), (0, 1)]), ([(0, 2), (0, 3), (1, 1), (4, 3)], [(0, 2), (0, 3), (1, 2), (0, 2)])]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6478
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.51917173  0.2558798   0.81546689]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6642
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.01230638  0.8572991   0.51467155]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6496
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.82224612 0.15086668 0.54877187]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5714
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.78484614 0.16294636 0.59788378]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5574
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.17245583 0.31903818 0.93191932]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5638
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.51955367 -0.07854732  0.85081978]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running experiment 6/50...
Shuffled Demos: [([(0, 0), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 1), (4, 1)]), ([(0, 3), (1, 3), (2, 1), (5, None)], [(0, 3), (1, 3), (2, 3), (2, 1)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 0), (2, 1)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 0), (0, 0)]), ([(0, 2), (0, 1), (3, 3), (4, 3)], [(0, 2), (0, 3), (1, 1), (4, 2)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 2), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6636
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.28578589 0.61546139 0.73452958]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5704
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.51032657 -0.3472194   0.78676901]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.4844
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.42184065  0.28332101  0.86126632]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.4952
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.56998058  0.08232902  0.81752313]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.3162
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.79574562 -0.40058683  0.45422361]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.3080
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.58411687 -0.16407733  0.79491264]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [([(0, 1), (0, 1), (0, 1), (0, 1)], [(0, 3), (1, 3), (1, 1), (4, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 2), (0, 2)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 0), (4, 1)]), ([(0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 2), (3, 1), (3, 2), (3, 1)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 2), (0, 3)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 3), (4, 0)])]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6648
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.59386652 -0.35983215  0.71961335]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.3316
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.58552688  0.05505577  0.80878126]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.3118
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.14535976  0.14300026  0.97899002]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.3092
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.11241126  0.28321733  0.95244509]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.3134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.75943885 -0.35339736  0.54622608]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.3090
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.90296369 -0.04315138  0.42754477]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running experiment 8/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (4, 3)], [(0, 2), (0, 3), (1, 0), (1, 0)]), ([(0, 0), (0, 1), (0, 1), (3, 3)], [(0, 0), (0, 1), (0, 0), (1, 3)]), ([(0, 2), (0, 0), (0, 1), (3, 3)], [(0, 2), (0, 0), (0, 2), (0, 2)]), ([(0, 1), (3, 3), (4, 3), (1, 1)], [(0, 0), (0, 0), (0, 3), (1, 0)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 3), (4, 1)]), ([(0, 3), (1, 1), (4, 3), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 1), (2, 1)])]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6606
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.22592916  0.86795785  0.44227274]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6460
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.90531918 -0.40937524  0.11317729]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6610
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.52755608  0.63846357 -0.56040062]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6656
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.73218359  0.63906054 -0.23560309]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.4418
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.20763675  0.63841448  0.74115716]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.4372
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.07824394  0.87908475  0.47019983]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 3), (0, 2)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 3), (0, 1)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 0), (0, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 0), (1, 3), (1, 2)]), ([(0, 1), (3, 3), (4, 3), (1, 1)], [(0, 2), (0, 3), (0, 2), (0, 0)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 3), (2, 3)])]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6592
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.06583648 -0.29739035  0.95248335]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5214
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.07685933 0.15456869 0.9849879 ]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5052
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.62644988 -0.45526556  0.63268777]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.3260
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.22489881  0.18459661  0.95673644]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.1790
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.22020404 -0.15256109  0.96344969]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.1800
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.02000386 -0.44428885  0.89566024]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running experiment 10/50...
Shuffled Demos: [([(0, 1), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 2), (3, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 2), (3, 2)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (3, 3)]), ([(0, 0), (0, 1), (3, 3), (3, 3)], [(0, 0), (0, 1), (3, 0), (0, 2)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 3), (1, 1)]), ([(0, 1), (3, 1), (3, 3), (3, 3)], [(0, 1), (3, 1), (3, 1), (3, 1)])]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6624
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.35575405 -0.32385035  0.87667554]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5670
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.26871017 0.09893775 0.95812638]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5698
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.72317655 -0.49717379  0.47940995]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5586
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.71756887 0.15906944 0.67807952]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.4380
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.10586903  0.31992372  0.94150972]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.4262
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.3669214   0.31909423  0.87381208]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [([(0, 0), (0, 1), (0, 1), (3, 3)], [(0, 0), (0, 0), (0, 0), (0, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (1, 2), (0, 3), (0, 3)]), ([(0, 1), (3, 3), (0, 1), (3, 3)], [(0, 1), (3, 2), (3, 2), (3, 0)]), ([(0, 0), (0, 2), (0, 1), (3, 3)], [(0, 0), (0, 2), (0, 3), (1, 1)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 2), (0, 0)]), ([(0, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 1), (3, 0), (0, 1)])]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.21849178  0.63967917  0.73693412]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6488
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.76312271  0.63844808 -0.10013882]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6878
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.76772367  0.63969174  0.03734763]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.94594979  0.31963247 -0.0549006 ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.3354
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.80466394  0.15987543  0.57180048]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.3204
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.89461775  0.06599774  0.44193142]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running experiment 12/50...
Shuffled Demos: [([(0, 1), (0, 1), (3, 3), (3, 3)], [(0, 3), (1, 1), (0, 1), (1, 1)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 0), (1, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 0), (0, 1)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 1), (3, 3)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 1), (4, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 0), (1, 1)])]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6596
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.44392699 -0.01650028  0.89591103]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.44760982  0.89392828  0.02318793]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.3220
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.90303166 -0.42804328 -0.03623217]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.3266
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.72254036  0.11198962  0.68219774]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.3342
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.2942355   0.34940026  0.8895757 ]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.3294
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.53532381 -0.13928297  0.83308383]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (3, 1)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (0, 3), (1, 0)]), ([(0, 2), (0, 1), (3, 3), (3, 3)], [(0, 2), (0, 0), (0, 0), (0, 1)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 3), (2, 3)]), ([(0, 2), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 3), (0, 1)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 3), (4, 3)])]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6460
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.01074847  0.18323334  0.98301069]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5682
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.10926854 -0.16433993  0.98033299]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5884
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.24238976 0.31948379 0.91606621]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.48283758 -0.0495351   0.87430781]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3542
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.23333894  0.31979662  0.91830445]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3310
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.38101836 0.31960179 0.86757116]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running experiment 14/50...
Shuffled Demos: [([(0, 1), (1, 3), (2, 1), (5, None)], [(0, 1), (1, 3), (2, 2), (1, 3)]), ([(0, 0), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 2), (4, 3)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 2), (4, 3), (5, None)]), ([(0, 1), (0, 1), (3, 3), (0, 1)], [(0, 1), (0, 2), (0, 1), (3, 2)]), ([(0, 3), (1, 2), (4, 3), (5, None)], [(0, 3), (1, 2), (4, 1), (4, 2)]), ([(0, 1), (1, 0), (1, 1), (4, 3), (5, None)], [(0, 1), (1, 0), (1, 0), (1, 3)])]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6524
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.08070368 -0.83804841  0.53959409]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5690
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.78062824  0.50304901  0.37089249]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5648
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.40615022 -0.02101722  0.9135646 ]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5564
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.63165456  0.63873608  0.43935037]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.4992
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.11519704 0.08508054 0.98969235]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.4230
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.12128909  0.21350302  0.96938404]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (3, 3)], [(0, 2), (0, 2), (0, 1), (3, 3)]), ([(0, 0), (0, 2), (0, 1), (3, 3)], [(0, 0), (0, 2), (0, 2), (0, 3)]), ([(0, 1), (1, 0), (1, 1), (4, 3), (5, None)], [(0, 1), (1, 0), (1, 0), (1, 3)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 1), (3, 2)]), ([(0, 1), (3, 1), (4, 3), (5, None)], [(0, 1), (3, 1), (4, 1), (4, 3)]), ([(0, 1), (3, 3), (3, 3), (3, 3)], [(0, 3), (1, 0), (1, 1), (4, 0)])]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.46536459  0.63875647 -0.61272014]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.7498307 0.6387422 0.1725176]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6642
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.65624132  0.63849522  0.40208356]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5462
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.11610509  0.31877506  0.94069234]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.4288
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.18339107  0.31854914  0.92999686]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.3144
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.10173987 0.3189967  0.94227921]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running experiment 16/50...
Shuffled Demos: [([(0, 3), (0, 1), (0, 1), (0, 1)], [(0, 3), (0, 2), (3, 3), (4, 2)]), ([(0, 1), (3, 3), (3, 3), (0, 1)], [(0, 1), (3, 1), (3, 1), (3, 3)]), ([(0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 0), (0, 2)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 3), (1, 3)]), ([(0, 1), (3, 3), (0, 1), (3, 3)], [(0, 1), (3, 0), (0, 3), (0, 0)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 2), (3, 3), (3, 3), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.57028355  0.63861715 -0.51666702]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.23843987  0.63943944  0.7309334 ]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6674
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.47978274  0.63925906  0.60096288]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5628
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.38810281 -0.07010343  0.91894598]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5650
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.5441641   0.63933759  0.54326134]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.4198
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.49838122 0.05551061 0.86517902]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 0), (1, 3)]), ([(0, 2), (0, 1), (3, 3), (4, 3)], [(0, 2), (0, 0), (0, 1), (3, 1)]), ([(0, 2), (0, 2), (0, 1), (3, 3)], [(0, 2), (0, 2), (0, 2), (0, 1)]), ([(0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 3), (4, 3)]), ([(0, 1), (3, 3), (0, 1), (3, 3)], [(0, 2), (0, 3), (1, 3), (2, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (3, 3)])]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6554
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.31441618 0.93812434 0.14513848]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6604
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.65235405  0.63978911  0.40633003]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6594
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.03979499  0.63920926  0.76800253]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.27052985  0.3184789   0.9085069 ]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.4410
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.41099055  0.3193779   0.85386446]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3186
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.50346464  0.31878281  0.80305721]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running experiment 18/50...
Shuffled Demos: [([(0, 1), (3, 1), (3, 3), (3, 3)], [(0, 1), (3, 1), (3, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 1), (4, 0)]), ([(0, 1), (3, 3), (0, 1), (3, 3)], [(0, 0), (0, 1), (3, 0), (3, 1)]), ([(0, 0), (0, 1), (3, 3), (3, 3)], [(0, 0), (0, 3), (3, 3), (4, 2)]), ([(0, 3), (1, 3), (2, 1), (5, None)], [(0, 3), (1, 3), (2, 2), (1, 0)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 3), (2, 3)])]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.34353887 0.63833897 0.68884281]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6586
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.04048779 0.63869425 0.76839469]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6562
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.85386688  0.04411281  0.51861875]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6686
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.93854371  0.31935722  0.13094529]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6548
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.7038656   0.31945384  0.63444658]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.70886255  0.63874647 -0.29919362]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [([(0, 3), (1, 0), (1, 1), (4, 3)], [(0, 3), (1, 0), (1, 0), (1, 0)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 1), (4, 2)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 1), (2, 2)]), ([(0, 2), (0, 0), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 0), (1, 0), (1, 3)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 3), (4, 3)]), ([(0, 1), (3, 3), (0, 1), (3, 3)], [(0, 0), (0, 0), (0, 2), (0, 2)])]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6552
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94410372  0.320517    0.07705204]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.3254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9370531  -0.24067762  0.25299364]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.3158
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.75083043 -0.09026312  0.65429828]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.3356
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.30206919  0.31437967  0.89995535]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.3140
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.36783071 -0.03584062  0.92920182]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.3150
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.53413515  0.31922671  0.78281157]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running experiment 20/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (3, 3)], [(0, 2), (0, 1), (3, 0), (0, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 2), (3, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 0), (0, 2)]), ([(0, 1), (3, 0), (0, 1), (3, 3)], [(0, 1), (3, 0), (0, 0), (0, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 3), (4, 1)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 2), (0, 1)])]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.25597407 0.63878397 0.72555656]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6598
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.02763516 0.31905952 0.94733169]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6478
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.66281169  0.31893473  0.67746683]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6470
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.18515744  0.31989735  0.92918373]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6582
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.52203085 0.3195244  0.79081474]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5262
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.31335357 0.15948984 0.93614771]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.
