Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6298
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.81120267 -0.18766145  0.55383519]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000031

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2908
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88534963 -0.14765649  0.44085552]
True reward weights: [-0.69406161 -0.37835187  0.61247722]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004398

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2750
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94713165 -0.0991756   0.30513248]
True reward weights: [-0.69406161 -0.37835187  0.61247722]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021914

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.82601016  0.17896922 -0.53448782]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000016

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6114
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.84291657  0.16928102 -0.51072066]
True reward weights: [-0.40968181  0.86750062 -0.28214089]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000270

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.79089003 -0.01942812  0.61164982]
True reward weights: [-0.40968181  0.86750062 -0.28214089]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.023696

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6214
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.97389072 -0.20041869 -0.10662655]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000019

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2792
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.95519115 -0.09586218  0.28003626]
True reward weights: [-0.52083557  0.6575741  -0.5443589 ]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.005418

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2782
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.63552628 -0.24528706  0.73207964]
True reward weights: [-0.52083557  0.6575741  -0.5443589 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022644

Running experiment 4/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6172
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.89117719  0.14154017 -0.43100997]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000037

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6208
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99982723  0.00434291 -0.01807325]
True reward weights: [-0.66773457  0.57263704  0.47562314]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000541

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.91450911 -0.2235149   0.33721533]
True reward weights: [-0.66773457  0.57263704  0.47562314]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.022181

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6210
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.91914602 -0.12410925  0.3738549 ]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000027

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6186
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.79979544  0.58104236 -0.15072168]
True reward weights: [-0.49947356  0.44838884  0.74126488]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000565

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.79803086 -0.19091321  0.5715758 ]
True reward weights: [-0.49947356  0.44838884  0.74126488]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.022540

Running experiment 6/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6166
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.74071308 -0.65662451 -0.14208585]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000017

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.8952357  -0.42046266  0.1475269 ]
True reward weights: [-0.67858025 -0.51973182  0.51904497]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.006559

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2882
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.92707522 -0.12035297  0.35503057]
True reward weights: [-0.67858025 -0.51973182  0.51904497]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023465

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6310
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.90295619 -0.13583282  0.40770033]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000025

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6238
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.8397954   0.17239004 -0.51480613]
True reward weights: [-0.60192987  0.79397385  0.08535785]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000366

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2872
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.69996376 -0.22678273  0.67721513]
True reward weights: [-0.60192987  0.79397385  0.08535785]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.023035

Running experiment 8/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6120
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.95727857  0.08926536 -0.27504441]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000022

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.70549116 -0.22114454  0.67333299]
True reward weights: [0.29592428 0.31772925 0.90082015]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.009652

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83732378 -0.12285903  0.53272371]
True reward weights: [0.29592428 0.31772925 0.90082015]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022812

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.88422428  0.4665401   0.02208546]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000016

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6130
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99567622  0.02789762 -0.08860355]
True reward weights: [-0.72134736  0.0976646   0.68565269]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000293

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.2762
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.71213514 -0.22455877  0.66515931]
True reward weights: [-0.72134736  0.0976646   0.68565269]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.025124

Running experiment 10/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.33197561  0.74699833  0.57600841]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000013

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2808
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92503153 -0.11997644  0.3604474 ]
True reward weights: [-0.68001524  0.61840421  0.39389784]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004805

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2796
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.51139624  0.34611819  0.78655965]
True reward weights: [-0.68001524  0.61840421  0.39389784]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021825

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6182
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.68861621 -0.22819398  0.68828426]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000011

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9133602  -0.40714096  0.00306416]
True reward weights: [-0.7052099   0.61609904 -0.35085749]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004590

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2762
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.54240055  0.25820071  0.79945859]
True reward weights: [-0.7052099   0.61609904 -0.35085749]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022448

Running experiment 12/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.6025175   0.2508312  -0.75766508]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000024

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92051653 -0.12349128  0.37067401]
True reward weights: [-0.19133946  0.70974388  0.67797702]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.003227

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2830
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.21573419  0.45587481  0.8635027 ]
True reward weights: [-0.19133946  0.70974388  0.67797702]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021662

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6352
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99660434 -0.02467226  0.07855618]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000042

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.46171803  0.27993636 -0.84169596]
True reward weights: [0.21114975 0.24523709 0.94618949]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000580

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.2808
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93340526 -0.11504974  0.33987964]
True reward weights: [0.21114975 0.24523709 0.94618949]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.021457

Running experiment 14/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6094
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.15636329 -0.3119196   0.9371535 ]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000050

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2952
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.84640591 -0.16601897  0.50599875]
True reward weights: [-0.24358336  0.10856806  0.96378427]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.009225

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2824
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.70499014  0.03025126  0.70857163]
True reward weights: [-0.24358336  0.10856806  0.96378427]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023995

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6182
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.76473993  0.20305585 -0.61150728]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000050

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.96692479 -0.08272368  0.24127421]
True reward weights: [-0.4273052   0.63775735  0.64083994]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000643

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.2896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.64366417  0.02802961  0.7647946 ]
True reward weights: [-0.4273052   0.63775735  0.64083994]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.021902

Running experiment 16/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6322
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.51696613 -0.26870374  0.81273878]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000021

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2920
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89979419 -0.13918789  0.41351802]
True reward weights: [ 0.11433351 -0.7248169   0.67938819]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.005524

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.88820573 -0.14701998  0.43528807]
True reward weights: [ 0.11433351 -0.7248169   0.67938819]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022231

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99283931  0.04042289 -0.11241038]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000037

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.2864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92125058 -0.12073188  0.36975827]
True reward weights: [-0.59887405  0.18350539 -0.77953553]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.006849

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.2840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.7781344  -0.44667001  0.44157983]
True reward weights: [-0.59887405  0.18350539 -0.77953553]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021959

Running experiment 18/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6204
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.26693304  0.94782459 -0.17428513]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000025

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.2932
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.67693888 -0.23358856  0.69799007]
True reward weights: [-0.78467424  0.11244514  0.60962483]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.005618

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.2810
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.01829898 0.44726725 0.89421315]
True reward weights: [-0.78467424  0.11244514  0.60962483]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022119

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.79565523 -0.19352854  0.57400302]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000069

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.2782
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92811528 -0.11834559  0.35298209]
True reward weights: [-0.66310115 -0.29507162  0.68791685]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.005313

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.2924
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94159792 -0.1085329   0.31876944]
True reward weights: [-0.66310115 -0.29507162  0.68791685]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021440

Running experiment 20/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6276
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.89980748 -0.13649412  0.41438611]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000032

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2878
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.55687878  0.00187958  0.83059165]
True reward weights: [ 0.67688053 -0.70850592 -0.19962993]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.009196

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2844
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.43002364  0.18836725  0.88294816]
True reward weights: [ 0.67688053 -0.70850592 -0.19962993]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023732

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6250
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.6731057   0.23228988 -0.70211831]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000026

Running PBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.2800
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.62262766 -0.0194997   0.78227524]
True reward weights: [-0.76935721  0.3719409  -0.51937409]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.003773

Running PBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.2836
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.87050657 -0.15652003  0.46660454]
True reward weights: [-0.76935721  0.3719409  -0.51937409]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.020894

Running experiment 22/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.23271321 -0.69700731  0.6782517 ]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000033

Running PBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2846
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.68624468  0.26363646  0.67791154]
True reward weights: [0.742021   0.08861444 0.66449403]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.008821

Running PBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2836
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.73543702 -0.37991752  0.56106601]
True reward weights: [0.742021   0.08861444 0.66449403]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023803

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6166
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.80272155  0.19107739 -0.56491376]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000035

Running PBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.2900
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.93021502 -0.11676268  0.3479461 ]
True reward weights: [-0.53023366  0.79118108 -0.30477002]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.007687

Running PBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.2762
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.82477854 -0.17768959  0.53681166]
True reward weights: [-0.53023366  0.79118108 -0.30477002]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023922

Running experiment 24/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99991161  0.00493757 -0.01234467]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000022

Running PBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6308
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.46933436  0.2809412  -0.83713637]
True reward weights: [-0.91758979 -0.39236334  0.06387476]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000386

Running PBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.2788
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.69813399 -0.22795339  0.6787092 ]
True reward weights: [-0.91758979 -0.39236334  0.06387476]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.025003

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6168
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.90951542  0.13006682 -0.39479655]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000038

Running PBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.2826
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.95426006 -0.09412793  0.28377398]
True reward weights: [-0.20908832  0.34161442  0.91628689]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.001434

Running PBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.2764
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83369513 -0.19739706  0.51573911]
True reward weights: [-0.20908832  0.34161442  0.91628689]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.020473

Running experiment 26/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6218
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.60031815 -0.25074899  0.75943601]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000035

Running PBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.2774
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9527266  -0.21425464  0.21542277]
True reward weights: [ 0.05748513 -0.95067959  0.3048012 ]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.005410

Running PBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.2800
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.2883887   0.37606778  0.88057083]
True reward weights: [ 0.05748513 -0.95067959  0.3048012 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023088

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6234
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98095073  0.05953945 -0.18490734]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000026

Running PBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6184
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88667152 -0.14501047  0.43907354]
True reward weights: [-0.11755895  0.07449586 -0.99026777]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000379

Running PBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.2894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.79035487 -0.19248574  0.58162566]
True reward weights: [-0.11755895  0.07449586 -0.99026777]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.021642

Running experiment 28/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.21368862 -0.31073179  0.92616571]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000041

Running PBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.2980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88321715 -0.14585115  0.4457072 ]
True reward weights: [-0.92441361 -0.37944483  0.03848502]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.006789

Running PBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.2870
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.90775568 -0.13142278  0.39838132]
True reward weights: [-0.92441361 -0.37944483  0.03848502]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021550

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6208
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.93723997  0.1075205  -0.33169351]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000020

Running PBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.2938
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89564071 -0.13831506  0.42272527]
True reward weights: [0.34748463 0.89934947 0.26537702]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004584

Running PBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.2832
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.8660755  -0.15791906  0.47431508]
True reward weights: [0.34748463 0.89934947 0.26537702]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022979

Running experiment 30/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6242
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.84837993 -0.1693194   0.50157994]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000037

Running PBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.2928
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.70813878  0.23989573  0.66407041]
True reward weights: [-0.93983369  0.27847179  0.19790425]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.005894

Running PBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.2744
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.69513458 -0.22930283  0.68132821]
True reward weights: [-0.93983369  0.27847179  0.19790425]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022016

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94952506 -0.0990587   0.29763993]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000053

Running PBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.2910
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.36741349  0.11433737  0.92300287]
True reward weights: [ 0.30159324 -0.73693498 -0.60495318]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.003049

Running PBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.2796
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.80240991 -0.27306477  0.53063543]
True reward weights: [ 0.30159324 -0.73693498 -0.60495318]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022863

Running experiment 32/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.19431243 -0.31126293  0.93024624]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000011

Running PBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.2796
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.94260599 -0.10296674  0.31763469]
True reward weights: [ 0.03657931 -0.8358425  -0.54774928]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.005665

Running PBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.2758
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.91788296 -0.12257935  0.3774456 ]
True reward weights: [ 0.03657931 -0.8358425  -0.54774928]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021319

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6152
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.94125969 -0.10796469  0.31995909]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000013

Running PBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.2808
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.13221526  0.34795014  0.92814321]
True reward weights: [ 0.24366191 -0.77291507 -0.58585934]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.008379

Running PBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.2876
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83484578 -0.17515387  0.52187513]
True reward weights: [ 0.24366191 -0.77291507 -0.58585934]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023713

Running experiment 34/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6174
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.90513732 -0.42057674  0.06198087]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000017

Running PBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2866
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.91922947 -0.12588686  0.37305453]
True reward weights: [ 0.97526939 -0.02746142  0.21930683]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.008364

Running PBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2850
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.80153375 -0.19164278  0.56640682]
True reward weights: [ 0.97526939 -0.02746142  0.21930683]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.024053

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94352712  0.10571722 -0.31397522]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000025

Running PBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.2838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.12184074  0.21493208  0.96899899]
True reward weights: [ 0.26630042  0.96084171 -0.07659829]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.001465

Running PBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.2698
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.08199408  0.46115403  0.88352359]
True reward weights: [ 0.26630042  0.96084171 -0.07659829]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021802

Running experiment 36/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6096
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94712897 -0.10113862  0.30449581]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000035

Running PBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.2730
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.78329735 -0.19449427  0.59043818]
True reward weights: [ 0.44175477 -0.88992131 -0.11354637]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.005349

Running PBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.2848
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.66665847 -0.19488532  0.71943463]
True reward weights: [ 0.44175477 -0.88992131 -0.11354637]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023409

Saving results to files...
Results saved successfully.

Running experiment 37/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6216
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.23735174  0.3077866  -0.92137482]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000035

Running PBIRL with 2 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.2838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.87025928 -0.46060459  0.17462018]
True reward weights: [-0.96603264 -0.0327464   0.2563369 ]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004572

Running PBIRL with 3 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.2852
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.28916996  0.12535934  0.94903413]
True reward weights: [-0.96603264 -0.0327464   0.2563369 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022746

Running experiment 38/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6194
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.96515623  0.08098033 -0.24882854]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000014

Running PBIRL with 2 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.82222266 -0.17712782  0.54090261]
True reward weights: [-0.77980781  0.52351022  0.3432737 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000299

Running PBIRL with 3 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.2816
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.375587    0.37618239  0.84700721]
True reward weights: [-0.77980781  0.52351022  0.3432737 ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.021587

Saving results to files...
Results saved successfully.

Running experiment 39/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6198
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.48359427 -0.27695846  0.83031958]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000057

Running PBIRL with 2 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2710
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.075792    0.33826849  0.93799254]
True reward weights: [-0.98559998 -0.15176004  0.0745759 ]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.003100

Running PBIRL with 3 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2886
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.23513532  0.32406319  0.91634842]
True reward weights: [-0.98559998 -0.15176004  0.0745759 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021479

Running experiment 40/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6230
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.49823232  0.27232219 -0.82316777]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000033

Running PBIRL with 2 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.2698
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.64488623 -0.24427706  0.72418953]
True reward weights: [-0.84041903 -0.05013528 -0.53961311]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.001648

Running PBIRL with 3 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.2860
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.62013109 -0.247772    0.74434297]
True reward weights: [-0.84041903 -0.05013528 -0.53961311]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.019841

Saving results to files...
Results saved successfully.

Running experiment 41/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6200
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.6200001  -0.25013245  0.74366231]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000013

Running PBIRL with 2 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.2882
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.74051417 -0.21228321  0.63763203]
True reward weights: [0.98275298 0.09574651 0.15820617]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.003457

Running PBIRL with 3 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.2792
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83859819 -0.17107402  0.51719122]
True reward weights: [0.98275298 0.09574651 0.15820617]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021491

Running experiment 42/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6132
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.95426582  0.09159371 -0.28458273]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000019

Running PBIRL with 2 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.2794
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89277871 -0.14412659  0.42681811]
True reward weights: [-0.14723509  0.22256762 -0.96373517]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.012329

Running PBIRL with 3 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.2826
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.7291065  -0.21709474  0.64905592]
True reward weights: [-0.14723509  0.22256762 -0.96373517]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023754

Saving results to files...
Results saved successfully.

Running experiment 43/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6340
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.85027301 -0.37643518  0.36787548]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000018

Running PBIRL with 2 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6232
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.82277617 -0.18214383  0.53838927]
True reward weights: [-0.63979499 -0.6154027   0.46037146]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000313

Running PBIRL with 3 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.2858
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93846517 -0.12104686  0.32346683]
True reward weights: [-0.63979499 -0.6154027   0.46037146]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.021443

Running experiment 44/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6238
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.26260401 -0.30284229  0.91614719]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000013

Running PBIRL with 2 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.2934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.75274388 -0.24378755  0.61150984]
True reward weights: [-0.18531384  0.20139804  0.96181995]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004804

Running PBIRL with 3 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.2848
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.9466361  -0.10181067  0.30580171]
True reward weights: [-0.18531384  0.20139804  0.96181995]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.023280

Saving results to files...
Results saved successfully.

Running experiment 45/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6308
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.37486319 -0.9258173   0.04837275]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000028

Running PBIRL with 2 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.2946
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.7078693  -0.22378773  0.6699553 ]
True reward weights: [ 0.11002033 -0.98769098 -0.11118482]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004719

Running PBIRL with 3 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.2730
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89407875 -0.43448564 -0.10883663]
True reward weights: [ 0.11002033 -0.98769098 -0.11118482]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022957

Running experiment 46/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6216
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.15815626 -0.31513665  0.93577534]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000026

Running PBIRL with 2 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.2880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.81143442 -0.11308392  0.57339883]
True reward weights: [-0.27688787  0.6010734   0.74969586]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.005614

Running PBIRL with 3 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.2932
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.45601612  0.43767994  0.77491004]
True reward weights: [-0.27688787  0.6010734   0.74969586]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021411

Saving results to files...
Results saved successfully.

Running experiment 47/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6212
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.95954656  0.08849244 -0.26728165]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000037

Running PBIRL with 2 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6204
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.0567813  0.99647259 0.06179203]
True reward weights: [-0.80562855  0.58021353  0.1196449 ]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000294

Running PBIRL with 3 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.2846
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.80457735 -0.46639651  0.36759975]
True reward weights: [-0.80562855  0.58021353  0.1196449 ]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.022821

Running experiment 48/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6176
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.68890543  0.22780933 -0.68812224]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000004

Running PBIRL with 2 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.42921535  0.5207998  -0.73793072]
True reward weights: [-0.62694459  0.67253361  0.39324168]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000047

Running PBIRL with 3 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.2800
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.88271012 -0.14868156  0.44577645]
True reward weights: [-0.62694459  0.67253361  0.39324168]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.021517

Saving results to files...
Results saved successfully.

Running experiment 49/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6072
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.9741113  -0.0732024   0.21388918]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000014

Running PBIRL with 2 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.2882
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.23175263  0.13731216  0.96303483]
True reward weights: [ 0.00156936  0.76209684 -0.64746115]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.004843

Running PBIRL with 3 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.2858
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.67010137 -0.23374305  0.70450574]
True reward weights: [ 0.00156936  0.76209684 -0.64746115]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022363

Running experiment 50/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6276
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94878873  0.09938503 -0.29987089]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000006

Running PBIRL with 2 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6100
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.81514531  0.18168867 -0.55002486]
True reward weights: [-0.88704884  0.40315454 -0.22496839]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000210

Running PBIRL with 3 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.2770
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.28825789  0.10121958  0.952188  ]
True reward weights: [-0.88704884  0.40315454 -0.22496839]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.024597

Saving results to files...
Results saved successfully.
