Config file loaded successfully.
Feature weights for environment: [-0.21542894 -0.89013091  0.40156859]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Estops: [([(0, 2), (0, 0), (0, 3), (1, 3), (2, 0), (2, 1), (5, None)], 0), ([(0, 1), (3, 3), (4, 0), (1, 1), (4, 1), (5, None)], 0), ([(0, 3), (1, 3), (2, 3), (2, 2), (1, 1), (4, 2), (3, 3), (4, 0), (1, 3), (2, 3)], 0), ([(0, 0), (1, 1), (4, 0), (1, 1), (4, 0), (1, 1), (4, 0), (1, 1), (4, 3), (1, 0)], 0), ([(0, 3), (1, 2), (0, 2), (0, 3), (1, 0), (0, 1), (3, 3), (4, 2), (3, 2), (3, 2)], 0), ([(0, 3), (1, 0), (1, 1), (4, 1), (3, 0), (0, 2), (0, 2), (0, 2), (0, 2), (0, 3)], 0)]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5866
Using 3250 samples after burn-in.
MAP Solution: [ 0.17522522  0.02992593 -0.98407345]
True reward weights: [-0.21542894 -0.89013091  0.40156859]
MAP Policy for current environment:
0.9-VaR-max-normalization for 1 demonstrations: 14.692814
0.95-VaR-max-normalization for 1 demonstrations: 17.879750
