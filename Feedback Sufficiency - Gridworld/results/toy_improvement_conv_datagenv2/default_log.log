Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 0), (0, 3), (1, 3), (2, 3), (2, 0), (2, 1), (5, None)]), ([(0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 2), (0, 2), (3, 3), (4, 2), (4, 3), (5, None)]), ([(0, 3), (1, 1), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (2, 2), (1, 0), (1, 0), (1, 1), (4, 3), (5, None)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 3), (1, 2), (0, 2), (0, 1), (1, 3), (2, 0), (2, 0), (2, 0), (2, 0)]), ([(0, 1), (3, 1), (3, 2), (3, 3), (0, 1), (3, 2), (3, 3), (3, 3), (4, 3), (1, 1)], [(0, 1), (3, 1), (3, 2), (3, 3), (0, 1), (3, 2), (3, 2), (3, 1), (3, 0), (0, 0)]), ([(0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (4, 3), (5, 0), (5, 0)], [(0, 2), (0, 0), (0, 2), (0, 1), (3, 3), (3, 1), (3, 3), (4, 2), (3, 3), (4, 2)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6594
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.5534159   0.10676339  0.82603415]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6278
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.10169218 -0.44942703  0.88751002]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5072
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83736402 -0.44604343  0.31601701]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5184
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.96832309 -0.23469614 -0.08525321]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2398
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.28363508 -0.86102233  0.42212758]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2326
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.48478207 0.14034472 0.86330163]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (4, 1), (4, 0), (1, 0), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 3), (4, 1), (4, 0), (1, 0), (1, 1), (4, 2), (3, 1), (3, 3)]), ([(0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 2), (0, 1), (3, 0), (0, 2), (0, 0), (0, 2), (0, 1), (3, 2), (3, 3)]), ([(0, 3), (1, 3), (2, 3), (2, 2), (1, 1), (4, 2), (3, 0), (0, 0), (0, 1), (3, 3)], [(0, 3), (1, 3), (2, 3), (2, 2), (1, 1), (4, 2), (3, 0), (0, 0), (0, 2), (3, 2)]), ([(0, 0), (0, 0), (0, 2), (0, 2), (0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 0), (0, 0), (0, 2), (0, 2), (0, 2), (0, 1), (3, 2), (3, 1), (3, 0), (0, 1)]), ([(0, 3), (3, 1), (3, 3), (4, 1), (4, 2), (3, 2), (3, 0), (0, 1), (3, 3), (4, 3)], [(0, 3), (3, 1), (3, 3), (4, 1), (4, 2), (3, 2), (3, 0), (0, 2), (3, 2), (3, 0)]), ([(0, 3), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 1), (2, 3), (2, 0), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6548
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.01970094 -0.79231517  0.60979385]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6494
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.42928134 -0.08412191  0.8992447 ]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6608
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.00114107 -0.87600218 -0.4823058 ]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6632
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.02878295 -0.92754452 -0.37260261]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6574
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.76881211 -0.54959286 -0.32691838]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6592
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.20191555 -0.79702722  0.56919041]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 3), (1, 3), (2, 2), (1, 1), (4, 2), (1, 2), (0, 1), (1, 3), (2, 1), (5, 0)], [(0, 3), (1, 3), (2, 2), (1, 1), (4, 2), (1, 2), (0, 1), (1, 3), (2, 3), (2, 2)]), ([(0, 2), (0, 3), (1, 2), (0, 1), (3, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 3), (1, 2), (0, 1), (3, 1), (3, 2), (3, 1), (3, 3), (3, 0), (0, 1)]), ([(0, 1), (3, 0), (0, 1), (1, 1), (2, 3), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 0), (0, 1), (1, 1), (2, 3), (2, 2), (1, 3), (2, 3), (2, 2), (1, 1)]), ([(0, 0), (0, 1), (3, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 0), (0, 2), (0, 2), (0, 1), (3, 2), (3, 3), (4, 2), (3, 0), (0, 0)]), ([(0, 1), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (0, 3), (1, 1), (4, 2), (3, 2), (3, 1), (3, 2), (3, 3), (4, 2), (3, 1)]), ([(0, 0), (0, 1), (0, 3), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (0, 3), (1, 2), (0, 2), (0, 0), (0, 1), (3, 2), (3, 0), (0, 1)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6650
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.97200066 -0.1021731   0.21160193]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6520
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.74687153  0.17697758  0.64098506]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.36917596 -0.33237151  0.86789302]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6062
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.13212772 -0.92236926 -0.36301131]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5958
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.17979915 -0.5459258   0.81831369]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6054
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.10673097 -0.23435842  0.96627358]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running experiment 4/50...
Shuffled Demos: [([(0, 1), (1, 1), (4, 2), (3, 2), (3, 1), (3, 0), (3, 0), (0, 1), (1, 1), (4, 3)], [(0, 1), (1, 1), (4, 2), (3, 2), (3, 1), (3, 0), (3, 0), (0, 0), (0, 1), (3, 3)]), ([(0, 2), (0, 1), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 0), (0, 0), (0, 3), (1, 2), (0, 0), (0, 1), (3, 2), (3, 0), (0, 3)]), ([(0, 1), (3, 2), (3, 0), (0, 1), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 2), (3, 0), (0, 1), (1, 2), (0, 1), (3, 3), (3, 2), (3, 1), (3, 1)]), ([(0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 0), (0, 0), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 3), (3, 2), (3, 1), (3, 0), (4, 1), (4, 0), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 3), (3, 2), (3, 1), (3, 0), (4, 1), (4, 0), (1, 1), (4, 0), (1, 2), (0, 3)]), ([(0, 2), (0, 1), (3, 2), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 2), (3, 3), (4, 2), (3, 2), (0, 2), (0, 0), (0, 0), (0, 2)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6496
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.873856   -0.45847783  0.1617831 ]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4930
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.47085028 -0.17282092  0.86512019]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5106
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.76306335 -0.62757361 -0.15454994]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5072
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.46730415 -0.80607291 -0.36314364]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4348
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.50248823 -0.35317152  0.78916124]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4398
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.08546972 -0.97089281 -0.22374558]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [([(0, 2), (0, 0), (1, 1), (4, 1), (4, 2), (1, 1), (4, 1), (4, 0), (1, 1), (4, 3)], [(0, 2), (0, 0), (1, 1), (4, 1), (4, 2), (1, 1), (4, 1), (4, 0), (1, 2), (0, 2)]), ([(0, 3), (1, 3), (2, 3), (2, 2), (1, 0), (1, 0), (1, 1), (4, 3), (1, 1), (0, 1)], [(0, 3), (1, 3), (2, 3), (2, 2), (1, 0), (1, 0), (1, 2), (0, 3), (3, 3), (4, 0)]), ([(0, 1), (3, 1), (4, 1), (4, 1), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 1), (4, 1), (4, 1), (3, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 3), (4, 1), (4, 1), (4, 2), (3, 1), (3, 0), (0, 1), (3, 0), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 0), (0, 3), (1, 0), (0, 3), (1, 1), (4, 1), (3, 2), (3, 2)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 0), (1, 1), (4, 0), (1, 3), (4, 0), (1, 0), (1, 0), (1, 0), (1, 3)])]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.07057998  0.96609012  0.24837137]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6656
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.05889864 -0.94994148  0.3068259 ]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5324
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.50412794 -0.85849421  0.09403572]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5262
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.31861513 -0.88906522  0.32870571]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.04494853 -0.9399414  -0.33836342]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.25850858 -0.96594964  0.01070528]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running experiment 6/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 0), (0, 2), (0, 0), (0, 2), (3, 1), (4, 2), (3, 0), (0, 1), (3, 1)]), ([(0, 0), (0, 1), (0, 2), (0, 1), (1, 1), (2, 1), (5, 0)], [(0, 0), (0, 1), (0, 2), (0, 1), (1, 3), (4, 3), (5, None)]), ([(0, 0), (0, 3), (1, 1), (4, 0), (1, 0), (1, 0), (1, 0), (1, 1), (2, 1), (5, 0)], [(0, 0), (0, 3), (1, 1), (4, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 2), (0, 1)]), ([(0, 0), (0, 0), (1, 3), (2, 1), (1, 1)], [(0, 0), (0, 0), (1, 3), (2, 2), (5, None)]), ([(0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 0), (0, 0), (0, 3), (1, 0), (1, 0), (0, 2), (0, 3), (1, 0), (1, 2)]), ([(0, 3), (3, 1), (3, 2), (3, 3), (4, 3), (1, 2), (1, 1), (2, 1), (5, 0), (5, 0)], [(0, 3), (3, 1), (3, 2), (3, 3), (4, 3), (1, 2), (1, 2), (0, 1), (3, 2), (3, 3)])]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6486
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.91331896 -0.40012206 -0.07583407]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6642
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.09896806 -0.97104375 -0.21743817]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6684
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.23108559 -0.96964283 -0.07995148]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.3274
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.95425904 -0.11842735  0.27452621]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.0718
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.50446404 -0.81450359  0.28653084]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.0748
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.48816665 -0.82854444  0.27423972]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 1), (4, 2), (3, 0), (0, 0), (0, 1), (1, 0), (1, 1), (4, 3), (4, 0)]), ([(0, 1), (3, 0), (0, 3), (1, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 0), (0, 3), (1, 2), (0, 0), (0, 1), (3, 2), (3, 1), (3, 3), (4, 3)]), ([(0, 1), (3, 3), (4, 2), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 3), (4, 2), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 3), (1, 3), (2, 3), (2, 0), (2, 1), (5, None)]), ([(0, 0), (1, 0), (2, 1), (5, 0)], [(0, 0), (1, 0), (2, 2), (5, None)]), ([(0, 0), (0, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (3, 3), (0, 1), (3, 3)], [(0, 0), (0, 2), (0, 0), (0, 0), (0, 0), (0, 0), (0, 2), (0, 3), (1, 0), (1, 1)])]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6604
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.11399166 -0.71614595  0.68857888]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6136
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.75125201  0.12125018  0.64878256]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6228
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.61751284  0.28678304  0.73241613]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5996
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.09144408 -0.89557406  0.43541368]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6054
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.47605973 -0.03783236  0.87859879]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.3320
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.41608687  0.45310548  0.78839529]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running experiment 8/50...
Shuffled Demos: [([(0, 1), (1, 1), (2, 1), (5, 0)], [(0, 3), (1, 2), (4, 3), (5, None)]), ([(0, 2), (3, 1), (3, 0), (0, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 2), (3, 1), (3, 0), (0, 1), (3, 0), (0, 1), (3, 3), (4, 0), (5, None)]), ([(0, 3), (1, 1), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 0), (1, 2), (0, 3), (1, 1), (4, 3), (4, 0), (3, 2), (3, 0)]), ([(0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 2), (0, 3), (3, 0), (0, 2), (0, 3), (1, 3), (2, 0), (2, 3), (2, 2)]), ([(0, 1), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 3), (4, 0), (5, None)]), ([(0, 3), (0, 2), (0, 0), (0, 0), (0, 3), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0)], [(0, 3), (0, 2), (0, 0), (0, 0), (0, 3), (1, 3), (2, 3), (2, 0), (2, 0), (2, 0)])]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.8661913  -0.04290549  0.4978672 ]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.2874669   0.7565044  -0.58742137]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6490
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.76452576  0.62900358  0.14090728]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5900
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.75407853 -0.65333087 -0.06726322]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5158
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.70635124 -0.68230016 -0.18850576]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5074
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.41324361 -0.78127025  0.46781033]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 0), (1, 3), (2, 2), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 3), (3, 3), (3, 3), (4, 3), (5, None)]), ([(0, 2), (0, 0), (1, 3), (2, 2), (1, 0), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 2), (0, 0), (1, 3), (2, 2), (1, 0), (0, 3), (1, 3), (2, 2), (1, 1), (4, 1)]), ([(0, 3), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 3), (0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 2), (0, 0), (0, 3), (1, 3), (2, 0), (2, 3), (5, None)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (4, 3), (5, 0)], [(0, 3), (1, 3), (2, 2), (1, 3), (2, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6538
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.45673541  0.63005556  0.62803086]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5552
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.14350347 -0.70276843  0.69679501]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5682
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.01662375 -0.96355738  0.26698471]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.0206
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.4367781   0.63601274  0.63617032]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.0164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.22086352  0.68970215  0.68958701]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.0184
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.40598814  0.64615167  0.64626747]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running experiment 10/50...
Shuffled Demos: [([(0, 0), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 0), (0, 2), (3, 0), (4, 1), (4, 3), (5, None)]), ([(0, 1), (3, 1), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 1), (4, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 1), (0, 2), (0, 2), (0, 0), (0, 2), (0, 1), (3, 1), (3, 1), (3, 3)]), ([(0, 0), (0, 1), (0, 1), (3, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 0), (0, 3), (1, 2), (0, 0), (0, 3), (1, 3), (2, 2), (1, 3), (4, 1)]), ([(0, 2), (0, 2), (0, 3), (1, 1), (4, 0), (1, 2), (4, 0), (1, 0), (1, 1), (4, 3)], [(0, 2), (0, 2), (0, 3), (1, 1), (4, 0), (1, 2), (4, 0), (1, 0), (1, 2), (0, 1)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (1, 3), (4, 3), (1, 0), (1, 1), (4, 2), (1, 0), (1, 0), (1, 1), (0, 2)])]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6528
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.48246275 -0.52639923  0.70009538]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6564
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.54383493 -0.42069142  0.72612829]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6386
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.2421843  -0.77194357  0.58774986]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5590
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.60254403 -0.70906995  0.36627925]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5672
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.60894018 -0.5277915   0.59213848]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5060
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.39854963 -0.90457443  0.15133838]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 1), (1, 2), (1, 3), (2, 1), (5, 0), (5, 0)], [(0, 2), (0, 0), (0, 1), (1, 2), (1, 3), (2, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 3), (2, 3), (2, 1), (5, None)]), ([(0, 3), (0, 1), (3, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (0, 1), (3, 0), (0, 2), (0, 3), (1, 1), (4, 2), (3, 3), (4, 1), (4, 2)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 1), (3, 0), (0, 1), (3, 1), (3, 3), (4, 2), (3, 0), (3, 1)]), ([(0, 1), (3, 2), (3, 2), (3, 1), (3, 0), (0, 0), (0, 3), (1, 2), (0, 1), (3, 3)], [(0, 1), (3, 2), (3, 2), (3, 1), (3, 0), (0, 0), (0, 3), (1, 2), (0, 0), (1, 3)]), ([(0, 0), (0, 1), (3, 0), (0, 3), (1, 0), (1, 3), (2, 1), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 0), (0, 3), (1, 0), (1, 3), (2, 3), (2, 0), (2, 3), (2, 1)])]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6580
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.21573421 -0.70986021  0.6704903 ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6036
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.3929544  -0.19490842  0.89866432]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5944
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.13395332 -0.83466676  0.5342171 ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.43545272 -0.89687032  0.07748906]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.3394
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.72946934  0.23971322  0.6406341 ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.3282
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.3017362   0.3754377   0.87635712]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running experiment 12/50...
Shuffled Demos: [([(0, 3), (1, 1), (4, 2), (3, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 1), (4, 2), (3, 0), (0, 0), (0, 1), (3, 2), (3, 2), (3, 3), (0, 2)]), ([(0, 1), (3, 1), (3, 3), (4, 1), (3, 1), (3, 0), (0, 0), (0, 2), (0, 1), (1, 1)], [(0, 1), (3, 1), (3, 3), (4, 1), (3, 1), (3, 0), (0, 0), (0, 2), (0, 0), (0, 2)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 0), (0, 1), (3, 0), (3, 1), (3, 3), (4, 1), (5, None)]), ([(0, 1), (0, 1), (3, 1), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (0, 1), (3, 1), (3, 3), (4, 3), (4, 0), (1, 3), (2, 0), (2, 1), (1, 0)]), ([(0, 3), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 3), (1, 1), (4, 1), (4, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 2), (3, 2), (0, 2), (0, 3), (1, 3), (2, 3), (2, 3), (2, 0), (2, 3)])]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6472
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.81847091 -0.49366199 -0.29394422]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5336
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.44620833 -0.04893493  0.89359023]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5268
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.84111394 -0.30581956  0.44609611]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.4464
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.50002313 -0.8659934  -0.00568366]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.4440
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.52643963 -0.78700852  0.32168138]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.4440
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.14402523 -0.89171518 -0.42906965]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 0), (0, 3), (1, 0), (1, 1), (2, 1), (2, 1), (5, None)]), ([(0, 0), (0, 0), (0, 3), (1, 2), (0, 1), (3, 3), (3, 3), (4, 3), (1, 1), (4, 3)], [(0, 0), (0, 0), (0, 3), (1, 2), (0, 2), (0, 1), (3, 3), (3, 1), (3, 2), (3, 3)]), ([(0, 0), (0, 1), (3, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 1), (4, 1), (4, 2), (3, 1), (3, 2), (3, 2), (3, 3), (4, 0)]), ([(0, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 0), (0, 0), (0, 3), (1, 2), (0, 1), (1, 3), (2, 0), (1, 1), (4, 2)]), ([(0, 0), (0, 1), (3, 2), (3, 2), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 2), (3, 2), (3, 1), (3, 1), (3, 0), (0, 0), (0, 3), (1, 3)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 0), (0, 0), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6690
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.40128511 -0.84081117  0.36332746]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3188
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.0068586  -0.74583467  0.66609579]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3392
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.13874719 -0.9850675   0.10193743]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3308
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.28985063 -0.77300528  0.56431325]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3350
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.21698425 -0.79474325  0.56683419]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3340
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.00330555 -0.93382448  0.35771625]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running experiment 14/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 1), (3, 1), (3, 0), (0, 1), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 2), (0, 1), (3, 1), (3, 1), (3, 0), (0, 3), (1, 3), (2, 2), (1, 3), (2, 2)]), ([(0, 0), (0, 2), (0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 2), (0, 0), (0, 2), (0, 1), (3, 0), (0, 2), (0, 1), (3, 0)]), ([(0, 2), (0, 3), (1, 1), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 3), (1, 1), (0, 0), (0, 1), (3, 1), (3, 2), (3, 2), (3, 2), (3, 0)]), ([(0, 1), (3, 2), (3, 3), (4, 2), (3, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 2), (3, 3), (4, 2), (3, 3), (3, 2), (3, 1), (3, 1), (3, 3), (4, 2)]), ([(0, 0), (0, 0), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 0), (0, 0), (0, 1), (3, 2), (3, 3), (4, 1), (4, 0), (5, None)]), ([(0, 3), (0, 3), (1, 0), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 3), (0, 3), (1, 0), (1, 1), (4, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6520
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.83423765 -0.14736636  0.53134801]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.4480
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.15934949 0.54587017 0.82257735]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.4442
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.01552017  0.2928881   0.95602076]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.4380
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.33540294 0.30403476 0.89166571]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.4472
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.59419682 -0.80394372  0.0245892 ]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.4418
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.54100139 -0.82954622  0.13845781]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [([(0, 1), (0, 3), (3, 3), (4, 1), (4, 2), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 1), (0, 3), (3, 3), (4, 1), (4, 2), (3, 2), (3, 0), (3, 2), (3, 3), (4, 3)]), ([(0, 1), (3, 0), (4, 2), (3, 0), (0, 0), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 1), (3, 0), (4, 2), (3, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 2), (0, 1)]), ([(0, 3), (1, 1), (0, 2), (0, 1), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 1), (0, 2), (0, 0), (0, 2), (0, 3), (1, 0), (1, 2), (0, 1), (3, 3)]), ([(0, 3), (1, 0), (0, 2), (0, 2), (0, 2), (0, 1), (1, 1), (2, 1), (5, 0), (5, 0)], [(0, 3), (1, 0), (0, 2), (0, 2), (0, 2), (0, 3), (1, 1), (2, 3), (2, 1), (5, None)]), ([(0, 0), (0, 2), (0, 1), (3, 2), (3, 0), (0, 1), (3, 3), (4, 3), (1, 1), (4, 3)], [(0, 0), (0, 2), (0, 1), (3, 2), (3, 0), (0, 0), (0, 3), (1, 0), (1, 2), (0, 1)]), ([(0, 3), (1, 1), (4, 0), (1, 1), (4, 2), (3, 1), (3, 3), (4, 0), (1, 1), (4, 3)], [(0, 3), (1, 1), (4, 0), (1, 1), (4, 2), (3, 1), (3, 3), (4, 0), (1, 3), (2, 3)])]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6500
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.78548497 -0.11961172  0.60721199]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.4448
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.10062983 -0.05986528  0.99312123]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.4358
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.81820385 -0.54170417  0.19261114]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.4374
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.81005902 -0.38920446  0.43854792]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.3316
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.58929156  0.20565159  0.78130844]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.3372
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.86553217 -0.49903127 -0.04268318]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running experiment 16/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 2), (4, 3), (5, None)]), ([(0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (2, 3), (2, 3), (2, 3), (5, None)]), ([(0, 0), (0, 3), (1, 3), (2, 0), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 3), (2, 0), (2, 2), (1, 2), (0, 0), (0, 2), (3, 2), (3, 0)]), ([(0, 2), (0, 1), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 1), (3, 3), (4, 0), (3, 1), (3, 3), (4, 0), (1, 2), (0, 2)]), ([(0, 3), (1, 3), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (2, 2), (1, 2), (0, 1), (3, 2), (3, 3), (4, 0), (1, 1), (4, 3)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 0), (0, 2), (0, 0), (0, 3), (0, 2), (0, 3), (1, 3), (2, 0)])]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6528
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.07242825 -0.883552    0.46269861]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5326
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.21292732 -0.11880817  0.96981781]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5186
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.04988779 0.01848132 0.99858382]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5310
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.91349243  0.17262278  0.36841954]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5290
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.65588772 -0.56156591  0.50443535]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5356
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.17460359  0.13392549  0.97548836]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 0), (0, 1), (3, 0), (0, 2), (0, 0), (1, 2), (0, 2), (0, 1), (3, 3)]), ([(0, 3), (1, 0), (1, 2), (0, 1), (0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 2), (0, 1), (0, 2), (0, 3), (1, 1), (2, 0), (2, 0), (2, 0)]), ([(0, 3), (1, 0), (1, 2), (0, 0), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 3), (1, 0), (1, 2), (0, 0), (0, 3), (1, 0), (1, 3), (2, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 2), (0, 2), (0, 1), (1, 3), (2, 2), (1, 1), (4, 2), (3, 0), (4, 1)]), ([(0, 2), (0, 2), (3, 0), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 2), (3, 0), (3, 1), (3, 0), (0, 2), (0, 1), (3, 3), (4, 2), (3, 2)]), ([(0, 0), (0, 3), (1, 0), (1, 0), (1, 0), (1, 3), (2, 1), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 0), (1, 0), (1, 0), (1, 3), (2, 0), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6670
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.26966025 -0.59104451  0.76023005]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6044
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.33778052 -0.51936639  0.78496043]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3574
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.19167425  0.04493086  0.9804296 ]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3638
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.986526   -0.15038921  0.0644169 ]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3250
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.45156003  0.49907051  0.73960947]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3286
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.20576557  0.37837819  0.90249126]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running experiment 18/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 1), (3, 0), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 0), (0, 1), (3, 0), (0, 3), (1, 2), (0, 3), (1, 3), (2, 0), (2, 1)]), ([(0, 2), (0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 2), (0, 0), (0, 2), (0, 1), (3, 0), (3, 2), (3, 2), (3, 3), (4, 1)]), ([(0, 3), (1, 1), (4, 2), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 3), (1, 1), (4, 2), (3, 0), (0, 3), (1, 1), (4, 3), (4, 3), (5, None)]), ([(0, 1), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 1), (1, 1), (4, 1), (4, 3), (5, None)]), ([(0, 3), (1, 3), (2, 2), (1, 0), (1, 1), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (2, 2), (1, 0), (1, 0), (1, 0), (2, 2), (1, 3), (2, 1), (2, 3)]), ([(0, 1), (3, 3), (0, 1), (1, 1)], [(0, 3), (3, 3), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6668
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.96946495 -0.15994674 -0.18588911]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6330
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.4729481  -0.54052781  0.69580873]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5294
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.40253688 -0.21070168  0.89082482]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5344
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.38236831 -0.80190175  0.45907304]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5296
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.3448881  -0.75250919  0.56105447]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.0204
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.65832585 0.36470308 0.65848215]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [([(0, 1), (3, 1), (4, 0), (1, 1), (4, 3), (4, 3), (1, 1), (0, 1), (3, 3), (4, 3)], [(0, 1), (3, 1), (4, 0), (1, 3), (2, 2), (1, 2), (4, 2), (3, 0), (0, 3), (1, 3)]), ([(0, 0), (0, 1), (3, 0), (0, 1), (0, 0), (0, 2), (0, 0), (1, 1), (4, 3), (5, 0)], [(0, 0), (0, 1), (3, 0), (0, 1), (0, 0), (0, 2), (0, 0), (1, 0), (1, 1), (4, 3)]), ([(0, 2), (0, 1), (3, 1), (3, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 1), (3, 2), (0, 2), (0, 1), (1, 1), (2, 0), (2, 0), (2, 1)]), ([(0, 1), (3, 3), (4, 3), (4, 0), (1, 3), (1, 1), (4, 3), (1, 1)], [(0, 1), (3, 3), (4, 3), (4, 0), (1, 3), (1, 3), (2, 1), (5, None)]), ([(0, 2), (0, 2), (0, 1), (3, 1), (3, 2), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0)], [(0, 2), (0, 2), (0, 1), (3, 1), (3, 2), (3, 0), (0, 0), (0, 0), (0, 0), (0, 3)]), ([(0, 3), (1, 3), (2, 0), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (2, 0), (2, 2), (1, 2), (4, 2), (3, 3), (4, 0), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6700
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.61294415 -0.27669819  0.74009295]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5284
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.12827653  0.6547496   0.74488126]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.3952
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.6205968  -0.24147275  0.74602314]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.0030
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.59494264 -0.57715547 -0.55940577]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.0016
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.5673258  0.57679967 0.58774448]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.0024
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.59086778 -0.58202595 -0.55867796]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running experiment 20/50...
Shuffled Demos: [([(0, 1), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 3), (4, 2), (3, 3), (3, 3), (4, 0), (1, 0), (1, 2), (0, 3)]), ([(0, 3), (1, 0), (1, 1), (4, 0), (1, 3), (2, 0), (2, 3), (2, 1), (5, 0)], [(0, 3), (1, 0), (1, 1), (4, 0), (1, 3), (2, 0), (2, 3), (2, 3), (5, None)]), ([(0, 3), (3, 0), (0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (3, 0), (0, 0), (0, 2), (0, 0), (0, 1), (0, 0), (0, 3), (0, 0), (0, 2)]), ([(0, 2), (3, 0), (0, 1), (0, 1), (3, 3), (4, 3), (1, 1), (2, 1), (5, 0), (5, 0)], [(0, 2), (3, 0), (0, 3), (1, 0), (1, 1), (4, 1), (4, 1), (4, 2), (3, 0), (0, 0)]), ([(0, 2), (0, 3), (3, 3), (3, 3), (4, 3), (5, 0)], [(0, 2), (0, 3), (3, 2), (3, 3), (4, 3), (5, None)]), ([(0, 0), (0, 1), (3, 3), (4, 0), (1, 0), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 3), (4, 0), (1, 0), (1, 3), (2, 3), (2, 1), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6670
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.53549636 -0.30931491  0.78585491]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6600
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.53115469 -0.84133012  0.10019148]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5976
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.68810411 -0.70731899  0.161903  ]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5728
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.4296406  -0.8838487   0.18498764]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5604
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.5945856  -0.72366414 -0.35039718]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5736
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.21957396 -0.94088623 -0.25791546]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Shuffled Demos: [([(0, 1), (3, 2), (3, 3), (3, 3), (4, 1), (4, 1), (4, 2), (3, 3), (3, 3), (4, 3)], [(0, 1), (3, 2), (3, 3), (3, 3), (4, 1), (4, 1), (4, 2), (3, 1), (3, 1), (3, 2)]), ([(0, 2), (0, 1), (3, 0), (0, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 0), (0, 3), (0, 2), (0, 1), (0, 1), (3, 3), (4, 0), (1, 3)]), ([(0, 1), (0, 0), (0, 0), (1, 0), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (0, 0), (0, 0), (1, 0), (1, 2), (0, 1), (3, 3), (4, 0), (1, 1), (2, 3)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 2), (1, 2), (1, 3), (2, 3), (5, None)]), ([(0, 0), (0, 2), (0, 3), (1, 1), (4, 0), (1, 3), (1, 0), (1, 2), (0, 1), (3, 3)], [(0, 0), (0, 2), (0, 3), (1, 1), (4, 0), (1, 3), (1, 0), (1, 2), (0, 2), (0, 1)]), ([(0, 2), (0, 1), (3, 1), (3, 0), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 1), (3, 0), (0, 3), (1, 1), (4, 2), (3, 0), (0, 1), (1, 3)])]

Running PBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.49362141  0.60781691 -0.62201006]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6636
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.30401296 -0.91375868 -0.26948319]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6506
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.85312263 -0.51502032 -0.0832817 ]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5130
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.54772105 -0.6937046   0.46773453]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5206
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.75287231 -0.54624061  0.36715729]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.11715283 -0.82718377  0.54958369]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running experiment 22/50...
Shuffled Demos: [([(0, 2), (0, 3), (3, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 2), (0, 3), (3, 0), (0, 3), (3, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 3), (0, 1), (3, 3), (0, 2), (0, 1), (3, 1), (3, 3), (4, 1)]), ([(0, 2), (0, 3), (1, 1), (0, 2), (0, 1), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 2), (0, 3), (1, 1), (0, 2), (0, 1), (3, 1), (3, 2), (3, 0), (0, 0), (0, 3)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 2), (0, 3), (1, 0), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 3), (1, 0), (2, 0), (2, 1), (1, 2), (0, 2), (3, 0), (0, 1), (3, 2)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 3), (1, 0), (1, 0), (1, 3), (2, 2), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6514
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.91987571 -0.02109266  0.39164241]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6404
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.06533076 -0.85879999  0.50812839]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6532
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.95576029 -0.28391711  0.07689823]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6376
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.72628333 -0.25914533  0.63667591]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.28303679 -0.62761015  0.72525559]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2082
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.92842906 -0.0522802   0.3678128 ]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Shuffled Demos: [([(0, 1), (0, 2), (0, 2), (0, 0), (0, 3), (1, 1), (4, 3), (1, 1), (4, 3), (5, 0)], [(0, 1), (0, 2), (0, 2), (0, 0), (0, 3), (1, 3), (2, 2), (2, 2), (1, 0), (1, 1)]), ([(0, 2), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 3), (1, 0), (1, 3), (2, 0), (2, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, 0)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (0, 1), (3, 2), (0, 2), (0, 2), (0, 2), (0, 3), (1, 2), (0, 3), (1, 3)]), ([(0, 2), (0, 1), (3, 2), (3, 2), (3, 2), (3, 3), (0, 1), (3, 3), (0, 1), (3, 3)], [(0, 2), (0, 1), (3, 2), (3, 2), (3, 2), (3, 2), (0, 1), (3, 2), (3, 1), (4, 1)]), ([(0, 0), (0, 3), (1, 0), (1, 3), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 0), (1, 3), (2, 0), (2, 2), (1, 3), (4, 1), (4, 2), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6588
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.80512941 -0.46174818 -0.3722301 ]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6072
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.82624016 -0.41959459 -0.37585579]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.4372
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93348292  0.22926878  0.27576341]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.4282
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.83665315 -0.1621511   0.52318115]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.4234
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.04937022 0.80535571 0.5907324 ]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.3762
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.66971746  0.58186302  0.46142599]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running experiment 24/50...
Shuffled Demos: [([], [(0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 0), (0, 2), (0, 1), (3, 3), (4, 3), (4, 3), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 0), (0, 2), (0, 0), (0, 1), (3, 1), (3, 1), (3, 2), (3, 3), (4, 0)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 3), (1, 1), (2, 1), (2, 3), (2, 1), (5, None)]), ([(0, 0), (0, 0), (0, 1), (3, 2), (3, 2), (3, 0), (4, 3), (1, 1), (0, 1)], [(0, 0), (0, 0), (0, 1), (3, 2), (3, 2), (3, 0), (4, 1), (4, 3), (5, None)]), ([(0, 1), (3, 0), (0, 0), (0, 0), (0, 2), (0, 1), (3, 2), (3, 3), (3, 3), (4, 3)], [(0, 1), (3, 0), (0, 0), (0, 0), (0, 2), (0, 1), (3, 2), (3, 3), (3, 1), (3, 0)]), ([(0, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (3, 2), (3, 0), (0, 1), (3, 3), (4, 0), (1, 1), (4, 0), (1, 0), (2, 1)])]

Running PBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6560
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.30125502 -0.21299582 -0.92945048]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5214
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.4524657  -0.5270595   0.71936296]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.3770
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.29341598 -0.55522257  0.77822552]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.0160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.25804204 -0.93124548  0.25728615]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.0156
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.15502448 -0.97561316 -0.15539106]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.0160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.66808322 -0.32718057  0.66829461]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Shuffled Demos: [([(0, 1), (3, 3), (3, 1), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 3), (3, 1), (3, 1), (3, 0), (0, 3), (0, 2), (0, 0), (0, 3), (1, 1)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 0), (4, 2), (3, 3), (4, 2), (3, 1), (3, 3), (0, 1), (3, 3), (4, 3)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 3), (4, 0), (1, 2), (0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (1, 1), (4, 2), (3, 3), (3, 1), (3, 3), (3, 0), (0, 1), (3, 3), (4, 3)], [(0, 1), (1, 1), (4, 2), (3, 3), (3, 1), (3, 3), (3, 0), (0, 0), (0, 0), (1, 1)]), ([(0, 1), (3, 1), (4, 2), (3, 0), (0, 0), (0, 1), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 1), (3, 1), (4, 2), (3, 0), (0, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 2), (3, 0), (0, 1), (0, 1), (1, 1), (0, 1), (3, 3), (4, 3), (4, 3), (1, 1)], [(0, 2), (3, 0), (0, 0), (0, 1), (3, 2), (3, 0), (0, 3), (1, 1), (4, 1), (3, 3)])]

Running PBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6608
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.93063994 -0.28873323  0.22481644]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.50397888 -0.42014435  0.75464164]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.45372406  0.04504037  0.89000328]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.3272
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.33326945  0.63588968  0.69611478]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.3402
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.38786273  0.49911808  0.77488299]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.0202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.13230556 -0.13291903  0.98225647]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running experiment 26/50...
Shuffled Demos: [([(0, 3), (1, 0), (1, 3), (2, 1), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 3), (2, 2), (1, 1), (4, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 3), (4, 1), (4, 0), (1, 3), (2, 1), (5, None)]), ([(0, 0), (0, 2), (0, 2), (0, 0), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 2), (0, 0), (0, 3), (1, 3), (2, 2), (1, 1), (4, 3), (5, None)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 2), (0, 1), (3, 0), (0, 2), (0, 0), (0, 1), (3, 0), (0, 2), (0, 2)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 2), (0, 3), (1, 2), (0, 1), (3, 0), (0, 1), (3, 3), (4, 3)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 2), (0, 1), (3, 2), (3, 3), (4, 2), (3, 1), (3, 3), (4, 1), (4, 2)])]

Running PBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6592
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.16409549 -0.82537254  0.54021555]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6522
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.70151149 -0.62419183 -0.34389852]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6732
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.54170586 -0.59221407  0.59652096]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.5824
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.41642746 -0.71470627  0.56194583]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.24467657 -0.72420259  0.64472008]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.5982
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.36549593 -0.05196339  0.92936136]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Shuffled Demos: [([(0, 2), (3, 0), (0, 1), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0)], [(0, 2), (3, 0), (0, 1), (3, 2), (3, 1), (3, 3), (4, 3), (5, None)]), ([(0, 0), (0, 1), (3, 0), (4, 0), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 0), (4, 0), (3, 2), (3, 1), (3, 3), (4, 0), (1, 1), (0, 3)]), ([(0, 3), (0, 3), (0, 3), (1, 1), (4, 0), (1, 1), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 3), (0, 3), (0, 3), (1, 1), (4, 0), (1, 0), (2, 3), (2, 3), (2, 3), (5, None)]), ([(0, 1), (3, 3), (4, 2), (3, 2), (3, 0), (0, 1), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 1), (3, 3), (4, 2), (3, 2), (3, 0), (0, 1), (0, 1), (3, 1), (3, 1), (4, 2)]), ([(0, 1), (3, 0), (0, 0), (0, 2), (0, 0), (0, 3), (1, 0), (1, 1), (4, 3), (5, 0)], [(0, 1), (3, 0), (0, 0), (0, 2), (0, 0), (0, 3), (1, 0), (1, 3), (2, 2), (1, 3)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 0), (0, 3), (1, 3), (2, 0), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6590
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.72760137 0.22176829 0.6491649 ]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6238
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.10463434 -0.97025837  0.21828959]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6230
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.39358549 -0.91928684  0.00147004]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6392
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.08348491 -0.95485895 -0.2850871 ]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5324
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.42375565 -0.85840849  0.28907788]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5270
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.0625653  -0.9141146   0.40059965]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running experiment 28/50...
Shuffled Demos: [([(0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 3), (1, 0), (1, 3), (2, 1), (5, None)]), ([(0, 3), (1, 3), (1, 0), (1, 1), (4, 0), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (1, 0), (1, 1), (4, 0), (1, 3), (1, 3), (4, 2), (3, 3), (4, 0)]), ([(0, 1), (3, 2), (3, 0), (3, 3), (3, 3), (0, 1), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 2), (3, 0), (3, 3), (3, 2), (3, 2), (0, 1), (1, 1), (4, 3), (5, None)]), ([(0, 2), (0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 2), (0, 0), (0, 2), (0, 2), (0, 0), (0, 2), (0, 2), (0, 2), (0, 0)]), ([(0, 3), (0, 1), (1, 1), (4, 2), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 3), (0, 1), (1, 1), (4, 2), (3, 0), (3, 3), (4, 3), (5, None)]), ([(0, 3), (1, 3), (2, 1), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (2, 0), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6566
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.64778684 -0.44887269  0.61553678]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6562
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.22760575 -0.2808187   0.93238215]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6148
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.14044478 -0.9606369  -0.23969149]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6072
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.36876169 -0.85938036 -0.35423187]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6244
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.40701996  0.23992505  0.88134597]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.5962
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.59894389  0.29224392  0.74555999]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Shuffled Demos: [([(0, 2), (0, 2), (0, 3), (1, 0), (1, 3), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 2), (0, 3), (1, 0), (1, 3), (2, 2), (1, 2), (0, 2), (3, 1), (3, 2)]), ([(0, 0), (0, 2), (0, 3), (3, 3), (4, 0), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 3), (3, 3), (4, 0), (1, 2), (0, 3), (1, 2), (0, 2), (3, 1)]), ([(0, 1), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 2), (0, 1), (3, 2), (3, 2), (3, 2), (0, 1), (0, 0), (0, 1), (3, 0)]), ([(0, 3), (1, 0), (1, 1), (4, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 1), (4, 1), (4, 0), (1, 1), (4, 1), (4, 1), (5, None)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (3, 3), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 3), (1, 0), (1, 2), (0, 2), (0, 0), (1, 0), (0, 3), (1, 1), (4, 1), (4, 3)]), ([(0, 1), (3, 0), (0, 1), (3, 1), (3, 3), (4, 2), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 0), (0, 1), (3, 1), (3, 3), (4, 2), (3, 3), (4, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6562
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.18569731 -0.96181673  0.20105992]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6556
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.68569605  0.59700613  0.41641879]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6170
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.02859685 0.4618961  0.8864729 ]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6302
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.95100705  0.00916594  0.30903328]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.3826
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.35117177 0.58364287 0.73214711]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.3884
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.63146415 -0.45648585  0.62679637]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running experiment 30/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 2), (3, 1), (3, 0), (0, 1), (3, 1), (3, 3), (4, 3), (5, 0)], [(0, 2), (0, 1), (3, 2), (3, 1), (3, 0), (0, 1), (3, 1), (3, 3), (4, 1), (5, None)]), ([(0, 3), (0, 1), (3, 2), (3, 1), (3, 3), (4, 3), (5, 0)], [(0, 3), (0, 1), (3, 2), (3, 1), (3, 3), (4, 0), (5, None)]), ([(0, 1), (3, 2), (3, 2), (3, 3), (4, 3), (5, 0)], [(0, 1), (3, 2), (3, 2), (3, 3), (4, 1), (5, None)]), ([(0, 3), (0, 1), (3, 0), (4, 2), (3, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 3), (0, 1), (3, 0), (4, 2), (3, 0), (0, 0), (0, 0), (0, 1), (3, 1), (3, 1)]), ([(0, 0), (0, 1), (3, 3), (3, 0), (0, 2), (0, 3), (0, 2), (0, 1), (3, 3), (4, 3)], [(0, 0), (0, 1), (3, 3), (3, 0), (0, 2), (0, 3), (0, 2), (0, 3), (1, 1), (0, 0)]), ([(0, 2), (0, 3), (1, 2), (0, 2), (0, 0), (0, 1), (3, 2), (3, 3), (0, 1), (3, 3)], [(0, 2), (0, 3), (1, 2), (0, 2), (0, 0), (0, 1), (3, 2), (3, 2), (3, 2), (3, 3)])]

Running PBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.22995375  0.94670286  0.22555478]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.06432689 -0.97632503 -0.20652235]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.25744529 0.94821154 0.18605589]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6790
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.17105912 -0.96159845 -0.2146327 ]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.3216
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.06382747  0.47274907  0.87888245]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.3356
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.11752755  0.61596389  0.77895812]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 2), (0, 1), (3, 1), (3, 1), (3, 0), (0, 0), (0, 1), (1, 1), (4, 3), (5, 0)], [(0, 2), (0, 1), (3, 1), (3, 1), (3, 0), (0, 0), (0, 1), (1, 2), (0, 1), (3, 3)]), ([(0, 1), (3, 2), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 2), (3, 0), (0, 3), (0, 0), (0, 3), (1, 2), (1, 1), (4, 2), (3, 3)]), ([(0, 0), (0, 1), (3, 0), (3, 1), (3, 3), (4, 3), (4, 3), (5, 0)], [(0, 0), (0, 1), (3, 0), (3, 1), (3, 2), (3, 3), (4, 0), (5, None)]), ([(0, 2), (0, 3), (1, 1), (4, 3), (5, 0)], [(0, 2), (0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 3), (1, 3), (2, 0), (2, 0), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6744
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.49130072 -0.49088938  0.71947983]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6644
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.12446422 0.45293707 0.8828118 ]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6154
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.23762979 -0.88038557 -0.41043066]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6172
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.03839108 -0.99351355  0.10703713]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6228
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.09207944 -0.91790588  0.38596655]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6122
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.21747301 -0.89809606 -0.38226817]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running experiment 32/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 0), (1, 0), (1, 3), (4, 3), (5, None)]), ([(0, 3), (1, 3), (2, 2), (1, 1), (4, 2), (3, 1), (3, 2), (3, 0), (0, 1), (3, 3)], [(0, 3), (1, 3), (2, 2), (1, 1), (4, 2), (3, 1), (3, 2), (3, 0), (0, 3), (1, 2)]), ([(0, 3), (1, 1), (4, 0), (3, 3), (4, 3), (1, 1), (4, 3)], [(0, 3), (1, 1), (4, 0), (3, 0), (3, 3), (4, 3), (5, None)]), ([(0, 3), (1, 0), (1, 0), (1, 1), (4, 2), (3, 0), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 3), (1, 0), (1, 0), (1, 1), (4, 2), (3, 0), (0, 1), (3, 2), (3, 3), (4, 2)]), ([(0, 2), (0, 2), (0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 2), (0, 2), (0, 2), (0, 1), (3, 2), (3, 2), (3, 1), (4, 3), (5, None)]), ([(0, 1), (3, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 1), (4, 0), (1, 0), (1, 3), (4, 0), (1, 1), (4, 0), (1, 1), (4, 0)])]

Running PBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6546
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.83854707 -0.54318524 -0.04229188]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5670
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.57799167  0.05253629  0.81434978]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.1256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.2146479   0.81641948 -0.53608349]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.0044
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.59003659 -0.55802151 -0.58349706]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.0032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.57943748 0.57153387 0.58103463]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.0014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.58329925 -0.5918549  -0.55630007]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Shuffled Demos: [([(0, 3), (1, 2), (0, 2), (0, 2), (0, 0), (0, 0), (0, 2), (0, 0), (0, 1), (3, 3)], [(0, 3), (1, 2), (0, 2), (0, 2), (0, 0), (0, 0), (0, 2), (0, 0), (0, 0), (0, 3)]), ([(0, 1), (3, 1), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 1), (3, 1), (3, 2), (3, 0), (0, 0), (0, 1), (3, 0), (0, 1), (3, 2)]), ([(0, 1), (1, 2), (4, 1), (4, 3), (1, 1), (4, 3), (5, 0)], [(0, 1), (1, 2), (4, 1), (4, 0), (1, 3), (2, 1), (5, None)]), ([(0, 0), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 2), (4, 3), (1, 0), (2, 3), (2, 1), (5, None)]), ([(0, 2), (0, 3), (1, 1), (4, 3), (4, 3), (5, 0)], [(0, 2), (0, 3), (1, 0), (1, 3), (2, 1), (5, None)]), ([(0, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 1), (3, 1), (4, 0), (1, 2), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.1067994   0.8899892  -0.44329799]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6604
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.00843523 -0.73705738  0.67577752]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6670
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.62706092 -0.64785136 -0.43253118]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6218
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.08955529 -0.74254896  0.66377775]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.3318
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.26357752 0.59718944 0.75755638]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.3256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.0237898  0.63046804 0.77585056]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running experiment 34/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 0), (1, 1), (0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, 0)], [(0, 1), (3, 3), (4, 0), (1, 2), (0, 3), (1, 1), (4, 2), (3, 0), (0, 1), (3, 0)]), ([(0, 3), (1, 1), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 1), (0, 2), (0, 2), (0, 0), (0, 2), (0, 1), (3, 1), (3, 0), (0, 3)]), ([(0, 3), (0, 3), (1, 0), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (0, 3), (1, 0), (1, 3), (4, 0), (1, 0), (1, 0), (1, 1), (4, 0), (1, 0)]), ([(0, 0), (0, 1), (3, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 1), (3, 1), (3, 1), (4, 2), (3, 3), (4, 2), (3, 3), (4, 1)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 2), (3, 0), (0, 3), (1, 2), (0, 2), (0, 2), (0, 1), (3, 0)]), ([(0, 1), (3, 0), (0, 0), (0, 1), (0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, 0)], [(0, 1), (3, 0), (0, 0), (0, 2), (0, 1), (3, 2), (3, 1), (3, 1), (3, 3), (4, 0)])]

Running PBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6650
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.3822783   0.41675817  0.82472779]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6540
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.89773808 -0.33393655  0.2873199 ]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5516
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.06233707  0.4232009   0.90388887]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5502
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.21140508 -0.60770615  0.76550711]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5472
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.83946575  0.06199088  0.53986516]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.4782
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.12924363 -0.05049758  0.99032625]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 0), (0, 3), (1, 1), (4, 0), (1, 2), (0, 1), (3, 2), (3, 1), (3, 2)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (3, 1), (3, 1), (3, 2), (3, 3), (4, 1), (5, None)]), ([(0, 3), (1, 2), (0, 2), (0, 0), (0, 2), (0, 3), (1, 2), (0, 1), (3, 3), (4, 3)], [(0, 3), (1, 2), (0, 2), (0, 0), (0, 2), (0, 3), (1, 2), (0, 2), (3, 0), (0, 1)]), ([(0, 0), (0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 2), (0, 1), (3, 0), (0, 3), (1, 0), (1, 1), (0, 3), (1, 0)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 0), (0, 2), (3, 1), (3, 0), (0, 2), (0, 2), (3, 2), (3, 2), (3, 3)]), ([(0, 1), (3, 1), (3, 1), (3, 0), (3, 3), (4, 3), (1, 3), (4, 1), (4, 3), (5, 0)], [(0, 1), (3, 1), (3, 1), (3, 0), (3, 3), (4, 3), (1, 3), (4, 1), (4, 2), (3, 1)])]

Running PBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6566
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.41373741  0.18535363  0.89132788]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6456
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.83295677 -0.54905073 -0.06874821]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6576
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.12618161 -0.96889461  0.21288832]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5640
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.06634866 -0.78698492  0.61339432]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5674
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.14936698 -0.97766119  0.14787865]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5612
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.21712056 -0.76931402  0.6008449 ]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running experiment 36/50...
Shuffled Demos: [([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 1), (4, 1), (4, 2), (3, 1), (4, 1), (4, 3), (5, None)]), ([(0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 3), (1, 1), (4, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3)], [(0, 3), (1, 1), (4, 1), (4, 3), (5, None)]), ([(0, 2), (0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 2), (0, 2), (0, 2), (3, 1), (4, 1), (5, None)]), ([(0, 1), (1, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 1), (1, 2), (0, 0), (1, 0), (1, 3), (2, 2), (5, None)]), ([(0, 3), (1, 1), (4, 1), (4, 2), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 1), (4, 1), (4, 2), (1, 3), (1, 0), (1, 1), (4, 0), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6682
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.27791694  0.3951941   0.87554771]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5976
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.63906828 -0.31520305  0.7015973 ]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.1868
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93081421  0.11778523  0.34599357]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.0732
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.73819046  0.10299165  0.66668401]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.0738
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.85249973 -0.02975281  0.52188023]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.0730
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.75120954  0.09160412  0.65367646]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 37/50...
Shuffled Demos: [([(0, 0), (0, 3), (1, 3), (2, 1), (1, 1), (4, 3)], [(0, 0), (0, 3), (1, 3), (2, 3), (2, 1), (5, None)]), ([(0, 2), (3, 1), (3, 1), (4, 2), (3, 2), (3, 2), (3, 3), (4, 3), (1, 1), (4, 3)], [(0, 2), (3, 1), (3, 1), (4, 2), (3, 2), (3, 2), (3, 1), (3, 1), (3, 1), (4, 0)]), ([(0, 1), (0, 1), (3, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 0), (0, 1), (3, 3), (0, 2), (0, 3), (3, 1), (3, 0), (0, 2)]), ([(0, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (0, 3), (1, 1), (4, 0), (1, 0), (1, 2), (1, 2), (0, 0), (0, 3), (3, 0)]), ([(0, 3), (3, 3), (4, 0), (1, 2), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (3, 3), (4, 0), (1, 2), (4, 3), (4, 2), (3, 1), (4, 0), (1, 2), (0, 0)]), ([(0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 2), (1, 0), (1, 3), (2, 2), (2, 3), (2, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6570
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.1434452   0.95276935 -0.2676827 ]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5376
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.78057382  0.28653123 -0.5555217 ]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.3334
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.86842507 0.05041344 0.49325084]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.1224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.24296231 -0.96568225 -0.09179931]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.1240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.68986811 -0.62768624  0.36068265]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.1246
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.34477999 -0.93863606 -0.0094395 ]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running experiment 38/50...
Shuffled Demos: [([(0, 0), (0, 0), (1, 1), (4, 2), (4, 0), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 0), (1, 1), (4, 2), (4, 0), (1, 3), (2, 2), (1, 1), (4, 3), (5, None)]), ([(0, 2), (0, 3), (1, 0), (1, 0), (1, 3), (2, 1), (5, 0)], [(0, 2), (0, 3), (1, 0), (1, 0), (1, 3), (2, 2), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 0), (0, 3), (0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 3), (1, 0), (1, 2), (0, 1), (3, 1), (3, 1), (3, 1), (3, 3), (4, 3), (5, 0)], [(0, 3), (1, 0), (1, 2), (0, 1), (3, 1), (3, 1), (3, 1), (3, 0), (4, 2), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 1), (3, 0), (3, 0), (0, 3), (1, 0), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 1), (3, 0), (3, 0), (0, 3), (1, 0), (1, 0), (1, 3), (2, 0), (2, 1)])]

Running PBIRL with 1 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6632
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.38885369 -0.41939728  0.82030405]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6648
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.52608201 0.0424255  0.84937495]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6532
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.74188731 -0.61735377  0.26168214]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.5946
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.39763741 0.15227169 0.90481922]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.5870
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.22548889  0.11498721  0.96743615]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.50603274  0.32995369  0.79690742]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 39/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (1, 1)], [(0, 3), (1, 1), (2, 1), (5, None)]), ([(0, 3), (1, 1), (0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 1), (0, 3), (1, 2), (0, 2), (0, 0), (0, 3), (1, 0), (1, 0), (0, 2)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (4, 3), (5, 0)], [(0, 2), (0, 2), (0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 0), (0, 2), (0, 2), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 2), (0, 3), (1, 0), (1, 0), (1, 3), (2, 3), (5, None)]), ([(0, 3), (1, 2), (0, 2), (0, 3), (3, 1), (3, 3), (4, 1), (4, 3), (5, 0), (5, 0)], [(0, 3), (1, 2), (0, 2), (0, 3), (3, 1), (3, 3), (4, 1), (4, 1), (4, 0), (1, 3)]), ([(0, 2), (3, 1), (3, 2), (3, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 2), (3, 1), (3, 2), (3, 1), (3, 3), (0, 2), (0, 2), (0, 1), (3, 1), (3, 1)])]

Running PBIRL with 1 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6618
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.82808715 0.55728571 0.06086304]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2394
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.53367465  0.78978292  0.30238108]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2460
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.90768555  0.06235102 -0.41499312]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2398
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.43044585  0.7885114   0.43927912]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.1778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.74867103  0.62937658  0.208271  ]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.0160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.2002514  0.69090823 0.69465473]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running experiment 40/50...
Shuffled Demos: [([(0, 0), (0, 3), (1, 3), (4, 2), (3, 2), (3, 1), (3, 2), (3, 3), (4, 3), (5, 0)], [(0, 0), (0, 3), (1, 3), (4, 2), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (3, 0)]), ([(0, 1), (3, 2), (3, 0), (0, 0), (0, 3), (1, 2), (1, 1), (0, 2), (3, 3), (4, 3)], [(0, 1), (3, 2), (3, 0), (0, 0), (0, 3), (1, 2), (1, 1), (0, 2), (3, 2), (3, 3)]), ([(0, 1), (3, 3), (4, 2), (3, 3), (4, 3), (1, 2), (1, 2), (0, 2), (0, 1), (0, 1)], [(0, 1), (3, 3), (4, 2), (3, 3), (4, 3), (1, 2), (1, 2), (0, 2), (0, 0), (0, 2)]), ([(0, 3), (1, 0), (1, 0), (1, 1), (4, 2), (3, 3), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 0), (1, 1), (4, 2), (3, 3), (3, 3), (4, 2), (3, 0), (0, 2)]), ([(0, 1), (3, 2), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 2), (0, 3), (0, 0), (0, 2), (0, 0), (0, 1), (3, 3), (4, 1), (4, 0)]), ([(0, 0), (0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 2), (0, 0), (0, 3), (3, 0), (0, 2), (0, 0), (0, 3), (1, 0)])]

Running PBIRL with 1 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6558
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.92547263 -0.08203893  0.36982433]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6612
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.28062601 -0.7695363   0.57364007]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6694
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.78936142 -0.59289161 -0.1593364 ]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6584
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.74765106 -0.58235587  0.31918573]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6536
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.28304827 -0.9385015   0.19773367]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6450
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.37562191 -0.92321342 -0.08114905]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 41/50...
Shuffled Demos: [([(0, 1), (3, 2), (3, 3), (4, 1), (4, 0), (1, 1), (4, 3), (1, 1), (4, 3), (5, 0)], [(0, 1), (3, 2), (3, 3), (4, 1), (4, 0), (1, 0), (1, 2), (0, 2), (0, 3), (1, 1)]), ([(0, 0), (0, 1), (3, 0), (0, 1), (3, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 0), (0, 2), (0, 1), (3, 1), (3, 1), (3, 1), (4, 1), (4, 1)]), ([(0, 3), (1, 0), (1, 0), (1, 3), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 0), (1, 3), (2, 0), (2, 0), (2, 2), (1, 3), (4, 0), (3, 1)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 2), (0, 1), (0, 3), (3, 2), (3, 1), (3, 1), (3, 1), (3, 1)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 0), (0, 3), (3, 3), (4, 2), (1, 3), (2, 0), (2, 1), (2, 0)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, 0)], [(0, 0), (0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6722
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.76163454  0.64406769 -0.07134165]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5366
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.66606075  0.34779668  0.65984889]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5338
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94107961 -0.19935999  0.27317532]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.04443842  0.3390664   0.9397123 ]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5344
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.19694581 -0.92598971  0.32211086]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.3298
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.92318602  0.1654497   0.34692069]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running experiment 42/50...
Shuffled Demos: [([(0, 0), (0, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (3, 2), (3, 1), (3, 3), (4, 3), (4, 3), (5, None)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 0), (0, 2), (0, 1), (1, 0), (1, 0), (1, 2), (0, 0), (0, 1), (1, 0)]), ([(0, 3), (1, 3), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (2, 2), (2, 2), (1, 3), (4, 0), (1, 1), (4, 2), (3, 3), (3, 2)]), ([(0, 1), (3, 1), (3, 1), (3, 2), (3, 1), (3, 2), (0, 3), (1, 1), (2, 1), (1, 1)], [(0, 1), (3, 1), (3, 1), (3, 2), (3, 1), (3, 2), (0, 3), (1, 2), (0, 0), (0, 2)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 2), (3, 1), (3, 1), (3, 1), (3, 2), (3, 2), (3, 2), (3, 0)]), ([(0, 3), (1, 2), (0, 1), (3, 0), (3, 2), (0, 2), (0, 1), (1, 2), (0, 1), (0, 1)], [(0, 3), (1, 2), (0, 1), (3, 0), (3, 2), (0, 2), (0, 1), (1, 2), (0, 0), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6630
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.72350604 -0.10991943  0.68151062]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5648
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.74810325 -0.03941239  0.66241089]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5790
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.08225971 -0.99580359  0.04010684]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.4104
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.69054349 -0.54267781  0.47817411]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.4046
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.13257509 -0.98468291 -0.11324049]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.3960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.12553867 -0.99198178 -0.01456687]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 43/50...
Shuffled Demos: [([(0, 1), (0, 3), (1, 2), (1, 1), (4, 2), (3, 2), (3, 2), (3, 3), (4, 3), (5, 0)], [(0, 1), (0, 3), (1, 2), (1, 1), (4, 2), (3, 2), (3, 2), (3, 1), (3, 3), (4, 1)]), ([(0, 2), (0, 3), (0, 3), (1, 0), (1, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 3), (0, 3), (1, 0), (1, 3), (1, 3), (2, 2), (1, 1), (4, 0), (5, None)]), ([(0, 3), (1, 3), (2, 2), (1, 1), (4, 3), (4, 3), (5, 0)], [(0, 3), (1, 3), (2, 2), (1, 0), (1, 3), (2, 1), (5, None)]), ([(0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 0), (2, 3), (2, 3), (2, 1), (2, 0), (2, 2), (1, 2), (0, 0), (0, 3)]), ([(0, 1), (1, 1), (2, 1), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (3, 1), (3, 3), (4, 2), (3, 1), (3, 1), (3, 3), (4, 0), (1, 1)]), ([(0, 1), (3, 3), (4, 3), (5, 0)], [(0, 3), (3, 3), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6590
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.54628497 -0.50550787  0.66785816]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5998
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.41371057 -0.90977272  0.03401713]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.3294
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.62679675  0.1998391   0.75312029]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.3292
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.55465267  0.34867125  0.75550564]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.3266
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.93366793 -0.35733531 -0.02399321]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.3272
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.84574388 -0.24989005  0.47145758]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running experiment 44/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 2), (0, 0), (0, 3), (1, 0), (1, 3), (2, 2), (1, 0), (1, 3), (2, 0)]), ([(0, 1), (3, 3), (3, 0), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 3), (3, 0), (0, 0), (0, 3), (1, 3), (2, 3), (2, 3), (2, 1), (1, 2)]), ([(0, 1), (3, 1), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 1), (3, 1), (3, 3), (4, 2), (3, 3), (3, 3), (3, 2), (3, 3), (3, 3)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 0), (0, 2), (0, 0), (0, 2), (0, 3), (1, 1), (2, 2), (1, 2), (0, 1)]), ([(0, 0), (0, 0), (0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 0), (0, 3), (1, 0), (1, 1), (4, 0), (1, 3), (2, 2), (1, 0), (1, 1)]), ([(0, 1), (3, 0), (0, 0), (0, 0), (0, 3), (1, 1), (4, 3), (4, 3), (1, 1), (4, 3)], [(0, 1), (3, 0), (0, 0), (0, 0), (0, 3), (1, 0), (2, 0), (2, 2), (1, 3), (2, 3)])]

Running PBIRL with 1 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6530
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.16045726 -0.85672867  0.49017288]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6380
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.58620582 -0.7476161  -0.31214244]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5484
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.36264359 -0.43846043  0.82233939]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5570
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.98011186  0.03163201  0.19590853]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5538
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.43736703 -0.84478811 -0.30829065]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5596
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.11914419 -0.78713182  0.60516787]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 45/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 1), (0, 2), (0, 2), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3)], [(0, 0), (0, 0), (0, 1), (0, 2), (0, 2), (0, 1), (3, 2), (3, 2), (3, 2), (3, 2)]), ([(0, 1), (3, 0), (0, 1), (0, 2), (0, 2), (3, 0), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 1), (3, 0), (0, 1), (0, 2), (0, 2), (3, 0), (3, 3), (4, 1), (4, 0), (1, 0)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 3), (1, 2), (0, 1), (3, 3), (4, 1), (4, 2), (3, 1), (3, 2), (3, 2)]), ([(0, 3), (1, 3), (1, 1), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (1, 1), (0, 0), (0, 3), (1, 1), (4, 0), (3, 1), (4, 2), (3, 2)]), ([(0, 3), (3, 1), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (3, 1), (3, 1), (3, 2), (3, 3), (0, 1), (0, 0), (0, 0), (0, 1), (3, 0)]), ([(0, 0), (0, 3), (1, 0), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 3), (1, 0), (1, 1), (4, 1), (4, 2), (3, 0), (0, 3), (1, 1), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 45
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.80015407 -0.55199591 -0.23463585]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6476
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.48960174 -0.82455504  0.28354739]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6346
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.44583941 -0.88797944 -0.11278183]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.56306177 -0.79553024  0.22381483]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5870
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.13005778 -0.9824437   0.1337511 ]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5956
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.0805198  -0.99674101 -0.00488993]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running experiment 46/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 2), (0, 1), (3, 0), (4, 3), (5, None)]), ([(0, 1), (0, 1), (3, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (0, 0), (1, 3), (2, 0), (2, 3), (2, 2), (1, 1), (4, 0), (1, 1), (4, 1)]), ([(0, 1), (3, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 1), (4, 2), (3, 3), (4, 0), (1, 3), (4, 3), (1, 2), (0, 2), (0, 3)]), ([(0, 3), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (3, 2), (3, 3), (4, 0), (3, 3), (3, 2), (3, 3), (4, 0), (1, 3), (2, 3)]), ([(0, 3), (1, 3), (2, 3), (2, 3), (2, 2), (1, 2), (0, 3), (1, 1), (4, 3), (5, 0)], [(0, 3), (1, 3), (2, 3), (2, 3), (2, 2), (1, 2), (0, 3), (1, 3), (1, 0), (2, 3)]), ([(0, 3), (1, 1), (4, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 3), (1, 1), (4, 1), (3, 2), (3, 3), (4, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 46
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.76636723  0.64221239 -0.01563699]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6486
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.73192024  0.53216337  0.42555248]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.65218998  0.13242013  0.74640012]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6094
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.34840552 0.43164873 0.83204145]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5420
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.24255146  0.42120501  0.87393085]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5246
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.31020833  0.42729728  0.84922778]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 47/50...
Shuffled Demos: [([(0, 1), (3, 3), (0, 3), (1, 2), (1, 1), (2, 3), (2, 3), (2, 2), (1, 1), (4, 3)], [(0, 1), (3, 3), (0, 3), (1, 2), (1, 1), (2, 3), (2, 3), (2, 2), (1, 3), (2, 2)]), ([(0, 3), (3, 1), (3, 2), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (3, 1), (3, 2), (3, 3), (4, 2), (3, 2), (3, 0), (0, 1), (3, 2), (3, 1)]), ([(0, 2), (0, 1), (3, 0), (0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 0), (0, 2), (0, 0), (0, 2), (0, 2), (0, 0), (0, 3), (1, 2)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 2), (0, 1), (3, 2), (3, 3), (4, 0), (1, 0), (1, 1), (4, 2), (3, 3), (4, 3)]), ([(0, 1), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 2), (0, 2), (3, 0), (0, 2), (0, 1), (3, 1), (3, 2), (3, 2), (3, 0)]), ([(0, 2), (0, 1), (1, 3), (2, 2), (1, 1), (4, 1), (4, 3), (1, 1), (4, 3), (5, 0)], [(0, 2), (0, 1), (1, 3), (2, 2), (1, 1), (4, 1), (4, 2), (3, 3), (4, 1), (4, 3)])]

Running PBIRL with 1 demonstrations for experiment 47
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.27282123  0.96176893 -0.02385573]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6612
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.5662397  -0.58713144  0.57848879]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5948
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.87428255 -0.44403322  0.19612376]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6004
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.46005976 -0.76339928 -0.45339449]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.35687145 -0.8298758  -0.42889268]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5296
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.44833247 -0.73785752  0.50454363]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running experiment 48/50...
Shuffled Demos: [([(0, 1), (3, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 1), (3, 1), (3, 1), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, 0)], [(0, 0), (0, 1), (3, 3), (3, 2), (3, 3), (4, 3), (5, None)]), ([(0, 3), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 0), (1, 1), (0, 3), (1, 1), (4, 1), (4, 0), (1, 1), (4, 1), (4, 2)]), ([(0, 1), (3, 2), (0, 3), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 2), (0, 3), (0, 0), (0, 2), (0, 3), (0, 1), (3, 0), (4, 1), (4, 2)]), ([(0, 1), (3, 3), (0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 3), (0, 1), (1, 1), (4, 2), (3, 1), (3, 2), (3, 0), (0, 0), (0, 0)]), ([(0, 1), (3, 1), (3, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 1), (3, 1), (4, 1), (4, 1), (4, 0), (1, 2), (4, 2), (3, 2), (3, 2)])]

Running PBIRL with 1 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6576
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.37920843 -0.68989899  0.61663632]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.2061826  -0.91839666 -0.33769262]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.4630
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.28945013 -0.44025157  0.84993951]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.4676
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.1203604  -0.64782581  0.75222011]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.4526
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.71782258 0.35854998 0.59680202]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.4660
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.64178784 -0.70346357  0.30536431]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 49/50...
Shuffled Demos: [([(0, 0), (0, 1), (1, 3), (2, 0), (2, 2), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (1, 3), (2, 0), (2, 2), (1, 2), (0, 3), (1, 1), (2, 2), (1, 1)]), ([(0, 3), (1, 2), (0, 1), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 2), (0, 0), (0, 0), (0, 3), (1, 1), (0, 1), (0, 1), (0, 0), (0, 0)]), ([(0, 2), (0, 0), (0, 0), (0, 3), (1, 1), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 2), (0, 0), (0, 0), (0, 3), (1, 2), (0, 0), (0, 1), (3, 2), (3, 2), (3, 1)]), ([(0, 0), (0, 1), (0, 1), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (0, 2), (0, 0), (0, 3), (1, 1), (4, 2), (3, 3), (4, 2), (3, 3)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 3), (4, 0), (1, 3), (2, 0), (2, 0), (2, 1), (5, None)]), ([(0, 1), (1, 1), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 2), (0, 0), (0, 0), (0, 3), (1, 0), (1, 2), (0, 3), (1, 1), (4, 1)])]

Running PBIRL with 1 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6426
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.60848711 -0.35413946  0.71016102]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6086
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.39016765  0.18988862  0.90095034]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5702
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.00915385 -0.04836415  0.99878782]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.76838383 -0.34378048  0.53981595]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5788
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.63532363 -0.72158183 -0.27510644]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5742
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.8405556   0.11920422  0.52844739]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running experiment 50/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (4, 3), (5, 0)], [(0, 2), (0, 3), (1, 3), (4, 3), (5, None)]), ([(0, 1), (1, 0), (1, 1), (4, 3), (1, 1), (4, 3), (5, 0), (5, 0)], [(0, 1), (1, 0), (1, 1), (4, 2), (3, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 1), (3, 0), (0, 2), (0, 0), (0, 1), (3, 1), (3, 3), (4, 0), (1, 1), (4, 2)]), ([(0, 0), (0, 1), (3, 1), (3, 0), (0, 0), (0, 1), (3, 3), (4, 3), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 1), (3, 0), (0, 0), (0, 1), (3, 1), (3, 3), (4, 2), (4, 3)]), ([(0, 3), (1, 3), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 3), (1, 3), (2, 0), (2, 1), (1, 0), (1, 2), (0, 0), (0, 3), (3, 3), (4, 3)]), ([(0, 0), (0, 1), (3, 3), (4, 0), (1, 1), (2, 1), (5, 0), (5, 0), (5, 0), (5, 0)], [(0, 0), (0, 1), (3, 3), (4, 0), (1, 2), (0, 3), (3, 0), (0, 2), (0, 0), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6688
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.38864041  0.29868049  0.87163559]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.1874
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.66276899 -0.25490763  0.70410181]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.1822
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.44846551 -0.00505236  0.89378586]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.1870
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.57498528 -0.14302406  0.80556567]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.1940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.7733443  -0.4232564   0.47200912]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.1896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.82888014 -0.47501238  0.29550117]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 0), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 0), (0, 3), (1, 3), (2, 3), (2, 0), (2, 1), (5, None)]), ([(0, 3), (1, 1), (2, 1), (5, None)], [(0, 3), (1, 0), (1, 2), (0, 2), (3, 3), (4, 2), (4, 3), (5, None)]), ([(0, 3), (1, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 2), (1, 0), (1, 0), (1, 1), (4, 3), (5, None)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (1, 1), (2, 1), (5, None)], [(0, 2), (0, 3), (1, 2), (0, 2), (0, 1), (1, 3), (2, 0), (2, 0), (2, 0), (2, 0)]), ([(0, 1), (3, 1), (3, 2), (3, 3), (0, 1), (3, 2), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 2), (3, 3), (0, 1), (3, 2), (3, 2), (3, 1), (3, 0), (0, 0)]), ([(0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 2), (0, 1), (3, 3), (3, 1), (3, 3), (4, 2), (3, 3), (4, 2)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6630
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.45935461 -0.8833812  -0.09290317]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6390
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.56031704 -0.42497358 -0.71094463]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.4390
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.39797195 -0.70163168  0.59104257]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.4088
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.96832309 -0.23469614 -0.08525321]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2996
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.87857111 -0.10338189  0.46628853]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2738
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.4789844  -0.10354544  0.87169506]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 0), (0, 2), (3, 3), (4, 1), (3, 3), (3, 0), (0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (3, 3), (4, 1), (3, 3), (3, 0), (0, 2), (0, 0), (0, 1), (3, 1)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 3), (4, 0), (1, 3), (2, 3), (2, 0), (2, 0), (2, 2), (1, 1)]), ([(0, 1), (3, 1), (3, 1), (3, 3), (3, 2), (3, 3), (4, 0), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (3, 3), (3, 2), (3, 3), (4, 0), (3, 3), (4, 1), (4, 3)]), ([(0, 3), (1, 2), (1, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (1, 3), (4, 2), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 2), (3, 1), (3, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 1), (3, 2), (0, 3), (1, 1), (4, 0), (1, 0), (1, 0), (1, 0)]), ([(0, 2), (0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 2), (0, 1), (3, 0), (0, 1), (3, 3), (4, 2), (4, 1), (4, 1)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6524
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.17746266 -0.87292649  0.45442969]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.4812
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.64058138 -0.22452998  0.73433084]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.4782
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.76787331 -0.48288569  0.42094179]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.4272
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.2696626  -0.84398614  0.46364802]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.3046
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.73893502 -0.59648762  0.31333298]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2964
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.6772348  -0.57782201  0.45549396]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 0), (1, 1), (2, 1), (5, None)], [(0, 1), (3, 3), (4, 0), (1, 1), (2, 3), (2, 0), (2, 3), (5, None)]), ([(0, 2), (0, 3), (1, 1), (4, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 1), (4, 2), (3, 0), (4, 3), (1, 1), (4, 2), (3, 1), (3, 0)]), ([(0, 0), (0, 2), (0, 1), (3, 0), (4, 2), (3, 2), (3, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 1), (3, 0), (4, 2), (3, 2), (3, 1), (3, 3), (3, 2), (3, 1)]), ([(0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 3), (1, 0), (1, 3), (2, 2), (5, None)]), ([(0, 3), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 0), (0, 3), (3, 0), (0, 2), (0, 0), (0, 3), (1, 0), (1, 3), (2, 2)]), ([(0, 3), (1, 0), (1, 3), (2, 2), (1, 0), (1, 2), (4, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 3), (2, 2), (1, 0), (1, 2), (4, 1), (4, 1), (4, 2), (3, 1)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6618
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.13812773 -0.6337172  -0.76113287]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6354
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.2581765  -0.96565346  0.02929647]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.4398
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.32175939 -0.78110068  0.53511926]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2408
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.80148157 -0.24558887  0.54526453]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2304
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.65131813 -0.38512498  0.65380688]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2322
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.66718993 -0.21419529  0.71342692]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running experiment 4/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 0), (0, 1), (3, 1), (3, 2), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 0), (0, 1), (3, 1), (3, 2), (3, 0), (0, 2), (0, 0), (0, 3)]), ([(0, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 1), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 3), (1, 1), (0, 3), (1, 0), (0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (0, 3), (1, 0), (0, 2), (0, 0), (0, 2), (0, 0), (0, 0), (0, 2)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 0), (1, 3), (2, 0), (2, 0), (2, 3), (2, 2), (5, None)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (2, 0), (1, 0), (1, 1), (4, 3), (5, None)]), ([(0, 3), (1, 3), (1, 3), (2, 1), (5, None)], [(0, 3), (1, 3), (1, 3), (2, 0), (2, 2), (1, 3), (2, 2), (1, 1), (4, 3), (4, 0)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6652
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.86495417 0.24064599 0.4403905 ]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4404
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.61761023 -0.71322967  0.33145291]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4442
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.80464423 -0.43932076  0.39943077]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4116
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.30068515 -0.70196281  0.64562888]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.1128
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.8998368  -0.29249787  0.32363364]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.1122
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.90046807 -0.29674995  0.31795711]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 0), (0, 2), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 3), (1, 1), (4, 2), (3, 2), (0, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 2), (3, 2), (0, 3), (0, 1), (3, 0), (0, 3), (1, 3), (1, 3)]), ([(0, 1), (3, 2), (3, 2), (3, 0), (4, 1), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 2), (3, 0), (4, 1), (4, 1), (4, 0), (1, 1), (4, 1), (3, 3)]), ([(0, 2), (0, 3), (1, 3), (2, 3), (2, 2), (1, 0), (2, 0), (2, 2), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 3), (2, 3), (2, 2), (1, 0), (2, 0), (2, 2), (1, 3), (2, 2)]), ([(0, 2), (0, 1), (3, 2), (3, 2), (3, 3), (4, 1), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 2), (3, 2), (3, 3), (4, 1), (4, 0), (1, 3), (2, 3), (2, 2)])]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6580
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.15415626  0.53056553 -0.83350829]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6266
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.38232143  0.22477814 -0.8962729 ]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83460422  0.38431026  0.39464088]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2804
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.65901234  0.03593452  0.75127321]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2262
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.62603374  0.29333125  0.72252234]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2260
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.65681093 -0.0452084   0.75269888]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running experiment 6/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (3, 2), (3, 0), (3, 1), (3, 2), (0, 0), (0, 2), (0, 3), (1, 1)]), ([], [(0, 1), (1, 1), (4, 3), (5, None)]), ([], [(0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 1), (3, 1), (3, 3), (4, 1), (4, 1), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (3, 3), (4, 1), (4, 1), (4, 0), (1, 2), (0, 3), (1, 2)]), ([(0, 1), (0, 3), (1, 1), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 1), (0, 3), (1, 0), (1, 1), (4, 0), (5, None)]), ([(0, 0), (0, 1), (0, 1), (3, 0), (0, 0), (0, 0), (0, 3), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (0, 1), (3, 0), (0, 0), (0, 0), (0, 3), (3, 1), (3, 3), (4, 0)])]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6628
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.6492265  -0.60606513 -0.45955413]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.27287676 -0.71922901 -0.6389428 ]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5616
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.78260159 -0.41837537 -0.46097375]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.4618
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.29035097 -0.90511555  0.31058357]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.0212
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.93880568  0.08043944 -0.33492295]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.0028
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.9998176  -0.01877941  0.00347846]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [([(0, 3), (1, 1), (0, 1), (3, 3)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 2), (0, 3), (1, 1), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 3), (2, 2), (1, 1), (2, 0), (1, 0), (0, 3), (3, 1), (3, 2)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (4, 0), (5, None)]), ([(0, 1), (3, 0), (0, 1), (3, 2), (3, 2), (3, 2), (3, 2), (3, 0), (0, 1), (0, 1)], [(0, 1), (3, 0), (0, 1), (3, 2), (3, 2), (3, 2), (3, 2), (3, 0), (0, 3), (1, 1)]), ([(0, 1), (1, 2), (0, 2), (0, 0), (0, 2), (0, 3), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (1, 2), (0, 2), (0, 0), (0, 2), (0, 3), (3, 1), (3, 2), (3, 2), (3, 0)]), ([(0, 1), (3, 0), (0, 0), (0, 2), (3, 3), (4, 1), (4, 1), (4, 2), (3, 3), (0, 1)], [(0, 1), (3, 0), (0, 0), (0, 2), (3, 3), (4, 1), (4, 1), (4, 2), (3, 1), (3, 2)])]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6484
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.06117815  0.95363481 -0.29468268]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.3016
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.84479229  0.38433848 -0.37230353]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.96734678  0.17966797 -0.17877256]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2964
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.64879532  0.74477017  0.15614745]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.0148
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.19467823  0.69355676  0.69359888]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.0190
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.99889601  0.03333443  0.03309945]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running experiment 8/50...
Shuffled Demos: [([(0, 2), (0, 3), (1, 1), (4, 0), (1, 2), (0, 3), (1, 1), (4, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 1), (4, 0), (1, 2), (0, 3), (1, 3), (4, 3), (5, None)]), ([(0, 1), (3, 1), (3, 2), (3, 0), (0, 3), (1, 3), (2, 3), (2, 1), (5, None)], [(0, 1), (3, 1), (3, 2), (3, 0), (0, 3), (1, 3), (2, 3), (2, 3), (2, 2), (1, 2)]), ([(0, 2), (0, 2), (0, 1), (1, 2), (0, 1), (3, 3), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 1), (1, 2), (0, 1), (3, 3), (3, 0), (0, 2), (0, 1), (3, 0)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (2, 3), (2, 1), (2, 2), (2, 1), (5, None)]), ([(0, 0), (0, 1), (3, 2), (3, 3), (4, 0), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 2), (3, 3), (4, 0), (3, 2), (3, 2), (0, 2), (0, 1), (3, 1)]), ([(0, 1), (3, 1), (3, 3), (3, 3), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 3), (3, 3), (0, 3), (1, 0), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6524
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.73354718  0.48708506  0.47397962]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.3048
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.59454795  0.38482472  0.70599056]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2900
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.6064375   0.67660396  0.41766092]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.0134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.67343588 -0.00473313  0.73923049]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.0170
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.78264226 -0.0044808   0.62245564]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.0142
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.96328522 -0.00458317  0.26844101]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [([(0, 0), (0, 1), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 2), (1, 2), (0, 0), (0, 3), (1, 1), (4, 0), (1, 3), (4, 3)]), ([(0, 1), (3, 2), (3, 0), (0, 0), (0, 2), (0, 1), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 0), (0, 0), (0, 2), (0, 1), (0, 0), (0, 0), (0, 1), (3, 2)]), ([(0, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 2), (0, 1), (3, 2), (3, 3), (4, 0), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 2), (3, 0), (0, 1), (3, 3), (4, 2), (3, 3), (4, 0)]), ([(0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (1, 1), (4, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 2), (0, 2), (0, 1), (3, 3), (4, 2), (3, 3), (4, 3), (1, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 2), (3, 2), (3, 2), (3, 3), (4, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6486
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.93811439 -0.33066301  0.10297261]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.4820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.53704207 -0.07827381  0.83991608]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.3038
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.68701635 -0.20664753  0.6966386 ]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.3050
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.01403138 -0.49555739  0.86846186]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.2466
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.45525911 -0.39639754  0.79725036]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.2466
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.65152463 -0.65267125  0.38669872]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running experiment 10/50...
Shuffled Demos: [([(0, 2), (0, 1), (0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 1), (0, 0), (0, 3), (1, 2), (0, 2), (0, 1), (3, 1), (3, 0), (0, 0)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3)], [(0, 1), (3, 1), (3, 3), (4, 3), (5, None)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 3), (4, 1), (4, 2), (3, 2), (3, 2), (3, 1), (3, 2), (0, 1)]), ([(0, 0), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 2), (3, 0), (0, 3), (1, 1), (4, 2), (3, 1), (3, 2), (3, 1), (3, 1)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 2), (0, 1), (3, 1), (3, 3), (0, 3), (1, 1), (2, 0), (2, 2)])]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6494
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.96555686 -0.25865577  0.02823379]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.1674
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.25317708 -0.423357   -0.86986793]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.1512
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.63031547 -0.354145   -0.69085724]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.1662
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.06275226 -0.51695909 -0.85370689]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.1670
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.64393665 -0.33398449 -0.68833128]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.1386
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.08315449 -0.41191703 -0.90741925]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 2), (4, 1), (4, 3), (1, 0), (1, 0), (1, 3), (2, 1), (5, None)]), ([(0, 3), (1, 2), (0, 0), (0, 1), (1, 0), (1, 1), (4, 3), (4, 0), (1, 1), (4, 3)], [(0, 3), (1, 2), (0, 0), (0, 1), (1, 0), (1, 1), (4, 3), (4, 0), (1, 0), (1, 0)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 1), (3, 0), (0, 1), (3, 1), (3, 2), (3, 0), (0, 1), (3, 2)]), ([(0, 2), (0, 3), (1, 0), (0, 3), (1, 2), (0, 0), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 2), (0, 3), (1, 0), (0, 3), (1, 2), (0, 0), (0, 2), (0, 3), (1, 0), (1, 0)]), ([(0, 3), (1, 1), (0, 1), (3, 1), (3, 3), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (0, 1), (3, 1), (3, 3), (3, 3), (0, 2), (0, 1), (0, 1), (3, 2)]), ([(0, 2), (0, 2), (0, 0), (0, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 0), (0, 3), (0, 0), (0, 1), (3, 2), (3, 2), (0, 0), (1, 1)])]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6684
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98195062  0.16146308 -0.098502  ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5362
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.36809429  0.83227702  0.41451364]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2132
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.68722322 -0.34647045 -0.63850018]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.73956542 -0.36888667 -0.562997  ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2140
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.85829288 -0.50332084  0.10000726]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2012
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.62975597 -0.08804524  0.77178718]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running experiment 12/50...
Shuffled Demos: [([(0, 3), (1, 0), (1, 3), (2, 3), (2, 2), (1, 2), (0, 1), (3, 3), (0, 1), (0, 1)], [(0, 3), (1, 0), (1, 3), (2, 3), (2, 2), (1, 2), (0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 2), (3, 1), (3, 2), (3, 3), (4, 2), (3, 2), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 1), (3, 2), (3, 3), (4, 2), (3, 2), (3, 1), (3, 2), (3, 3)]), ([(0, 3), (1, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 3), (1, 2), (0, 3), (1, 3), (2, 3), (2, 0), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 3), (0, 0), (0, 2), (0, 0), (0, 0), (0, 2), (0, 1), (3, 2)]), ([(0, 2), (0, 0), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 0), (0, 2), (0, 0), (0, 0), (0, 1), (0, 1), (3, 3), (4, 2)]), ([(0, 3), (1, 0), (1, 1), (4, 2), (1, 1), (4, 1), (4, 0), (1, 3), (2, 1), (5, None)], [(0, 3), (1, 0), (1, 1), (4, 2), (1, 1), (4, 1), (4, 0), (1, 3), (2, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.39462676 -0.91053214  0.12329208]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6616
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.74769112 0.58504653 0.31413143]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.4464
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.54195021 -0.68753966  0.4833003 ]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.4396
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.29059273 -0.72595969  0.62332848]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.4314
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.63401146 -0.5122191   0.57936263]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.4432
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.32037754 -0.87245212  0.36903325]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 2), (0, 3), (1, 0), (1, 2), (1, 1), (0, 2), (0, 0), (0, 3)]), ([(0, 1), (3, 3), (4, 0), (1, 3), (2, 1), (5, None)], [(0, 1), (3, 3), (4, 0), (1, 3), (2, 0), (2, 0), (2, 2), (1, 1), (4, 0), (1, 1)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 0), (0, 1), (1, 1), (4, 0), (1, 2), (0, 1), (3, 2), (3, 0)]), ([(0, 2), (0, 0), (0, 2), (0, 0), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 2), (0, 0), (0, 0), (0, 0), (0, 1), (3, 0), (4, 3), (1, 3)]), ([(0, 0), (0, 0), (0, 3), (1, 3), (1, 3), (1, 2), (1, 2), (0, 1), (3, 3), (4, 3)], [(0, 0), (0, 0), (0, 3), (1, 3), (1, 3), (1, 2), (1, 2), (0, 2), (0, 0), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6550
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.12794893 -0.80583394 -0.57815287]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5818
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.34674802 -0.61384846  0.70919383]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5782
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.43965265 -0.88184509  0.17045462]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5682
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.11963354 -0.92965736  0.34846091]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5348
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.3308794  -0.87713585 -0.34806828]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5298
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.40760201 -0.90846556 -0.09247122]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running experiment 14/50...
Shuffled Demos: [([(0, 1), (3, 0), (0, 3), (1, 1), (2, 1), (5, None)], [(0, 1), (3, 0), (0, 3), (1, 2), (0, 2), (0, 3), (0, 0), (0, 0), (0, 0), (0, 0)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 2), (1, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 1), (3, 3), (4, 3), (4, 1), (4, 1), (4, 1), (4, 2), (3, 0), (0, 2), (0, 3)]), ([(0, 1), (1, 1), (4, 3), (1, 1), (4, 3)], [(0, 2), (0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 2), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 3), (1, 1), (4, 1), (4, 2), (4, 1), (4, 1), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 1), (4, 2), (4, 1), (4, 1), (4, 2), (3, 3), (4, 0), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6644
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.90002555 -0.08010501  0.42841241]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5286
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.06465802 -0.48052841  0.87459236]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5042
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93795114 -0.33530074  0.08843688]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.3032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.1931619  -0.97698041 -0.09054149]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.3108
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.1119265  -0.92467538  0.36393392]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.13188973 -0.98984619 -0.05300579]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [([(0, 3), (1, 3), (2, 1), (5, None)], [(0, 3), (1, 3), (2, 2), (1, 1), (4, 2), (3, 2), (3, 0), (0, 0), (1, 3), (1, 1)]), ([(0, 2), (0, 2), (0, 3), (1, 0), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 3), (1, 0), (1, 2), (0, 0), (1, 0), (1, 2), (0, 1), (1, 3)]), ([(0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 0), (0, 3), (0, 1), (3, 2), (3, 0), (0, 0), (0, 3), (1, 3)]), ([(0, 2), (0, 1), (1, 1), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 0), (0, 2), (0, 3), (1, 3), (2, 2), (1, 0), (1, 0), (1, 2), (0, 1), (3, 3)], [(0, 0), (0, 2), (0, 3), (1, 3), (2, 2), (1, 0), (1, 0), (1, 2), (0, 3), (1, 0)]), ([(0, 0), (0, 2), (0, 3), (1, 3), (2, 0), (2, 1), (5, None)], [(0, 0), (0, 2), (0, 3), (1, 3), (2, 0), (2, 3), (2, 3), (2, 2), (1, 0), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6606
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.1711544  -0.5585588   0.81161459]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.71523522 -0.1580783  -0.6807715 ]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5472
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.9991021  0.0233848 -0.0353291]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.3552
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.07843051 -0.50075679  0.86202743]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.0186
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.6869841  -0.68661237 -0.23794181]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.0188
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.6542955  -0.65446949 -0.37890247]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running experiment 16/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 0), (0, 0), (0, 2), (0, 3), (1, 1), (4, 2), (3, 2), (3, 3)]), ([(0, 0), (0, 2), (0, 2), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 2), (0, 3), (1, 3), (2, 0), (2, 1), (5, None)]), ([(0, 2), (0, 1), (3, 0), (3, 1), (3, 0), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 0), (3, 1), (3, 0), (0, 3), (1, 0), (2, 2), (1, 3), (1, 0)]), ([(0, 0), (0, 0), (0, 2), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 2), (0, 2), (0, 2), (0, 3), (3, 2), (3, 1), (3, 2), (3, 1)]), ([(0, 1), (3, 2), (3, 2), (3, 2), (3, 0), (4, 2), (3, 3), (4, 0), (1, 1), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 2), (3, 2), (3, 0), (4, 2), (3, 3), (4, 0), (1, 2), (0, 3)]), ([(0, 2), (0, 3), (1, 3), (2, 0), (2, 1), (5, None)], [(0, 2), (0, 3), (1, 3), (2, 0), (2, 0), (2, 0), (2, 3), (2, 3), (2, 2), (1, 1)])]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6630
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.31857317 -0.86089429  0.3967016 ]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.40899192 -0.68048446  0.60800207]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.4354
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.08631933 -0.92682747  0.365431  ]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.4354
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.67654679 -0.72420808 -0.13344326]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.3528
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.59133823 -0.53405877  0.60423532]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.3534
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.61861982 -0.70296862  0.35091969]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [([], [(0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 0), (0, 2), (0, 2), (0, 2), (0, 0), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 2), (0, 2), (0, 0), (1, 1), (4, 1), (3, 2), (3, 1), (3, 0)]), ([(0, 1), (3, 1), (3, 1), (4, 0), (1, 1), (4, 2), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (4, 0), (1, 1), (4, 2), (3, 0), (0, 1), (3, 1), (3, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 2), (0, 3), (1, 0), (1, 3), (2, 0), (1, 3), (1, 1), (4, 2), (3, 0)]), ([(0, 2), (0, 3), (0, 3), (3, 2), (3, 1), (4, 1), (4, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (0, 3), (3, 2), (3, 1), (4, 1), (4, 3), (4, 1), (4, 3), (5, None)]), ([(0, 2), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6706
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.11514938 -0.99119693 -0.06533963]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5764
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.20198841 -0.51092009  0.8355605 ]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3718
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.39238424 -0.59748902  0.69931501]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3496
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.10270865 -0.86342432  0.49391231]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3416
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.01187965 -0.92952043  0.36857923]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.3428
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.36407302 -0.75705953  0.54250502]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running experiment 18/50...
Shuffled Demos: [([(0, 2), (3, 1), (3, 3), (4, 0), (1, 2), (4, 0), (1, 2), (0, 1), (1, 1), (4, 3)], [(0, 2), (3, 1), (3, 3), (4, 0), (1, 2), (4, 0), (1, 2), (0, 3), (1, 0), (1, 0)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 3), (4, 3), (4, 1), (5, None)]), ([(0, 2), (0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 0), (0, 3), (0, 3), (1, 1), (2, 0), (2, 2), (5, None)]), ([(0, 1), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 2), (0, 0), (1, 2), (0, 3), (1, 2), (0, 0), (0, 2), (0, 1)]), ([(0, 2), (3, 2), (3, 0), (0, 1), (3, 1), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 2), (3, 2), (3, 0), (0, 1), (3, 1), (3, 2), (3, 2), (3, 1), (3, 3), (4, 0)]), ([(0, 1), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 1), (0, 3), (1, 0), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6596
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.16813928  0.34185541  0.92458859]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.1626
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.86411091 -0.4906082  -0.1123207 ]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.0040
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.02390548 -0.01635531 -0.99958043]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.0026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.03442447 -0.00570124  0.99939104]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.0034
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.0122781  0.00189389 0.99992283]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.0028
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.04096325 -0.01246739  0.99908287]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 2), (3, 3), (4, 2), (4, 1), (3, 1), (3, 2), (3, 1), (3, 1)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 0), (0, 2), (0, 1), (1, 2), (0, 3), (1, 2), (0, 3), (1, 0)]), ([(0, 2), (0, 0), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 3), (1, 0), (1, 0), (1, 2), (1, 1), (4, 0), (1, 1), (4, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 0), (0, 2), (0, 0), (0, 1), (3, 2), (3, 1), (3, 1), (3, 3), (4, 3)]), ([(0, 2), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 0), (0, 0), (0, 3), (1, 1), (4, 0), (1, 2), (0, 0), (0, 2)]), ([(0, 3), (3, 3), (4, 3), (5, None)], [(0, 3), (3, 0), (0, 1), (1, 1), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6510
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.28946815 -0.00417686  0.95717853]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5726
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.42559374 -0.82059798  0.3814301 ]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.4980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.55906153 -0.44403645 -0.70020128]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.4828
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.03618698 -0.61669034  0.78637366]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.4876
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.7899143  -0.53752313 -0.29513435]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.4752
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.5645406  -0.80792863 -0.16895336]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running experiment 20/50...
Shuffled Demos: [([(0, 3), (1, 0), (1, 0), (1, 3), (4, 1), (4, 0), (1, 2), (1, 3), (2, 1), (5, None)], [(0, 3), (1, 0), (1, 0), (1, 3), (4, 1), (4, 0), (1, 2), (1, 3), (2, 0), (2, 1)]), ([(0, 1), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 1), (4, 1), (4, 1), (4, 3), (5, None)]), ([(0, 1), (3, 0), (4, 2), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (4, 2), (3, 0), (0, 1), (0, 1), (3, 0), (3, 3), (3, 3), (4, 0)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 1), (3, 1), (3, 3), (4, 1), (4, 1), (5, None)]), ([(0, 0), (0, 1), (3, 3), (3, 0), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 3), (3, 0), (3, 3), (4, 1), (4, 2), (3, 3), (4, 1), (5, None)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 3), (0, 0), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6512
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.10121209  0.45713941  0.88361738]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.3240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.87760847 -0.37487533  0.29878397]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2332
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89230902 -0.39694257  0.21499118]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.78496724 -0.28546724  0.54984988]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2204
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.84932847 -0.51839925 -0.09951567]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2092
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.92870027 -0.32343886  0.18139213]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Shuffled Demos: [([(0, 1), (3, 1), (3, 0), (4, 2), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 0), (4, 2), (3, 2), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1)]), ([(0, 2), (0, 1), (3, 3), (3, 3), (0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 1), (4, 1), (3, 1), (3, 3), (3, 3), (4, 2), (3, 0), (0, 3)]), ([(0, 1), (0, 2), (0, 2), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (0, 2), (0, 2), (3, 0), (0, 1), (3, 1), (3, 3), (4, 2), (4, 1), (3, 3)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 2), (3, 1), (3, 0), (0, 1), (1, 2), (1, 1), (4, 1), (4, 3)]), ([(0, 1), (3, 2), (3, 1), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 0), (3, 3), (4, 0), (5, None)]), ([(0, 1), (3, 1), (4, 0), (1, 1), (4, 2), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (4, 0), (1, 1), (4, 2), (3, 0), (0, 0), (0, 2), (0, 0), (0, 2)])]

Running PBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6546
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.52629241 0.01982063 0.85007261]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5702
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.86949008 -0.38450693  0.3100668 ]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5700
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.13644482 0.09194389 0.9863717 ]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5592
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.31784122 -0.66280048  0.6779915 ]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5362
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.48911367 -0.25067454  0.8354221 ]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.59422674 -0.64261125  0.48367899]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running experiment 22/50...
Shuffled Demos: [([(0, 0), (1, 3), (2, 0), (2, 1), (5, None)], [(0, 0), (1, 3), (2, 0), (2, 2), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 1), (4, 0), (1, 0), (1, 0), (1, 3), (2, 2), (1, 2), (0, 2)]), ([(0, 2), (0, 1), (3, 0), (0, 2), (0, 1), (3, 1), (3, 3), (4, 2), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 0), (0, 2), (0, 1), (3, 1), (3, 3), (4, 2), (3, 2), (3, 0)]), ([(0, 3), (1, 2), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 3), (1, 3), (2, 1), (1, 2), (1, 2), (1, 1), (4, 0), (3, 0)]), ([(0, 0), (0, 0), (0, 2), (0, 3), (1, 0), (1, 1), (4, 1), (4, 3), (1, 1), (4, 3)], [(0, 0), (0, 0), (0, 2), (0, 3), (1, 0), (1, 1), (4, 1), (4, 0), (1, 2), (0, 2)]), ([(0, 1), (3, 1), (3, 3), (0, 1), (3, 0), (0, 1), (3, 2), (3, 1), (3, 3), (4, 3)], [(0, 1), (3, 1), (3, 3), (0, 1), (3, 0), (0, 1), (3, 2), (3, 1), (3, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.75715046  0.64105844 -0.12556776]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6494
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.62551529  0.5909986  -0.50936361]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.4842
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.35771973 -0.24127882  0.90212035]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.4754
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.22825652 -0.03690548  0.9729013 ]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.4674
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.49505305 -0.74765938  0.44263747]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.4626
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.73102923 -0.5954357   0.33324555]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 2), (0, 2), (0, 3), (1, 0), (1, 3), (1, 0), (1, 0), (1, 1)]), ([(0, 1), (3, 0), (3, 1), (3, 0), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 1), (3, 0), (3, 1), (3, 0), (0, 3), (1, 0), (1, 3), (1, 0), (1, 3), (2, 1)]), ([(0, 2), (0, 0), (1, 0), (1, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (1, 0), (1, 1), (0, 0), (0, 1), (3, 3), (4, 0), (1, 2), (0, 3)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 0), (0, 3), (3, 1), (3, 0), (0, 3), (1, 2), (0, 0), (0, 1), (0, 1), (3, 3)], [(0, 0), (0, 3), (3, 1), (3, 0), (0, 3), (1, 2), (0, 0), (0, 3), (1, 2), (0, 1)])]

Running PBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6574
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.41178849  0.80255536  0.43166554]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6398
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.08599654 -0.92805947  0.36236751]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.5176
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.61865408  0.17453544  0.76603166]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.5300
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.26096343 -0.03196112  0.96481945]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.4262
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.49427674 -0.29554089  0.81752436]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.2464
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.59534975 -0.18213473  0.78255071]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running experiment 24/50...
Shuffled Demos: [([(0, 0), (0, 3), (0, 0), (0, 0), (1, 0), (1, 0), (1, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (0, 0), (0, 0), (1, 0), (1, 0), (1, 2), (0, 2), (0, 2), (0, 2)]), ([(0, 2), (0, 3), (1, 0), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 0), (1, 0), (1, 0), (1, 1), (4, 0), (1, 3), (4, 2), (3, 1)]), ([(0, 2), (0, 1), (3, 0), (0, 1), (3, 0), (0, 2), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 2), (0, 1), (3, 0), (0, 1), (3, 0), (0, 2), (0, 3), (1, 0), (1, 3), (2, 3)]), ([(0, 0), (0, 0), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 0), (0, 2), (0, 2), (0, 3), (1, 2), (0, 0), (0, 0), (0, 0)]), ([(0, 0), (1, 0), (1, 1), (4, 0), (1, 1), (4, 3), (5, None)], [(0, 0), (1, 0), (1, 1), (4, 0), (1, 1), (4, 0), (1, 0), (1, 1), (0, 3), (1, 2)]), ([(0, 1), (0, 1), (3, 3), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 0), (0, 1), (1, 0), (1, 2), (0, 0), (0, 1), (3, 2), (3, 1)])]

Running PBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6438
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.82456815  0.34205961  0.45064686]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.4896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.6032499  -0.01307542  0.79744504]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.3530
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.80701884 -0.04111034  0.58909297]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.2848
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.85351712  0.26752538  0.44714505]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.2766
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.5845365  -0.17272448  0.79276941]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.2678
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.86608602 -0.26753803  0.42227764]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 1), (3, 0), (0, 3), (1, 1), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 1), (3, 0), (0, 3), (1, 2), (0, 2), (0, 2), (0, 0), (1, 2)]), ([(0, 3), (1, 3), (2, 1), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 2), (1, 1), (2, 3), (2, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 3), (3, 1), (4, 3), (1, 1), (4, 1), (4, 2), (3, 3), (4, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 2), (0, 1), (3, 1), (3, 1), (3, 3), (4, 2), (1, 2), (0, 2)]), ([(0, 1), (3, 3), (4, 2), (3, 1), (3, 1), (3, 2), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 1), (3, 3), (4, 2), (3, 1), (3, 1), (3, 2), (3, 1), (3, 1), (4, 0), (1, 0)]), ([(0, 2), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 2), (0, 3), (1, 1), (4, 0), (1, 0), (1, 1), (4, 2), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6508
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.56393276 -0.26295109  0.78283879]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5784
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.87218408 -0.35307587  0.33857401]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5566
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.64688073 -0.50092355  0.57499646]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5544
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.2426106  -0.56465382  0.78886384]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.4242
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.24096879 -0.34868029  0.90573511]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.4172
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.70927067 -0.37253338  0.59845969]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running experiment 26/50...
Shuffled Demos: [([(0, 3), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (4, 0), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (4, 0), (1, 2), (4, 3), (5, None)]), ([(0, 1), (1, 1), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 1), (1, 0), (1, 3), (2, 1), (5, None)]), ([(0, 1), (0, 0), (1, 1), (4, 3), (5, None)], [(0, 1), (0, 0), (1, 3), (2, 0), (2, 3), (2, 0), (2, 0), (2, 0), (2, 3), (2, 3)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 0), (0, 3), (1, 0), (1, 2), (0, 2), (3, 0), (0, 1), (1, 1)]), ([(0, 2), (0, 0), (0, 3), (1, 3), (4, 0), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 3), (1, 3), (4, 0), (3, 0), (0, 2), (3, 3), (4, 2), (4, 3)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 1), (4, 0), (1, 1), (4, 0), (1, 0), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.80460548 0.47833394 0.35186171]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6666
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.88774063  0.41999761 -0.18846373]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.0628
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.1907135  0.13498697 0.97232036]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.0482
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.05671061  0.13944557  0.98860449]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.0470
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.00178373  0.13927016  0.99025282]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.0452
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.09179489  0.13397148  0.98672455]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (1, 3), (4, 3), (4, 0), (5, None)]), ([(0, 2), (0, 0), (0, 1), (3, 1), (3, 1), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 1), (3, 1), (3, 1), (3, 2), (3, 1), (3, 1), (3, 3), (4, 2)]), ([(0, 0), (0, 3), (1, 1), (4, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 0), (1, 0), (0, 2), (0, 3), (3, 1), (3, 0), (0, 0), (1, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 1), (3, 1), (3, 2), (3, 1), (3, 2), (0, 2), (0, 2), (0, 3)]), ([(0, 3), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (3, 0), (0, 1), (3, 2), (3, 2), (3, 3), (4, 2), (1, 1), (4, 1), (5, None)]), ([(0, 3), (1, 2), (1, 0), (1, 0), (1, 1), (4, 1), (4, 2), (3, 3), (3, 3), (4, 3)], [(0, 3), (1, 2), (1, 0), (1, 0), (1, 1), (4, 1), (4, 2), (3, 1), (3, 1), (3, 3)])]

Running PBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6550
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.29806603 -0.62218909 -0.72390426]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5426
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.08952754 -0.79659477 -0.59784746]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5506
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.59395635 -0.63074099  0.49938128]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5436
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.65109532 -0.15539018  0.74291909]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5356
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.33037008 -0.80303015 -0.49598204]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5374
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.36074632 -0.87526839 -0.32212938]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running experiment 28/50...
Shuffled Demos: [([(0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 3), (4, 0), (5, None)]), ([(0, 3), (1, 0), (1, 2), (0, 1), (3, 3), (4, 2), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 2), (0, 1), (3, 3), (4, 2), (3, 0), (0, 2), (0, 1), (3, 1)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 2), (3, 1), (3, 1), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (0, 1)], [(0, 2), (0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 2), (0, 3), (1, 3), (2, 1), (5, None)], [(0, 2), (0, 3), (1, 3), (2, 2), (5, None)]), ([(0, 1), (3, 3), (4, 3), (4, 3), (4, 3), (1, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 2), (0, 2), (0, 0), (0, 0), (1, 2), (0, 2), (0, 0), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.77927558 0.57831058 0.24142585]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6558
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.55348254  0.11371926  0.82506061]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6140
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.87915043 -0.16750506  0.44613515]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.1248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.94094165 -0.15480315  0.30110597]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.1266
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.97540467 -0.10680682  0.19281607]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.1202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.96849518 -0.1251256   0.21531528]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Shuffled Demos: [([(0, 3), (1, 0), (1, 1), (0, 2), (0, 1), (3, 2), (3, 3), (4, 1), (4, 3), (4, 3)], [(0, 3), (1, 0), (1, 1), (0, 2), (0, 1), (3, 2), (3, 3), (4, 1), (4, 0), (1, 2)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (3, 3), (4, 0), (1, 2), (0, 1), (3, 1), (3, 1), (3, 2), (3, 2)]), ([(0, 1), (0, 2), (0, 2), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 1), (0, 2), (0, 2), (0, 3), (1, 3), (2, 2), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 2), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 0), (0, 1), (3, 0), (3, 2), (3, 2), (3, 2), (0, 3), (3, 2)]), ([(0, 1), (3, 1), (3, 3), (4, 3), (4, 3), (1, 1)], [(0, 1), (3, 1), (3, 2), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 1), (3, 3), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6540
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.11125146  0.74978895  0.65225735]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.3474
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.76344478 -0.1846156  -0.6189258 ]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.3442
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.91198246  0.03515119 -0.40872043]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.2682
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.99196121 -0.07524006  0.10174428]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.0388
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.53906552 -0.26605253 -0.7991398 ]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.0396
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.55343599 -0.27694023 -0.78550157]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running experiment 30/50...
Shuffled Demos: [([(0, 0), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 1), (1, 1), (4, 0), (1, 1), (4, 2), (3, 2), (3, 2), (3, 1)]), ([(0, 0), (0, 1), (0, 3), (1, 1), (2, 3), (2, 1), (5, None)], [(0, 0), (0, 1), (0, 3), (1, 1), (2, 3), (2, 2), (1, 0), (1, 0), (1, 0), (1, 2)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (0, 2), (3, 2), (3, 3), (4, 3), (5, None)]), ([(0, 0), (0, 3), (1, 1), (4, 2), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 1), (4, 2), (3, 0), (0, 1), (3, 1), (3, 2), (3, 2), (3, 2)]), ([(0, 0), (1, 1), (4, 3), (5, None)], [(0, 0), (1, 0), (2, 0), (2, 0), (2, 2), (1, 2), (1, 0), (1, 1), (0, 3), (3, 3)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 1), (4, 2), (3, 3), (4, 0), (3, 3), (4, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6568
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.19409794 -0.92742959 -0.31968789]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5410
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.63864528 -0.1662778   0.75132143]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.4394
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.28227827 -0.76866228 -0.57400112]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.4366
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.77554481 -0.38313143 -0.50173754]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.4310
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.48124105 -0.87627034 -0.02360814]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.4346
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.11858467 -0.57375583  0.81039615]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 3), (1, 1), (4, 2), (4, 0), (3, 3), (3, 2), (3, 2), (3, 0)]), ([(0, 1), (3, 2), (3, 2), (3, 2), (3, 2), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 2), (3, 2), (3, 2), (3, 1), (3, 2), (3, 3), (4, 2), (4, 0)]), ([(0, 0), (0, 2), (0, 0), (0, 3), (1, 1), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 0), (0, 3), (1, 0), (1, 1), (4, 2), (1, 1), (4, 1), (4, 3)]), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 3), (1, 2), (0, 2), (0, 0), (0, 3), (1, 0), (1, 2), (1, 0)]), ([(0, 2), (3, 2), (0, 1), (0, 0), (0, 3), (1, 3), (2, 3), (2, 1), (2, 1), (5, None)], [(0, 2), (3, 2), (0, 1), (0, 0), (0, 3), (1, 3), (2, 3), (2, 3), (2, 3), (2, 0)]), ([(0, 1), (3, 1), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 2), (3, 2), (3, 2), (3, 2), (3, 0), (0, 0), (0, 1), (3, 1)])]

Running PBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6640
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.74814909 -0.64590737 -0.15190988]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6226
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.67027599 -0.39853721  0.62601772]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.5590
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.19173066 -0.98040629  0.04519812]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.5020
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.13975575  0.12740292  0.98195561]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.4934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.31006189 -0.43251551  0.84663567]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.4784
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.65447387 -0.29933642  0.69430661]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running experiment 32/50...
Shuffled Demos: [([(0, 1), (3, 3), (0, 2), (0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 3), (0, 2), (0, 1), (3, 1), (4, 2), (3, 0), (0, 1), (3, 2), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 2), (0, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 3), (1, 2), (0, 3), (1, 2), (0, 3), (3, 1), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 3), (1, 2), (0, 3), (3, 1), (3, 2), (3, 1), (3, 1), (3, 1)]), ([(0, 0), (0, 0), (0, 3), (3, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 3), (3, 1), (3, 1), (3, 2), (3, 3), (4, 3), (5, None)]), ([(0, 0), (0, 0), (1, 3), (1, 1), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 0), (1, 3), (1, 0), (1, 1), (4, 3), (5, None)]), ([(0, 2), (3, 0), (0, 0), (0, 3), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 2), (3, 0), (0, 0), (0, 3), (0, 0), (0, 1), (3, 3), (4, 1), (4, 0), (1, 3)])]

Running PBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6550
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.52248371 -0.6515664  -0.54997455]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6234
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.43482525 -0.87130636  0.22749117]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5662
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.82880076 -0.10801164  0.54901983]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5708
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.04473824 -0.99548413  0.08372478]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.0174
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.84599429 -0.00568314  0.53316166]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.0196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.53290056 -0.00600647  0.84615655]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Shuffled Demos: [([(0, 1), (3, 0), (0, 1), (3, 2), (3, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 2), (3, 0), (0, 2), (0, 0), (1, 2), (0, 1), (3, 3)]), ([(0, 3), (1, 3), (1, 3), (2, 0), (2, 0), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 3), (1, 3), (2, 0), (2, 0), (1, 3), (1, 3), (2, 2), (5, None)]), ([(0, 2), (0, 3), (0, 0), (0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (0, 0), (0, 1), (3, 3), (3, 0), (0, 2), (0, 3), (3, 0), (0, 2)]), ([(0, 2), (3, 2), (3, 3), (4, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (3, 2), (3, 2), (3, 0), (0, 1), (3, 1), (3, 2), (0, 0), (0, 0), (0, 2)]), ([(0, 2), (0, 0), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 0), (1, 2), (1, 1), (2, 3), (2, 0), (2, 0), (2, 1), (5, None)]), ([(0, 0), (0, 3), (1, 0), (1, 2), (4, 2), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 0), (1, 2), (4, 2), (3, 1), (3, 1), (3, 3), (4, 2), (1, 2)])]

Running PBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6568
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.22680927 -0.67822358  0.69897806]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.5626
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.61166148  0.28837659  0.73668797]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.4122
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.63368204 -0.68528633  0.35892857]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.3586
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.40074586 -0.48755761  0.775687  ]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.3544
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.42403763 -0.74804206  0.51051461]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.3534
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.34951011 -0.33086332  0.87656839]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running experiment 34/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 2), (0, 0), (0, 2), (0, 1), (1, 3), (2, 2), (1, 0), (2, 3)]), ([(0, 0), (0, 3), (1, 2), (4, 2), (4, 0), (1, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 2), (4, 2), (4, 0), (1, 0), (1, 1), (4, 3), (5, None)]), ([(0, 3), (1, 1), (4, 1), (3, 3), (0, 1), (1, 1), (4, 1), (4, 1), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 1), (3, 3), (0, 1), (1, 1), (4, 1), (4, 1), (4, 2), (3, 3)]), ([(0, 1), (3, 3), (3, 3), (3, 2), (3, 2), (0, 0), (0, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 3), (3, 3), (3, 2), (3, 2), (0, 0), (0, 3), (0, 1), (3, 2), (0, 1)]), ([(0, 1), (1, 1), (4, 3), (1, 1)], [(0, 1), (1, 0), (2, 1), (5, None)]), ([(0, 0), (0, 0), (0, 1), (3, 3), (3, 0), (0, 1), (3, 3), (4, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 1), (3, 3), (3, 0), (0, 1), (3, 3), (4, 1), (3, 0), (0, 1)])]

Running PBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6614
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.59699638 -0.51619713  0.61411387]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.91597846 -0.1742585  -0.36141034]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2096
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.50284525 -0.01722616  0.86420479]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2074
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.61700015 -0.07965124  0.78292177]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.0020
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.21311667 0.1100414  0.97081006]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.0034
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.23006371 0.08765289 0.96922013]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (4, 3), (4, 3), (5, None)], [(0, 3), (3, 2), (3, 3), (4, 3), (5, None)]), ([(0, 3), (1, 2), (0, 2), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 2), (3, 1), (3, 2), (3, 3), (3, 1), (3, 0), (3, 2), (3, 3)]), ([(0, 2), (0, 3), (1, 1), (4, 2), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 1), (4, 2), (3, 3), (0, 1), (3, 1), (3, 0), (0, 1), (3, 1)]), ([(0, 0), (0, 2), (0, 3), (0, 0), (0, 2), (3, 0), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 0), (0, 2), (0, 3), (0, 0), (0, 2), (3, 0), (0, 1), (3, 0), (0, 3), (1, 1)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 1), (0, 0), (0, 1), (3, 3), (3, 3), (4, 1), (4, 2), (3, 3)]), ([(0, 0), (0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (1, 1), (4, 3)], [(0, 0), (0, 3), (1, 2), (0, 0), (0, 3), (1, 3), (2, 3), (2, 0), (2, 2), (1, 3)])]

Running PBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6604
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.61529116 0.77771886 0.12872514]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.0920
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.00933257  0.1944085   0.98087626]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.0888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.02709758 0.19285309 0.98085341]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.0960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.04264236  0.19203696  0.98046083]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.0768
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.19236827  0.18609507  0.96351599]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.0708
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.19857166  0.18881128  0.9617274 ]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running experiment 36/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 1), (3, 3), (4, 1), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 1), (3, 3), (4, 1), (4, 2), (3, 2), (3, 1), (3, 1), (3, 3)]), ([], [(0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 3), (1, 1), (4, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 1), (5, None)]), ([(0, 0), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 1), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6634
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.66743947 -0.43215856  0.6064351 ]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5878
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.10381774 -0.83410616 -0.54174605]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.89012547 -0.44360261 -0.10437132]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.0026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.99998636 -0.00498352 -0.00156274]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.0040
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.99980498 -0.01702556  0.01000645]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.0034
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.99995113 -0.00263519 -0.00952871]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 37/50...
Shuffled Demos: [([(0, 0), (0, 3), (1, 0), (0, 3), (1, 0), (1, 1), (0, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 0), (0, 3), (1, 0), (1, 1), (0, 3), (0, 0), (1, 1), (4, 2)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 2), (0, 0), (0, 1), (0, 3), (3, 0), (0, 0), (0, 1), (3, 1)]), ([(0, 2), (0, 1), (3, 2), (3, 3), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 2), (3, 3), (0, 2), (0, 0), (0, 1), (3, 0), (3, 2), (3, 2)]), ([(0, 3), (1, 0), (1, 0), (2, 2), (1, 0), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 0), (2, 2), (1, 0), (1, 0), (0, 3), (1, 0), (1, 1), (4, 3)])]

Running PBIRL with 1 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6570
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.72815218 -0.46782518  0.50093312]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6570
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.59548256  0.6144191  -0.51758061]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.3006
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.59046244 -0.46102641  0.66242641]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.3030
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.90263211 -0.37934512  0.20335328]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.2972
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.89747088 -0.44051165  0.02225985]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.3036
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.8305113  -0.54561863  0.11203258]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running experiment 38/50...
Shuffled Demos: [([(0, 0), (0, 3), (1, 2), (0, 1), (3, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 2), (0, 1), (3, 1), (3, 1), (3, 3), (0, 1), (3, 0), (0, 2)]), ([(0, 0), (0, 1), (3, 2), (3, 2), (3, 1), (3, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 2), (3, 2), (3, 1), (3, 1), (3, 1), (3, 2), (0, 0), (0, 2)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 1), (1, 3), (2, 1), (5, None)]), ([(0, 0), (0, 3), (3, 3), (4, 2), (3, 2), (3, 1), (3, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (3, 3), (4, 2), (3, 2), (3, 1), (3, 0), (0, 0), (0, 2), (3, 0)]), ([(0, 3), (1, 2), (4, 3), (4, 3)], [(0, 3), (1, 2), (4, 0), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (3, 2), (3, 3), (0, 3), (1, 3), (1, 3), (4, 0), (3, 1)])]

Running PBIRL with 1 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6688
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.76142587 -0.51920121 -0.38815042]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.04648576 -0.62971873  0.77543111]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6290
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.88422763 -0.03649924  0.46562786]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.5204
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.10036174 0.09236327 0.99065461]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.0028
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.99967411  0.0012754   0.02549586]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.0038
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-9.99983072e-01  4.61807408e-04  5.80022901e-03]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 39/50...
Shuffled Demos: [([(0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 2), (0, 0), (0, 0), (0, 0), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 0), (0, 0), (1, 3), (4, 0), (1, 1), (4, 2), (1, 0), (1, 0)]), ([(0, 1), (3, 3), (0, 1), (3, 3), (0, 1), (3, 3), (3, 3), (4, 3), (1, 1), (4, 3)], [(0, 3), (1, 0), (2, 2), (1, 0), (1, 3), (2, 2), (1, 2), (0, 3), (1, 2), (0, 2)]), ([(0, 1), (3, 1), (3, 2), (3, 3), (4, 2), (3, 0), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 2), (3, 3), (4, 2), (3, 0), (4, 0), (1, 3), (2, 0), (2, 3)]), ([(0, 1), (3, 1), (3, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (3, 2), (0, 1), (3, 2), (3, 2), (0, 1), (3, 1), (3, 3)]), ([(0, 1), (1, 2), (0, 2), (0, 0), (0, 0), (0, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (1, 2), (0, 2), (0, 0), (0, 0), (0, 2), (0, 0), (0, 2), (3, 2), (3, 1)])]

Running PBIRL with 1 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6630
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.05085325 -0.50745291 -0.8601776 ]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5002
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.1698809  -0.46950921  0.86643037]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2546
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.84150144 -0.3818201   0.38221557]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2548
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.55404176 -0.45589249 -0.69656282]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2382
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.68734236 -0.46003114  0.56207813]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.1786
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.72173773 -0.56069552  0.40585117]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running experiment 40/50...
Shuffled Demos: [([(0, 3), (1, 0), (2, 2), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (2, 2), (1, 2), (0, 3), (1, 0), (1, 3), (4, 0), (1, 3), (2, 0)]), ([(0, 3), (0, 3), (1, 0), (1, 3), (2, 1), (5, None)], [(0, 3), (0, 3), (1, 0), (1, 3), (2, 2), (5, None)]), ([(0, 1), (0, 0), (0, 2), (0, 2), (3, 3), (4, 1), (4, 0), (1, 3), (2, 1), (5, None)], [(0, 1), (0, 0), (0, 2), (0, 2), (3, 3), (4, 1), (4, 0), (1, 3), (2, 2), (1, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (4, 3), (1, 2), (1, 3), (2, 3), (2, 2), (2, 1), (5, None)]), ([(0, 0), (1, 1), (4, 3), (1, 2), (0, 1), (3, 1), (3, 1), (3, 2), (3, 3), (4, 3), (5, None)], [(0, 0), (1, 1), (4, 3), (1, 2), (0, 1), (3, 1), (3, 1), (3, 2), (3, 2), (3, 0)]), ([(0, 0), (0, 2), (0, 0), (0, 3), (3, 2), (3, 0), (0, 1), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 0), (0, 3), (3, 2), (3, 0), (0, 3), (1, 1), (0, 1), (3, 3)])]

Running PBIRL with 1 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6438
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.01057961 -0.14085815  0.98997326]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6566
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.58215398  0.65208299  0.48567944]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5842
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.59164252  0.67031895  0.44791923]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5274
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.36830635  0.39102126  0.84347662]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.4494
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.26732775  0.06918866  0.96111852]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.4402
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.59468962  0.67625881  0.43476233]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 41/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (0, 1), (0, 1), (3, 3), (4, 3), (4, 3), (1, 1), (0, 1)], [(0, 2), (0, 0), (0, 2), (3, 0), (0, 1), (3, 1), (3, 1), (3, 1), (3, 3), (4, 0)]), ([(0, 2), (0, 1), (3, 2), (3, 2), (3, 3), (4, 0), (1, 2), (0, 2), (0, 1), (3, 3)], [(0, 2), (0, 1), (3, 2), (3, 2), (3, 3), (4, 0), (1, 2), (0, 2), (0, 2), (0, 1)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 3), (2, 1), (5, None)]), ([(0, 1), (3, 2), (3, 0), (0, 2), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 1), (3, 2), (3, 0), (0, 2), (0, 3), (1, 2), (0, 0), (0, 1), (3, 2), (3, 0)]), ([(0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 0), (0, 0), (0, 1), (0, 2), (0, 1), (3, 3), (3, 3), (4, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 0), (0, 0), (0, 0), (1, 1), (4, 0), (3, 0), (0, 3), (1, 2)])]

Running PBIRL with 1 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6624
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.01697651 -0.77037676 -0.63736289]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6584
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.51846703 -0.7981312   0.3068852 ]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5644
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.07824521 -0.99360129  0.0814504 ]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5526
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.28441964 -0.71280043 -0.64110921]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5346
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.39759465 -0.90413042  0.15641826]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5040
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.58209733 -0.81210566  0.04058428]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running experiment 42/50...
Shuffled Demos: [([(0, 2), (3, 3), (4, 3), (1, 3), (2, 1), (2, 1), (5, None)], [(0, 2), (3, 3), (4, 3), (1, 3), (2, 0), (2, 2), (1, 3), (2, 1), (5, None)]), ([(0, 1), (0, 2), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 1), (0, 2), (0, 1), (3, 3), (4, 0), (5, None)]), ([(0, 2), (3, 1), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (3, 1), (4, 0), (1, 2), (0, 3), (0, 0), (0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (0, 3), (1, 0), (1, 1), (4, 2), (3, 3), (4, 3), (5, None)], [(0, 1), (0, 3), (1, 0), (1, 1), (4, 2), (3, 2), (3, 2), (3, 1), (3, 0), (0, 0)]), ([(0, 3), (1, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 2), (0, 0), (0, 3), (1, 2), (0, 2), (0, 2), (0, 3), (1, 0), (1, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 2), (0, 2), (0, 1), (3, 2), (3, 3), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6604
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.0620974  -0.9181522   0.39133164]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.3222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.07369444 -0.74003869 -0.66851468]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.3150
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.19201602 -0.67246563 -0.71478655]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.2904
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.2826443  -0.95672679 -0.06918127]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.1588
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.06578948 -0.77850262 -0.6241838 ]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.1634
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.24488055 -0.50212901 -0.82939735]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 43/50...
Shuffled Demos: [([(0, 1), (1, 1), (2, 1), (2, 1), (5, None)], [(0, 0), (0, 2), (3, 1), (4, 2), (3, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 2), (5, None)]), ([(0, 1), (3, 3), (4, 2), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 3), (4, 2), (3, 1), (3, 3), (4, 1), (4, 3), (5, None)]), ([(0, 0), (0, 1), (3, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 1), (3, 3), (3, 0), (0, 3), (1, 2), (0, 2), (3, 0), (0, 3)]), ([(0, 0), (0, 1), (3, 1), (3, 2), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 1), (3, 2), (3, 1), (3, 1), (3, 1), (3, 1), (3, 3), (3, 1)]), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 3), (1, 0), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6576
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.08096434 -0.79894589 -0.59592805]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.1866
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.90505075 -0.42528933  0.00348066]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.1942
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.81817965 -0.37572857  0.43521271]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.1876
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.85183784 -0.46030112 -0.24999035]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.1642
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.84268972 -0.49374827  0.2146781 ]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.1526
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.81240837 -0.39887223  0.42531587]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running experiment 44/50...
Shuffled Demos: [([(0, 3), (1, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 1), (4, 0), (1, 2), (0, 0), (0, 3), (1, 3), (1, 1), (0, 2)]), ([(0, 1), (1, 2), (0, 3), (1, 1), (2, 0), (2, 1), (2, 2), (1, 3), (2, 1), (5, None)], [(0, 1), (1, 2), (0, 3), (1, 1), (2, 0), (2, 1), (2, 2), (1, 3), (2, 3), (2, 3)]), ([(0, 1), (3, 1), (3, 0), (0, 1), (3, 3), (3, 3), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 0), (0, 0), (0, 1), (3, 0), (0, 2), (0, 0), (0, 1), (1, 2)]), ([(0, 1), (3, 2), (3, 0), (3, 1), (3, 1), (3, 2), (3, 1), (3, 3), (0, 1), (3, 3)], [(0, 1), (3, 2), (3, 0), (3, 1), (3, 1), (3, 2), (3, 1), (3, 0), (4, 1), (3, 1)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 3), (4, 1), (4, 0), (1, 3), (1, 1), (0, 1), (3, 3), (0, 1)]), ([(0, 0), (0, 1), (3, 3), (3, 1), (3, 1), (3, 3), (4, 0), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 3), (3, 1), (3, 1), (3, 3), (4, 0), (3, 1), (3, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6600
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-9.05504606e-01 -2.80319427e-04  4.24336340e-01]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5056
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.48430718  0.32915779  0.8106181 ]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.4718
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.15594245 -0.74713982  0.64611457]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.4680
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.00761246 -0.79558904  0.60578885]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.4456
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.26291116 -0.71759292  0.64493265]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.4084
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.5170357  -0.6621864   0.54238662]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 45/50...
Shuffled Demos: [([(0, 0), (0, 1), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 2), (0, 3), (1, 2), (0, 1), (3, 3), (4, 2), (4, 2), (3, 1)]), ([(0, 1), (3, 3), (4, 3), (1, 1), (2, 1), (2, 1), (5, None)], [(0, 3), (3, 2), (3, 1), (3, 3), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 3), (1, 0), (1, 0), (1, 3), (1, 3), (2, 2), (5, None)]), ([(0, 2), (0, 0), (0, 1), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 1), (3, 1), (3, 1), (3, 2), (3, 1), (3, 3), (4, 1), (4, 2)]), ([(0, 0), (0, 1), (3, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 1), (3, 3), (4, 2), (4, 2), (4, 3), (5, None)]), ([(0, 2), (3, 2), (3, 0), (0, 0), (0, 3), (1, 0), (1, 3), (2, 2), (2, 1), (5, None)], [(0, 2), (3, 2), (3, 0), (0, 0), (0, 3), (1, 0), (1, 3), (2, 2), (2, 2), (1, 1)])]

Running PBIRL with 1 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6524
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.8406777  -0.48691551 -0.23701116]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.4378
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.81806875 -0.55344941  0.15638823]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.0136
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.0042532  -0.89187955 -0.45225301]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.0162
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.00444032 -0.84372035  0.53676462]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.0162
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.00426759 -0.74227935 -0.67007698]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.0114
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.00410764 -0.17149998  0.98517556]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running experiment 46/50...
Shuffled Demos: [([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (0, 3), (1, 3), (4, 2), (1, 0), (1, 1), (4, 3), (5, None)]), ([], [(0, 1), (3, 3), (4, 3), (5, None)]), ([(0, 2), (0, 2), (0, 0), (0, 3), (3, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 2), (0, 0), (0, 3), (3, 1), (3, 3), (4, 2), (1, 3), (4, 0), (1, 0)]), ([(0, 2), (3, 0), (3, 0), (0, 2), (0, 3), (1, 1), (2, 0), (2, 2), (1, 1), (4, 3), (5, None)], [(0, 2), (3, 0), (3, 0), (0, 2), (0, 3), (1, 1), (2, 0), (2, 2), (1, 2), (0, 1)]), ([(0, 1), (3, 0), (0, 1), (3, 0), (0, 1), (3, 3), (0, 1), (3, 3), (4, 3), (1, 1)], [(0, 1), (3, 0), (0, 1), (3, 0), (0, 1), (3, 0), (3, 3), (4, 1), (4, 2), (3, 2)]), ([(0, 0), (0, 1), (3, 3), (4, 1), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 3), (4, 1), (4, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6520
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.5666294  -0.67868072  0.46725111]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5366
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.77322053 -0.04363093 -0.63263445]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.4710
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.18105433 -0.91214753  0.36770397]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.3080
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.7417505  -0.51919368  0.42455166]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.2786
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.20215953 -0.66697706  0.71712838]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.2628
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.03040928 -0.81119412  0.58398576]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 47/50...
Shuffled Demos: [([(0, 3), (1, 3), (2, 1), (5, None)], [(0, 3), (1, 3), (2, 0), (2, 1), (5, None)]), ([(0, 1), (3, 2), (3, 3), (4, 3), (1, 1), (2, 1), (5, None)], [(0, 1), (3, 2), (3, 3), (4, 3), (1, 2), (0, 1), (3, 2), (3, 0), (0, 1), (3, 2)]), ([(0, 0), (1, 1), (4, 3), (5, None)], [(0, 0), (1, 2), (4, 3), (5, None)]), ([(0, 3), (1, 3), (2, 1), (5, None)], [(0, 3), (1, 3), (2, 3), (2, 1), (5, None)]), ([(0, 0), (0, 0), (0, 1), (3, 2), (3, 0), (0, 0), (1, 3), (4, 0), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 0), (0, 1), (3, 2), (3, 0), (0, 0), (1, 3), (4, 0), (3, 0), (4, 3)]), ([(0, 0), (1, 0), (1, 0), (0, 1), (3, 3), (0, 0), (0, 3), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 0), (1, 0), (1, 0), (0, 1), (3, 3), (0, 0), (0, 3), (3, 2), (0, 0), (0, 0)])]

Running PBIRL with 1 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6516
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.18239066 -0.55119084 -0.81420041]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6308
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.50374484 -0.61966024  0.60188232]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6184
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.80722636 -0.58251095  0.09521864]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6398
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.84958598 -0.50775983 -0.1427712 ]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.4422
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.51836187 -0.50916075  0.68706354]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.4366
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.63623521 -0.3445215   0.69029681]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running experiment 48/50...
Shuffled Demos: [([(0, 3), (0, 1), (0, 1), (1, 1), (0, 1), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (0, 0), (0, 1), (0, 3), (1, 0), (1, 1), (4, 2), (3, 3), (4, 1), (4, 2)]), ([(0, 0), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 1), (3, 0), (0, 2), (0, 3), (1, 1), (0, 1), (1, 2), (0, 1), (3, 1)]), ([(0, 3), (1, 0), (1, 1), (4, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 1), (4, 1), (4, 2), (3, 0), (0, 3), (1, 1), (4, 3), (4, 2)]), ([(0, 0), (0, 0), (0, 0), (0, 3), (1, 0), (2, 1), (1, 1)], [(0, 0), (0, 0), (0, 0), (0, 3), (1, 0), (2, 2), (5, None)]), ([(0, 1), (3, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 2), (0, 1), (3, 1), (4, 3), (4, 2), (4, 3), (5, None)]), ([(0, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 0), (1, 0), (1, 3), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6786
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.81135608 -0.24828871  0.52920132]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5982
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.39190178 -0.54540774  0.74090714]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5876
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.60362736 -0.6930936   0.39402446]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.2134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.57501617 -0.79101666  0.20892353]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.2108
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.51499432 -0.83837464  0.17863036]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.1098
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.23681954 -0.76788047 -0.59521096]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 49/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 0), (1, 1), (2, 1), (5, None)]), ([(0, 1), (3, 1), (3, 1), (3, 2), (3, 1), (3, 3), (4, 3), (1, 1), (4, 3), (5, None)], [(0, 1), (3, 1), (3, 1), (3, 2), (3, 1), (3, 2), (3, 0), (0, 1), (3, 0), (4, 3)]), ([(0, 1), (1, 1), (4, 3), (5, None)], [(0, 2), (0, 1), (3, 3), (4, 0), (1, 2), (0, 3), (1, 1), (2, 0), (2, 2), (1, 2)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (1, 1), (4, 0), (1, 0), (2, 0), (2, 1), (5, None)]), ([(0, 0), (0, 3), (1, 1), (4, 3), (5, None)], [(0, 0), (0, 3), (1, 0), (1, 0), (1, 3), (4, 1), (5, None)]), ([(0, 0), (0, 2), (0, 3), (1, 2), (0, 1), (3, 3), (4, 3), (5, None)], [(0, 0), (0, 2), (0, 3), (1, 2), (0, 2), (0, 0), (1, 3), (1, 3), (2, 1), (2, 3)])]

Running PBIRL with 1 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6596
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.87512153  0.31340668 -0.36869846]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.1904
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.73713703 -0.35059652  0.57767731]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.1700
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.34046138  0.0872682   0.93619993]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.1710
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.84398729 -0.4302723   0.32023618]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.1768
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.81578504 -0.33551544  0.47108828]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.1706
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.77030742 -0.27603711  0.5748304 ]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running experiment 50/50...
Shuffled Demos: [([(0, 1), (3, 1), (3, 3), (4, 2), (3, 0), (0, 3), (0, 3), (1, 2), (0, 1), (3, 3)], [(0, 1), (3, 1), (3, 3), (4, 2), (3, 0), (0, 3), (0, 3), (1, 2), (0, 3), (1, 1)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 2), (3, 3), (3, 3), (4, 1), (3, 1), (3, 1), (3, 0)]), ([(0, 0), (1, 2), (4, 2), (3, 3), (4, 3), (5, None)], [(0, 0), (1, 2), (4, 2), (3, 2), (3, 0), (0, 1), (3, 2), (3, 0), (0, 0), (0, 2)]), ([(0, 3), (0, 2), (0, 0), (0, 2), (0, 2), (0, 3), (3, 3), (4, 2), (3, 3), (0, 1)], [(0, 3), (0, 2), (0, 0), (0, 2), (0, 2), (0, 3), (3, 3), (4, 2), (3, 2), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 1), (1, 1), (4, 3), (5, None)]), ([(0, 2), (0, 0), (0, 2), (3, 0), (0, 0), (0, 1), (3, 3), (3, 3), (4, 3), (5, None)], [(0, 2), (0, 0), (0, 2), (3, 0), (0, 0), (0, 1), (3, 3), (3, 2), (3, 0), (0, 3)])]

Running PBIRL with 1 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6500
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.85390957 -0.41618707 -0.31245283]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.2626
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.72151222 -0.2898244   0.62882583]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.2590
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.98001566 -0.19804497 -0.01864098]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 4 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.2634
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.84977676 -0.5171218   0.10229617]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 5 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.2698
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.85444652 -0.51714495 -0.0498222 ]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 6 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.2338
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.8432653  -0.53221645 -0.07516171]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.
