Config file loaded successfully.
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.4922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.54204289 -0.43539275  0.71876467]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000008

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.4768
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.19115738 0.39795013 0.89727061]
True reward weights: [-0.50608883 -0.81587892 -0.27967068]
MAP Policy for current environment:
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.4894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.68860818 -0.51181974  0.5136724 ]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000002

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2986
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.72673587 -0.04995652  0.68509804]
True reward weights: [-0.52139663 -0.32441569  0.78924015]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000397

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.9627961  -0.24093983  0.12235876]
True reward weights: [-0.52139663 -0.32441569  0.78924015]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.020591

Running experiment 2/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.82440274  0.15169632  0.54529656]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.002326

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.3008
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88886267  0.04885882  0.45556116]
True reward weights: [-0.87961469 -0.4754758  -0.01416911]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003723

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.2282642   0.47364965  0.85061829]
True reward weights: [-0.87961469 -0.4754758  -0.01416911]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.000778

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [(0, 1), (2, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.88356539 -0.03044707  0.467317  ]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.003036

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2938
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.7473082  -0.10627935  0.65592313]
True reward weights: [-0.87980725 -0.23568349  0.41278625]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.004435

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.3030
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.75732605 -0.0164391   0.65283001]
True reward weights: [-0.87980725 -0.23568349  0.41278625]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.001132

Running experiment 4/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4902
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.42871308 -0.65790045  0.61917049]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000006

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.4856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.01996465 -0.99601825 -0.08688529]
True reward weights: [-0.47095708 -0.2063328   0.85768654]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000315

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2964
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.72495105  0.20951489  0.6561627 ]
True reward weights: [-0.47095708 -0.2063328   0.85768654]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.022574

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.4794
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.24745295 -0.43229243  0.86711608]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000007

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.4832
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.91815557 -0.05333405  0.3926141 ]
True reward weights: [0.17168623 0.49027632 0.85448989]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000094

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2986
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.81340101  0.03761729  0.58048577]
True reward weights: [0.17168623 0.49027632 0.85448989]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.026296

Running experiment 6/50...
Shuffled Demos: [(0, 1), (2, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2992
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.23542194  0.47341858  0.84879406]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.003865

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2946
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9229496  -0.09003547  0.37424278]
True reward weights: [-0.57981603  0.1683954   0.79715516]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.005475

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.6033944   0.23168385  0.76304508]
True reward weights: [-0.57981603  0.1683954   0.79715516]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.002105

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.4862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.24868296  0.09461278  0.96395291]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000002

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2968
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.6132328   0.0831854   0.78550985]
True reward weights: [ 0.15523568 -0.29278476  0.94349296]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.001640

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2924
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.81530239 -0.0087132   0.57896985]
True reward weights: [ 0.15523568 -0.29278476  0.94349296]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.019693

Running experiment 8/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.4878
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.79150916 -0.60938984  0.04644632]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000005

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.4778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.22958081 -0.17988206  0.9565224 ]
True reward weights: [-0.54409757 -0.43776258  0.71576655]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000196

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2972
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.51143296  0.12338115  0.85041955]
True reward weights: [-0.54409757 -0.43776258  0.71576655]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.026521

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.4810
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.06846669 -0.89148685  0.44784317]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000008

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.4790
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.5040084  -0.35219984  0.7886259 ]
True reward weights: [-0.6095265  -0.61822532 -0.49626092]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000347

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.3024
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.8038607   0.13741728  0.57872659]
True reward weights: [-0.6095265  -0.61822532 -0.49626092]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.027487

Running experiment 10/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.4824
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.07146691  0.28292653  0.95647533]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000008

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.4820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.3864662  -0.03146298  0.92176676]
True reward weights: [-0.31572597  0.08375926  0.94514629]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000173

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2870
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.67908237  0.16832631  0.7145022 ]
True reward weights: [-0.31572597  0.08375926  0.94514629]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.025694

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.4874
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.78479831  0.00748134  0.6197061 ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000002

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89214493 -0.25323346  0.37409924]
True reward weights: [ 0.3417161  -0.51049489  0.78906595]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000308

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.3016
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.68937074  0.15030462  0.70864413]
True reward weights: [ 0.3417161  -0.51049489  0.78906595]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.020957

Running experiment 12/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.4878
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.15640099 0.23879271 0.95839281]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000003

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2972
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.53690621  0.05212364  0.84203019]
True reward weights: [0.57065136 0.24000527 0.78533718]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002558

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2998
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.45256002  0.26297711  0.85207539]
True reward weights: [0.57065136 0.24000527 0.78533718]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.020051

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.4736
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.02614222 -0.99718797  0.0702334 ]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000002

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.4856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.60171222 -0.62261849  0.50028854]
True reward weights: [-0.47136966 -0.42507514  0.77273655]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000126

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.3054
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94288095 -0.11395942  0.31303156]
True reward weights: [-0.47136966 -0.42507514  0.77273655]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.025952

Running experiment 14/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.4856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.24816453 -0.40714081  0.87900553]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000009

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.4766
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.57704043 -0.45758416  0.67649175]
True reward weights: [-0.81524319  0.14983201  0.55940049]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000071

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2902
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.43109623  0.27295017  0.86003153]
True reward weights: [-0.81524319  0.14983201  0.55940049]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.024108

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.4860
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.80100014 -0.53764232  0.26332396]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000002

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.2962
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.84624976 -0.13735293  0.51477716]
True reward weights: [-0.03336678 -0.99189224 -0.1226232 ]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.002114

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.2928
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.88770008  0.07246846  0.45468329]
True reward weights: [-0.03336678 -0.99189224 -0.1226232 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022009

Running experiment 16/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.3010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.80774027  0.03665782  0.5883977 ]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.002037

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2952
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.53184415  0.32189774  0.7832775 ]
True reward weights: [0.11466427 0.52814692 0.84137562]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.003436

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2920
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.78881096 -0.16459909  0.59218613]
True reward weights: [0.11466427 0.52814692 0.84137562]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.002556

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.4910
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.08510628 -0.37805865  0.92186148]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000003

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.4790
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.6833328  -0.50874557  0.52367379]
True reward weights: [-0.58972463 -0.16322186  0.79093836]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000051

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.2982
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94396788 -0.05335051  0.32569672]
True reward weights: [-0.58972463 -0.16322186  0.79093836]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.022621

Running experiment 18/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.4828
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.93710825 -0.2367678   0.25645494]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000015

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.2956
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.20875082  0.48018062  0.85196811]
True reward weights: [-0.17747488 -0.93383449 -0.31057336]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.001109

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.3014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.35975481  0.31833528  0.87706278]
True reward weights: [-0.17747488 -0.93383449 -0.31057336]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.019073

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.4780
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.79326311 -0.40094177  0.45823501]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000002

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.3010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.77386755  0.02586408  0.63281915]
True reward weights: [-0.64274177 -0.62536219 -0.44249876]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000575

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.3032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.7070405  -0.00654096  0.70714281]
True reward weights: [-0.64274177 -0.62536219 -0.44249876]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.020095

Running experiment 20/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.4880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.20456977 -0.58604235  0.78403162]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000006

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.3028
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.60922518  0.22607748  0.76008793]
True reward weights: [ 0.41190345 -0.67653094  0.61044364]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.002030

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2926
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.95223639 -0.20844604  0.2231504 ]
True reward weights: [ 0.41190345 -0.67653094  0.61044364]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.019871

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.4960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.45828259 -0.39157816  0.7978995 ]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000010

Running PBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.4880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.30630107 -0.71909162  0.62376831]
True reward weights: [-0.51294026 -0.73110749  0.44986013]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000048

Running PBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.2964
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.85893908 -0.12713042  0.49604588]
True reward weights: [-0.51294026 -0.73110749  0.44986013]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.026906

Running experiment 22/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.4862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.64157217 0.22991501 0.73179522]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000004

Running PBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2926
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.94097885 -0.21258052  0.26337867]
True reward weights: [0.0566212  0.34503451 0.93688058]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000568

Running PBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2992
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.81722473  0.09599891  0.5682675 ]
True reward weights: [0.0566212  0.34503451 0.93688058]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.020214

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.4768
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.90355162  0.01373693  0.428259  ]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000015

Running PBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.4784
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.28175331 -0.88912152  0.36066327]
True reward weights: [-0.17614961 -0.9059822   0.38492541]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000291

Running PBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.3038
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.35390933  0.34398956  0.86972373]
True reward weights: [-0.17614961 -0.9059822   0.38492541]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.026427

Running experiment 24/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.3014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.58313619  0.2300807   0.77911171]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.008485

Running PBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.2906
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.36436473  0.34900684  0.86338437]
True reward weights: [-0.33046353  0.33672453  0.88170882]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.008019

Running PBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.3032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.45613527  0.40334684  0.79325402]
True reward weights: [-0.33046353  0.33672453  0.88170882]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.004179

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.4838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.65212663 -0.21018905  0.72838961]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000006

Running PBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.4990
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.46501761 -0.66361925  0.58597621]
True reward weights: [-0.22918209  0.21542473  0.94924589]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000111

Running PBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.2934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.9348221  -0.28688296  0.20929839]
True reward weights: [-0.22918209  0.21542473  0.94924589]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.025664

Running experiment 26/50...
Shuffled Demos: [(4, 3), (2, 1), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.4932
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.49039145 -0.77889139  0.39095324]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000009

Running PBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.4800
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.83330175  0.02869846  0.55207299]
True reward weights: [-0.45259233 -0.05552222  0.88998734]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000372

Running PBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.2924
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.20566917  0.33705929  0.91874438]
True reward weights: [-0.45259233 -0.05552222  0.88998734]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.024569

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.2990
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94659347 -0.14798742  0.28646209]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.004592

Running PBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.3046
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.30856089  0.44939499  0.83835215]
True reward weights: [0.04134906 0.60988968 0.79140687]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.006177

Running PBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.2924
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.59854889  0.26821537  0.7548508 ]
True reward weights: [0.04134906 0.60988968 0.79140687]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.002833

Running experiment 28/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.2906
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.61119111  0.28358712  0.73893421]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.004252

Running PBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.3034
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92772674 -0.11455136  0.35524792]
True reward weights: [-0.98852749 -0.15078118 -0.00885612]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.005094

Running PBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.3078
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.75811444  0.23308476  0.6090435 ]
True reward weights: [-0.98852749 -0.15078118 -0.00885612]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.001102

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.4852
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.66595596  0.00820086  0.74594598]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000003

Running PBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.3012
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.65880672  0.05401893  0.75037035]
True reward weights: [ 0.60910324 -0.17112624  0.77440884]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.000846

Running PBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.3010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.86453821 -0.20219681  0.46009796]
True reward weights: [ 0.60910324 -0.17112624  0.77440884]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.020669

Running experiment 30/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.4896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.14482318 -0.98736545  0.06430952]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000007

Running PBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.4846
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.28545003 -0.75165932  0.59458098]
True reward weights: [-0.07394889 -0.97114766 -0.22672403]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000169

Running PBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.2990
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93384624 -0.22737717  0.27609928]
True reward weights: [-0.07394889 -0.97114766 -0.22672403]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.023656

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.4790
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.18900783 -0.45396647  0.87074134]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000005

Running PBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.2998
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.48337291  0.18379608  0.85590281]
True reward weights: [-0.93576511 -0.05143809  0.3488521 ]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.002158

Running PBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.3040
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.65727947  0.03771688  0.75270255]
True reward weights: [-0.93576511 -0.05143809  0.3488521 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.022681

Running experiment 32/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.4922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.58724512  0.09836802  0.80340955]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000006

Running PBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.4848
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.11789692 -0.02288478  0.99276211]
True reward weights: [-0.5151109  -0.0522277   0.85553085]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000134

Running PBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.2976
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.37068603  0.33420966  0.86654242]
True reward weights: [-0.5151109  -0.0522277   0.85553085]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.026552

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Shuffled Demos: [(2, 1), (4, 3), (0, 1)]

Running PBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.4784
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.63310396 -0.09351106  0.76839772]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000008

Running PBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.4844
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.25074896 -0.62844881  0.73632673]
True reward weights: [ 0.05740467 -0.71309899  0.69870919]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000078

Running PBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.2968
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.82182987  0.18181914  0.53994209]
True reward weights: [ 0.05740467 -0.71309899  0.69870919]
MAP Policy for current environment:
Information gain 3 demonstrations: 0.024243

Running experiment 34/50...
Shuffled Demos: [(4, 3), (0, 1), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.4900
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.22443426 -0.95483278 -0.1947399 ]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000003

Running PBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.3008
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-8.89963112e-01  5.33477364e-04  4.56032208e-01]
True reward weights: [-0.61750171 -0.76511501  0.1824573 ]
MAP Policy for current environment:
Information gain 2 demonstrations: -0.001182

Running PBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2984
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.45712933  0.34594002  0.81936456]
True reward weights: [-0.61750171 -0.76511501  0.1824573 ]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021515

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Shuffled Demos: [(2, 1), (0, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.4916
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.56507904 -0.27628137  0.77740227]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.000017

Running PBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.2980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.70344351  0.18292827  0.68680746]
True reward weights: [-0.5100116   0.22595387  0.82995965]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.000311

Running PBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.2976
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93885035 -0.3400998   0.0537787 ]
True reward weights: [-0.5100116   0.22595387  0.82995965]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.021382

Running experiment 36/50...
Shuffled Demos: [(0, 1), (2, 1), (4, 3)]

Running PBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.2934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.49192374  0.13100127  0.86072626]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.005386

Running PBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.2936
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88612946 -0.22141999  0.40712132]
True reward weights: [-0.80150021  0.08613786  0.59175813]
MAP Policy for current environment:
Information gain 2 demonstrations: 0.006113

Running PBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.2960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89302899 -0.28532947  0.3479746 ]
True reward weights: [-0.80150021  0.08613786  0.59175813]
MAP Policy for current environment:
Information gain 3 demonstrations: -0.002609

Saving results to files...
Results saved successfully.

Running experiment 37/50...
Shuffled Demos: [(0, 1), (4, 3), (2, 1)]

Running PBIRL with 1 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.2910
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.20552657  0.3448053   0.91589745]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:
Information gain 1 demonstrations: 1.007926

Running PBIRL with 2 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.2938
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.90563971 -0.22453039  0.35972604]
True reward weights: [0.02036899 0.59469469 0.80369356]
MAP Policy for current environment:
