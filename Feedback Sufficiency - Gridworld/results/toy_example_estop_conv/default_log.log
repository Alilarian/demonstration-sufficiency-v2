Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 1), (3, 2), (3, 3), (0, 1), (3, 2), (3, 2), (3, 1), (3, 0), (0, 0)], 0), ([(0, 0), (0, 2), (0, 0), (0, 3), (1, 3), (2, 3), (2, 0), (2, 1), (5, None)], 0), ([(0, 3), (1, 0), (1, 2), (0, 2), (3, 3), (4, 2), (4, 3), (5, None)], 0), ([(0, 2), (0, 0), (0, 2), (0, 1), (3, 3), (3, 1), (3, 3), (4, 2), (3, 3), (4, 2)], 0), ([(0, 3), (1, 3), (2, 2), (1, 0), (1, 0), (1, 1), (4, 3), (5, None)], 0), ([(0, 2), (0, 3), (1, 2), (0, 2), (0, 1), (1, 3), (2, 0), (2, 0), (2, 0), (2, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.1108282  -0.96242967  0.24788351]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5874
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.14786828  0.98063069  0.12844616]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5696
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.39286738 0.91331576 0.10728257]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5646
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.56157724  0.82428609 -0.07199619]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5516
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.1494253   0.84747367 -0.5093726 ]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5318
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.46250555 0.83489659 0.29838951]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 3), (1, 0), (1, 3), (2, 2), (1, 0), (1, 1), (0, 0), (0, 1), (0, 1), (3, 2)], 0), ([(0, 1), (1, 3), (2, 1), (5, None)], 3), ([(0, 3), (1, 0), (1, 2), (4, 1), (5, None)], 4), ([(0, 2), (0, 1), (1, 1), (4, 2), (3, 0), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], 9), ([(0, 2), (0, 2), (0, 2), (0, 0), (0, 0), (1, 3), (2, 0), (2, 1), (5, None)], 8), ([(0, 0), (0, 1), (3, 0), (0, 3), (0, 0), (0, 0), (0, 2), (0, 2), (0, 3), (1, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.5940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.21207031  0.79733906 -0.56504566]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.5868
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.55503076  0.7994232   0.22992044]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.5862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.4784413   0.52755373  0.70198361]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.5832
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.18018348 0.88986328 0.41913871]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.5856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.25134034 0.68422141 0.68459411]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.5918
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.23534199 0.95681246 0.17065775]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 0), (0, 3), (1, 1), (4, 1), (3, 0), (0, 3), (1, 0), (2, 2), (1, 1), (0, 0)], 0), ([(0, 1), (1, 3), (2, 2), (1, 3), (1, 1), (2, 0), (1, 2), (0, 0), (0, 1), (3, 1)], 0), ([(0, 0), (0, 0), (0, 2), (3, 1), (3, 2), (0, 3), (1, 0), (1, 0), (1, 1), (4, 3)], 0), ([(0, 2), (0, 1), (1, 3), (2, 1), (1, 2), (0, 1), (3, 2), (0, 1), (3, 3), (0, 0)], 0), ([(0, 2), (0, 3), (1, 2), (0, 1), (3, 2), (0, 2), (0, 1), (3, 0), (0, 1), (3, 3)], 0), ([(0, 0), (0, 2), (0, 1), (3, 0), (0, 1), (3, 3), (3, 2), (3, 3), (0, 0), (0, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5770
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98615609 -0.12764805 -0.10584016]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5810
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.55578462 -0.14987353 -0.81770495]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5750
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.48604907  0.26148755  0.83389482]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5844
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.85548218 -0.13695117  0.49939425]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.34532731  0.5820407  -0.73619133]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5806
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.22886062  0.89155758  0.39082976]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running experiment 4/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 2), (3, 2), (3, 0), (0, 1), (3, 0), (0, 0), (0, 2), (0, 3)], 2), ([(0, 2), (0, 2), (0, 2), (3, 0), (0, 2), (0, 3), (1, 3), (2, 3), (2, 0), (2, 3)], 0), ([(0, 3), (1, 0), (1, 3), (1, 1), (4, 0), (1, 3), (2, 2), (2, 1), (5, None)], 0), ([(0, 2), (0, 0), (0, 2), (3, 3), (4, 3), (5, None)], 5), ([(0, 1), (3, 3), (4, 3), (5, None)], 3), ([(0, 0), (0, 0), (0, 0), (1, 2), (0, 2), (0, 3), (1, 2), (1, 2), (0, 1), (1, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.43662139 -0.89703339  0.06850445]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.10345784  0.9946311  -0.00233481]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5678
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.34938688  0.93089302 -0.10661607]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5722
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.21682026  0.9665171  -0.13723585]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5566
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.11608872 0.93227429 0.34261942]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5722
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.48167565  0.87115745 -0.09525366]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [([(0, 3), (1, 1), (2, 3), (2, 3), (2, 0), (2, 2), (1, 2), (0, 0), (0, 1), (3, 0)], 0), ([(0, 0), (0, 2), (3, 3), (4, 2), (1, 0), (1, 1), (2, 2), (1, 2), (0, 1), (0, 0)], 0), ([(0, 1), (3, 1), (3, 3), (4, 0), (1, 1), (4, 2), (3, 3), (4, 0), (1, 0), (2, 2)], 0), ([(0, 3), (1, 0), (1, 3), (1, 2), (0, 2), (0, 3), (0, 1), (1, 3), (2, 1), (5, None)], 0), ([(0, 2), (0, 3), (1, 3), (2, 2), (1, 0), (1, 2), (0, 2), (0, 3), (1, 0), (1, 3)], 0), ([(0, 3), (1, 0), (1, 1), (0, 2), (0, 3), (1, 3), (2, 1), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.31915771  0.87954024 -0.35291264]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.6825035   0.0154088   0.73071988]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5816
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.84728093  0.29937308  0.43873772]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5708
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.88396511 -0.28785508 -0.36843608]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5550
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.1666144   0.98391984 -0.06435367]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5496
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.74017462 -0.19238525 -0.6443054 ]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running experiment 6/50...
Shuffled Demos: [([(0, 1), (3, 1), (3, 3), (4, 1), (4, 3), (5, None)], 5), ([(0, 3), (1, 0), (0, 0), (0, 2), (0, 1), (3, 3), (3, 3), (4, 2), (3, 3), (4, 1)], 0), ([(0, 2), (0, 1), (3, 3), (4, 0), (1, 0), (1, 1), (4, 3), (5, None)], 7), ([(0, 3), (0, 0), (0, 3), (1, 2), (1, 3), (2, 2), (1, 2), (0, 2), (0, 1), (3, 2)], 0), ([(0, 2), (0, 0), (0, 1), (3, 0), (4, 0), (1, 2), (0, 2), (0, 3), (1, 0), (2, 1)], 0), ([(0, 2), (0, 0), (0, 1), (3, 2), (3, 2), (3, 1), (3, 1), (3, 2), (3, 0), (0, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.10357442  0.32337396  0.94058579]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5912
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.85591838  0.51635739 -0.02790655]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.37001779 0.91714627 0.14808633]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.28785719 0.95189043 0.10508498]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.4264777  0.78276645 0.45320354]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.48018623  0.8650753  -0.14514099]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 3), (1, 2), (0, 0), (0, 2), (0, 1), (1, 3), (2, 1), (5, None)], 9), ([(0, 0), (0, 2), (0, 3), (0, 1), (3, 0), (4, 3), (5, None)], 6), ([(0, 2), (0, 0), (1, 0), (1, 3), (2, 2), (5, None)], 5), ([(0, 3), (3, 0), (0, 3), (1, 1), (2, 2), (1, 1), (4, 0), (1, 0), (1, 1), (4, 3)], 0), ([(0, 0), (0, 3), (1, 0), (2, 3), (2, 1), (5, None)], 5), ([(0, 2), (0, 1), (1, 3), (2, 2), (1, 2), (0, 3), (1, 3), (4, 0), (1, 2), (0, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.05060207 0.98885722 0.14000294]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.00460517 0.87127509 0.49077337]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.25170658  0.91742711  0.30817414]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.03891445  0.96441565 -0.26151123]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5930
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.24483593  0.87611348  0.41530776]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5860
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.07366594  0.97382975 -0.21500918]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running experiment 8/50...
Shuffled Demos: [([(0, 3), (3, 1), (3, 0), (0, 3), (1, 3), (2, 2), (1, 3), (2, 0), (2, 1), (5, None)], 9), ([(0, 3), (1, 3), (2, 1), (2, 0), (2, 3), (2, 1), (5, None)], 6), ([(0, 2), (0, 1), (3, 3), (3, 1), (3, 1), (3, 3), (4, 0), (1, 2), (0, 3), (1, 3)], 0), ([(0, 2), (0, 0), (0, 2), (0, 3), (1, 0), (1, 2), (1, 1), (4, 1), (4, 0), (1, 1)], 0), ([(0, 1), (3, 2), (3, 1), (3, 2), (0, 2), (0, 0), (0, 2), (0, 3), (1, 0), (2, 2)], 0), ([(0, 2), (0, 0), (1, 1), (4, 0), (1, 0), (1, 0), (1, 0), (2, 0), (2, 2), (1, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.22831809 -0.62750032 -0.74438847]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.26997956 0.95272507 0.13937709]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5966
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.16601226 0.96697194 0.19340422]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.27620178 0.91809345 0.28428328]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5852
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.16010552 0.96605853 0.2027243 ]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5822
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.25430368 0.93925604 0.23049452]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [([(0, 1), (0, 0), (0, 0), (0, 0), (1, 1), (4, 2), (3, 1), (3, 3), (3, 2), (3, 1)], 0), ([(0, 2), (0, 1), (3, 3), (4, 2), (3, 2), (3, 1), (3, 3), (4, 2), (3, 3), (4, 0)], 7), ([(0, 2), (0, 2), (0, 2), (0, 0), (0, 3), (1, 1), (4, 3), (5, None)], 7), ([(0, 3), (1, 2), (0, 2), (0, 1), (3, 0), (0, 3), (1, 2), (0, 2), (0, 3), (1, 3)], 0), ([(0, 3), (1, 1), (4, 0), (1, 2), (0, 3), (1, 2), (0, 1), (3, 0), (0, 0), (0, 1)], 0), ([(0, 0), (0, 2), (0, 2), (0, 3), (1, 3), (2, 3), (2, 1), (5, None)], 7)]

Running EBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5928
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.40894801 0.79709798 0.44429306]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5730
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.00085523  0.84268214 -0.5384107 ]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5938
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.02427274  0.94571687  0.32408398]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5830
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.14479582  0.98923656 -0.0210996 ]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.13071201  0.98605365  0.10301735]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5764
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.10787227  0.992681    0.05429547]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running experiment 10/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 2), (0, 0), (0, 3), (1, 1), (4, 3), (5, None)], 7), ([(0, 3), (3, 0), (3, 3), (4, 3), (5, None)], 4), ([(0, 3), (1, 3), (2, 3), (2, 2), (1, 0), (2, 2), (1, 3), (2, 2), (2, 1), (5, None)], 9), ([(0, 2), (0, 2), (0, 2), (0, 0), (0, 1), (3, 0), (4, 1), (4, 1), (4, 0), (1, 0)], 0), ([(0, 0), (0, 0), (0, 3), (1, 0), (1, 1), (4, 2), (3, 3), (4, 3), (5, None)], 8), ([(0, 0), (0, 1), (3, 2), (3, 0), (0, 3), (1, 1), (4, 2), (3, 0), (0, 2), (0, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.11940662 -0.94653962 -0.29967449]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.58691328 -0.70352177 -0.40073672]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.5728838  -0.7590141  -0.30935699]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.05634157  0.99765089 -0.03896588]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.04622665 0.7348084  0.67669765]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5800
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.17275373  0.98489349 -0.01187287]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 3), (4, 1), (3, 0), (0, 3), (1, 2), (0, 1), (3, 1), (3, 1)], 0), ([(0, 0), (0, 3), (0, 3), (1, 2), (0, 3), (3, 2), (0, 0), (0, 1), (3, 3), (4, 0)], 0), ([(0, 1), (3, 1), (3, 0), (0, 0), (0, 1), (3, 2), (3, 0), (4, 0), (3, 3), (4, 1)], 0), ([(0, 2), (0, 3), (0, 0), (0, 3), (3, 2), (3, 3), (4, 0), (1, 3), (2, 0), (2, 0)], 0), ([(0, 3), (1, 2), (0, 3), (0, 1), (3, 0), (0, 2), (0, 1), (0, 2), (0, 0), (1, 1)], 0), ([(0, 2), (0, 1), (3, 0), (0, 2), (3, 1), (3, 0), (3, 2), (3, 3), (0, 2), (0, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.7149234   0.19235932  0.67222201]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5792
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.17936033  0.41820392  0.89046918]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5890
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.21045391  0.94768229  0.24001549]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5764
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.29063612  0.95609318 -0.03763612]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5814
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.0345595   0.97862833 -0.20271218]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5846
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.22437514  0.95519189 -0.19303949]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running experiment 12/50...
Shuffled Demos: [([(0, 0), (1, 1), (4, 0), (1, 0), (1, 3), (2, 1), (2, 2), (2, 1), (1, 2), (0, 0)], 0), ([(0, 0), (0, 3), (1, 1), (4, 1), (4, 0), (3, 2), (3, 3), (4, 3), (4, 2), (3, 1)], 0), ([(0, 0), (1, 3), (1, 1), (4, 2), (4, 0), (1, 2), (4, 3), (1, 1), (4, 0), (3, 3)], 0), ([(0, 0), (0, 3), (1, 1), (4, 2), (3, 1), (3, 1), (3, 1), (3, 3), (4, 1), (4, 0)], 0), ([(0, 1), (3, 2), (3, 2), (3, 2), (3, 2), (3, 3), (4, 0), (1, 3), (2, 1), (5, None)], 9), ([(0, 1), (3, 3), (4, 3), (5, None)], 3)]

Running EBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5916
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.74651275  0.6551468  -0.11619549]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5822
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.22092146 0.78967896 0.57236426]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5878
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.53974447  0.81476703  0.21173237]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5892
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.98147317 -0.07490278 -0.17635191]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5794
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.34275283  0.86218737 -0.37303277]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5910
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.25647586  0.93427452 -0.24769187]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [([(0, 0), (0, 2), (0, 0), (1, 3), (2, 0), (2, 2), (1, 2), (0, 0), (0, 2), (0, 1)], 0), ([(0, 1), (0, 3), (3, 0), (0, 3), (1, 3), (2, 0), (2, 1), (5, None)], 7), ([(0, 2), (0, 0), (0, 0), (0, 2), (0, 1), (3, 3), (0, 1), (1, 2), (0, 3), (1, 0)], 0), ([(0, 1), (3, 2), (3, 0), (0, 2), (0, 3), (1, 1), (4, 0), (1, 2), (0, 1), (3, 2)], 0), ([(0, 2), (0, 2), (0, 0), (1, 2), (0, 1), (3, 3), (4, 2), (3, 1), (3, 3), (0, 1)], 0), ([(0, 0), (0, 3), (3, 1), (4, 2), (3, 1), (3, 1), (3, 0), (0, 3), (0, 2), (0, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5920
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.47288218 -0.11235805 -0.87393255]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5996
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.00411458  0.95685908 -0.29052328]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5868
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.44996194 0.68617331 0.57157716]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5802
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.3563022  0.69622455 0.62315337]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.31369501  0.93084781 -0.18739743]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5906
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.18288306  0.87123947  0.45551682]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running experiment 14/50...
Shuffled Demos: [([(0, 0), (1, 3), (4, 1), (4, 1), (4, 1), (5, None)], 5), ([(0, 0), (0, 2), (0, 3), (1, 1), (4, 2), (3, 0), (0, 1), (3, 2), (3, 1), (3, 0)], 0), ([(0, 2), (0, 1), (3, 1), (3, 1), (3, 1), (3, 0), (0, 0), (0, 2), (0, 2), (0, 0)], 1), ([(0, 0), (0, 1), (1, 1), (4, 0), (1, 2), (0, 1), (3, 0), (0, 3), (1, 3), (2, 3)], 0), ([(0, 2), (0, 1), (3, 0), (0, 0), (0, 3), (1, 3), (2, 2), (1, 1), (4, 2), (3, 3)], 0), ([(0, 1), (3, 3), (4, 1), (5, None)], 3)]

Running EBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.62856654  0.72974037  0.26904107]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5878
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.60825179  0.69470235  0.38395104]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5744
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.05825491 0.78195046 0.62061247]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5766
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.18871738 0.75892974 0.6232266 ]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5808
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.54727944  0.77496821  0.31608462]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5912
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.26435349 0.78848748 0.55534199]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 2), (3, 0), (0, 0), (0, 1), (3, 1), (3, 1), (3, 1), (3, 3)], 0), ([(0, 0), (0, 0), (0, 1), (1, 2), (0, 3), (1, 0), (1, 1), (2, 1), (5, None)], 0), ([(0, 3), (1, 2), (0, 3), (1, 3), (2, 1), (1, 0), (0, 2), (0, 0), (0, 3), (1, 3)], 0), ([(0, 0), (0, 0), (0, 3), (1, 0), (0, 0), (0, 1), (1, 0), (1, 0), (1, 0), (0, 3)], 0), ([(0, 2), (0, 2), (0, 3), (1, 3), (2, 1), (1, 1), (4, 3), (5, None)], 0), ([(0, 0), (0, 3), (3, 0), (0, 3), (3, 1), (3, 0), (0, 3), (1, 2), (4, 2), (3, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.11135383 -0.95686773  0.26833651]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.48320314  0.83805933 -0.25332052]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5606
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.4158858   0.86623467 -0.27690521]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5628
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.5100359  0.81861273 0.26407685]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5460
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.17254645 0.98379848 0.04866492]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5500
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.08255347  0.97956144  0.18342386]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running experiment 16/50...
Shuffled Demos: [([(0, 1), (3, 3), (3, 1), (3, 0), (0, 2), (0, 0), (0, 2), (0, 3), (1, 2), (1, 1)], 0), ([(0, 3), (1, 0), (1, 1), (4, 1), (4, 0), (5, None)], 0), ([(0, 1), (3, 3), (4, 2), (3, 0), (0, 1), (1, 2), (0, 1), (3, 0), (3, 0), (0, 1)], 0), ([(0, 0), (0, 1), (1, 2), (0, 1), (3, 2), (3, 2), (3, 3), (4, 1), (4, 1), (3, 1)], 0), ([(0, 0), (0, 3), (1, 2), (0, 2), (0, 3), (1, 1), (4, 0), (1, 1), (4, 2), (4, 3)], 0), ([(0, 3), (1, 3), (2, 0), (2, 2), (2, 1), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.48619616 -0.13307473 -0.86365758]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5604
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.68455629 -0.04604063  0.7275046 ]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5462
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.51553307  0.19460962  0.83447753]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5504
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.8943406   0.24107433  0.37687936]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5456
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.40078941  0.54820275  0.7340583 ]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5320
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.89007829  0.27986549  0.35977207]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 3), (1, 3), (2, 2), (1, 2), (0, 0), (0, 2), (0, 0), (0, 0)], 0), ([(0, 1), (3, 3), (4, 0), (1, 3), (2, 2), (1, 1), (4, 1), (5, None)], 0), ([(0, 3), (1, 0), (0, 1), (3, 0), (0, 3), (1, 2), (0, 3), (1, 3), (2, 0), (2, 3)], 0), ([(0, 2), (0, 1), (3, 0), (0, 1), (0, 0), (0, 3), (1, 1), (4, 1), (4, 2), (3, 0)], 0), ([(0, 3), (1, 3), (2, 2), (1, 1), (4, 1), (4, 0), (1, 1), (4, 2), (3, 3), (4, 1)], 0), ([(0, 2), (0, 3), (0, 0), (0, 0), (0, 3), (3, 1), (3, 1), (3, 0), (0, 2), (0, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.42242356  0.07252262 -0.90349256]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5528
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92133501 -0.34318724  0.18265903]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5514
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.57541443 0.76202101 0.29702224]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5496
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.34903144  0.61127736 -0.71029363]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5422
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.18090107  0.93592132 -0.30220206]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5462
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.01591931  0.99197473 -0.12543013]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running experiment 18/50...
Shuffled Demos: [([(0, 0), (0, 3), (0, 1), (3, 3), (0, 1), (3, 2), (3, 1), (3, 1), (3, 2), (3, 2)], 2), ([(0, 3), (1, 3), (2, 2), (5, None)], 3), ([(0, 2), (0, 3), (1, 2), (0, 2), (0, 3), (1, 1), (4, 0), (1, 1), (2, 1), (5, None)], 9), ([(0, 0), (0, 3), (0, 3), (1, 2), (4, 1), (4, 2), (3, 3), (3, 3), (4, 2), (1, 1)], 0), ([(0, 1), (3, 3), (4, 3), (5, None)], 3), ([(0, 2), (0, 3), (1, 0), (1, 3), (2, 1), (5, None)], 5)]

Running EBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.27252782 -0.88915862  0.36759425]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.12350208  0.84025281 -0.52794171]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.03953787  0.97595048  0.21437679]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5900
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.13446951 0.98422545 0.11497052]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5900
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.06587079  0.96491781 -0.25415481]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5844
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.04685793  0.99028908 -0.13088879]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 2), (0, 3), (1, 3), (2, 3), (2, 2), (5, None)], 0), ([(0, 1), (1, 3), (2, 0), (2, 2), (1, 2), (0, 0), (0, 1), (3, 1), (3, 0), (3, 1)], 0), ([(0, 0), (0, 3), (3, 2), (3, 2), (3, 1), (3, 3), (4, 0), (1, 3), (2, 2), (1, 0)], 0), ([(0, 0), (0, 1), (3, 0), (3, 3), (4, 3), (5, None)], 5), ([(0, 2), (0, 3), (1, 3), (2, 2), (2, 0), (2, 2), (1, 0), (1, 3), (4, 2), (3, 1)], 0), ([(0, 2), (0, 1), (0, 0), (0, 2), (0, 0), (0, 1), (0, 0), (0, 1), (3, 3), (4, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5914
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.56228066 -0.10882503 -0.81975458]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5246
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89310935  0.36026584  0.26937746]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5252
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.72297835  0.60832077  0.32748763]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5278
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.430888    0.63886322 -0.63732983]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5152
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.07870748  0.66087393 -0.74635835]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5224
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.50036147  0.82962611 -0.24770731]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running experiment 20/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 0), (0, 3), (1, 0), (1, 1), (4, 0), (1, 1), (4, 1), (3, 3)], 0), ([(0, 0), (1, 1), (4, 2), (3, 1), (3, 0), (0, 1), (3, 2), (3, 3), (4, 3), (5, None)], 9), ([(0, 1), (3, 3), (4, 3), (5, None)], 3), ([(0, 2), (0, 1), (3, 3), (4, 3), (5, None)], 4), ([(0, 3), (1, 1), (4, 3), (5, None)], 3), ([(0, 1), (3, 0), (0, 1), (0, 0), (0, 3), (1, 2), (4, 3), (5, None)], 7)]

Running EBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.82193266 -0.38766466  0.41730422]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5828
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.44312278  0.88939976  0.11229544]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5794
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.58736781 0.75341489 0.29557582]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5748
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.57792425 0.73511981 0.35440433]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5808
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.32541198  0.61224162  0.720602  ]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5890
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.23269159  0.93826722 -0.25594774]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Shuffled Demos: [([(0, 0), (1, 1), (4, 2), (3, 2), (3, 0), (0, 0), (0, 1), (0, 0), (0, 3), (1, 2)], 0), ([(0, 0), (0, 1), (3, 1), (4, 2), (3, 1), (3, 3), (4, 0), (1, 2), (1, 2), (4, 3)], 0), ([(0, 1), (3, 0), (0, 1), (1, 1), (4, 0), (3, 0), (0, 2), (0, 3), (1, 1), (4, 2)], 0), ([(0, 2), (0, 1), (3, 2), (3, 3), (4, 0), (1, 1), (4, 3), (4, 3), (5, None)], 8), ([(0, 0), (1, 1), (4, 0), (1, 1), (4, 2), (3, 1), (3, 2), (3, 0), (4, 2), (1, 3)], 0), ([(0, 1), (3, 0), (3, 3), (4, 2), (3, 1), (3, 2), (3, 3), (3, 0), (0, 2), (0, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.12581325  0.13420518 -0.98293438]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5844
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.04110645  0.54186726  0.83945824]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5844
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.18003405 0.76678015 0.61614604]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5722
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.44506821  0.86830727 -0.21899037]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5832
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.22120894  0.78883179  0.57342045]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5866
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.01927211  0.89329906  0.44904941]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running experiment 22/50...
Shuffled Demos: [([(0, 0), (0, 2), (0, 0), (0, 0), (0, 0), (0, 2), (0, 1), (1, 2), (0, 1), (3, 1)], 0), ([(0, 2), (0, 0), (0, 1), (3, 1), (3, 2), (3, 2), (3, 2), (3, 2), (3, 1), (3, 2)], 0), ([(0, 3), (1, 1), (4, 3), (4, 0), (1, 1), (4, 1), (4, 1), (3, 2), (3, 2), (3, 2)], 0), ([(0, 1), (0, 2), (0, 0), (0, 3), (1, 0), (2, 1), (5, None)], 6), ([(0, 1), (3, 3), (4, 3), (4, 3), (5, None)], 4), ([(0, 0), (0, 0), (0, 0), (0, 1), (3, 3), (4, 1), (4, 0), (1, 2), (0, 3), (3, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.5892
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.52680705  0.79846601 -0.29142129]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.5942
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.06847524 0.95474144 0.28944762]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.5830
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.19566141  0.96373878 -0.18145022]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.5788
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.31418577 0.91367495 0.2578476 ]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.5800
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.09126716 0.97560737 0.1996511 ]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.5826
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.04538    0.98599096 0.16050692]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (3, 3), (4, 0), (5, None)], 7), ([(0, 3), (0, 2), (0, 1), (3, 2), (3, 1), (3, 2), (3, 3), (4, 3), (5, None)], 8), ([(0, 1), (3, 0), (0, 0), (0, 3), (0, 2), (0, 1), (3, 2), (3, 0), (0, 3), (1, 2)], 0), ([(0, 0), (0, 2), (3, 2), (3, 1), (3, 2), (3, 2), (0, 2), (0, 1), (3, 3), (4, 2)], 0), ([(0, 3), (1, 0), (1, 2), (0, 2), (0, 2), (0, 0), (0, 3), (1, 1), (4, 0), (1, 0)], 0), ([(0, 2), (0, 3), (1, 0), (1, 2), (0, 0), (0, 2), (0, 3), (1, 2), (0, 0), (0, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.10166521  0.98874812 -0.10973302]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.62515083 -0.77863664 -0.05395752]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.5960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.30605037  0.76880051  0.56149706]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.5866
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.48053068  0.87647187 -0.02978819]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.39245482  0.84755635 -0.35724983]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.5814
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.27686056  0.95902406 -0.06017545]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running experiment 24/50...
Shuffled Demos: [([(0, 0), (1, 1), (0, 2), (0, 0), (0, 1), (3, 2), (3, 1), (4, 3), (5, None)], 8), ([(0, 2), (0, 3), (1, 0), (1, 1), (4, 2), (1, 0), (1, 3), (2, 2), (1, 0), (1, 0)], 0), ([(0, 0), (0, 2), (0, 3), (1, 0), (1, 0), (2, 3), (2, 0), (2, 2), (1, 3), (2, 1)], 0), ([(0, 3), (1, 3), (1, 0), (1, 2), (0, 3), (1, 2), (0, 2), (0, 1), (1, 3), (2, 0)], 0), ([(0, 3), (1, 2), (0, 3), (1, 0), (1, 0), (1, 0), (0, 1), (3, 0), (0, 1), (3, 3)], 0), ([(0, 1), (3, 0), (0, 1), (3, 1), (4, 3), (4, 0), (1, 3), (1, 1), (4, 3), (5, None)], 9)]

Running EBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.11425378 -0.83428533  0.5393645 ]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.17028542  0.85339466 -0.49266665]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5904
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.40765482  0.89216375 -0.19458006]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5636
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.29410275  0.86621655  0.4039461 ]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.50070232 0.62662246 0.59719467]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5964
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.2174101   0.77249328  0.59664645]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 1), (3, 2), (3, 0), (0, 1), (3, 1), (3, 3), (4, 3), (5, None)], 9), ([(0, 0), (0, 2), (0, 2), (0, 1), (3, 0), (0, 3), (1, 2), (0, 2), (0, 2), (0, 0)], 0), ([(0, 2), (0, 3), (1, 2), (0, 3), (1, 2), (0, 3), (1, 1), (4, 0), (1, 1), (4, 1)], 0), ([(0, 2), (3, 2), (3, 3), (0, 3), (1, 3), (2, 1), (5, None)], 6), ([(0, 1), (3, 2), (3, 1), (3, 0), (0, 1), (3, 0), (0, 0), (0, 3), (3, 3), (4, 2)], 2), ([(0, 1), (3, 0), (0, 1), (3, 0), (0, 3), (3, 3), (4, 0), (5, None)], 7)]

Running EBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.17457367  0.97926195 -0.10281083]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.35424825  0.92834867 -0.1125919 ]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5956
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.36188926 0.88564245 0.29098731]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5776
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.27396678 0.95746887 0.09052938]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5872
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.3674255   0.91706765  0.15487228]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.32720642 0.92945019 0.17046496]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running experiment 26/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 2), (0, 3), (0, 0), (0, 0), (0, 3), (3, 2), (3, 1), (3, 1)], 0), ([(0, 3), (1, 0), (1, 2), (0, 2), (0, 1), (3, 1), (4, 2), (3, 1), (3, 0), (0, 1)], 0), ([(0, 3), (1, 1), (4, 3), (5, None)], 3), ([(0, 0), (0, 1), (3, 3), (4, 1), (3, 0), (0, 2), (0, 3), (1, 3), (4, 2), (3, 0)], 0), ([(0, 2), (0, 3), (1, 3), (2, 2), (1, 2), (0, 1), (3, 2), (3, 1), (3, 2), (3, 2)], 0), ([(0, 3), (1, 1), (4, 2), (3, 1), (3, 2), (3, 0), (4, 2), (3, 2), (3, 1), (4, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.28220173 -0.93653639  0.20799464]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.5774
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.26164252  0.96516103  0.00271754]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.5908
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.04432408  0.85246745 -0.5208979 ]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.5840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.46153024  0.88649479 -0.03341887]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.5958
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.38215854  0.85320808 -0.35495184]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.5812
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.36164666  0.87665432 -0.31731513]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Shuffled Demos: [([(0, 3), (1, 2), (0, 3), (1, 0), (1, 1), (4, 0), (1, 3), (2, 1), (5, None)], 0), ([(0, 1), (3, 1), (3, 1), (4, 2), (3, 1), (3, 3), (4, 0), (1, 3), (2, 3), (2, 3)], 0), ([(0, 3), (1, 2), (0, 0), (0, 0), (0, 1), (3, 1), (3, 2), (3, 3), (4, 2), (1, 2)], 0), ([(0, 3), (1, 2), (4, 2), (4, 3), (5, None)], 4), ([(0, 2), (0, 1), (3, 2), (3, 0), (0, 0), (0, 3), (1, 0), (2, 1), (5, None)], 8), ([(0, 1), (3, 3), (4, 3), (5, None)], 3)]

Running EBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5826
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.44481689  0.78890332  0.42399232]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5626
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.62523469  0.75812781  0.18526688]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5676
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.6113558   0.17269236  0.77228326]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5586
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.03068067  0.94787215 -0.31717043]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5522
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.16236033  0.96867174 -0.1879207 ]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5606
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.30489742  0.87599596 -0.37372267]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running experiment 28/50...
Shuffled Demos: [([(0, 0), (0, 2), (0, 2), (0, 3), (1, 3), (2, 0), (2, 0), (2, 1), (5, None)], 8), ([(0, 2), (0, 3), (1, 3), (2, 2), (2, 1), (5, None)], 5), ([(0, 0), (1, 3), (2, 1), (2, 0), (2, 0), (2, 0), (2, 2), (1, 1), (4, 1), (4, 1)], 0), ([(0, 0), (0, 2), (0, 0), (0, 0), (0, 3), (1, 1), (4, 1), (4, 2), (3, 3), (4, 3)], 0), ([(0, 2), (0, 1), (0, 0), (0, 1), (3, 0), (0, 1), (3, 2), (3, 2), (3, 2), (3, 1)], 0), ([(0, 3), (0, 0), (0, 3), (1, 2), (0, 1), (3, 1), (3, 2), (3, 3), (4, 1), (4, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.18868402 -0.61215795 -0.76789387]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.42659046  0.7864844   0.44661267]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.5874
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.35546968 0.79209082 0.49621915]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.5862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.28412227 0.95154955 0.11759248]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.5930
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.34431113  0.84722607 -0.40454646]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.5830
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.43757583  0.85592991  0.27552021]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 3), (1, 1), (0, 3), (1, 2), (0, 1), (3, 0), (0, 1), (3, 2)], 0), ([(0, 0), (0, 1), (3, 2), (0, 0), (0, 2), (0, 1), (3, 3), (4, 2), (3, 2), (0, 0)], 0), ([(0, 2), (0, 0), (0, 0), (0, 1), (3, 1), (3, 0), (0, 1), (3, 0), (4, 2), (3, 2)], 0), ([(0, 0), (1, 0), (1, 1), (4, 0), (1, 1), (4, 3), (5, None)], 0), ([(0, 1), (3, 2), (0, 0), (0, 1), (3, 3), (4, 1), (4, 2), (1, 2), (1, 0), (1, 1)], 0), ([(0, 0), (0, 3), (3, 1), (3, 3), (4, 0), (1, 2), (4, 1), (4, 1), (4, 3), (5, None)], 9)]

Running EBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.5788
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.22145614  0.43045705 -0.87502223]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.5878
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.53380911  0.82374899  0.1910116 ]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.5798
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.28179907  0.81933388  0.49928076]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.5516
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.40923843  0.84556334 -0.34285063]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.5570
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.04415856 0.92290606 0.38248454]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.5592
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.49159239 0.85366509 0.1720257 ]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running experiment 30/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 2), (0, 3), (1, 3), (2, 0), (2, 2), (1, 3), (2, 2), (1, 1)], 0), ([(0, 1), (3, 3), (4, 0), (1, 0), (1, 1), (4, 3), (5, None)], 0), ([(0, 1), (3, 0), (0, 1), (3, 1), (3, 3), (4, 1), (3, 1), (4, 2), (3, 0), (0, 0)], 0), ([(0, 0), (0, 0), (0, 2), (0, 0), (0, 0), (0, 3), (1, 1), (4, 0), (5, None)], 0), ([(0, 1), (3, 1), (4, 1), (3, 0), (0, 3), (1, 0), (1, 1), (4, 2), (3, 2), (3, 2)], 0), ([(0, 3), (1, 1), (4, 2), (3, 2), (3, 0), (0, 0), (0, 3), (1, 2), (0, 1), (3, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5858
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.11974361 0.66067123 0.74106342]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5508
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.43956437 0.79828372 0.41173569]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5446
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.21937434  0.97142082  0.09064488]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5340
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.52848777 0.8456268  0.07493987]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5336
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.1398223   0.91610824 -0.37575979]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5308
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.37265379  0.90922525 -0.18557641]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Shuffled Demos: [([(0, 2), (0, 1), (3, 1), (3, 0), (4, 1), (3, 3), (3, 2), (0, 0), (0, 1), (1, 0)], 0), ([(0, 3), (1, 2), (0, 2), (0, 3), (3, 1), (3, 1), (3, 0), (0, 2), (0, 3), (1, 1)], 0), ([(0, 0), (0, 2), (3, 1), (3, 1), (3, 0), (0, 3), (0, 1), (3, 3), (4, 2), (4, 3)], 0), ([(0, 2), (0, 1), (3, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 2), (0, 3), (0, 1)], 0), ([(0, 1), (3, 0), (0, 2), (0, 0), (0, 1), (3, 2), (3, 0), (0, 0), (0, 0), (0, 3)], 0), ([(0, 2), (0, 1), (3, 0), (0, 3), (0, 0), (0, 2), (3, 1), (3, 0), (0, 0), (0, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.84390748  0.26578149 -0.46602614]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.5912
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.90143617  0.03258812 -0.43168373]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.5862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.15565979  0.81606668 -0.55660148]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.5834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.0954461   0.93468704 -0.34241813]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.5872
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.32399644  0.94008698 -0.10612621]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.5862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.03698913  0.95986443 -0.27801454]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running experiment 32/50...
Shuffled Demos: [([(0, 2), (0, 3), (3, 1), (3, 1), (3, 0), (0, 2), (0, 2), (0, 0), (0, 2), (3, 1)], 0), ([(0, 1), (3, 3), (4, 1), (4, 2), (3, 0), (0, 3), (1, 2), (4, 2), (3, 3), (4, 0)], 0), ([(0, 1), (0, 1), (3, 0), (4, 1), (4, 2), (3, 3), (3, 2), (3, 2), (3, 0), (0, 1)], 0), ([(0, 3), (1, 1), (4, 2), (3, 1), (3, 0), (0, 2), (0, 0), (0, 3), (1, 1), (0, 3)], 0), ([(0, 2), (0, 1), (0, 2), (0, 1), (3, 2), (3, 0), (3, 2), (3, 1), (3, 3), (0, 0)], 0), ([(0, 0), (0, 3), (3, 1), (3, 1), (3, 2), (3, 2), (3, 2), (3, 2), (3, 1), (3, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.04821193  0.96723531 -0.24926183]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5916
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.02534915  0.85277732  0.52165915]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.25155942  0.96019456 -0.12142594]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5884
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.53480468  0.81272675 -0.23121243]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5898
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.14818301  0.91198067 -0.38253505]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5816
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.1317364   0.96326458 -0.23402323]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Shuffled Demos: [([(0, 1), (3, 0), (0, 3), (0, 2), (0, 2), (0, 0), (0, 2), (0, 3), (3, 2), (0, 2)], 0), ([(0, 3), (1, 1), (4, 0), (1, 0), (1, 3), (2, 1), (5, None)], 6), ([(0, 2), (0, 3), (1, 0), (0, 3), (3, 1), (3, 1), (3, 0), (0, 2), (3, 3), (4, 2)], 0), ([(0, 3), (1, 3), (1, 2), (0, 3), (3, 0), (0, 2), (0, 1), (0, 1), (0, 3), (1, 3)], 0), ([(0, 3), (1, 0), (1, 1), (4, 0), (1, 1), (4, 1), (5, None)], 6), ([(0, 2), (0, 1), (3, 3), (4, 0), (5, None)], 4)]

Running EBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.5465349  -0.80526318  0.22989306]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.16035606 0.87755882 0.45185888]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.5812
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.14177826  0.98881933 -0.04620883]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.5932
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.0377275  0.92798434 0.37070433]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.5794
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.23402506  0.8811596   0.41084064]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.5800
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.1626202   0.98115938  0.10431178]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running experiment 34/50...
Shuffled Demos: [([(0, 0), (1, 1), (4, 0), (1, 1), (4, 3), (5, None)], 0), ([(0, 3), (1, 1), (4, 0), (1, 0), (1, 2), (0, 0), (0, 3), (1, 0), (1, 3), (2, 1)], 0), ([(0, 3), (1, 2), (0, 2), (0, 0), (0, 1), (1, 2), (1, 0), (1, 2), (0, 2), (0, 0)], 0), ([(0, 0), (1, 0), (1, 3), (1, 3), (2, 2), (1, 2), (4, 2), (1, 3), (2, 3), (5, None)], 0), ([(0, 3), (1, 0), (1, 0), (2, 2), (1, 0), (1, 2), (0, 1), (3, 0), (0, 1), (3, 3)], 0), ([(0, 2), (3, 1), (3, 2), (3, 2), (0, 2), (0, 2), (0, 2), (0, 1), (3, 3), (4, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.96656386  0.14527457  0.21130453]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5494
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.07154753  0.98530741 -0.15508143]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5360
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.91900472 -0.32421454 -0.22431064]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5536
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.55187127  0.67882008  0.48439798]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5560
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.86045787  0.28673914 -0.42118038]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5472
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.10770039  0.98607157  0.12674183]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Shuffled Demos: [([(0, 0), (0, 2), (0, 1), (3, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 3), (2, 0)], 0), ([(0, 0), (0, 3), (3, 2), (0, 3), (1, 1), (4, 1), (4, 1), (4, 3), (5, None)], 0), ([(0, 0), (0, 0), (0, 0), (0, 1), (3, 3), (4, 2), (3, 2), (3, 1), (4, 1), (4, 1)], 6), ([(0, 0), (0, 2), (0, 1), (3, 2), (3, 2), (0, 0), (0, 2), (0, 1), (3, 0), (3, 3)], 6), ([(0, 2), (0, 2), (3, 3), (3, 3), (4, 3), (5, None)], 5), ([(0, 3), (1, 1), (4, 2), (3, 0), (0, 0), (0, 2), (0, 0), (0, 1), (3, 0), (0, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5860
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.16851079  0.62450343 -0.76262676]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5268
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.08550288  0.89764974  0.43233575]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5270
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.29711627  0.72560912  0.62065556]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.30113324  0.92408635  0.23533634]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5214
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.2642724   0.90385418 -0.33646355]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5334
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.26202678  0.87997671  0.39621075]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running experiment 36/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 0), (1, 2), (0, 1), (0, 0), (0, 3), (1, 1), (4, 1), (4, 2)], 0), ([(0, 0), (0, 0), (0, 1), (3, 1), (3, 1), (3, 2), (3, 3), (4, 0), (1, 2), (0, 2)], 0), ([(0, 0), (0, 1), (1, 0), (1, 3), (4, 1), (4, 0), (1, 0), (1, 3), (2, 3), (2, 0)], 0), ([(0, 2), (0, 3), (1, 3), (4, 1), (3, 1), (3, 3), (4, 3), (4, 1), (4, 1), (4, 3)], 0), ([(0, 3), (1, 1), (4, 0), (1, 1), (4, 2), (3, 0), (0, 2), (0, 3), (1, 2), (0, 3)], 0), ([(0, 0), (0, 3), (1, 2), (0, 0), (0, 2), (0, 3), (1, 1), (4, 2), (3, 0), (0, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5882
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94515114  0.30501368  0.1168588 ]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.16882161  0.9834698   0.06547065]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5746
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.41409323  0.86254053  0.29077591]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5952
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.46829801  0.39475703  0.79048331]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.97994767 -0.19855874 -0.01664326]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.31709068  0.51493452  0.79642699]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 37/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], 3), ([(0, 0), (0, 0), (0, 1), (3, 0), (0, 0), (0, 0), (0, 0), (0, 3), (1, 3), (4, 2)], 0), ([(0, 1), (3, 2), (3, 3), (4, 0), (1, 0), (2, 0), (2, 2), (5, None)], 7), ([(0, 0), (0, 2), (0, 3), (1, 0), (1, 2), (0, 3), (1, 2), (0, 1), (3, 1), (3, 0)], 0), ([(0, 3), (1, 2), (0, 3), (3, 1), (3, 0), (0, 0), (0, 2), (0, 0), (0, 3), (1, 1)], 0), ([(0, 1), (3, 2), (3, 2), (3, 1), (3, 3), (4, 0), (1, 0), (1, 1), (4, 2), (3, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 37
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.44666171 0.64488343 0.62017633]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.09884259 0.58451446 0.80534029]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5762
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.32279684  0.93360104 -0.15553554]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5670
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.19890373  0.9418661  -0.27078691]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5892
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.36253089  0.9297142  -0.06482945]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5874
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.39716293  0.90426112 -0.15675916]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running experiment 38/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 0), (5, None)], 3), ([(0, 2), (0, 0), (0, 2), (0, 0), (0, 1), (3, 2), (3, 2), (3, 0), (0, 0), (0, 3)], 1), ([(0, 3), (1, 1), (4, 3), (5, None)], 3), ([(0, 2), (0, 3), (1, 3), (2, 3), (2, 1), (1, 2), (0, 2), (0, 2), (0, 0), (0, 3)], 0), ([(0, 0), (0, 1), (1, 1), (2, 2), (1, 0), (1, 2), (0, 2), (0, 2), (0, 0), (0, 2)], 0), ([(0, 2), (0, 3), (1, 2), (0, 2), (0, 3), (0, 2), (0, 3), (1, 3), (1, 0), (1, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 38
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.55878534  0.82529557  0.08152397]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 38
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.23690342 -0.90312256 -0.35811507]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 38
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.60763596 -0.66986287  0.42668757]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.5752
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.04840554 0.96167079 0.26990033]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.5796
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.3001878   0.8354344   0.46036577]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.5952
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.50944758  0.86008933 -0.02663668]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 39/50...
Shuffled Demos: [([(0, 3), (1, 0), (1, 1), (2, 3), (2, 3), (2, 3), (2, 2), (1, 0), (1, 2), (1, 3)], 0), ([(0, 2), (0, 0), (0, 1), (0, 2), (0, 1), (3, 3), (4, 1), (4, 3), (5, None)], 8), ([(0, 3), (1, 1), (4, 3), (5, None)], 3), ([(0, 3), (1, 0), (1, 1), (4, 2), (3, 0), (0, 3), (1, 2), (0, 3), (1, 1), (4, 1)], 0), ([(0, 2), (0, 1), (3, 1), (4, 0), (1, 1), (0, 3), (1, 3), (4, 1), (4, 2), (3, 3)], 0), ([(0, 2), (0, 1), (3, 2), (3, 0), (3, 2), (3, 2), (3, 1), (3, 2), (3, 2), (3, 3)], 7)]

Running EBIRL with 1 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5852
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.85313816 -0.39857546  0.33659008]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5802
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.22236387  0.92461175  0.30926916]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5870
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.74069957  0.6287659   0.23668035]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.22784991  0.91631248 -0.32932638]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5848
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.70844976  0.70288702 -0.06362999]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.23742636  0.9115435   0.33573378]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running experiment 40/50...
Shuffled Demos: [([(0, 3), (1, 1), (4, 2), (3, 3), (0, 0), (0, 3), (1, 2), (0, 1), (1, 0), (1, 1)], 0), ([(0, 0), (0, 3), (0, 2), (0, 2), (0, 0), (0, 1), (3, 0), (0, 3), (1, 0), (1, 2)], 0), ([(0, 0), (0, 1), (3, 2), (3, 2), (3, 3), (4, 0), (5, None)], 6), ([(0, 2), (0, 1), (3, 0), (4, 3), (5, None)], 4), ([(0, 1), (3, 2), (3, 1), (3, 3), (4, 2), (3, 3), (4, 1), (4, 3), (5, None)], 8), ([(0, 2), (0, 1), (0, 3), (1, 0), (1, 1), (4, 0), (1, 2), (0, 2), (0, 2), (0, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5902
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.89743649  0.29748142  0.32574921]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5754
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.41086953 -0.08367258  0.90784642]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5904
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.01547197  0.87947091  0.47570111]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5750
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.01157543 0.83693106 0.54718591]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5898
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.34063807  0.79309202  0.50494629]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5686
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.34199222 0.84686754 0.40725507]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 41/50...
Shuffled Demos: [([(0, 0), (1, 3), (2, 3), (2, 0), (2, 1), (5, None)], 5), ([(0, 1), (3, 1), (3, 3), (4, 2), (3, 1), (3, 0), (0, 3), (1, 1), (2, 0), (1, 0)], 0), ([(0, 0), (0, 0), (1, 2), (0, 3), (1, 1), (4, 0), (1, 0), (1, 2), (0, 2), (3, 1)], 0), ([(0, 1), (3, 1), (3, 0), (4, 3), (4, 2), (1, 3), (2, 2), (2, 1), (5, None)], 8), ([(0, 3), (1, 0), (2, 1), (2, 0), (2, 2), (1, 3), (2, 1), (5, None)], 7), ([(0, 2), (0, 3), (1, 2), (0, 3), (1, 2), (0, 1), (3, 2), (3, 2), (3, 1), (3, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 41
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.55293672  0.64597737  0.5262834 ]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.22346654  0.57285493 -0.78860632]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.8816288   0.28476653  0.37634915]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.3648462   0.78606403 -0.49898958]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.27094224 0.94410341 0.18777396]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.51489431 0.85325937 0.08265772]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running experiment 42/50...
Shuffled Demos: [([(0, 3), (1, 3), (2, 3), (2, 0), (1, 2), (0, 3), (1, 2), (0, 1), (3, 1), (4, 2)], 0), ([(0, 1), (3, 2), (3, 3), (0, 2), (0, 3), (0, 0), (0, 3), (1, 0), (1, 2), (0, 1)], 0), ([(0, 2), (3, 3), (0, 3), (1, 1), (4, 3), (1, 0), (1, 3), (2, 1), (5, None)], 8), ([(0, 1), (3, 1), (3, 1), (3, 3), (4, 2), (3, 0), (0, 2), (0, 3), (1, 1), (4, 0)], 0), ([(0, 0), (0, 1), (3, 3), (4, 2), (3, 3), (4, 2), (3, 1), (3, 0), (0, 2), (0, 3)], 0), ([(0, 3), (1, 2), (0, 1), (3, 1), (3, 2), (3, 3), (4, 2), (3, 3), (4, 0), (1, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5832
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.71511889  0.43259087 -0.54906294]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5798
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.34943819  0.12413286 -0.92870016]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.43713348 0.7963082  0.41809997]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5770
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.28612044 0.94356892 0.16677166]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5832
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.05384048 0.97851081 0.19904218]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5806
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.41879585 0.80648628 0.41736066]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 43/50...
Shuffled Demos: [([(0, 2), (0, 2), (0, 0), (0, 3), (1, 0), (2, 2), (5, None)], 0), ([(0, 2), (0, 0), (0, 3), (1, 2), (0, 3), (1, 3), (1, 3), (2, 2), (5, None)], 0), ([(0, 1), (3, 1), (3, 2), (3, 1), (3, 3), (4, 3), (5, None)], 6), ([(0, 2), (0, 0), (0, 1), (3, 3), (4, 0), (1, 3), (2, 2), (1, 1), (4, 2), (4, 3)], 0), ([(0, 3), (1, 1), (4, 3), (5, None)], 0), ([(0, 2), (0, 2), (0, 0), (0, 0), (0, 2), (0, 2), (3, 3), (4, 1), (5, None)], 8)]

Running EBIRL with 1 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.25134449  0.96408191  0.08586042]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5478
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.65582116  0.69210897 -0.30146937]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5538
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.08808861  0.97182248  0.21863548]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5212
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.4673127   0.88264297  0.0505986 ]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5148
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.10037032  0.82897952  0.55019884]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5318
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.07220392  0.98371462 -0.16459692]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running experiment 44/50...
Shuffled Demos: [([(0, 1), (3, 2), (3, 0), (0, 1), (3, 3), (4, 3), (4, 2), (3, 1), (3, 2), (3, 2)], 0), ([(0, 1), (0, 2), (0, 1), (3, 0), (0, 1), (3, 1), (3, 3), (4, 1), (4, 3), (5, None)], 9), ([(0, 1), (0, 2), (0, 1), (3, 2), (3, 0), (0, 2), (0, 1), (3, 3), (4, 1), (4, 3)], 0), ([(0, 0), (0, 0), (0, 3), (1, 1), (4, 0), (3, 2), (3, 0), (0, 3), (1, 2), (0, 3)], 0), ([(0, 2), (0, 0), (0, 1), (1, 1), (4, 2), (3, 1), (3, 3), (4, 3), (4, 3), (4, 0)], 0), ([(0, 3), (1, 2), (0, 3), (1, 0), (1, 2), (0, 1), (3, 2), (3, 0), (0, 2), (0, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 44
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.16983605 -0.98117526  0.09192833]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 44
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.537885   -0.80770787 -0.24142852]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 44
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.10812153 -0.85449796  0.50807772]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.2717911   0.89387404  0.35653723]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5876
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.02301107  0.97188243  0.23433957]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5822
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.06137801  0.99801737  0.0139305 ]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 45/50...
Shuffled Demos: [([(0, 1), (1, 1), (4, 0), (1, 2), (0, 1), (3, 1), (3, 1), (3, 2), (3, 3), (3, 3)], 0), ([(0, 0), (1, 3), (2, 0), (2, 1), (1, 1), (0, 1), (3, 0), (0, 1), (3, 2), (3, 0)], 0), ([(0, 1), (3, 1), (3, 2), (0, 2), (0, 2), (0, 2), (0, 3), (1, 3), (2, 2), (1, 3)], 0), ([(0, 0), (0, 2), (0, 2), (0, 1), (3, 2), (0, 1), (3, 0), (0, 3), (1, 3), (2, 2)], 0), ([(0, 2), (0, 0), (0, 3), (1, 1), (0, 2), (0, 1), (3, 0), (0, 0), (0, 3), (1, 1)], 0), ([(0, 0), (0, 2), (0, 0), (0, 2), (0, 3), (1, 3), (1, 0), (1, 0), (1, 2), (0, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5866
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.9183874   0.03309631 -0.39429586]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.07122069  0.72227017 -0.68793417]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5714
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.38993233  0.90473945  0.17146225]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.13067503  0.58562595 -0.79997893]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.58297373  0.00092525  0.81249048]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.78821528 -0.07787601  0.61045229]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running experiment 46/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 1), (4, 1), (4, 2), (3, 2), (3, 0), (3, 2), (3, 2), (3, 2)], 2), ([(0, 0), (0, 3), (1, 2), (0, 1), (3, 3), (4, 2), (1, 3), (2, 3), (2, 1), (2, 1)], 0), ([(0, 3), (0, 0), (0, 3), (1, 2), (0, 1), (3, 3), (4, 2), (3, 3), (4, 2), (3, 1)], 0), ([(0, 3), (1, 2), (0, 3), (1, 2), (0, 3), (1, 1), (4, 3), (5, None)], 0), ([(0, 3), (0, 3), (1, 0), (1, 3), (1, 3), (2, 2), (5, None)], 0), ([(0, 3), (0, 3), (1, 0), (1, 3), (4, 1), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 46
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.11371465 -0.90062209 -0.41946255]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5886
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.07957533  0.86152966 -0.50143237]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5806
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.18229585  0.980555   -0.07266436]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5548
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.0997371   0.91607256 -0.38841161]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5436
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.34662721  0.82921006  0.43847492]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5482
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.10904663  0.97580297 -0.18951883]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 47/50...
Shuffled Demos: [([(0, 0), (0, 3), (0, 1), (3, 3), (4, 3), (4, 2), (3, 1), (3, 0), (0, 3), (0, 2)], 0), ([(0, 2), (0, 0), (0, 1), (1, 1), (2, 2), (1, 2), (1, 1), (2, 0), (2, 1), (5, None)], 0), ([(0, 2), (0, 1), (3, 1), (3, 3), (4, 2), (3, 2), (3, 3), (4, 0), (1, 1), (2, 2)], 0), ([(0, 2), (0, 2), (0, 1), (3, 1), (3, 0), (0, 1), (0, 3), (1, 2), (0, 1), (3, 2)], 0), ([(0, 3), (1, 1), (4, 0), (1, 1), (2, 2), (5, None)], 0), ([(0, 2), (0, 0), (0, 1), (3, 0), (3, 3), (4, 3), (5, None)], 6)]

Running EBIRL with 1 demonstrations for experiment 47
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.45436833 0.88591604 0.09328555]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5924
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.33053991  0.94372009 -0.01165185]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5626
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.32102245 0.82737825 0.46085771]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5582
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.28339331 0.80942447 0.51431532]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5502
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.17184085  0.97918775 -0.1079911 ]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5498
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.1768194   0.91567656 -0.36093121]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running experiment 48/50...
Shuffled Demos: [([(0, 3), (1, 3), (2, 1), (5, None)], 0), ([(0, 0), (0, 0), (0, 0), (0, 2), (0, 2), (0, 2), (0, 1), (3, 3), (4, 2), (3, 2)], 0), ([(0, 2), (3, 1), (3, 3), (4, 3), (4, 3), (5, None)], 5), ([(0, 2), (0, 1), (3, 2), (3, 1), (3, 2), (3, 3), (4, 2), (3, 3), (0, 1), (3, 0)], 0), ([(0, 1), (3, 1), (3, 0), (3, 1), (3, 0), (0, 2), (0, 2), (0, 1), (3, 1), (3, 1)], 0), ([(0, 1), (0, 1), (3, 1), (3, 3), (4, 0), (1, 1), (4, 1), (4, 2), (4, 3), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.37472532  0.61847636 -0.69070104]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5924
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.35388777 0.87900096 0.31956339]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5990
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.5514655  0.83131909 0.06924147]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5910
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.23624946  0.84728674  0.47570093]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5698
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.0759073   0.90195116 -0.42511433]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.11443268  0.97838275  0.17225665]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 49/50...
Shuffled Demos: [([(0, 0), (0, 2), (0, 0), (0, 2), (0, 3), (1, 2), (0, 1), (3, 3), (4, 0), (1, 0)], 0), ([(0, 1), (3, 1), (3, 2), (3, 1), (3, 0), (0, 3), (1, 3), (2, 1), (5, None)], 0), ([(0, 0), (0, 2), (0, 0), (0, 2), (0, 1), (3, 1), (3, 3), (4, 3), (5, None)], 8), ([(0, 1), (3, 1), (3, 2), (3, 3), (4, 1), (4, 0), (1, 2), (0, 1), (1, 3), (2, 3)], 0), ([(0, 2), (0, 1), (1, 0), (1, 3), (2, 1), (1, 2), (0, 3), (1, 1), (4, 1), (5, None)], 0), ([(0, 1), (3, 1), (3, 3), (4, 0), (1, 3), (2, 2), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5830
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.56408796  0.66599071 -0.48812001]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5162
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.93339208 -0.02541343  0.35795723]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5194
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.64917178  0.74124479 -0.17068148]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5304
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.31746027  0.73698967 -0.59671199]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5314
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.1367401   0.85151961 -0.50617832]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5346
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.02272721  0.97815123 -0.20664858]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running experiment 50/50...
Shuffled Demos: [([(0, 2), (0, 0), (1, 3), (2, 3), (2, 2), (1, 2), (0, 3), (1, 3), (2, 2), (1, 2)], 0), ([(0, 3), (1, 1), (4, 2), (3, 3), (4, 0), (1, 0), (1, 0), (1, 1), (4, 0), (1, 1)], 0), ([(0, 3), (3, 3), (4, 3), (5, None)], 3), ([(0, 1), (3, 2), (3, 0), (3, 1), (3, 3), (3, 1), (3, 3), (3, 2), (3, 2), (3, 3)], 0), ([(0, 2), (0, 2), (0, 2), (0, 3), (1, 1), (4, 2), (4, 0), (1, 1), (4, 1), (4, 2)], 0), ([(0, 1), (3, 2), (3, 3), (4, 3), (5, None)], 4)]

Running EBIRL with 1 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.5814
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.08216978 0.67346567 0.73463741]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.5934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.86697932 -0.29703426  0.40014685]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.5860
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.48780546  0.87103198 -0.05787163]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.5894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.12382575  0.93056265 -0.34455818]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.5850
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.44013568  0.8885717   0.1293094 ]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.5750
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.27263537 0.96211355 0.00273297]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (3, 1), (3, 0), (0, 0), (0, 1), (3, 1), (3, 2), (3, 1), (3, 1)], 0), ([(0, 1), (3, 1), (3, 2), (3, 2), (3, 1), (3, 0), (0, 0), (0, 3), (1, 2), (0, 2)], 0), ([(0, 1), (0, 3), (1, 2), (0, 0), (0, 3), (1, 1), (4, 0), (1, 3), (2, 2), (1, 3)], 0), ([(0, 1), (0, 3), (1, 2), (0, 1), (1, 3), (2, 1), (5, None)], 0), ([(0, 3), (1, 1), (4, 3), (4, 2), (3, 3), (4, 3), (4, 2), (1, 0), (1, 1), (4, 1)], 0), ([(0, 3), (1, 1), (4, 0), (1, 1), (4, 2), (4, 0), (1, 1), (4, 2), (4, 2), (3, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.18512985 -0.82512775  0.53375195]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5902
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.28185713  0.81569195  0.50517641]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5998
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.05976667  0.884747   -0.46222363]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5686
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.19584489  0.8629013  -0.4658821 ]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5652
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.08938797  0.9633854  -0.25278124]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.5656
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.53338249  0.80751375 -0.25184254]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (1, 2), (0, 1), (0, 1), (3, 2), (3, 2), (3, 0), (0, 0), (0, 0), (0, 1)], 0), ([(0, 2), (3, 1), (4, 0), (3, 1), (3, 3), (4, 2), (3, 2), (3, 1), (3, 1), (3, 0)], 0), ([(0, 3), (1, 1), (0, 1), (0, 2), (3, 0), (3, 1), (4, 3), (4, 1), (3, 2), (3, 1)], 0), ([(0, 1), (1, 1), (4, 1), (3, 0), (0, 2), (0, 3), (1, 1), (4, 0), (1, 3), (2, 3)], 0), ([(0, 2), (0, 3), (0, 1), (3, 0), (0, 3), (3, 0), (0, 0), (0, 2), (0, 0), (0, 0)], 0), ([(0, 3), (1, 2), (0, 2), (0, 0), (0, 2), (0, 2), (0, 2), (0, 1), (3, 2), (3, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.5902
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.29820649  0.62088301 -0.72496702]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.33664065  0.93888834  0.07184538]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.5934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.12260304  0.90081352 -0.41653751]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6140
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.03521097  0.92304073 -0.38308745]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6038
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.16687729 0.98597493 0.00232432]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.5994
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.36760775  0.91982771  0.13704572]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 2), (0, 3), (3, 3), (4, 2), (3, 2), (3, 0), (0, 1), (3, 2), (3, 3), (4, 1)], 0), ([(0, 1), (3, 3), (4, 1), (4, 3), (5, None)], 4), ([(0, 1), (0, 3), (1, 2), (1, 3), (2, 2), (1, 1), (4, 0), (1, 0), (1, 3), (1, 3)], 0), ([(0, 3), (1, 3), (2, 2), (5, None)], 3), ([(0, 1), (3, 1), (4, 3), (1, 1), (4, 1), (5, None)], 5), ([(0, 2), (0, 0), (0, 0), (0, 3), (3, 1), (3, 0), (3, 0), (0, 3), (3, 2), (3, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.251278   -0.95386078  0.16434411]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.24310089  0.92762188 -0.28358351]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5946
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.41797966 0.90663956 0.05742571]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6018
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.18341278  0.97445682 -0.12959033]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.5978
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.47100493  0.80895929  0.35176587]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6052
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.50509152 0.85432457 0.12252381]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running experiment 4/50...
Shuffled Demos: [([(0, 0), (1, 2), (0, 3), (1, 2), (0, 0), (0, 0), (0, 3), (1, 2), (0, 3), (1, 0)], 0), ([(0, 3), (1, 0), (1, 2), (0, 1), (0, 2), (0, 3), (3, 1), (3, 1), (3, 0), (0, 2)], 0), ([(0, 3), (1, 2), (0, 2), (0, 3), (1, 2), (0, 2), (0, 0), (0, 3), (3, 0), (0, 2)], 0), ([(0, 0), (0, 3), (1, 3), (2, 1), (1, 0), (1, 0), (1, 3), (2, 3), (2, 2), (1, 3)], 0), ([(0, 1), (3, 3), (4, 2), (3, 3), (4, 1), (3, 3), (4, 1), (4, 0), (1, 2), (1, 2)], 0), ([(0, 1), (3, 0), (0, 3), (3, 0), (4, 1), (4, 3), (5, None)], 6)]

Running EBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.43522945 -0.14136177 -0.88915251]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6150
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.65201307  0.32776727  0.68370137]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5986
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.42304337  0.89615038  0.13397312]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.74383602  0.56911413 -0.35045267]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.5940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.70456591 -0.32483192 -0.63092876]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6034
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.05256003 0.90942969 0.41252282]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [([(0, 0), (0, 3), (1, 2), (0, 1), (1, 3), (2, 2), (1, 1), (4, 1), (5, None)], 0), ([(0, 0), (0, 2), (0, 3), (1, 1), (4, 0), (1, 3), (2, 0), (2, 0), (2, 2), (1, 3)], 0), ([(0, 0), (1, 1), (4, 3), (5, None)], 3), ([(0, 3), (1, 1), (4, 2), (1, 0), (1, 2), (0, 2), (0, 0), (0, 1), (1, 0), (1, 0)], 0), ([(0, 0), (0, 2), (0, 3), (1, 1), (4, 1), (3, 2), (3, 0), (0, 0), (0, 2), (0, 3)], 0), ([(0, 0), (0, 3), (1, 0), (1, 0), (2, 0), (2, 1), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6090
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.85468625 -0.44365537  0.26959474]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5736
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.72058134  0.06191982 -0.69060008]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5770
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.55144576  0.65978595  0.51048025]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.33810096  0.91523736 -0.21915364]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5674
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.3489812   0.91509485 -0.2020236 ]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.5638
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.55988911  0.68479329  0.46645722]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running experiment 6/50...
Shuffled Demos: [([(0, 2), (0, 1), (0, 1), (0, 0), (0, 1), (3, 2), (3, 1), (3, 3), (4, 2), (3, 1)], 0), ([(0, 3), (1, 0), (1, 1), (4, 2), (3, 0), (4, 3), (5, None)], 6), ([(0, 3), (1, 0), (1, 2), (0, 0), (0, 2), (0, 1), (0, 1), (3, 1), (3, 1), (4, 1)], 0), ([(0, 1), (3, 0), (0, 3), (1, 1), (4, 1), (4, 0), (1, 0), (1, 1), (4, 2), (3, 3)], 0), ([(0, 1), (0, 1), (0, 1), (3, 3), (0, 0), (0, 3), (1, 1), (4, 1), (4, 0), (1, 2)], 0), ([(0, 0), (0, 2), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3), (2, 3), (2, 3), (2, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.5012583  -0.84283964  0.19586079]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.41102637 -0.8285493  -0.38021491]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.29762962  0.94280241 -0.15013402]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6066
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.18452779  0.96790265 -0.17062812]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.5992
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.15413394  0.95437217 -0.25576647]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6082
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.0367936   0.85021609 -0.52514649]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [([(0, 0), (0, 1), (0, 3), (0, 2), (3, 2), (3, 1), (3, 2), (3, 1), (3, 1), (3, 3)], 0), ([(0, 1), (1, 0), (1, 3), (2, 2), (1, 1), (2, 2), (1, 3), (2, 1), (5, None)], 0), ([(0, 2), (0, 0), (0, 0), (0, 1), (3, 0), (0, 1), (0, 3), (1, 2), (0, 0), (1, 1)], 0), ([(0, 3), (1, 2), (0, 0), (0, 3), (3, 3), (0, 3), (1, 2), (0, 3), (0, 2), (0, 3)], 0), ([(0, 0), (0, 0), (0, 1), (3, 3), (0, 2), (0, 2), (0, 2), (0, 0), (0, 0), (0, 2)], 0), ([(0, 2), (0, 0), (1, 1), (4, 2), (4, 3), (5, None)], 5)]

Running EBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.15270676  0.95769176  0.24394084]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6016
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.36083332 0.91771092 0.16615047]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5824
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.22294023  0.85459567 -0.46900309]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.12855968  0.95118262 -0.28057804]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5762
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.28873476  0.87099755 -0.39748649]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.5772
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.25312547  0.94702594  0.19765971]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running experiment 8/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 0), (0, 0), (0, 1), (3, 0), (0, 0), (0, 3), (1, 1), (4, 3)], 0), ([(0, 0), (0, 3), (1, 0), (1, 2), (0, 2), (0, 2), (0, 1), (3, 0), (0, 3), (0, 0)], 0), ([(0, 0), (0, 3), (0, 0), (0, 2), (0, 0), (1, 3), (2, 1), (5, None)], 7), ([(0, 0), (0, 2), (0, 2), (0, 0), (0, 2), (0, 3), (0, 2), (0, 1), (3, 1), (3, 2)], 2), ([(0, 0), (0, 2), (0, 2), (0, 0), (0, 1), (3, 3), (4, 1), (4, 3), (5, None)], 8), ([(0, 3), (1, 1), (4, 1), (4, 1), (4, 3), (5, None)], 5)]

Running EBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6016
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.13058579  0.68944717 -0.71246751]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5958
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.93119384 -0.36300812 -0.03321355]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.2945321   0.95539999 -0.02148742]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6054
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.33771097 0.94117861 0.01158143]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.36522507  0.85365847 -0.3713191 ]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.5970
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.49519356 0.868356   0.02722496]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [([(0, 1), (3, 0), (4, 1), (4, 2), (1, 1), (4, 2), (1, 1), (4, 2), (1, 2), (0, 2)], 0), ([(0, 2), (0, 3), (1, 3), (1, 0), (1, 2), (0, 2), (0, 1), (3, 2), (3, 1), (3, 1)], 0), ([(0, 1), (3, 3), (4, 0), (1, 1), (2, 2), (1, 0), (1, 1), (4, 2), (4, 0), (1, 3)], 0), ([(0, 0), (0, 1), (3, 2), (3, 2), (3, 2), (3, 1), (3, 3), (4, 3), (5, None)], 8), ([(0, 3), (1, 0), (0, 0), (0, 3), (1, 3), (2, 3), (2, 1), (1, 1), (4, 2), (3, 1)], 0), ([(0, 2), (0, 1), (3, 3), (0, 0), (0, 2), (3, 1), (3, 0), (0, 0), (0, 0), (0, 1)], 7)]

Running EBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5970
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.97250572 -0.21735355 -0.08360662]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6090
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.8363272  -0.53412188 -0.12357442]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5938
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.30344622 0.9049362  0.29834689]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6024
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.41289066  0.84621882  0.33680114]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.5926
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.08794064 0.67625023 0.73140418]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6062
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.03208184  0.91831491  0.39454845]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running experiment 10/50...
Shuffled Demos: [([(0, 3), (1, 2), (0, 3), (3, 2), (3, 1), (3, 1), (3, 3), (4, 1), (4, 2), (3, 0)], 0), ([(0, 0), (0, 0), (0, 0), (0, 2), (0, 2), (0, 1), (3, 2), (3, 2), (3, 0), (3, 0)], 0), ([(0, 1), (3, 3), (4, 2), (3, 2), (3, 1), (3, 2), (3, 0), (0, 0), (1, 2), (0, 2)], 0), ([(0, 1), (3, 2), (3, 2), (3, 1), (3, 0), (0, 3), (1, 3), (2, 0), (2, 2), (1, 0)], 0), ([(0, 1), (3, 2), (3, 2), (3, 0), (0, 3), (3, 0), (0, 3), (1, 1), (2, 1), (5, None)], 9), ([(0, 0), (0, 2), (0, 0), (0, 1), (3, 0), (4, 0), (1, 0), (1, 1), (4, 1), (4, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5984
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.61949587  0.76537889  0.17441337]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6096
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.4810247   0.85402745 -0.19812206]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6008
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.20742725 0.95877771 0.19421441]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5956
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.11398182  0.8787638  -0.46344615]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5938
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.01976448 0.80974009 0.58645576]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.5954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.14800328  0.84340249 -0.51649519]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [([(0, 2), (0, 3), (1, 2), (0, 2), (0, 3), (1, 0), (1, 0), (1, 2), (0, 3), (1, 1)], 0), ([(0, 3), (1, 0), (1, 0), (1, 3), (2, 2), (1, 1), (2, 2), (1, 3), (2, 0), (2, 0)], 0), ([(0, 2), (0, 1), (3, 1), (3, 0), (4, 2), (3, 3), (4, 1), (3, 1), (3, 0), (0, 2)], 0), ([(0, 3), (1, 2), (4, 2), (1, 0), (1, 1), (4, 0), (1, 0), (1, 0), (1, 2), (0, 3)], 0), ([(0, 2), (0, 2), (0, 1), (3, 1), (3, 1), (3, 0), (0, 3), (1, 0), (1, 0), (1, 1)], 0), ([(0, 2), (0, 1), (3, 3), (0, 2), (0, 2), (0, 0), (1, 3), (2, 1), (5, None)], 8)]

Running EBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5982
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.58660758  0.68464901 -0.43260522]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.28039446  0.93907882 -0.19877101]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5942
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.07806803  0.96376188 -0.25508514]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6140
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.23686773  0.9456217   0.2229199 ]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.5994
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.1470412   0.94766819 -0.28337941]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6084
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.12952919  0.8611397   0.49158988]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running experiment 12/50...
Shuffled Demos: [([(0, 1), (3, 2), (3, 2), (0, 2), (0, 3), (1, 3), (2, 2), (2, 0), (1, 0), (1, 1)], 0), ([(0, 1), (3, 3), (4, 1), (4, 1), (4, 0), (3, 2), (3, 0), (0, 2), (0, 1), (3, 3)], 0), ([(0, 3), (1, 2), (1, 0), (0, 3), (3, 1), (4, 1), (5, None)], 0), ([(0, 3), (1, 3), (2, 3), (2, 3), (2, 0), (2, 0), (2, 1), (5, None)], 7), ([(0, 0), (0, 2), (0, 1), (3, 0), (0, 2), (0, 2), (0, 2), (3, 2), (3, 3), (4, 2)], 0), ([(0, 3), (1, 2), (4, 3), (5, None)], 3)]

Running EBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5998
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.64195892  0.58946253 -0.49032914]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5928
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.46917859 0.85626661 0.2160531 ]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5660
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.46006751  0.84549521 -0.2710641 ]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5668
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.27611733  0.95838435  0.07251665]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5678
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.00673339  0.96080779 -0.27713364]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.5614
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.0068267   0.97038585 -0.24146366]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [([(0, 1), (3, 0), (3, 2), (3, 2), (3, 3), (4, 3), (5, None)], 6), ([(0, 2), (0, 2), (0, 0), (0, 1), (3, 3), (3, 1), (3, 2), (3, 3), (4, 1), (4, 1)], 0), ([(0, 0), (0, 1), (3, 2), (3, 2), (3, 3), (0, 3), (1, 0), (2, 0), (2, 1), (5, None)], 9), ([(0, 3), (1, 3), (2, 3), (5, None)], 3), ([(0, 0), (0, 3), (3, 1), (3, 1), (3, 3), (4, 3), (5, None)], 6), ([(0, 2), (0, 0), (0, 2), (0, 2), (0, 2), (0, 3), (3, 3), (4, 3), (1, 1), (4, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.12332528  0.91029944  0.39515289]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.26921233 -0.91237065  0.3083902 ]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.36461568  0.90942513 -0.20000336]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 13
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.51735938  0.83125379  0.20336275]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 13
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.4100013   0.90981621 -0.06429156]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.5990
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.36561587  0.9303124  -0.02904932]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running experiment 14/50...
Shuffled Demos: [([(0, 3), (3, 2), (3, 2), (3, 0), (0, 1), (3, 1), (3, 2), (3, 0), (3, 0), (0, 2)], 1), ([(0, 3), (1, 2), (0, 3), (1, 3), (2, 2), (5, None)], 5), ([(0, 3), (1, 1), (0, 0), (0, 0), (0, 1), (3, 3), (4, 1), (3, 2), (3, 2), (3, 2)], 0), ([(0, 3), (1, 0), (1, 1), (4, 1), (3, 3), (4, 1), (5, None)], 6), ([(0, 1), (3, 1), (3, 3), (3, 1), (3, 3), (4, 1), (5, None)], 6), ([(0, 3), (1, 0), (1, 0), (2, 0), (2, 0), (2, 0), (2, 1), (5, None)], 7)]

Running EBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.32783697 -0.78345938  0.52793401]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.04954668 -0.70689216 -0.70558387]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.5924
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.12397426  0.86276368 -0.49017264]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6024
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.19137451  0.8731305  -0.44835134]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6050
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.3348112   0.92247779 -0.19218789]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6054
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.29730623 0.85663338 0.42164945]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 1), (1, 2), (0, 3), (1, 3), (2, 3), (2, 1), (5, None)], 0), ([(0, 2), (3, 3), (3, 3), (4, 1), (4, 2), (3, 1), (3, 0), (4, 3), (5, None)], 8), ([(0, 3), (0, 3), (1, 2), (0, 1), (3, 3), (4, 0), (1, 0), (1, 2), (0, 1), (3, 3)], 0), ([(0, 3), (1, 2), (0, 2), (0, 2), (0, 2), (0, 2), (0, 2), (3, 0), (0, 0), (1, 0)], 0), ([(0, 0), (0, 3), (1, 1), (4, 3), (5, None)], 0), ([(0, 2), (0, 0), (0, 0), (0, 3), (1, 0), (1, 1), (4, 0), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5952
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.57580639 -0.46321156 -0.67370769]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5968
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.28890716  0.82141601  0.49174016]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5620
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.15148329  0.98063978 -0.12409044]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5680
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.41744495  0.83550654 -0.35730733]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5472
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.11188819  0.79977752 -0.58977704]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.5408
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.44569467 0.88257148 0.14974591]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running experiment 16/50...
Shuffled Demos: [([(0, 2), (0, 2), (0, 2), (0, 3), (1, 2), (0, 2), (0, 2), (3, 0), (3, 1), (4, 3)], 0), ([(0, 2), (0, 1), (3, 3), (4, 0), (1, 3), (2, 1), (1, 3), (2, 2), (1, 1), (4, 3)], 0), ([(0, 0), (1, 3), (2, 1), (1, 0), (1, 0), (1, 1), (4, 3), (5, None)], 0), ([(0, 1), (3, 2), (0, 0), (0, 1), (3, 3), (4, 3), (5, None)], 6), ([(0, 3), (1, 1), (4, 3), (1, 3), (2, 0), (2, 1), (1, 2), (0, 2), (0, 2), (0, 0)], 0), ([(0, 0), (0, 3), (3, 2), (3, 3), (4, 2), (4, 1), (4, 0), (5, None)], 7)]

Running EBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6042
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.95670155 -0.27759087  0.08755254]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5982
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.75659059  0.54127186 -0.36687253]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5594
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.16672454 0.72324789 0.67016074]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5738
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.00549452  0.96251354  0.27117796]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5716
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.51824456  0.85118269  0.08313004]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.5770
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.02008617  0.97257207 -0.23173287]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [([(0, 2), (0, 2), (0, 3), (1, 0), (1, 0), (1, 0), (1, 3), (2, 2), (1, 0), (1, 0)], 0), ([(0, 1), (3, 0), (4, 3), (5, None)], 3), ([(0, 0), (0, 2), (0, 3), (1, 3), (2, 3), (2, 2), (1, 3), (2, 1), (2, 2), (1, 0)], 0), ([(0, 0), (1, 1), (4, 3), (5, None)], 3), ([(0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 3), (4, 2), (3, 1), (3, 0)], 0), ([(0, 2), (3, 1), (3, 0), (3, 2), (3, 0), (0, 2), (0, 2), (3, 3), (4, 3), (1, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5966
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.82494863 -0.56013592 -0.07554804]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6060
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.53753973 0.84283918 0.02594519]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6090
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.37589179  0.91035373 -0.17309376]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5832
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.49073313  0.86985143 -0.05039325]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5950
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.58453303  0.78638857  0.19978527]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.5986
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.46482137  0.88129027 -0.08525583]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running experiment 18/50...
Shuffled Demos: [([(0, 0), (0, 2), (0, 3), (1, 2), (0, 2), (0, 2), (0, 2), (0, 1), (0, 1), (3, 2)], 0), ([(0, 0), (0, 3), (3, 3), (4, 3), (5, None)], 4), ([(0, 0), (0, 1), (0, 3), (1, 2), (0, 3), (1, 0), (1, 2), (0, 3), (1, 0), (1, 3)], 0), ([(0, 1), (3, 0), (0, 1), (3, 0), (0, 0), (0, 0), (0, 1), (3, 3), (4, 2), (3, 0)], 2), ([(0, 0), (0, 1), (3, 2), (3, 2), (3, 0), (0, 3), (1, 0), (1, 0), (1, 2), (0, 2)], 0), ([(0, 2), (3, 1), (3, 2), (0, 0), (0, 1), (0, 3), (1, 0), (1, 3), (2, 1), (1, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5972
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.49214856  0.67387725 -0.551071  ]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6088
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.7146786   0.68011605 -0.16332991]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6038
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.44509575  0.44542692  0.77684273]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.5996
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.28817534  0.83576539 -0.46738762]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6076
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.39749453  0.91116225 -0.10854242]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.03907214  0.99919388 -0.00921713]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [([(0, 1), (3, 2), (0, 2), (0, 2), (0, 3), (1, 3), (2, 0), (2, 1), (5, None)], 0), ([(0, 0), (0, 1), (3, 0), (0, 3), (3, 2), (0, 2), (0, 2), (0, 2), (0, 0), (0, 3)], 0), ([(0, 0), (0, 1), (3, 2), (3, 3), (4, 0), (1, 3), (1, 3), (2, 1), (5, None)], 0), ([(0, 1), (3, 2), (3, 0), (0, 1), (3, 0), (4, 1), (4, 0), (1, 0), (2, 2), (1, 3)], 0), ([(0, 2), (0, 1), (3, 3), (4, 2), (3, 3), (4, 3), (5, None)], 6), ([(0, 3), (1, 2), (1, 2), (0, 0), (0, 0), (0, 2), (0, 0), (0, 0), (0, 0), (0, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6004
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.95925658 -0.10023663  0.26415797]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5982
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.42802039  0.85127754 -0.30352115]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5730
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.32891571  0.80324014 -0.49660824]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5432
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.30895959 0.94807981 0.07542306]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5394
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.41687069  0.86385221  0.28280416]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.5390
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.21726923 0.94920826 0.22759122]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running experiment 20/50...
Shuffled Demos: [([(0, 1), (3, 2), (3, 3), (4, 1), (4, 1), (4, 0), (1, 0), (1, 1), (4, 3), (5, None)], 9), ([(0, 0), (0, 2), (0, 0), (0, 3), (1, 1), (4, 1), (4, 0), (5, None)], 7), ([(0, 3), (1, 2), (0, 0), (0, 3), (1, 2), (0, 2), (0, 3), (3, 3), (0, 3), (1, 0)], 0), ([(0, 1), (3, 1), (3, 2), (3, 1), (3, 1), (3, 0), (0, 3), (1, 3), (4, 2), (3, 0)], 0), ([(0, 1), (3, 0), (4, 3), (5, None)], 3), ([(0, 3), (1, 3), (2, 2), (1, 1), (4, 1), (5, None)], 5)]

Running EBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.03366188 -0.94701404 -0.31942335]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.15485481 -0.98628696  0.05707916]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.17201866  0.93617914 -0.30655862]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6020
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.22752493  0.89285011  0.38865291]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6004
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.185789    0.97353053 -0.13311933]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.5912
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.09021078  0.97712173 -0.19260098]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Shuffled Demos: [([(0, 0), (0, 3), (1, 2), (0, 0), (0, 1), (3, 2), (3, 1), (3, 2), (3, 0), (4, 3)], 0), ([(0, 0), (0, 3), (1, 3), (2, 1), (1, 1), (0, 3), (1, 1), (4, 3), (1, 3), (2, 1)], 0), ([(0, 0), (1, 1), (4, 3), (4, 3), (1, 0), (1, 3), (2, 3), (2, 0), (2, 0), (2, 2)], 0), ([(0, 3), (1, 2), (0, 1), (1, 2), (0, 2), (0, 2), (0, 0), (0, 0), (0, 2), (0, 3)], 0), ([(0, 3), (1, 1), (4, 0), (3, 1), (3, 2), (3, 3), (3, 0), (3, 2), (3, 0), (0, 1)], 0), ([(0, 0), (0, 0), (0, 0), (0, 2), (0, 2), (0, 2), (0, 3), (1, 1), (4, 1), (4, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.20012132  0.17808077 -0.96345145]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5976
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.98410679 -0.17323176 -0.03904582]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5926
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.52357485  0.66167896 -0.53670321]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.5902
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.9412475   0.19804032 -0.27355654]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.78602699  0.53867654 -0.30329714]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6040
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.09275015  0.83885051  0.53640212]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running experiment 22/50...
Shuffled Demos: [([(0, 3), (1, 0), (1, 2), (0, 0), (0, 1), (3, 3), (4, 0), (1, 0), (1, 1), (4, 2)], 0), ([(0, 3), (1, 1), (4, 0), (1, 0), (1, 1), (4, 2), (3, 2), (3, 2), (3, 0), (4, 0)], 0), ([(0, 3), (1, 3), (2, 3), (2, 0), (2, 1), (5, None)], 5), ([(0, 0), (0, 3), (1, 3), (2, 2), (1, 0), (1, 3), (1, 1), (4, 1), (3, 1), (3, 0)], 0), ([(0, 3), (1, 0), (1, 0), (1, 1), (2, 0), (2, 0), (2, 1), (2, 2), (1, 2), (0, 1)], 0), ([(0, 1), (3, 0), (0, 2), (0, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 1), (3, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.5944
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.45482531 -0.07755011  0.88719779]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6110
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.82644572  0.1578722   0.54042931]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6036
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.47484612  0.59948721 -0.64431068]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6058
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.62787259  0.7272012   0.27740662]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6030
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.3464847   0.70687464 -0.61666571]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6030
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.20164011  0.80097039 -0.56372662]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Shuffled Demos: [([(0, 1), (3, 1), (3, 1), (3, 1), (3, 0), (0, 3), (1, 1), (4, 2), (3, 1), (3, 0)], 0), ([(0, 3), (3, 1), (3, 1), (3, 2), (3, 1), (3, 2), (3, 0), (0, 3), (1, 3), (2, 3)], 0), ([(0, 1), (3, 0), (3, 3), (4, 2), (3, 0), (0, 2), (0, 1), (3, 2), (3, 3), (0, 2)], 0), ([(0, 1), (3, 3), (4, 0), (1, 0), (0, 1), (3, 0), (0, 2), (0, 3), (1, 0), (1, 0)], 0), ([(0, 1), (3, 1), (3, 3), (4, 0), (1, 0), (2, 2), (2, 2), (1, 2), (0, 2), (0, 3)], 0), ([(0, 0), (0, 2), (0, 2), (0, 1), (3, 3), (4, 0), (1, 3), (2, 2), (1, 0), (1, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.5998
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.38733479  0.86165536 -0.32790516]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6006
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.08192376  0.41051033  0.90816836]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6152
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.0890392   0.94794119 -0.30574422]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.5990
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.17952794  0.97499182 -0.13099871]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.5968
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.37063101  0.92309059 -0.10264705]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6110
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.02936514  0.80012047 -0.59912012]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running experiment 24/50...
Shuffled Demos: [([(0, 3), (1, 2), (0, 0), (0, 1), (3, 1), (3, 1), (3, 1), (3, 0), (4, 2), (3, 0)], 0), ([(0, 0), (0, 0), (0, 3), (1, 1), (4, 1), (4, 1), (5, None)], 6), ([(0, 3), (1, 1), (4, 2), (3, 1), (3, 3), (0, 3), (1, 0), (1, 2), (1, 1), (4, 3)], 0), ([(0, 0), (1, 2), (0, 2), (0, 2), (0, 2), (0, 3), (1, 3), (2, 3), (2, 0), (2, 1)], 0), ([(0, 2), (0, 1), (3, 3), (4, 2), (3, 2), (3, 0), (0, 0), (0, 3), (0, 0), (0, 2)], 1), ([(0, 3), (1, 0), (1, 0), (1, 3), (2, 0), (2, 1), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6038
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.57399307  0.80069192  0.17153546]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5994
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.06428472 0.98236832 0.17555614]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5968
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.35403821 0.90460874 0.23736044]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5958
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.14429876 0.97702374 0.15685181]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5954
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.31301601 0.91124188 0.26769237]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.3202007  0.94050081 0.113709  ]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Shuffled Demos: [([(0, 0), (0, 3), (3, 3), (4, 2), (3, 3), (4, 3), (5, None)], 6), ([(0, 1), (3, 2), (3, 3), (4, 2), (3, 3), (4, 0), (5, None)], 6), ([(0, 2), (3, 2), (3, 2), (3, 2), (3, 0), (3, 3), (4, 2), (3, 0), (0, 3), (0, 3)], 2), ([(0, 1), (3, 0), (0, 3), (1, 0), (1, 0), (1, 1), (4, 1), (3, 1), (3, 0), (0, 0)], 0), ([(0, 1), (1, 0), (1, 2), (0, 2), (0, 2), (0, 0), (0, 3), (3, 2), (3, 2), (3, 2)], 0), ([(0, 2), (0, 2), (0, 2), (0, 1), (0, 0), (0, 1), (3, 0), (0, 0), (1, 1), (4, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.46184596 -0.87888945  0.11938023]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.1135351  -0.86119386 -0.49543407]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.30824677  0.87032615  0.38407853]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5962
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.2053675   0.96086252  0.18592311]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5994
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.14843223  0.98189201 -0.11771128]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.5894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.30437655  0.80210201  0.51379693]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running experiment 26/50...
Shuffled Demos: [([(0, 0), (0, 2), (0, 0), (0, 0), (0, 1), (3, 3), (0, 3), (1, 3), (1, 3), (2, 0)], 0), ([(0, 2), (0, 0), (1, 2), (0, 2), (3, 1), (3, 1), (3, 2), (3, 1), (3, 2), (3, 1)], 0), ([(0, 3), (1, 2), (0, 3), (0, 2), (0, 3), (0, 3), (1, 1), (4, 3), (5, None)], 8), ([(0, 2), (0, 2), (0, 3), (0, 0), (0, 2), (0, 1), (3, 0), (0, 2), (0, 0), (0, 3)], 0), ([(0, 1), (3, 3), (4, 0), (1, 1), (2, 3), (2, 1), (5, None)], 6), ([(0, 1), (3, 0), (0, 1), (3, 3), (0, 2), (0, 1), (3, 3), (4, 2), (3, 3), (4, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6002
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.12169635  0.9562781   0.26593644]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.5916
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88902581  0.43959491  0.1280212 ]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6016
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.2424099  0.9367852  0.25233099]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6032
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.11095717  0.97371377 -0.19892211]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.02538067 0.98052492 0.19474781]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.17276564 0.95965322 0.2218507 ]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Shuffled Demos: [([(0, 0), (0, 3), (1, 0), (1, 0), (2, 0), (2, 1), (5, None)], 0), ([(0, 3), (1, 3), (2, 0), (2, 0), (2, 2), (1, 3), (2, 1), (5, None)], 0), ([(0, 0), (0, 2), (0, 2), (0, 0), (0, 3), (0, 3), (1, 3), (1, 2), (0, 0), (0, 3)], 0), ([(0, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 3), (4, 0), (1, 1), (4, 2)], 0), ([(0, 3), (1, 1), (4, 1), (4, 0), (3, 3), (0, 3), (1, 1), (0, 3), (0, 0), (0, 1)], 0), ([(0, 2), (0, 3), (1, 1), (4, 3), (5, None)], 4)]

Running EBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5992
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.01188739  0.12805106 -0.99169633]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6058
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.60659394 0.78132199 0.14690047]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5524
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.20003085  0.41193143  0.88898828]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5714
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.23648134  0.9658735  -0.10566437]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5680
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.59015774  0.18538354  0.78571419]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.5582
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.32626645  0.94402842  0.04858553]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running experiment 28/50...
Shuffled Demos: [([(0, 3), (1, 1), (4, 3), (5, None)], 3), ([(0, 3), (0, 0), (0, 2), (0, 0), (0, 0), (0, 3), (1, 1), (2, 2), (1, 3), (2, 1)], 0), ([(0, 2), (0, 3), (3, 2), (0, 2), (0, 3), (1, 3), (2, 3), (5, None)], 7), ([(0, 0), (0, 2), (0, 3), (1, 2), (4, 0), (3, 1), (3, 0), (0, 1), (3, 3), (4, 0)], 0), ([(0, 0), (0, 3), (1, 2), (0, 1), (3, 0), (0, 2), (0, 2), (0, 0), (0, 3), (1, 3)], 0), ([(0, 0), (0, 1), (3, 3), (0, 2), (0, 3), (1, 2), (0, 1), (3, 1), (3, 3), (4, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.73157187  0.50232978 -0.46094186]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6110
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.02374836  0.15644381  0.98740131]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6030
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.58480091 0.76968651 0.25610654]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.5980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.18089675  0.98245023 -0.04547431]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6050
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.39481002 0.91801554 0.03704746]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.5974
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.39681376 0.7507157  0.52817116]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Shuffled Demos: [([(0, 1), (1, 0), (1, 1), (4, 1), (4, 1), (4, 0), (1, 0), (1, 1), (4, 2), (3, 1)], 0), ([(0, 2), (0, 2), (0, 1), (3, 1), (3, 0), (4, 2), (3, 2), (3, 2), (3, 2), (3, 0)], 0), ([(0, 3), (1, 3), (2, 3), (2, 0), (2, 2), (1, 2), (4, 1), (4, 0), (1, 1), (4, 3)], 0), ([(0, 3), (1, 3), (2, 2), (1, 0), (1, 1), (4, 0), (5, None)], 0), ([(0, 2), (0, 3), (1, 1), (4, 2), (3, 0), (0, 0), (0, 1), (0, 0), (0, 3), (1, 0)], 0), ([(0, 0), (0, 0), (1, 0), (1, 0), (1, 0), (1, 2), (0, 0), (0, 1), (3, 0), (0, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6046
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.39676891 -0.08948047 -0.91354676]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6078
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.26567754  0.92232531 -0.28059129]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6130
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.40096232  0.86760166 -0.29410302]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.5744
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.04408784 0.82797269 0.55903263]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.5870
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.26643042  0.87419687 -0.40594908]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.5748
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.07327518  0.97649142  0.20271966]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running experiment 30/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 1), (3, 2), (3, 2), (3, 1), (3, 1), (3, 0), (0, 0), (0, 2)], 0), ([(0, 0), (0, 0), (0, 2), (0, 1), (3, 3), (4, 3), (5, None)], 6), ([(0, 1), (3, 2), (3, 3), (4, 3), (4, 1), (4, 2), (3, 3), (0, 1), (1, 1), (2, 1)], 0), ([(0, 3), (1, 2), (0, 3), (1, 0), (1, 3), (2, 3), (2, 2), (5, None)], 0), ([(0, 0), (0, 3), (1, 0), (0, 2), (0, 2), (0, 2), (0, 1), (3, 3), (0, 2), (0, 2)], 0), ([(0, 1), (3, 3), (4, 1), (4, 0), (1, 0), (1, 0), (1, 0), (1, 2), (0, 0), (0, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.30289419 -0.91114546  0.27940841]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.11728225  0.94287224 -0.31182819]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6004
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.22106433  0.95669742 -0.18936897]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5784
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.39043012 0.91232435 0.12340425]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5714
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.35487151 0.90793784 0.22296881]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.5780
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.36295391 0.87890209 0.3095086 ]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 3), (0, 0), (0, 3), (1, 0), (1, 3), (2, 0), (1, 2), (0, 0)], 0), ([(0, 1), (3, 3), (4, 0), (1, 1), (4, 1), (4, 1), (4, 1), (4, 1), (4, 0), (1, 2)], 0), ([(0, 1), (3, 1), (3, 3), (4, 1), (4, 1), (4, 2), (1, 1), (4, 3), (1, 2), (0, 2)], 0), ([(0, 2), (0, 3), (1, 0), (1, 3), (2, 1), (2, 1), (5, None)], 6), ([(0, 2), (3, 1), (4, 2), (3, 1), (3, 1), (3, 2), (0, 1), (3, 2), (3, 3), (4, 1)], 0), ([(0, 3), (1, 2), (0, 2), (0, 0), (0, 2), (0, 2), (0, 1), (3, 1), (3, 1), (3, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6058
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.75628473 -0.46376237 -0.4614736 ]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6052
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.22652741  0.00449131 -0.97399443]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.22273318  0.97277113 -0.06408013]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.5942
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.4462726   0.88867752 -0.10532348]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6020
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.23297429  0.95142472 -0.20128084]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6048
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.33704951  0.80499039  0.48825005]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running experiment 32/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 3), (1, 2), (1, 3), (2, 3), (2, 1), (1, 1), (4, 3), (5, None)], 0), ([(0, 0), (0, 3), (1, 3), (1, 3), (2, 2), (1, 1), (4, 2), (3, 2), (0, 0), (0, 3)], 0), ([(0, 0), (0, 3), (0, 2), (0, 2), (0, 1), (3, 1), (3, 3), (4, 2), (3, 0), (3, 2)], 0), ([(0, 0), (0, 0), (0, 2), (0, 3), (1, 3), (2, 2), (1, 3), (1, 2), (1, 3), (2, 2)], 0), ([(0, 1), (3, 1), (3, 2), (3, 0), (0, 1), (3, 1), (3, 1), (3, 2), (3, 1), (4, 2)], 0), ([(0, 0), (0, 2), (0, 2), (0, 2), (0, 3), (1, 2), (0, 0), (1, 3), (2, 2), (1, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5952
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.37115802 0.8018827  0.46821562]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5726
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.26154684  0.7927925   0.55052094]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5718
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.03367324  0.95988299 -0.27837162]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5714
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.0534464   0.85886943  0.50939846]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.43383515  0.87696991 -0.20666599]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.5702
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.37916061  0.90243196 -0.204582  ]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Shuffled Demos: [([(0, 0), (0, 0), (0, 1), (3, 2), (3, 3), (0, 1), (0, 2), (0, 1), (1, 2), (0, 1)], 0), ([(0, 1), (3, 1), (3, 2), (0, 1), (3, 1), (3, 1), (3, 1), (3, 3), (4, 2), (3, 1)], 0), ([(0, 1), (3, 3), (3, 3), (4, 2), (3, 0), (0, 2), (0, 0), (0, 2), (0, 2), (0, 2)], 0), ([(0, 0), (0, 0), (0, 0), (0, 3), (1, 1), (2, 2), (1, 3), (1, 2), (4, 2), (3, 2)], 0), ([(0, 0), (0, 1), (3, 0), (3, 0), (0, 0), (0, 3), (1, 3), (2, 1), (5, None)], 8), ([(0, 0), (0, 3), (1, 3), (2, 2), (1, 2), (0, 1), (3, 2), (3, 2), (3, 2), (0, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6014
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.20245132  0.97021831 -0.13300336]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.5928
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.16627976  0.95931677  0.22817181]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.5942
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.01155742  0.97045293 -0.24101356]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6018
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.48254095  0.87313932 -0.06915164]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.28566837  0.95412245 -0.08968795]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.0753579  0.92078322 0.38272634]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running experiment 34/50...
Shuffled Demos: [([(0, 3), (1, 1), (4, 0), (1, 2), (0, 2), (0, 2), (0, 2), (0, 3), (0, 0), (0, 1)], 0), ([(0, 3), (3, 2), (3, 2), (3, 1), (3, 2), (3, 1), (3, 2), (0, 1), (3, 1), (3, 2)], 0), ([(0, 3), (1, 3), (4, 0), (1, 3), (2, 3), (2, 3), (2, 1), (5, None)], 0), ([(0, 2), (0, 1), (0, 3), (1, 2), (0, 0), (0, 3), (1, 3), (2, 0), (2, 2), (5, None)], 0), ([(0, 1), (3, 0), (0, 1), (3, 3), (4, 1), (4, 0), (1, 2), (0, 3), (1, 1), (2, 2)], 0), ([(0, 1), (3, 0), (0, 2), (0, 0), (0, 3), (1, 1), (0, 3), (1, 3), (2, 2), (1, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5978
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.05094099  0.26085835  0.96403213]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6094
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.32783712 0.88852553 0.32100655]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5670
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.41509069 0.89248918 0.17652983]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5676
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.18592311  0.98241784 -0.0169644 ]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5590
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.07511893 0.96339431 0.25734907]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.5638
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.54785474  0.83513995 -0.04895345]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Shuffled Demos: [([(0, 0), (1, 3), (4, 0), (1, 3), (2, 0), (2, 3), (2, 2), (1, 0), (1, 0), (1, 2)], 0), ([(0, 2), (0, 1), (3, 2), (3, 1), (3, 3), (4, 3), (5, None)], 6), ([(0, 3), (1, 1), (4, 2), (3, 0), (0, 3), (1, 3), (2, 0), (1, 2), (0, 2), (0, 2)], 0), ([(0, 0), (0, 1), (3, 2), (3, 0), (0, 2), (0, 2), (0, 2), (0, 0), (0, 1), (1, 0)], 0), ([(0, 3), (3, 1), (3, 2), (3, 3), (4, 2), (3, 2), (3, 1), (3, 2), (3, 2), (3, 2)], 6), ([(0, 0), (0, 3), (1, 0), (0, 3), (1, 3), (2, 3), (2, 2), (1, 3), (2, 1), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.0328853  0.94817613 0.31603888]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6008
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.40071466  0.83180584  0.38409218]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5978
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.43913259  0.89361533  0.09281274]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6002
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.2338248   0.77540997  0.58657083]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6024
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.38353777  0.89688678 -0.22021101]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.5708
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.36653817 0.88530199 0.28616456]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running experiment 36/50...
Shuffled Demos: [([(0, 2), (0, 3), (3, 1), (3, 3), (4, 1), (4, 3), (5, None)], 6), ([(0, 1), (3, 0), (0, 1), (3, 1), (4, 2), (3, 0), (0, 0), (0, 3), (1, 1), (4, 1)], 0), ([(0, 1), (0, 3), (1, 3), (2, 1), (5, None)], 4), ([(0, 0), (0, 3), (1, 2), (0, 1), (3, 0), (3, 1), (3, 2), (0, 0), (0, 1), (0, 2)], 0), ([(0, 3), (1, 1), (4, 0), (1, 1), (4, 3), (5, None)], 5), ([(0, 0), (0, 2), (0, 1), (3, 2), (3, 0), (0, 1), (3, 1), (3, 0), (4, 2), (3, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.30117945 -0.94006429  0.15990643]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6070
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.3779275   0.89304639  0.24421089]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6028
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.36231406  0.91562799  0.17422374]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5864
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.35350281  0.8179206   0.45391812]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.5940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.06079446  0.93191432 -0.35754683]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6002
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.41597462  0.9073727  -0.0603315 ]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 37/50...
Shuffled Demos: [([(0, 3), (1, 1), (0, 3), (1, 0), (1, 1), (4, 3), (5, None)], 0), ([(0, 1), (3, 1), (4, 3), (5, None)], 3), ([(0, 1), (3, 1), (3, 2), (3, 1), (3, 1), (3, 0), (0, 1), (0, 3), (1, 3), (2, 0)], 0), ([(0, 0), (0, 3), (1, 1), (2, 2), (1, 3), (1, 3), (2, 3), (2, 1), (5, None)], 0), ([(0, 0), (1, 3), (1, 1), (4, 0), (1, 0), (1, 2), (0, 1), (0, 3), (3, 2), (3, 1)], 0), ([(0, 0), (0, 3), (1, 0), (2, 1), (1, 1), (4, 1), (4, 1), (4, 0), (1, 2), (0, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5934
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.26407625  0.13641013  0.95480679]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6062
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.32619149  0.92169687 -0.20993804]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5646
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.02458393  0.9533553  -0.30084764]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5628
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.4964535   0.86693596 -0.04422635]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.96603812  0.14016909  0.21707829]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.5732
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.96974931  0.14861353  0.19364994]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running experiment 38/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 0), (1, 3), (2, 2), (5, None)], 5), ([(0, 3), (1, 0), (1, 3), (2, 1), (5, None)], 4), ([(0, 2), (0, 2), (0, 1), (3, 3), (0, 3), (1, 2), (0, 3), (0, 2), (0, 2), (0, 1)], 0), ([(0, 2), (3, 3), (4, 2), (1, 0), (1, 2), (0, 1), (0, 0), (0, 1), (0, 2), (0, 0)], 0), ([(0, 3), (1, 0), (0, 2), (0, 0), (0, 3), (1, 1), (4, 3), (5, None)], 7), ([(0, 2), (0, 3), (1, 0), (1, 3), (2, 0), (2, 1), (5, None)], 6)]

Running EBIRL with 1 demonstrations for experiment 38
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.38159422  0.69615286 -0.60807651]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 38
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.38021996  0.83457826 -0.39863757]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.5980
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.12780603  0.7645757  -0.6317354 ]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.5992
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.42512549  0.90031521 -0.09327834]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.5986
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.23489594 0.95678597 0.17141906]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6034
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.17781857 0.88283678 0.43471804]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 39/50...
Shuffled Demos: [([(0, 0), (0, 1), (1, 2), (0, 3), (1, 2), (0, 3), (1, 1), (4, 2), (3, 3), (4, 3)], 0), ([(0, 0), (0, 2), (0, 1), (3, 3), (0, 3), (1, 2), (0, 3), (1, 0), (1, 2), (0, 0)], 0), ([(0, 2), (0, 0), (1, 0), (0, 0), (0, 2), (3, 0), (4, 3), (5, None)], 7), ([(0, 1), (3, 1), (3, 1), (3, 0), (4, 1), (4, 1), (5, None)], 6), ([(0, 0), (0, 0), (0, 0), (0, 3), (3, 2), (0, 3), (1, 0), (1, 2), (1, 2), (0, 0)], 0), ([(0, 3), (1, 1), (4, 1), (4, 0), (1, 3), (2, 2), (1, 1), (4, 0), (1, 1), (4, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.10631777  0.06862618  0.99196118]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6084
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.16825468 0.95581223 0.24106709]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5964
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.17975753  0.94322484  0.2793101 ]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6138
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.26255666 0.88765373 0.37833168]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6018
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.37866829  0.92458682  0.04182761]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.5994
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.22153222  0.81499435  0.53545091]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running experiment 40/50...
Shuffled Demos: [([(0, 1), (3, 2), (3, 0), (0, 1), (3, 3), (4, 1), (4, 1), (4, 2), (1, 2), (0, 0)], 0), ([(0, 0), (0, 3), (3, 2), (3, 1), (3, 0), (0, 3), (1, 0), (1, 0), (1, 2), (0, 2)], 0), ([(0, 2), (3, 3), (4, 0), (1, 0), (1, 2), (4, 1), (4, 2), (3, 0), (0, 0), (0, 3)], 0), ([(0, 1), (1, 2), (0, 2), (0, 2), (0, 2), (0, 1), (3, 3), (4, 2), (3, 0), (0, 2)], 0), ([(0, 0), (0, 0), (0, 1), (3, 3), (0, 1), (3, 1), (3, 2), (3, 3), (4, 1), (4, 2)], 0), ([(0, 0), (0, 2), (0, 2), (0, 2), (0, 2), (0, 3), (1, 1), (4, 0), (3, 0), (3, 0)], 0)]

Running EBIRL with 1 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5878
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.08828451  0.52512463 -0.84643368]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6008
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.07580245 0.56748546 0.81988672]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.08210491 0.56682136 0.81973918]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6040
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.79629028 -0.13802728 -0.58895693]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6038
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.35350054  0.93462671 -0.03886233]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6004
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.24126559  0.86787597  0.43426055]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 41/50...
Shuffled Demos: [([(0, 1), (3, 2), (3, 3), (4, 2), (1, 2), (4, 1), (4, 1), (4, 2), (3, 1), (3, 1)], 0), ([(0, 3), (0, 0), (0, 3), (1, 1), (4, 0), (5, None)], 5), ([(0, 0), (0, 1), (3, 0), (0, 3), (1, 1), (4, 0), (1, 0), (1, 1), (4, 2), (4, 0)], 0), ([(0, 3), (1, 2), (0, 0), (0, 3), (1, 2), (0, 1), (3, 0), (0, 1), (3, 1), (3, 1)], 0), ([(0, 3), (1, 3), (4, 2), (3, 0), (4, 2), (3, 1), (3, 2), (3, 0), (3, 3), (4, 0)], 0), ([(0, 1), (0, 1), (3, 0), (0, 0), (0, 1), (3, 0), (0, 1), (3, 3), (4, 0), (1, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5994
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.01061033  0.96392729 -0.26595414]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.11064399  0.81095803 -0.57454763]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5974
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [ 0.0406689   0.78389117 -0.6195649 ]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6110
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.29637646  0.72112002 -0.62621635]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5960
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.374523    0.69862544 -0.60963515]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.5962
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.60557235  0.47141804 -0.64112959]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running experiment 42/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 2), (3, 1), (3, 3), (4, 0), (1, 1), (2, 0), (2, 1), (5, None)], 9), ([(0, 1), (3, 1), (4, 2), (3, 1), (3, 2), (3, 3), (4, 1), (4, 1), (5, None)], 8), ([(0, 2), (0, 3), (1, 1), (0, 0), (0, 3), (1, 2), (0, 2), (3, 1), (3, 2), (3, 3)], 0), ([(0, 1), (3, 2), (3, 1), (3, 2), (3, 1), (3, 3), (4, 2), (3, 0), (3, 1), (3, 0)], 0), ([(0, 1), (3, 3), (4, 3), (4, 2), (3, 3), (4, 0), (1, 0), (2, 1), (5, None)], 8), ([(0, 0), (0, 0), (0, 1), (0, 1), (3, 2), (3, 0), (0, 3), (3, 2), (0, 1), (3, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 42
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.27807026  0.94003658  0.19750483]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 42
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.52467088 -0.83018289 -0.18845911]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6048
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.53341774 0.83755396 0.11819001]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6018
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.05215184 0.9160008  0.3977722 ]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5994
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.14478669  0.98832905 -0.04735504]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.5940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.56521147 0.82250924 0.06336041]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 43/50...
Shuffled Demos: [([(0, 2), (0, 3), (1, 1), (4, 1), (5, None)], 0), ([(0, 0), (0, 3), (1, 0), (0, 0), (0, 0), (0, 0), (1, 1), (4, 1), (4, 3), (5, None)], 0), ([(0, 3), (1, 0), (2, 3), (5, None)], 0), ([(0, 3), (3, 1), (3, 1), (3, 3), (4, 2), (3, 1), (3, 3), (3, 2), (3, 1), (3, 3)], 0), ([(0, 0), (0, 3), (1, 0), (0, 1), (1, 1), (4, 3), (5, None)], 0), ([(0, 3), (1, 1), (4, 0), (1, 1), (4, 1), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6082
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.74622251  0.36726224 -0.55522105]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5860
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.21719954 0.86885183 0.44488297]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.9580046  -0.27552255  0.07946393]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5920
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [ 0.29459453  0.93886463 -0.17817765]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5724
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.37251396  0.91775757 -0.137675  ]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.5888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.32134544  0.92059977 -0.2218855 ]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running experiment 44/50...
Shuffled Demos: [([(0, 1), (0, 3), (1, 0), (1, 2), (0, 3), (1, 1), (4, 1), (4, 3), (5, None)], 0), ([(0, 0), (0, 3), (3, 2), (3, 1), (3, 0), (4, 3), (5, None)], 6), ([(0, 0), (0, 0), (0, 1), (3, 2), (3, 3), (4, 3), (4, 0), (1, 0), (1, 0), (1, 2)], 0), ([(0, 1), (3, 0), (3, 3), (4, 0), (1, 1), (4, 1), (4, 1), (4, 2), (4, 1), (4, 1)], 0), ([(0, 2), (0, 1), (0, 3), (1, 3), (2, 1), (5, None)], 5), ([(0, 3), (1, 0), (0, 0), (0, 3), (1, 3), (2, 1), (5, None)], 0)]

Running EBIRL with 1 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.12977207 0.57234186 0.80968142]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.01565738  0.99837423  0.05480648]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5692
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.14157799  0.94496808 -0.29494236]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5804
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.36178699  0.90927242 -0.2057519 ]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5712
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.21130035  0.88171483  0.42181882]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.5654
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.21535297  0.96011473 -0.17833338]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 45/50...
Shuffled Demos: [([(0, 2), (0, 1), (1, 2), (4, 2), (3, 0), (0, 1), (3, 1), (3, 2), (3, 3), (4, 2)], 0), ([(0, 3), (0, 0), (0, 3), (1, 0), (1, 2), (0, 0), (0, 2), (0, 0), (0, 2), (0, 1)], 0), ([(0, 0), (0, 2), (0, 2), (0, 0), (0, 0), (0, 3), (3, 2), (3, 1), (3, 3), (3, 0)], 1), ([(0, 1), (3, 1), (3, 2), (3, 0), (0, 3), (1, 0), (1, 3), (1, 0), (1, 0), (1, 3)], 0), ([(0, 0), (0, 0), (0, 3), (1, 2), (1, 2), (0, 1), (3, 2), (3, 3), (4, 1), (4, 3)], 0), ([(0, 1), (3, 1), (3, 2), (3, 1), (3, 1), (3, 2), (3, 1), (4, 3), (5, None)], 8)]

Running EBIRL with 1 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.87256081  0.37766201 -0.30985327]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5998
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.78285493  0.2024526   0.58834607]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6076
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.21327257 0.89372502 0.39467759]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5944
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.56117971  0.82196421 -0.09722228]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5928
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.15539333  0.96460874 -0.21303262]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.5884
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.63744057  0.72469655 -0.26169531]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running experiment 46/50...
Shuffled Demos: [([(0, 2), (0, 0), (0, 1), (3, 1), (3, 0), (0, 1), (3, 2), (3, 1), (3, 2), (3, 1)], 2), ([(0, 1), (0, 0), (0, 3), (1, 3), (1, 0), (1, 0), (0, 0), (0, 1), (3, 1), (3, 3)], 0), ([(0, 1), (3, 0), (0, 0), (0, 3), (0, 0), (0, 0), (0, 0), (0, 2), (0, 2), (0, 3)], 2), ([(0, 3), (1, 3), (2, 0), (2, 2), (1, 2), (1, 3), (4, 1), (4, 2), (4, 2), (4, 2)], 0), ([(0, 3), (0, 2), (0, 0), (0, 1), (3, 3), (4, 1), (4, 2), (3, 3), (4, 3), (5, None)], 9), ([(0, 1), (0, 3), (1, 2), (0, 3), (1, 1), (4, 0), (1, 0), (1, 2), (0, 2), (0, 3)], 0)]

Running EBIRL with 1 demonstrations for experiment 46
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.28021774 -0.88545036 -0.37075017]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5948
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.45684259  0.85383572  0.24951838]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6012
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.08529382  0.8219162  -0.56318623]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6042
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.24437155  0.84779564 -0.47066453]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6006
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.56453995  0.82504569  0.0243773 ]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.5920
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.06789417  0.98976617 -0.12551216]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 47/50...
Shuffled Demos: [([(0, 3), (1, 2), (1, 1), (4, 1), (4, 2), (3, 0), (0, 2), (0, 0), (0, 2), (0, 1)], 0), ([(0, 2), (0, 1), (1, 0), (1, 0), (1, 3), (2, 0), (2, 1), (5, None)], 0), ([(0, 3), (0, 1), (3, 0), (0, 2), (0, 1), (3, 2), (3, 3), (4, 3), (5, None)], 8), ([(0, 1), (3, 2), (3, 1), (3, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1)], 0), ([(0, 0), (0, 1), (3, 0), (0, 1), (3, 1), (3, 1), (3, 3), (0, 2), (0, 3), (1, 3)], 0), ([(0, 3), (1, 2), (4, 0), (5, None)], 3)]

Running EBIRL with 1 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.53998576 -0.12780262 -0.83191458]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5742
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.43933719 0.89811976 0.01907174]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5756
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.02820264  0.89182815  0.45149437]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5816
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.38867284  0.87838146  0.27817157]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5846
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.1988275   0.83394289 -0.51478819]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.5782
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [ 0.13252139  0.93939229 -0.31619648]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running experiment 48/50...
Shuffled Demos: [([(0, 0), (0, 1), (3, 2), (3, 1), (3, 0), (0, 2), (0, 3), (3, 2), (3, 1), (3, 1)], 0), ([(0, 2), (0, 2), (3, 1), (3, 2), (3, 0), (0, 3), (1, 2), (0, 2), (0, 3), (3, 2)], 0), ([(0, 1), (0, 1), (3, 3), (4, 3), (5, None)], 4), ([(0, 1), (3, 1), (3, 3), (4, 3), (4, 0), (5, None)], 5), ([(0, 0), (0, 2), (0, 0), (0, 2), (0, 2), (0, 1), (1, 1), (4, 3), (1, 0), (1, 1)], 0), ([(0, 0), (0, 0), (0, 2), (0, 3), (1, 0), (1, 0), (1, 3), (1, 2), (1, 3), (2, 2)], 0)]

Running EBIRL with 1 demonstrations for experiment 48
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.1002285  0.99085864 0.09029621]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6112
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.52706129  0.84911597  0.03476295]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6022
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.35668474  0.88476404  0.29994765]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5984
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.45692704  0.82172624  0.34056374]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5964
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [-0.1280374   0.90076957 -0.41499471]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.5992
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.35267341 0.84249257 0.40721951]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 49/50...
Shuffled Demos: [([(0, 1), (3, 0), (0, 1), (1, 3), (4, 3), (5, None)], 0), ([(0, 2), (3, 1), (3, 1), (3, 3), (0, 3), (1, 3), (2, 3), (2, 2), (1, 0), (1, 3)], 0), ([(0, 1), (3, 1), (3, 0), (0, 0), (0, 1), (3, 2), (3, 0), (0, 3), (1, 2), (0, 1)], 0), ([(0, 3), (1, 3), (2, 3), (2, 2), (2, 0), (2, 0), (2, 3), (2, 3), (2, 2), (1, 3)], 0), ([(0, 3), (1, 2), (1, 0), (1, 3), (2, 1), (5, None)], 0), ([(0, 3), (1, 2), (1, 1), (4, 2), (3, 2), (3, 3), (4, 0), (1, 2), (0, 3), (1, 1)], 0)]

Running EBIRL with 1 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6100
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.50375646  0.36335272 -0.78371182]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5438
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.67452684  0.36962527  0.63905453]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5490
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.99398485  0.10368313  0.03526946]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5510
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [-0.11072475  0.23260855 -0.96624701]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5326
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [ 0.00529777  0.36608672 -0.93056566]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.5476
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [-0.88758628  0.44616346  0.11458081]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running experiment 50/50...
Shuffled Demos: [([(0, 0), (0, 2), (0, 2), (0, 3), (1, 3), (2, 1), (5, None)], 6), ([(0, 3), (1, 3), (4, 3), (5, None)], 3), ([(0, 1), (3, 2), (3, 3), (4, 2), (3, 2), (0, 3), (1, 3), (2, 1), (5, None)], 8), ([(0, 3), (1, 1), (4, 0), (1, 2), (0, 2), (0, 2), (0, 1), (3, 0), (0, 0), (0, 1)], 0), ([(0, 1), (3, 2), (3, 2), (3, 1), (3, 0), (4, 3), (5, None)], 6), ([(0, 3), (1, 2), (0, 3), (1, 3), (2, 1), (2, 1), (5, None)], 6)]

Running EBIRL with 1 demonstrations for experiment 50
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [0.18923674 0.93901204 0.28713385]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 2 demonstrations for experiment 50
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.09252233 0.96565724 0.2427874 ]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 3 demonstrations for experiment 50
MCMC completed with acceptance ratio: 1.0000
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.28119019 -0.9255145  -0.25368287]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 4 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6002
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 4
MAP Solution: [0.08141189 0.98236832 0.16829912]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 5 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6010
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 5
MAP Solution: [0.06242881 0.98354815 0.169516  ]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running EBIRL with 6 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6026
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 6
MAP Solution: [0.18059493 0.93924312 0.29190379]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.
