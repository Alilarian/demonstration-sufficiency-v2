Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6264
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.839361    0.13717412  0.52598134]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6200
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.75688917 -0.2044339   0.62074597]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2786
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94963558 -0.31309569  0.01278076]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.9504451   0.09794076 -0.29506222]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6176
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.98316802  0.05800318 -0.17325206]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6146
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.15301031  0.96699802 -0.20372204]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2806
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.78552569 -0.19604301  0.5869553 ]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2794
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.23034813  0.34424732  0.91018323]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6290
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.02964666  0.9995583  -0.00206816]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2752
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.67465941 -0.23311043  0.70035292]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2824
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.02642662  0.36351081  0.93121508]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6230
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.95112038 -0.09919273  0.29245653]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.63807652 -0.24505653  0.72993537]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2762
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.66198007 -0.23482802  0.71178521]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6348
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.73853622 -0.21191566  0.64004376]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6158
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9834445   0.0587002  -0.17143865]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.9475734  -0.10398469  0.30214539]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.21812791 -0.30803114  0.92603295]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2902
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.8832228  -0.46894301 -0.0031532 ]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2846
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.95661887 -0.16024508  0.2433143 ]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running experiment 4/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6154
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.19379712 -0.31016713  0.93071963]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2822
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.85248728 -0.16826903  0.49492522]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2792
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.65430917  0.07745563  0.75225005]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6158
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.72179747 -0.21891211  0.65657132]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2944
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.87090179 -0.32279661  0.37058389]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2692
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94832925 -0.1024033   0.3003085 ]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6332
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99813024 -0.01689125  0.05874279]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6182
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.06227059  0.31464163 -0.94716578]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2802
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.92782095 -0.11563492  0.35465033]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6236
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94853881  0.10085735 -0.30016982]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6242
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99336548  0.03639636 -0.10908866]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6254
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.62218162  0.51228398 -0.59199253]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2852
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.73765108 -0.21427903  0.64027758]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2890
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.65649585 -0.23814279  0.7157522 ]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6284
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.52220483 -0.26688629  0.80998384]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2834
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89731175  0.06826886  0.43608598]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.75320291 -0.38308662  0.53472424]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6092
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.07243965 -0.31825136  0.94523466]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2890
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.56888051  0.08458639  0.81805875]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.85184996 -0.16451352  0.49727955]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6322
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99792754 -0.02066382  0.06093961]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.44773724  0.44786086  0.7739199 ]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2886
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.81947694 -0.18087856  0.54382028]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6248
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.82610304 -0.17810573  0.53463269]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6076
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.70181672  0.22534801 -0.67577479]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2740
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.45882252  0.09831873  0.88307153]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6194
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.34534872 -0.29464978  0.89101951]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.71119808 -0.19053543  0.67667831]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.75893862 -0.08008767  0.64621834]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Config file loaded successfully.
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6272
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.67599368 -0.23401881  0.69876158]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2860
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88873186 -0.14529629  0.43479268]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2858
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.96137152 -0.15789953  0.22546074]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6322
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.21561676 -0.31017442  0.92590563]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2798
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.6850821  -0.22901451  0.69153081]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2808
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.95252026 -0.29960919  0.054217  ]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6166
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.97995347  0.06151676 -0.18949112]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2770
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.81017487 -0.1881419   0.55517503]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2750
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.86058729 -0.16164778  0.48296946]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running experiment 4/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6218
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.28071112  0.30476871 -0.91011939]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92549512  0.11929567 -0.35948203]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2786
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.60718541  0.29460577  0.73792501]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6180
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.33357017 -0.29789278  0.89442206]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2786
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [0.10790966 0.50115937 0.85860048]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2826
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.77377106 -0.20146853  0.6005737 ]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running experiment 6/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6180
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99851181 -0.01656306  0.05195983]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2824
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.39649086  0.40564196  0.8235591 ]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2924
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.95548749 -0.09285797  0.28003759]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6342
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.89911946  0.13988857 -0.41474737]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6186
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.15765768  0.74537866 -0.64773043]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2888
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.52671669  0.11714862  0.84192976]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running experiment 8/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6318
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.9991483  -0.01198769  0.03948368]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2842
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.78441078 -0.19770614  0.58788776]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2810
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.06627547  0.44231545  0.8944074 ]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6156
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.51630614 -0.1002866  -0.85051195]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6230
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.79102894  0.19466762 -0.57998081]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.2750
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.85605292 -0.16056565  0.49131668]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running experiment 10/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6110
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.88666411  0.1444699  -0.43926666]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2814
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92791188 -0.11683545  0.3540184 ]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.77512777 -0.19728131  0.60021415]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6246
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98394059  0.05820684 -0.16873911]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2752
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.74615476 -0.21104935  0.63143586]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2770
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.95199249 -0.30462692  0.03021153]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running experiment 12/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.87738559 -0.15467462  0.45416988]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2754
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92578997 -0.12219948  0.35774324]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2768
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.87764478  0.08922518  0.47093366]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6322
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.8732942  -0.15333709  0.46243376]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.2798
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.90735272 -0.10069593  0.40813156]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.2880
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.51995446  0.41205099  0.74823883]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running experiment 14/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6236
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.05993401  0.31404601 -0.94751412]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2874
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.9044173  -0.13268805  0.40549133]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.91786668 -0.12401449  0.37701612]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6150
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99963912 -0.00842152  0.02550905]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6166
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.22704811  0.89472327 -0.38460296]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.2854
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.72055536 -0.22037638  0.65744522]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running experiment 16/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6170
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.8086198  -0.51515367  0.28416669]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.83415183 -0.17522319  0.52296038]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2852
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.856065   -0.26198921  0.44554952]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6238
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.65654698  0.24086468 -0.71479386]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6142
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89375703 -0.2450121  -0.37572255]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.2812
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89420219 -0.39686512  0.20712443]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running experiment 18/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6206
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.9751667   0.16590005  0.14672107]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.2794
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.84953162 -0.16389269  0.50143316]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.2732
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83916927 -0.37704732  0.39195695]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6310
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.57248053  0.25986498 -0.77764789]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.2918
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.75228504 -0.2094732   0.62465046]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.2806
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83424067 -0.16484209  0.52618399]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running experiment 20/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6270
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.51078513  0.2743643  -0.8147532 ]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2898
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.86137074 -0.16259459  0.48125196]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2918
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.73762438 -0.21524564  0.63998405]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6228
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99993333 -0.00117558  0.01148751]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6122
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.96064116  0.08924701 -0.26306565]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.2804
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.91299413 -0.40796387 -0.00268472]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running experiment 22/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6250
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.85768149 -0.16146906  0.48817026]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.87713042 -0.33757181  0.34159552]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2874
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.76385257 -0.2011517   0.61324321]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6278
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.45734785  0.28042823 -0.84391525]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.2804
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.76860306  0.07916335  0.63480902]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.2950
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89421609 -0.14127473  0.42475762]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running experiment 24/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6208
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.85110771  0.16404959 -0.49870171]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 24
Config file loaded successfully.
Feature weights for environment: [-0.97266673 -0.03083248  0.23014951]
Feature weights for environment: [-0.35835056 -0.08647525  0.92957351]
Feature weights for environment: [-0.71046942 -0.64188771  0.28846728]
Feature weights for environment: [-0.89578956 -0.24432685  0.37130237]
Feature weights for environment: [-0.7282924  -0.22722733  0.64649665]
Feature weights for environment: [-0.75022399 -0.57596895  0.32469021]
Feature weights for environment: [-0.70842322 -0.26108332  0.65572254]
Feature weights for environment: [-0.74635145 -0.57484795  0.33542412]
Feature weights for environment: [-0.0505111  -0.01531811  0.99860602]
Feature weights for environment: [-0.76518493 -0.64328377  0.02603879]
Feature weights for environment: [-0.87829137 -0.24439244  0.41094598]
Feature weights for environment: [-0.8497926  -0.50850291  0.13884283]
Feature weights for environment: [-0.34477193 -0.32328333  0.88126058]
Feature weights for environment: [-0.43088031 -0.17122291  0.88601629]
Feature weights for environment: [-0.75433776 -0.02805593  0.65588674]
Feature weights for environment: [-0.92032338 -0.11683579  0.37330186]
Feature weights for environment: [-0.76208548 -0.28664819  0.58056743]
Feature weights for environment: [-0.39174849 -0.30341429  0.86860399]
Feature weights for environment: [-0.92648321 -0.16748955  0.33701054]
Feature weights for environment: [-0.61012931 -0.3129562   0.72787406]
Feature weights for environment: [-0.3738588  -0.3262014   0.86822937]
Feature weights for environment: [-0.70965126 -0.6051058   0.36089066]
Feature weights for environment: [-0.74528522 -0.55533186  0.36899385]
Feature weights for environment: [-0.68144434 -0.29187893  0.6711485 ]
Feature weights for environment: [-0.44714936 -0.30119858  0.84222139]
Feature weights for environment: [-0.7333898  -0.47830978  0.48307263]
Feature weights for environment: [-0.65557811 -0.01374154  0.75500233]
Feature weights for environment: [-0.866301   -0.34967581  0.35672034]
Feature weights for environment: [-0.6535586  -0.23072892  0.72085041]
Feature weights for environment: [-0.81326386 -0.04441834  0.5801973 ]
Feature weights for environment: [-0.27534761 -0.19938474  0.94044108]
Feature weights for environment: [-0.90753571 -0.40234227  0.1204144 ]
Feature weights for environment: [-0.32556312 -0.30396656  0.89532842]
Feature weights for environment: [-0.839382   -0.393236    0.37523766]
Feature weights for environment: [-0.94121751 -0.05112011  0.33391067]
Feature weights for environment: [-0.05456508 -0.040557    0.99768621]
Feature weights for environment: [-0.75478167 -0.33513042  0.563908  ]
Feature weights for environment: [-0.49248773 -0.22865786  0.83974486]
Feature weights for environment: [-0.56481614 -0.46100063  0.68444222]
Feature weights for environment: [-0.6667631  -0.57474284  0.47444455]
Feature weights for environment: [-0.46247666 -0.0267168   0.88622884]
Feature weights for environment: [-0.71505276 -0.68463496  0.14133129]
Feature weights for environment: [-0.94655708 -0.29794542  0.12352418]
Feature weights for environment: [-0.88315502 -0.32822573  0.33511952]
Feature weights for environment: [-0.83381491 -0.37890594  0.40147601]
Feature weights for environment: [-0.82098277 -0.18440172  0.54035479]
Feature weights for environment: [-0.73857451 -0.23755048  0.63093381]
Feature weights for environment: [-0.95541883 -0.18852986  0.22722531]
Feature weights for environment: [-0.98484463 -0.1489005   0.08893646]
Feature weights for environment: [-0.47840873 -0.41855607  0.77196885]
Generated optimal policies for all environments.

Running experiment 1/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.6216
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.12285721  0.63914475 -0.75921017]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2772
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88233366 -0.15062588  0.44586898]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 1
MCMC completed with acceptance ratio: 0.2856
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.73554096 -0.22509547  0.63899259]
True reward weights: [-0.97266673 -0.03083248  0.23014951]
MAP Policy for current environment:

Running experiment 2/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6150
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.7945772  -0.1830761  -0.57890432]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.6290
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.96158751  0.0865639  -0.26049214]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 2
MCMC completed with acceptance ratio: 0.2860
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.69083384  0.21395472  0.69063158]
True reward weights: [-0.35835056 -0.08647525  0.92957351]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 3/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.6220
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-9.99995597e-01 -3.62689281e-04  2.94530539e-03]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2756
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.19146007  0.17641063  0.96551662]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 3
MCMC completed with acceptance ratio: 0.2790
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89206172 -0.14163353  0.42914546]
True reward weights: [-0.71046942 -0.64188771  0.28846728]
MAP Policy for current environment:

Running experiment 4/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6154
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.87089844  0.15781631 -0.4654352 ]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.6144
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.50684079  0.27532124 -0.81689083]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 4
MCMC completed with acceptance ratio: 0.2830
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89170991 -0.14586714  0.42845795]
True reward weights: [-0.89578956 -0.24432685  0.37130237]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 5/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.6356
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.06714657 -0.31719895  0.94597895]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.68463739  0.14478611  0.7143589 ]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 5
MCMC completed with acceptance ratio: 0.2814
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.71590399 -0.22054146  0.66245221]
True reward weights: [-0.7282924  -0.22722733  0.64649665]
MAP Policy for current environment:

Running experiment 6/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.6270
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.63245705 -0.24347187  0.73533634]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2828
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.71116427 -0.22233024  0.66694426]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 6
MCMC completed with acceptance ratio: 0.2914
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.31583649  0.14253618  0.93804624]
True reward weights: [-0.75022399 -0.57596895  0.32469021]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 7/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.6138
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.59866641 -0.25264523  0.76011112]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2866
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.81209784 -0.17810324  0.55567647]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 7
MCMC completed with acceptance ratio: 0.2788
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.89740695 -0.3638157   0.24959747]
True reward weights: [-0.70842322 -0.26108332  0.65572254]
MAP Policy for current environment:

Running experiment 8/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.6210
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.48559857 -0.27383269  0.83018654]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.94655086 -0.10241664  0.3058632 ]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 8
MCMC completed with acceptance ratio: 0.2822
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.68324305 -0.23068626  0.69279346]
True reward weights: [-0.74635145 -0.57484795  0.33542412]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 9/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.6180
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.38987294  0.29311981 -0.87297186]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.2792
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.92024933 -0.38784407 -0.05213593]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 9
MCMC completed with acceptance ratio: 0.2772
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.03102376  0.33774631  0.94072576]
True reward weights: [-0.0505111  -0.01531811  0.99860602]
MAP Policy for current environment:

Running experiment 10/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6160
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.70435289 -0.22643772  0.67276517]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.6202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.74017469 -0.21440344  0.63731671]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 10
MCMC completed with acceptance ratio: 0.2730
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.93451348 -0.08335283  0.34603016]
True reward weights: [-0.76518493 -0.64328377  0.02603879]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 11/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.6284
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99672844 -0.02834125  0.07569147]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2726
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.25016244  0.17535229  0.95219238]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 11
MCMC completed with acceptance ratio: 0.2830
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.80662452 -0.18633568  0.56092414]
True reward weights: [-0.87829137 -0.24439244  0.41094598]
MAP Policy for current environment:

Running experiment 12/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.6226
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.15658945  0.31269356 -0.93685777]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2794
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.77107042 -0.10954488  0.62725619]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 12
MCMC completed with acceptance ratio: 0.2896
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.82386008 -0.18001219  0.53744784]
True reward weights: [-0.8497926  -0.50850291  0.13884283]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 13/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6182
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.93985588 -0.10769217  0.32415016]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.6158
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.8861284  -0.14569365  0.43994296]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 13
MCMC completed with acceptance ratio: 0.2768
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.50673532  0.24655419  0.82609342]
True reward weights: [-0.34477193 -0.32328333  0.88126058]
MAP Policy for current environment:

Running experiment 14/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.6242
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.89419961 -0.13962509  0.42533738]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2928
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.42993343  0.22266191  0.87497367]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 14
MCMC completed with acceptance ratio: 0.2760
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.90298485 -0.17135845  0.39402367]
True reward weights: [-0.43088031 -0.17122291  0.88601629]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 15/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6280
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.92150392  0.12234774 -0.36859403]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.6202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.91203251  0.12762605 -0.38975415]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 15
MCMC completed with acceptance ratio: 0.2830
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [0.10788941 0.52460307 0.84448297]
True reward weights: [-0.75433776 -0.02805593  0.65588674]
MAP Policy for current environment:

Running experiment 16/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.6294
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.25755906  0.91649461 -0.30610613]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2922
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.86246408 -0.15762189  0.48094808]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 16
MCMC completed with acceptance ratio: 0.2826
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.57416738  0.03607189  0.81794293]
True reward weights: [-0.92032338 -0.11683579  0.37330186]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 17/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94382306  0.10369169 -0.31376116]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.6180
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.13347615  0.45365569  0.88112464]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 17
MCMC completed with acceptance ratio: 0.2838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.39556298  0.28240738  0.87394279]
True reward weights: [-0.76208548 -0.28664819  0.58056743]
MAP Policy for current environment:

Running experiment 18/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.53716523  0.49948978  0.67967895]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.6196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.86566497  0.15812362 -0.47499586]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 18
MCMC completed with acceptance ratio: 0.2816
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.71658402 -0.220015    0.66189179]
True reward weights: [-0.39174849 -0.30341429  0.86860399]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 19/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6262
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.73371406  0.21430764 -0.64477587]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.6250
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.78604732 -0.19791934  0.58562577]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 19
MCMC completed with acceptance ratio: 0.2824
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.08290843  0.24829637  0.96512958]
True reward weights: [-0.92648321 -0.16748955  0.33701054]
MAP Policy for current environment:

Running experiment 20/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.6220
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.48219618  0.2797363  -0.83020145]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2914
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.79895238 -0.19070394  0.57035699]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 20
MCMC completed with acceptance ratio: 0.2862
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.64106554  0.06807478  0.76446111]
True reward weights: [-0.61012931 -0.3129562   0.72787406]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 21/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.6162
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.18965385 -0.31073441  0.93138367]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.2774
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.93714309 -0.10970222  0.33125254]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 21
MCMC completed with acceptance ratio: 0.2820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.72836853 -0.21457203  0.65072124]
True reward weights: [-0.3738588  -0.3262014   0.86822937]
MAP Policy for current environment:

Running experiment 22/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.84961285  0.16718596 -0.50020682]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.6256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.79525254 -0.19366334  0.57451536]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 22
MCMC completed with acceptance ratio: 0.2762
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.47997589  0.42655698  0.76659787]
True reward weights: [-0.70965126 -0.6051058   0.36089066]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 23/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.96542103 -0.20945215  0.15521606]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.2828
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.84901939 -0.16863451  0.50072794]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 23
MCMC completed with acceptance ratio: 0.2756
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.57527728  0.26486605  0.77388761]
True reward weights: [-0.74528522 -0.55533186  0.36899385]
MAP Policy for current environment:

Running experiment 24/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6330
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98201274  0.05681707 -0.18006332]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.6228
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.79363726 -0.19017884  0.57790303]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 24
MCMC completed with acceptance ratio: 0.2666
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.73918341 -0.21072372  0.63969008]
True reward weights: [-0.68144434 -0.29187893  0.6711485 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 25/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.6266
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.73940237 -0.21228784  0.63891941]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.2892
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.90850166 -0.22910589  0.3494785 ]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 25
MCMC completed with acceptance ratio: 0.2730
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.88484585 -0.14767107  0.44186093]
True reward weights: [-0.44714936 -0.30119858  0.84222139]
MAP Policy for current environment:

Running experiment 26/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6282
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99157357 -0.03977823  0.12328641]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.6260
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.83259849  0.17625743 -0.52508387]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 26
MCMC completed with acceptance ratio: 0.2870
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.66118847 -0.2364958   0.71196878]
True reward weights: [-0.7333898  -0.47830978  0.48307263]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 27/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6134
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.40753516  0.77439568 -0.48396944]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.6078
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.49795886  0.27185428 -0.82348784]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 27
MCMC completed with acceptance ratio: 0.2798
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94545095 -0.10047996  0.30988107]
True reward weights: [-0.65557811 -0.01374154  0.75500233]
MAP Policy for current environment:

Running experiment 28/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6140
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.94240326 -0.10747843  0.31674039]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.6086
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.33230807  0.29645523 -0.895369  ]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 28
MCMC completed with acceptance ratio: 0.2924
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.84682193 -0.52202226 -0.10190868]
True reward weights: [-0.866301   -0.34967581  0.35672034]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 29/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.6384
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.92199323 -0.11974871  0.36822374]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.2838
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.7890061  -0.19623931  0.58220229]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 29
MCMC completed with acceptance ratio: 0.2988
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.85934901  0.14725233  0.48973057]
True reward weights: [-0.6535586  -0.23072892  0.72085041]
MAP Policy for current environment:

Running experiment 30/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.6240
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.07128711  0.31440253 -0.94660931]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.2820
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89177649  0.06270302  0.44811051]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 30
MCMC completed with acceptance ratio: 0.2932
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.66130132 -0.23885722  0.7110751 ]
True reward weights: [-0.81326386 -0.04441834  0.5801973 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 31/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.6164
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98933881  0.04450679 -0.13866458]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.2804
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.82431137  0.04889302  0.56402148]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 31
MCMC completed with acceptance ratio: 0.2936
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.91960372 -0.12623905  0.37201169]
True reward weights: [-0.27534761 -0.19938474  0.94044108]
MAP Policy for current environment:

Running experiment 32/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.6308
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.98306891  0.0558979  -0.17450199]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.2894
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.2034004   0.14638894  0.96809016]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 32
MCMC completed with acceptance ratio: 0.2802
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.46213208 -0.09805593  0.88137335]
True reward weights: [-0.90753571 -0.40234227  0.1204144 ]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 33/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.6256
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.67270519  0.23381841 -0.70199479]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.2738
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.78240297  0.13804581  0.60727995]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 33
MCMC completed with acceptance ratio: 0.2724
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.65835233  0.17933534  0.73103423]
True reward weights: [-0.32556312 -0.30396656  0.89532842]
MAP Policy for current environment:

Running experiment 34/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6172
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.85850426  0.16013739 -0.48716163]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.6176
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.2175108   0.86421914 -0.45366763]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 34
MCMC completed with acceptance ratio: 0.2832
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.81985333 -0.18279137  0.54261204]
True reward weights: [-0.839382   -0.393236    0.37523766]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 35/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.6236
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.92878523 -0.11469546  0.35242437]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.2828
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.89069975 -0.14520161  0.43077889]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 35
MCMC completed with acceptance ratio: 0.2682
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.65883285 -0.23543094  0.71450091]
True reward weights: [-0.94121751 -0.05112011  0.33391067]
MAP Policy for current environment:

Running experiment 36/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6130
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.73520684 -0.21287757  0.64354801]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.6184
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.99283652  0.04041758 -0.11243695]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 36
MCMC completed with acceptance ratio: 0.2784
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.87047052 -0.31412688  0.37895299]
True reward weights: [-0.05456508 -0.040557    0.99768621]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 37/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6272
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.93569068 -0.11034115  0.33512352]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.6348
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.79966278  0.18715245 -0.57053782]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 37
MCMC completed with acceptance ratio: 0.2866
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.81036608 -0.22413734  0.54135872]
True reward weights: [-0.75478167 -0.33513042  0.563908  ]
MAP Policy for current environment:

Running experiment 38/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6142
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.91712648 -0.12314395  0.37909706]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.6100
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.20086538  0.84166822 -0.50124616]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 38
MCMC completed with acceptance ratio: 0.2728
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.04386511  0.38841415  0.92044027]
True reward weights: [-0.49248773 -0.22865786  0.83974486]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 39/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.6116
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.34384066 -0.29896224  0.89016581]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2948
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.67389187 -0.23330088  0.70102814]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 39
MCMC completed with acceptance ratio: 0.2704
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.39637558  0.36773578  0.84122339]
True reward weights: [-0.56481614 -0.46100063  0.68444222]
MAP Policy for current environment:

Running experiment 40/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.6198
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.8434112   0.17146227 -0.50917407]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.2788
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.43908193  0.10122147  0.89272687]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 40
MCMC completed with acceptance ratio: 0.2776
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.92400287 -0.35994912  0.12905551]
True reward weights: [-0.6667631  -0.57474284  0.47444455]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 41/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6288
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.95008295 -0.09783267  0.29626199]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.6188
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [ 0.47065365  0.81240148 -0.34422228]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 41
MCMC completed with acceptance ratio: 0.2786
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.83430777 -0.17293926  0.52347164]
True reward weights: [-0.46247666 -0.0267168   0.88622884]
MAP Policy for current environment:

Running experiment 42/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6316
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.74391034 -0.10121844  0.66056963]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.6222
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.29271965  0.29948406 -0.90808838]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 42
MCMC completed with acceptance ratio: 0.2872
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.47320339  0.10881686  0.87420675]
True reward weights: [-0.71505276 -0.68463496  0.14133129]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 43/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6242
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.2774153   0.668693   -0.68984811]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.6202
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.97402528 -0.07158835  0.21482518]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 43
MCMC completed with acceptance ratio: 0.2822
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.94800784 -0.09989228  0.30216331]
True reward weights: [-0.94655708 -0.29794542  0.12352418]
MAP Policy for current environment:

Running experiment 44/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)])]

Running PBIRL with 1 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6314
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.76384072  0.20351982 -0.61247615]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.6150
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.96958605 -0.07706017  0.23230285]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 44
MCMC completed with acceptance ratio: 0.2940
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.86896033 -0.15349976  0.47047398]
True reward weights: [-0.88315502 -0.32822573  0.33511952]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 45/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.6196
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.92803937  0.11987508 -0.35266542]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.2732
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.88027575 -0.14962319  0.45025271]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 45
MCMC completed with acceptance ratio: 0.2788
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.7990816  -0.43495783  0.41506661]
True reward weights: [-0.83381491 -0.37890594  0.40147601]
MAP Policy for current environment:

Running experiment 46/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.6192
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.59272043 -0.25174395  0.76505391]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.2826
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.69032428 -0.23017213  0.68591047]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 46
MCMC completed with acceptance ratio: 0.2868
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.62769337 -0.18303704  0.75663629]
True reward weights: [-0.82098277 -0.18440172  0.54035479]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 47/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.6270
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [ 0.93260543 -0.11402576  0.34241091]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.2738
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.93119477 -0.36060899  0.05326782]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 47
MCMC completed with acceptance ratio: 0.2778
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.76399005 -0.20150778  0.61295499]
True reward weights: [-0.73857451 -0.23755048  0.63093381]
MAP Policy for current environment:

Running experiment 48/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.6252
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.57222931  0.78738116 -0.22931316]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.2798
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.51258236 -0.09099169  0.85380316]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 48
MCMC completed with acceptance ratio: 0.2836
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.74339452  0.18531663  0.64266814]
True reward weights: [-0.95541883 -0.18852986  0.22722531]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.

Running experiment 49/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.6246
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-0.99287253  0.03683575 -0.11334575]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.2758
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.93658628 -0.10843351  0.33323912]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 49
MCMC completed with acceptance ratio: 0.2790
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.85043203 -0.16636859  0.49908602]
True reward weights: [-0.98484463 -0.1489005   0.08893646]
MAP Policy for current environment:

Running experiment 50/50...
Shuffled Demos: [([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 1), (4, 3), (5, None)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 1), (3, 0), (0, 1), (3, 0)]), ([(0, 1), (3, 3), (4, 3), (5, None)], [(0, 3), (1, 3), (2, 1), (5, None)])]

Running PBIRL with 1 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.6200
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 1
MAP Solution: [-9.99967320e-01 -2.76525743e-04  8.07970670e-03]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 2 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.2910
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 2
MAP Solution: [-0.90762494 -0.13324207  0.39807477]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Running PBIRL with 3 demonstrations for experiment 50
MCMC completed with acceptance ratio: 0.2840
Using 3250 samples after burn-in.
Stored 3250 MCMC samples for demonstration 3
MAP Solution: [-0.80530733 -0.18820227  0.56219215]
True reward weights: [-0.47840873 -0.41855607  0.77196885]
MAP Policy for current environment:

Saving results to files...
Results saved successfully.
